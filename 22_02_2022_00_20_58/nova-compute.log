Build Started 22_02_2022_00_20_58
2022-02-22 02:23:32.361 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 02:23:36.400 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 02:23:37.313 7 INFO nova.virt.driver [req-a0b91895-2b35-4e2d-a564-9781d1e772ea - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 02:23:37.699 7 INFO nova.compute.provider_config [req-a0b91895-2b35-4e2d-a564-9781d1e772ea - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 02:23:37.718 7 WARNING oslo_config.cfg [req-a0b91895-2b35-4e2d-a564-9781d1e772ea - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 02:23:37.739 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 02:23:37.752 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 02:23:37.788 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 02:23:37.885 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 02:23:37.901 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 02:23:37.903 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 02:23:38.437 7 INFO oslo.privsep.daemon [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'vif_plug_ovs.privsep.vif_plug', '--privsep_sock_path', '/tmp/tmp0zy7xp03/privsep.sock']
2022-02-22 02:23:40.065 7 INFO oslo.privsep.daemon [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] Spawned new privsep daemon via rootwrap
2022-02-22 02:23:39.911 47 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 02:23:39.917 47 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 02:23:39.923 47 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_NET_ADMIN/CAP_NET_ADMIN/none
2022-02-22 02:23:39.923 47 INFO oslo.privsep.daemon [-] privsep daemon running as pid 47
2022-02-22 02:23:40.662 7 INFO os_vif [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] Successfully plugged vif VIFBridge(active=True,address=fa:16:3e:00:d0:99,bridge_name='qbr539065bc-08',has_traffic_filtering=True,id=539065bc-0833-4e54-8624-eae196001950,network=Network(12ed2370-270f-4860-bc3c-5150df8fd894),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tap539065bc-08')
2022-02-22 02:23:40.667 7 INFO nova.compute.manager [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 02:23:40.800 7 INFO nova.service [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] Updating service version for nova-compute on rack08-server63 from 60 to 61
2022-02-22 02:23:42.692 7 INFO nova.virt.libvirt.host [req-76560d7a-d59a-404f-b176-0a7d22794573 - - - - -] kernel doesn't support AMD SEV
2022-02-22 02:24:28.464 7 INFO nova.compute.manager [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Terminating instance
2022-02-22 02:24:28.687 7 INFO nova.virt.libvirt.driver [-] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Instance destroyed successfully.
2022-02-22 02:24:29.049 7 INFO os_vif [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] Successfully unplugged vif VIFBridge(active=True,address=fa:16:3e:00:d0:99,bridge_name='qbr539065bc-08',has_traffic_filtering=True,id=539065bc-0833-4e54-8624-eae196001950,network=Network(12ed2370-270f-4860-bc3c-5150df8fd894),plugin='ovs',port_profile=VIFPortProfileOpenVSwitch,preserve_on_delete=False,vif_name='tap539065bc-08')
2022-02-22 02:24:29.055 7 INFO os_brick.initiator.connectors.lightos [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 08d1d372-13b0-4d28-9024-06be9b0dbfe3
2022-02-22 02:24:29.057 7 INFO oslo.privsep.daemon [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp4mx7i7_w/privsep.sock']
2022-02-22 02:24:29.723 7 INFO oslo.privsep.daemon [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] Spawned new privsep daemon via rootwrap
2022-02-22 02:24:29.635 82 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 02:24:29.642 82 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 02:24:29.648 82 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 02:24:29.648 82 INFO oslo.privsep.daemon [-] privsep daemon running as pid 82
2022-02-22 02:24:30.063 7 INFO nova.virt.libvirt.driver [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Deleting instance files /var/lib/nova/instances/828a97cc-80b1-4814-b03c-fd8b51e65276_del
2022-02-22 02:24:30.065 7 INFO nova.virt.libvirt.driver [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Deletion of /var/lib/nova/instances/828a97cc-80b1-4814-b03c-fd8b51e65276_del complete
2022-02-22 02:24:30.140 7 INFO nova.virt.libvirt.host [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] UEFI support detected
2022-02-22 02:24:30.142 7 INFO nova.compute.manager [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Took 1.68 seconds to destroy the instance on the hypervisor.
2022-02-22 02:24:30.867 7 INFO nova.compute.manager [-] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Took 0.72 seconds to deallocate network for instance.
2022-02-22 02:24:32.153 7 INFO nova.compute.manager [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] Took 1.28 seconds to detach 1 volumes for instance.
2022-02-22 02:24:32.354 7 INFO nova.scheduler.client.report [req-89256a3d-485d-47ab-8561-4e6b907cc7e7 c65951ebc3dd44c4b1361bd2e884d737 ce01fbf7673f4001b9e144ee7acfbbad - default default] Deleted allocations for instance 828a97cc-80b1-4814-b03c-fd8b51e65276
2022-02-22 02:24:38.207 7 INFO nova.compute.claims [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Claim successful on node rack08-server63
2022-02-22 02:24:38.627 7 INFO nova.virt.libvirt.driver [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Creating image
2022-02-22 02:24:38.631 7 INFO oslo.privsep.daemon [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpo265tcb8/privsep.sock']
2022-02-22 02:24:40.246 7 INFO oslo.privsep.daemon [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Spawned new privsep daemon via rootwrap
2022-02-22 02:24:40.102 101 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 02:24:40.108 101 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 02:24:40.113 101 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 02:24:40.113 101 INFO oslo.privsep.daemon [-] privsep daemon running as pid 101
2022-02-22 02:24:40.664 7 WARNING nova.compute.manager [req-37ff645b-e191-4acf-ae10-d1dce5f14440 - - - - -] While synchronizing instance power states, found 4 instances in the database and 3 instances on the hypervisor.
2022-02-22 02:24:42.156 7 INFO nova.compute.manager [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] VM Resumed (Lifecycle Event)
2022-02-22 02:24:42.173 7 INFO nova.virt.libvirt.driver [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Instance spawned successfully.
2022-02-22 02:24:42.173 7 INFO nova.compute.manager [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Took 3.55 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:42.212 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:42.213 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] VM Started (Lifecycle Event)
2022-02-22 02:24:42.261 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:42.279 7 INFO nova.compute.manager [req-f070c73a-9297-46f1-8918-37a94d6b019b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Took 4.11 seconds to build instance.
2022-02-22 02:24:42.304 7 INFO nova.compute.manager [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:43.686 7 INFO nova.compute.manager [-] [instance: 828a97cc-80b1-4814-b03c-fd8b51e65276] VM Stopped (Lifecycle Event)
2022-02-22 02:24:46.013 7 INFO nova.compute.manager [req-8024f30d-8c4d-484b-8425-b1e13993f345 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Attaching volume abdf2dc2-2197-476b-9bd0-d247766d44ab to /dev/vdb
2022-02-22 02:24:46.100 7 WARNING os_brick.initiator.connectors.nvmeof [req-8024f30d-8c4d-484b-8425-b1e13993f345 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:24:47.467 7 INFO os_brick.initiator.connectors.lightos [req-8024f30d-8c4d-484b-8425-b1e13993f345 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: connect_volume called for volume 4ad44c32-d84d-43dd-9db0-3db31afdee8d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4ad44c32-d84d-43dd-9db0-3db31afdee8d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:24:47.471 7 INFO os_brick.initiator.connectors.lightos [req-8024f30d-8c4d-484b-8425-b1e13993f345 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4ad44c32-d84d-43dd-9db0-3db31afdee8d
2022-02-22 02:24:49.535 7 INFO nova.compute.claims [req-3ada6bd3-0cf1-4d78-a052-862293632d41 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Claim successful on node rack08-server63
2022-02-22 02:24:50.074 7 INFO nova.virt.libvirt.driver [req-3ada6bd3-0cf1-4d78-a052-862293632d41 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Creating image
2022-02-22 02:24:51.271 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] VM Resumed (Lifecycle Event)
2022-02-22 02:24:51.278 7 INFO nova.virt.libvirt.driver [-] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Instance spawned successfully.
2022-02-22 02:24:51.279 7 INFO nova.compute.manager [req-3ada6bd3-0cf1-4d78-a052-862293632d41 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:51.325 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:51.326 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] VM Started (Lifecycle Event)
2022-02-22 02:24:51.368 7 INFO nova.compute.manager [req-3ada6bd3-0cf1-4d78-a052-862293632d41 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Took 1.87 seconds to build instance.
2022-02-22 02:24:52.167 7 INFO nova.compute.claims [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Claim successful on node rack08-server63
2022-02-22 02:24:52.430 7 INFO nova.virt.libvirt.driver [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 02:24:52.519 7 INFO nova.virt.block_device [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Booting with volume f6eb7be3-a194-400c-9459-c8d34808bde4 at /dev/vda
2022-02-22 02:24:52.603 7 WARNING os_brick.initiator.connectors.nvmeof [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:24:52.726 7 INFO nova.compute.manager [req-1618c2e0-0b55-4576-ad91-7ff26365103e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Detaching volume abdf2dc2-2197-476b-9bd0-d247766d44ab
2022-02-22 02:24:52.782 7 INFO nova.virt.block_device [req-1618c2e0-0b55-4576-ad91-7ff26365103e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Attempting to driver detach volume abdf2dc2-2197-476b-9bd0-d247766d44ab from mountpoint /dev/vdb
2022-02-22 02:24:52.801 7 INFO nova.virt.libvirt.driver [req-1618c2e0-0b55-4576-ad91-7ff26365103e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance bf830729-602a-4ffb-a93c-0a87ad414f5f from the persistent domain config.
2022-02-22 02:24:52.953 7 INFO nova.virt.libvirt.driver [req-1618c2e0-0b55-4576-ad91-7ff26365103e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance bf830729-602a-4ffb-a93c-0a87ad414f5f from the live domain config.
2022-02-22 02:24:52.956 7 INFO os_brick.initiator.connectors.lightos [req-1618c2e0-0b55-4576-ad91-7ff26365103e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4ad44c32-d84d-43dd-9db0-3db31afdee8d
2022-02-22 02:24:54.116 7 INFO nova.virt.libvirt.driver [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Creating image
2022-02-22 02:24:54.127 7 INFO os_brick.initiator.connectors.lightos [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: connect_volume called for volume 7fe79b1f-c163-4d46-869d-52a0e2cf99ae, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '7fe79b1f-c163-4d46-869d-52a0e2cf99ae', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:24:54.130 7 INFO os_brick.initiator.connectors.lightos [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 7fe79b1f-c163-4d46-869d-52a0e2cf99ae
2022-02-22 02:24:54.934 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] VM Resumed (Lifecycle Event)
2022-02-22 02:24:54.941 7 INFO nova.virt.libvirt.driver [-] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Instance spawned successfully.
2022-02-22 02:24:54.942 7 INFO nova.compute.manager [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Took 0.83 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:54.990 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:54.990 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] VM Started (Lifecycle Event)
2022-02-22 02:24:55.032 7 INFO nova.compute.manager [req-38e8dcca-8f14-4b3d-bd1a-88a39f083468 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Took 2.90 seconds to build instance.
2022-02-22 02:24:56.298 7 INFO nova.compute.claims [req-cfcc9f26-0635-4403-ac46-cd1b59608431 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Claim successful on node rack08-server63
2022-02-22 02:24:56.644 7 INFO nova.virt.libvirt.driver [req-cfcc9f26-0635-4403-ac46-cd1b59608431 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Creating image
2022-02-22 02:24:57.454 7 INFO nova.compute.claims [req-b56b9b9e-ef4a-48c8-84d9-bf07342df6e8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Claim successful on node rack08-server63
2022-02-22 02:24:57.776 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] VM Resumed (Lifecycle Event)
2022-02-22 02:24:57.782 7 INFO nova.virt.libvirt.driver [-] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Instance spawned successfully.
2022-02-22 02:24:57.783 7 INFO nova.compute.manager [req-cfcc9f26-0635-4403-ac46-cd1b59608431 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:57.823 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:57.824 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] VM Started (Lifecycle Event)
2022-02-22 02:24:57.872 7 INFO nova.compute.manager [req-cfcc9f26-0635-4403-ac46-cd1b59608431 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Took 1.61 seconds to build instance.
2022-02-22 02:24:57.905 7 INFO nova.virt.libvirt.driver [req-b56b9b9e-ef4a-48c8-84d9-bf07342df6e8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Creating image
2022-02-22 02:24:58.041 7 INFO nova.compute.claims [req-902c33f7-9bbe-4585-990c-a049a915562d 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Claim successful on node rack08-server63
2022-02-22 02:24:58.434 7 INFO nova.virt.libvirt.driver [req-902c33f7-9bbe-4585-990c-a049a915562d 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Creating image
2022-02-22 02:24:58.995 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] VM Resumed (Lifecycle Event)
2022-02-22 02:24:59.001 7 INFO nova.virt.libvirt.driver [-] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Instance spawned successfully.
2022-02-22 02:24:59.002 7 INFO nova.compute.manager [req-b56b9b9e-ef4a-48c8-84d9-bf07342df6e8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Took 1.10 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:59.052 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:59.053 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] VM Started (Lifecycle Event)
2022-02-22 02:24:59.088 7 INFO nova.compute.manager [req-b56b9b9e-ef4a-48c8-84d9-bf07342df6e8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Took 1.67 seconds to build instance.
2022-02-22 02:24:59.533 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] VM Resumed (Lifecycle Event)
2022-02-22 02:24:59.538 7 INFO nova.virt.libvirt.driver [-] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Instance spawned successfully.
2022-02-22 02:24:59.538 7 INFO nova.compute.manager [req-902c33f7-9bbe-4585-990c-a049a915562d 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Took 1.11 seconds to spawn the instance on the hypervisor.
2022-02-22 02:24:59.586 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:24:59.587 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] VM Started (Lifecycle Event)
2022-02-22 02:24:59.624 7 INFO nova.compute.manager [req-902c33f7-9bbe-4585-990c-a049a915562d 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Took 1.62 seconds to build instance.
2022-02-22 02:25:00.708 7 INFO nova.compute.manager [req-47ed0e21-d28b-4e1d-bc16-391b29cbfded 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Attaching volume 011b323b-4412-47de-903b-7ff51dc07c87 to /dev/vdb
2022-02-22 02:25:00.792 7 WARNING os_brick.initiator.connectors.nvmeof [req-47ed0e21-d28b-4e1d-bc16-391b29cbfded 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:25:01.605 7 INFO nova.compute.manager [req-bd8ff693-17af-4d99-8099-f0fcd462a7c8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Attaching volume 25b921a9-7047-483e-b66d-75841eefc8ba to /dev/vdb
2022-02-22 02:25:01.697 7 WARNING os_brick.initiator.connectors.nvmeof [req-bd8ff693-17af-4d99-8099-f0fcd462a7c8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:25:02.152 7 INFO os_brick.initiator.connectors.lightos [req-47ed0e21-d28b-4e1d-bc16-391b29cbfded 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: connect_volume called for volume f7147d27-2917-4828-8dcb-1e3190fa9b47, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f7147d27-2917-4828-8dcb-1e3190fa9b47', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:25:02.156 7 INFO os_brick.initiator.connectors.lightos [req-47ed0e21-d28b-4e1d-bc16-391b29cbfded 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f7147d27-2917-4828-8dcb-1e3190fa9b47
2022-02-22 02:25:03.038 7 INFO os_brick.initiator.connectors.lightos [req-bd8ff693-17af-4d99-8099-f0fcd462a7c8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: connect_volume called for volume 8719b4c8-ba49-434b-a8ce-9d5d868236d1, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8719b4c8-ba49-434b-a8ce-9d5d868236d1', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:25:03.041 7 INFO os_brick.initiator.connectors.lightos [req-bd8ff693-17af-4d99-8099-f0fcd462a7c8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 8719b4c8-ba49-434b-a8ce-9d5d868236d1
2022-02-22 02:25:03.296 7 INFO nova.compute.manager [req-88ccc68c-3907-492f-b3b5-3a27957b3f17 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Detaching volume 011b323b-4412-47de-903b-7ff51dc07c87
2022-02-22 02:25:03.356 7 INFO nova.virt.block_device [req-88ccc68c-3907-492f-b3b5-3a27957b3f17 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Attempting to driver detach volume 011b323b-4412-47de-903b-7ff51dc07c87 from mountpoint /dev/vdb
2022-02-22 02:25:03.374 7 INFO nova.virt.libvirt.driver [req-88ccc68c-3907-492f-b3b5-3a27957b3f17 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance 463609bb-33e0-4484-b157-5fd06786e5b6 from the persistent domain config.
2022-02-22 02:25:03.524 7 INFO nova.virt.libvirt.driver [req-88ccc68c-3907-492f-b3b5-3a27957b3f17 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance 463609bb-33e0-4484-b157-5fd06786e5b6 from the live domain config.
2022-02-22 02:25:03.527 7 INFO os_brick.initiator.connectors.lightos [req-88ccc68c-3907-492f-b3b5-3a27957b3f17 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f7147d27-2917-4828-8dcb-1e3190fa9b47
2022-02-22 02:25:04.088 7 INFO nova.compute.manager [req-0d4b3d04-6373-482b-ad33-fe80863581d6 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Attaching volume 25b921a9-7047-483e-b66d-75841eefc8ba to /dev/vdb
2022-02-22 02:25:04.181 7 WARNING os_brick.initiator.connectors.nvmeof [req-0d4b3d04-6373-482b-ad33-fe80863581d6 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:25:05.531 7 INFO os_brick.initiator.connectors.lightos [req-0d4b3d04-6373-482b-ad33-fe80863581d6 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: connect_volume called for volume 8719b4c8-ba49-434b-a8ce-9d5d868236d1, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8719b4c8-ba49-434b-a8ce-9d5d868236d1', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:25:05.532 7 INFO os_brick.initiator.connectors.lightos [req-0d4b3d04-6373-482b-ad33-fe80863581d6 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 8719b4c8-ba49-434b-a8ce-9d5d868236d1
2022-02-22 02:25:06.641 7 INFO nova.compute.manager [req-6023cfa8-6c28-48eb-b0a0-159582dca3f8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Detaching volume 25b921a9-7047-483e-b66d-75841eefc8ba
2022-02-22 02:25:06.716 7 INFO nova.compute.claims [req-ea719a06-0fcb-427e-8a7e-5cefe384bfbd 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Claim successful on node rack08-server63
2022-02-22 02:25:06.721 7 INFO nova.virt.block_device [req-6023cfa8-6c28-48eb-b0a0-159582dca3f8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Attempting to driver detach volume 25b921a9-7047-483e-b66d-75841eefc8ba from mountpoint /dev/vdb
2022-02-22 02:25:06.738 7 INFO nova.virt.libvirt.driver [req-6023cfa8-6c28-48eb-b0a0-159582dca3f8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Successfully detached device vdb from instance 8f02b207-0209-4875-9aa4-33da4bafaa8d from the persistent domain config.
2022-02-22 02:25:06.882 7 INFO nova.virt.libvirt.driver [req-6023cfa8-6c28-48eb-b0a0-159582dca3f8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Successfully detached device vdb from instance 8f02b207-0209-4875-9aa4-33da4bafaa8d from the live domain config.
2022-02-22 02:25:06.965 7 INFO nova.virt.libvirt.driver [req-6023cfa8-6c28-48eb-b0a0-159582dca3f8 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Detected multiple connections on this host for volume: 25b921a9-7047-483e-b66d-75841eefc8ba, skipping target disconnect.
2022-02-22 02:25:07.109 7 INFO nova.virt.libvirt.driver [req-ea719a06-0fcb-427e-8a7e-5cefe384bfbd 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Creating image
2022-02-22 02:25:08.279 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] VM Resumed (Lifecycle Event)
2022-02-22 02:25:08.288 7 INFO nova.virt.libvirt.driver [-] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Instance spawned successfully.
2022-02-22 02:25:08.289 7 INFO nova.compute.manager [req-ea719a06-0fcb-427e-8a7e-5cefe384bfbd 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 02:25:08.334 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:25:08.334 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] VM Started (Lifecycle Event)
2022-02-22 02:25:08.373 7 INFO nova.compute.manager [req-ea719a06-0fcb-427e-8a7e-5cefe384bfbd 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Took 1.70 seconds to build instance.
2022-02-22 02:25:09.124 7 INFO nova.compute.manager [req-3959b0b3-c69b-4fce-b4f7-524ec8394995 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Detaching volume 25b921a9-7047-483e-b66d-75841eefc8ba
2022-02-22 02:25:09.183 7 INFO nova.virt.block_device [req-3959b0b3-c69b-4fce-b4f7-524ec8394995 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Attempting to driver detach volume 25b921a9-7047-483e-b66d-75841eefc8ba from mountpoint /dev/vdb
2022-02-22 02:25:09.200 7 INFO nova.virt.libvirt.driver [req-3959b0b3-c69b-4fce-b4f7-524ec8394995 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Successfully detached device vdb from instance f213e23f-25b8-49f1-8198-ec766c310ea9 from the persistent domain config.
2022-02-22 02:25:09.378 7 INFO nova.virt.libvirt.driver [req-3959b0b3-c69b-4fce-b4f7-524ec8394995 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Successfully detached device vdb from instance f213e23f-25b8-49f1-8198-ec766c310ea9 from the live domain config.
2022-02-22 02:25:11.283 7 INFO nova.compute.manager [req-aa0a98db-188c-44d6-a2ee-5115f594b1df 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Attaching volume 7334d753-e404-42c2-8f51-9b3c1b72e012 to /dev/vdb
2022-02-22 02:25:11.370 7 WARNING os_brick.initiator.connectors.nvmeof [req-aa0a98db-188c-44d6-a2ee-5115f594b1df 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:26:10.106 7 INFO os_brick.initiator.connectors.lightos [req-aa0a98db-188c-44d6-a2ee-5115f594b1df 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: connect_volume called for volume b28cbc46-dc65-464d-9c5c-e13f955425e9, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'b28cbc46-dc65-464d-9c5c-e13f955425e9', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:26:10.111 7 INFO os_brick.initiator.connectors.lightos [req-aa0a98db-188c-44d6-a2ee-5115f594b1df 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b28cbc46-dc65-464d-9c5c-e13f955425e9
2022-02-22 02:26:11.011 7 INFO nova.compute.manager [req-89eb32c5-fa4d-43e7-a2bc-91d8633682ab 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Detaching volume 7334d753-e404-42c2-8f51-9b3c1b72e012
2022-02-22 02:26:11.069 7 INFO nova.virt.block_device [req-89eb32c5-fa4d-43e7-a2bc-91d8633682ab 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Attempting to driver detach volume 7334d753-e404-42c2-8f51-9b3c1b72e012 from mountpoint /dev/vdb
2022-02-22 02:26:11.089 7 INFO nova.virt.libvirt.driver [req-89eb32c5-fa4d-43e7-a2bc-91d8633682ab 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance 8d0cff77-e535-4541-a601-e1024e4eb898 from the persistent domain config.
2022-02-22 02:26:11.240 7 INFO nova.virt.libvirt.driver [req-89eb32c5-fa4d-43e7-a2bc-91d8633682ab 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Successfully detached device vdb from instance 8d0cff77-e535-4541-a601-e1024e4eb898 from the live domain config.
2022-02-22 02:26:11.243 7 INFO os_brick.initiator.connectors.lightos [req-89eb32c5-fa4d-43e7-a2bc-91d8633682ab 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b28cbc46-dc65-464d-9c5c-e13f955425e9
2022-02-22 02:26:14.452 7 INFO nova.compute.manager [req-0d823ba8-a0fa-4a14-bba1-1750bcabb571 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Terminating instance
2022-02-22 02:26:14.795 7 INFO nova.virt.libvirt.driver [-] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Instance destroyed successfully.
2022-02-22 02:26:14.810 7 INFO nova.virt.libvirt.driver [req-0d823ba8-a0fa-4a14-bba1-1750bcabb571 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Deleting instance files /var/lib/nova/instances/8d0cff77-e535-4541-a601-e1024e4eb898_del
2022-02-22 02:26:14.812 7 INFO nova.virt.libvirt.driver [req-0d823ba8-a0fa-4a14-bba1-1750bcabb571 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Deletion of /var/lib/nova/instances/8d0cff77-e535-4541-a601-e1024e4eb898_del complete
2022-02-22 02:26:14.882 7 INFO nova.compute.manager [req-0d823ba8-a0fa-4a14-bba1-1750bcabb571 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:14.958 7 INFO nova.compute.manager [-] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:15.136 7 INFO nova.scheduler.client.report [req-0d823ba8-a0fa-4a14-bba1-1750bcabb571 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Deleted allocations for instance 8d0cff77-e535-4541-a601-e1024e4eb898
2022-02-22 02:26:16.821 7 INFO nova.compute.manager [req-4c85d6c5-bfec-4e6b-8454-8ffd8cd1fd82 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Terminating instance
2022-02-22 02:26:17.175 7 INFO nova.virt.libvirt.driver [-] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Instance destroyed successfully.
2022-02-22 02:26:17.194 7 INFO nova.virt.libvirt.driver [req-4c85d6c5-bfec-4e6b-8454-8ffd8cd1fd82 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Deleting instance files /var/lib/nova/instances/463609bb-33e0-4484-b157-5fd06786e5b6_del
2022-02-22 02:26:17.196 7 INFO nova.virt.libvirt.driver [req-4c85d6c5-bfec-4e6b-8454-8ffd8cd1fd82 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Deletion of /var/lib/nova/instances/463609bb-33e0-4484-b157-5fd06786e5b6_del complete
2022-02-22 02:26:17.264 7 INFO nova.compute.manager [req-4c85d6c5-bfec-4e6b-8454-8ffd8cd1fd82 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:17.331 7 INFO nova.compute.manager [-] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:17.508 7 INFO nova.scheduler.client.report [req-4c85d6c5-bfec-4e6b-8454-8ffd8cd1fd82 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Deleted allocations for instance 463609bb-33e0-4484-b157-5fd06786e5b6
2022-02-22 02:26:17.953 7 INFO nova.compute.claims [req-a477ee77-4148-4ccd-bf9f-8b1a1c40e25c 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Claim successful on node rack08-server63
2022-02-22 02:26:18.077 7 INFO nova.compute.manager [req-15f76c3f-575c-4d2d-84a7-34e2ee52c60b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Terminating instance
2022-02-22 02:26:18.334 7 INFO nova.virt.libvirt.driver [req-a477ee77-4148-4ccd-bf9f-8b1a1c40e25c 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Creating image
2022-02-22 02:26:18.466 7 INFO nova.virt.libvirt.driver [-] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Instance destroyed successfully.
2022-02-22 02:26:18.485 7 INFO nova.virt.libvirt.driver [req-15f76c3f-575c-4d2d-84a7-34e2ee52c60b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Deleting instance files /var/lib/nova/instances/90d1bbac-4288-45f0-afce-f2d48254dda1_del
2022-02-22 02:26:18.487 7 INFO nova.virt.libvirt.driver [req-15f76c3f-575c-4d2d-84a7-34e2ee52c60b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Deletion of /var/lib/nova/instances/90d1bbac-4288-45f0-afce-f2d48254dda1_del complete
2022-02-22 02:26:18.566 7 INFO nova.compute.manager [req-15f76c3f-575c-4d2d-84a7-34e2ee52c60b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:18.637 7 INFO nova.compute.manager [-] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:18.813 7 INFO nova.scheduler.client.report [req-15f76c3f-575c-4d2d-84a7-34e2ee52c60b 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Deleted allocations for instance 90d1bbac-4288-45f0-afce-f2d48254dda1
2022-02-22 02:26:19.535 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 767e2c78-5369-430e-933f-a53588c1b740] VM Resumed (Lifecycle Event)
2022-02-22 02:26:19.542 7 INFO nova.virt.libvirt.driver [-] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Instance spawned successfully.
2022-02-22 02:26:19.543 7 INFO nova.compute.manager [req-a477ee77-4148-4ccd-bf9f-8b1a1c40e25c 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 02:26:19.589 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 767e2c78-5369-430e-933f-a53588c1b740] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:26:19.590 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 767e2c78-5369-430e-933f-a53588c1b740] VM Started (Lifecycle Event)
2022-02-22 02:26:19.628 7 INFO nova.compute.manager [req-a477ee77-4148-4ccd-bf9f-8b1a1c40e25c 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Took 1.71 seconds to build instance.
2022-02-22 02:26:20.505 7 INFO nova.compute.manager [req-c6b2d8a9-0607-4cea-a0ac-ddb7ccc5371e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Terminating instance
2022-02-22 02:26:20.851 7 INFO nova.virt.libvirt.driver [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Instance destroyed successfully.
2022-02-22 02:26:20.868 7 INFO nova.virt.libvirt.driver [req-c6b2d8a9-0607-4cea-a0ac-ddb7ccc5371e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Deleting instance files /var/lib/nova/instances/bf830729-602a-4ffb-a93c-0a87ad414f5f_del
2022-02-22 02:26:20.870 7 INFO nova.virt.libvirt.driver [req-c6b2d8a9-0607-4cea-a0ac-ddb7ccc5371e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Deletion of /var/lib/nova/instances/bf830729-602a-4ffb-a93c-0a87ad414f5f_del complete
2022-02-22 02:26:20.939 7 INFO nova.compute.manager [req-c6b2d8a9-0607-4cea-a0ac-ddb7ccc5371e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:21.008 7 INFO nova.compute.manager [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:21.204 7 INFO nova.scheduler.client.report [req-c6b2d8a9-0607-4cea-a0ac-ddb7ccc5371e 6b2ef24b96954ed696ee09ce70104f11 db226a587ae9411899c3cb9673e4131b - default default] Deleted allocations for instance bf830729-602a-4ffb-a93c-0a87ad414f5f
2022-02-22 02:26:24.404 7 INFO nova.compute.manager [req-b6716f33-bf68-4f0d-a4ae-336cb212d658 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Terminating instance
2022-02-22 02:26:24.735 7 INFO nova.virt.libvirt.driver [-] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Instance destroyed successfully.
2022-02-22 02:26:24.750 7 INFO nova.virt.libvirt.driver [req-b6716f33-bf68-4f0d-a4ae-336cb212d658 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Deleting instance files /var/lib/nova/instances/767e2c78-5369-430e-933f-a53588c1b740_del
2022-02-22 02:26:24.751 7 INFO nova.virt.libvirt.driver [req-b6716f33-bf68-4f0d-a4ae-336cb212d658 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Deletion of /var/lib/nova/instances/767e2c78-5369-430e-933f-a53588c1b740_del complete
2022-02-22 02:26:24.817 7 INFO nova.compute.manager [req-b6716f33-bf68-4f0d-a4ae-336cb212d658 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:24.885 7 INFO nova.compute.manager [-] [instance: 767e2c78-5369-430e-933f-a53588c1b740] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:25.079 7 INFO nova.scheduler.client.report [req-b6716f33-bf68-4f0d-a4ae-336cb212d658 0f14374980554ac8b7684dbdbe5aed6b 4ac49386ec004c9799326d75e5b2aaa2 - default default] Deleted allocations for instance 767e2c78-5369-430e-933f-a53588c1b740
2022-02-22 02:26:25.206 7 INFO nova.compute.claims [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Claim successful on node rack08-server63
2022-02-22 02:26:25.456 7 INFO nova.virt.libvirt.driver [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 02:26:25.548 7 INFO nova.virt.block_device [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Booting with volume 2826f53a-d6a2-4438-91bc-b4f7deefba65 at /dev/vda
2022-02-22 02:26:25.647 7 WARNING os_brick.initiator.connectors.nvmeof [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:26:27.175 7 INFO nova.virt.libvirt.driver [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Creating image
2022-02-22 02:26:27.188 7 INFO os_brick.initiator.connectors.lightos [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: connect_volume called for volume 3593d1f8-8058-4d4b-a4c5-b928a27e86f9, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '3593d1f8-8058-4d4b-a4c5-b928a27e86f9', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:26:27.192 7 INFO os_brick.initiator.connectors.lightos [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 3593d1f8-8058-4d4b-a4c5-b928a27e86f9
2022-02-22 02:26:27.970 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] VM Resumed (Lifecycle Event)
2022-02-22 02:26:27.977 7 INFO nova.virt.libvirt.driver [-] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Instance spawned successfully.
2022-02-22 02:26:27.977 7 INFO nova.compute.manager [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Took 0.80 seconds to spawn the instance on the hypervisor.
2022-02-22 02:26:28.027 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:26:28.027 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] VM Started (Lifecycle Event)
2022-02-22 02:26:28.060 7 INFO nova.compute.manager [req-021983fc-37e0-4234-b31a-d8e542539f1b 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Took 2.89 seconds to build instance.
2022-02-22 02:26:29.286 7 INFO nova.compute.manager [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Terminating instance
2022-02-22 02:26:29.620 7 INFO nova.virt.libvirt.driver [-] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Instance destroyed successfully.
2022-02-22 02:26:29.701 7 INFO os_brick.initiator.connectors.lightos [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 3593d1f8-8058-4d4b-a4c5-b928a27e86f9
2022-02-22 02:26:29.713 7 INFO nova.virt.libvirt.driver [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Deleting instance files /var/lib/nova/instances/13c67a16-6d28-408f-a7ac-a54aa8f0306d_del
2022-02-22 02:26:29.714 7 INFO nova.virt.libvirt.driver [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Deletion of /var/lib/nova/instances/13c67a16-6d28-408f-a7ac-a54aa8f0306d_del complete
2022-02-22 02:26:29.784 7 INFO nova.compute.manager [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:29.793 7 INFO nova.compute.manager [-] [instance: 8d0cff77-e535-4541-a601-e1024e4eb898] VM Stopped (Lifecycle Event)
2022-02-22 02:26:29.854 7 INFO nova.compute.manager [-] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:31.111 7 INFO nova.compute.manager [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] Took 1.26 seconds to detach 1 volumes for instance.
2022-02-22 02:26:31.297 7 INFO nova.scheduler.client.report [req-dbf7187c-8a91-4e47-a480-23a502c8667e 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Deleted allocations for instance 13c67a16-6d28-408f-a7ac-a54aa8f0306d
2022-02-22 02:26:32.173 7 INFO nova.compute.manager [-] [instance: 463609bb-33e0-4484-b157-5fd06786e5b6] VM Stopped (Lifecycle Event)
2022-02-22 02:26:33.464 7 INFO nova.compute.manager [-] [instance: 90d1bbac-4288-45f0-afce-f2d48254dda1] VM Stopped (Lifecycle Event)
2022-02-22 02:26:34.185 7 INFO nova.compute.manager [req-7a0fd277-bbae-4f2b-8d2e-e300c885a0d4 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Terminating instance
2022-02-22 02:26:34.529 7 INFO nova.virt.libvirt.driver [-] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Instance destroyed successfully.
2022-02-22 02:26:34.543 7 INFO nova.virt.libvirt.driver [req-7a0fd277-bbae-4f2b-8d2e-e300c885a0d4 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Deleting instance files /var/lib/nova/instances/f213e23f-25b8-49f1-8198-ec766c310ea9_del
2022-02-22 02:26:34.545 7 INFO nova.virt.libvirt.driver [req-7a0fd277-bbae-4f2b-8d2e-e300c885a0d4 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Deletion of /var/lib/nova/instances/f213e23f-25b8-49f1-8198-ec766c310ea9_del complete
2022-02-22 02:26:34.614 7 INFO nova.compute.manager [req-7a0fd277-bbae-4f2b-8d2e-e300c885a0d4 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:34.681 7 INFO nova.compute.manager [-] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:34.890 7 INFO nova.scheduler.client.report [req-7a0fd277-bbae-4f2b-8d2e-e300c885a0d4 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Deleted allocations for instance f213e23f-25b8-49f1-8198-ec766c310ea9
2022-02-22 02:26:35.428 7 INFO nova.compute.manager [req-e323e3a3-bead-48f5-89f9-25beceed52ba 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Terminating instance
2022-02-22 02:26:35.767 7 INFO nova.virt.libvirt.driver [-] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Instance destroyed successfully.
2022-02-22 02:26:35.783 7 INFO nova.virt.libvirt.driver [req-e323e3a3-bead-48f5-89f9-25beceed52ba 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Deleting instance files /var/lib/nova/instances/8f02b207-0209-4875-9aa4-33da4bafaa8d_del
2022-02-22 02:26:35.785 7 INFO nova.virt.libvirt.driver [req-e323e3a3-bead-48f5-89f9-25beceed52ba 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Deletion of /var/lib/nova/instances/8f02b207-0209-4875-9aa4-33da4bafaa8d_del complete
2022-02-22 02:26:35.851 7 INFO nova.compute.manager [-] [instance: bf830729-602a-4ffb-a93c-0a87ad414f5f] VM Stopped (Lifecycle Event)
2022-02-22 02:26:35.857 7 INFO nova.compute.manager [req-e323e3a3-bead-48f5-89f9-25beceed52ba 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:35.926 7 INFO nova.compute.manager [-] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:36.118 7 INFO nova.scheduler.client.report [req-e323e3a3-bead-48f5-89f9-25beceed52ba 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Deleted allocations for instance 8f02b207-0209-4875-9aa4-33da4bafaa8d
2022-02-22 02:26:36.665 7 INFO nova.compute.manager [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Terminating instance
2022-02-22 02:26:37.050 7 INFO nova.virt.libvirt.driver [-] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Instance destroyed successfully.
2022-02-22 02:26:37.130 7 INFO os_brick.initiator.connectors.lightos [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 7fe79b1f-c163-4d46-869d-52a0e2cf99ae
2022-02-22 02:26:37.140 7 INFO nova.virt.libvirt.driver [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Deleting instance files /var/lib/nova/instances/26d1e46d-0edd-417e-9e13-5b61d0678167_del
2022-02-22 02:26:37.141 7 INFO nova.virt.libvirt.driver [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Deletion of /var/lib/nova/instances/26d1e46d-0edd-417e-9e13-5b61d0678167_del complete
2022-02-22 02:26:37.208 7 INFO nova.compute.manager [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 02:26:37.274 7 INFO nova.compute.manager [-] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:26:38.511 7 INFO nova.compute.manager [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 02:26:38.704 7 INFO nova.scheduler.client.report [req-9aed446b-ffcc-4440-9f46-003fba4f41a0 2ae172231b17446db3f0f8feb30189d2 09bf34004aa74f469619d1fac07bbbff - default default] Deleted allocations for instance 26d1e46d-0edd-417e-9e13-5b61d0678167
2022-02-22 02:26:39.733 7 INFO nova.compute.manager [-] [instance: 767e2c78-5369-430e-933f-a53588c1b740] VM Stopped (Lifecycle Event)
2022-02-22 02:26:44.618 7 INFO nova.compute.manager [-] [instance: 13c67a16-6d28-408f-a7ac-a54aa8f0306d] VM Stopped (Lifecycle Event)
2022-02-22 02:26:49.527 7 INFO nova.compute.manager [-] [instance: f213e23f-25b8-49f1-8198-ec766c310ea9] VM Stopped (Lifecycle Event)
2022-02-22 02:26:50.764 7 INFO nova.compute.manager [-] [instance: 8f02b207-0209-4875-9aa4-33da4bafaa8d] VM Stopped (Lifecycle Event)
2022-02-22 02:26:52.048 7 INFO nova.compute.manager [-] [instance: 26d1e46d-0edd-417e-9e13-5b61d0678167] VM Stopped (Lifecycle Event)
2022-02-22 02:28:24.227 7 INFO nova.compute.claims [req-948a892f-dba8-421b-9400-2c40f129a5dd eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Claim successful on node rack08-server63
2022-02-22 02:28:24.634 7 INFO nova.virt.libvirt.driver [req-948a892f-dba8-421b-9400-2c40f129a5dd eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Creating image
2022-02-22 02:28:25.740 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] VM Resumed (Lifecycle Event)
2022-02-22 02:28:25.747 7 INFO nova.virt.libvirt.driver [-] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Instance spawned successfully.
2022-02-22 02:28:25.747 7 INFO nova.compute.manager [req-948a892f-dba8-421b-9400-2c40f129a5dd eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Took 1.11 seconds to spawn the instance on the hypervisor.
2022-02-22 02:28:25.793 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:28:25.794 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] VM Started (Lifecycle Event)
2022-02-22 02:28:25.832 7 INFO nova.compute.manager [req-948a892f-dba8-421b-9400-2c40f129a5dd eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Took 1.65 seconds to build instance.
2022-02-22 02:28:26.176 7 INFO nova.virt.libvirt.driver [req-0acefd89-147e-44be-a979-11a9c081ee35 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Ignoring supplied device name: /dev/vdb
2022-02-22 02:28:26.349 7 INFO nova.compute.manager [req-0acefd89-147e-44be-a979-11a9c081ee35 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Attaching volume b61630df-0908-4334-9d71-b14f8cb2768f to /dev/vdb
2022-02-22 02:28:26.432 7 WARNING os_brick.initiator.connectors.nvmeof [req-0acefd89-147e-44be-a979-11a9c081ee35 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:28:27.804 7 INFO os_brick.initiator.connectors.lightos [req-0acefd89-147e-44be-a979-11a9c081ee35 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] LIGHTOS: connect_volume called for volume e549c27d-b486-43a9-a1b2-7cc82224a7a0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'e549c27d-b486-43a9-a1b2-7cc82224a7a0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:28:27.807 7 INFO os_brick.initiator.connectors.lightos [req-0acefd89-147e-44be-a979-11a9c081ee35 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e549c27d-b486-43a9-a1b2-7cc82224a7a0
2022-02-22 02:28:29.568 7 INFO nova.compute.manager [req-9fc57fdc-57bf-4df1-9cf9-763853df644b e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Cinder extended volume b61630df-0908-4334-9d71-b14f8cb2768f; extending it to detect new size
2022-02-22 02:28:29.645 7 INFO os_brick.initiator.connectors.lightos [req-9fc57fdc-57bf-4df1-9cf9-763853df644b e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e549c27d-b486-43a9-a1b2-7cc82224a7a0
2022-02-22 02:28:30.360 7 INFO nova.compute.manager [req-4eebec2b-d94a-46be-bae8-1ba18a724fe6 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Detaching volume b61630df-0908-4334-9d71-b14f8cb2768f
2022-02-22 02:28:30.417 7 INFO nova.virt.block_device [req-4eebec2b-d94a-46be-bae8-1ba18a724fe6 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Attempting to driver detach volume b61630df-0908-4334-9d71-b14f8cb2768f from mountpoint /dev/vdb
2022-02-22 02:28:30.437 7 INFO nova.virt.libvirt.driver [req-4eebec2b-d94a-46be-bae8-1ba18a724fe6 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] Successfully detached device vdb from instance f20f7315-f4da-4fe3-be89-764c12b05c72 from the persistent domain config.
2022-02-22 02:28:30.582 7 INFO nova.virt.libvirt.driver [req-4eebec2b-d94a-46be-bae8-1ba18a724fe6 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] Successfully detached device vdb from instance f20f7315-f4da-4fe3-be89-764c12b05c72 from the live domain config.
2022-02-22 02:28:30.586 7 INFO os_brick.initiator.connectors.lightos [req-4eebec2b-d94a-46be-bae8-1ba18a724fe6 eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e549c27d-b486-43a9-a1b2-7cc82224a7a0
2022-02-22 02:28:32.607 7 INFO nova.compute.manager [req-2d89488c-ce60-443a-ac24-36816be6761d eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Terminating instance
2022-02-22 02:28:32.942 7 INFO nova.virt.libvirt.driver [-] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Instance destroyed successfully.
2022-02-22 02:28:32.958 7 INFO nova.virt.libvirt.driver [req-2d89488c-ce60-443a-ac24-36816be6761d eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Deleting instance files /var/lib/nova/instances/f20f7315-f4da-4fe3-be89-764c12b05c72_del
2022-02-22 02:28:32.959 7 INFO nova.virt.libvirt.driver [req-2d89488c-ce60-443a-ac24-36816be6761d eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Deletion of /var/lib/nova/instances/f20f7315-f4da-4fe3-be89-764c12b05c72_del complete
2022-02-22 02:28:33.023 7 INFO nova.compute.manager [req-2d89488c-ce60-443a-ac24-36816be6761d eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:28:33.090 7 INFO nova.compute.manager [-] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:28:33.294 7 INFO nova.scheduler.client.report [req-2d89488c-ce60-443a-ac24-36816be6761d eba40c01fa5a4030a11c4d94a3bb66a8 21ebb94c7558430781db78a35ec33805 - default default] Deleted allocations for instance f20f7315-f4da-4fe3-be89-764c12b05c72
2022-02-22 02:28:42.583 7 INFO nova.compute.claims [req-fd3b92ca-28af-4f17-9b8d-a33b7930f522 dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Claim successful on node rack08-server63
2022-02-22 02:28:43.134 7 INFO nova.virt.libvirt.driver [req-fd3b92ca-28af-4f17-9b8d-a33b7930f522 dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Creating image
2022-02-22 02:28:45.086 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] VM Resumed (Lifecycle Event)
2022-02-22 02:28:45.095 7 INFO nova.virt.libvirt.driver [-] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Instance spawned successfully.
2022-02-22 02:28:45.095 7 INFO nova.compute.manager [req-fd3b92ca-28af-4f17-9b8d-a33b7930f522 dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Took 1.96 seconds to spawn the instance on the hypervisor.
2022-02-22 02:28:45.145 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:28:45.146 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] VM Started (Lifecycle Event)
2022-02-22 02:28:45.190 7 INFO nova.compute.manager [req-fd3b92ca-28af-4f17-9b8d-a33b7930f522 dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Took 2.82 seconds to build instance.
2022-02-22 02:28:45.447 7 INFO nova.compute.manager [req-8c7ebd55-ec2b-406d-9477-ad827fa8dabe dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Terminating instance
2022-02-22 02:28:45.788 7 INFO nova.virt.libvirt.driver [-] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Instance destroyed successfully.
2022-02-22 02:28:45.804 7 INFO nova.virt.libvirt.driver [req-8c7ebd55-ec2b-406d-9477-ad827fa8dabe dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Deleting instance files /var/lib/nova/instances/cbf29805-797d-4378-a5ed-c6d7f20b7ba6_del
2022-02-22 02:28:45.805 7 INFO nova.virt.libvirt.driver [req-8c7ebd55-ec2b-406d-9477-ad827fa8dabe dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Deletion of /var/lib/nova/instances/cbf29805-797d-4378-a5ed-c6d7f20b7ba6_del complete
2022-02-22 02:28:45.873 7 INFO nova.compute.manager [req-8c7ebd55-ec2b-406d-9477-ad827fa8dabe dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:28:45.952 7 INFO nova.compute.manager [-] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] Took 0.08 seconds to deallocate network for instance.
2022-02-22 02:28:46.144 7 INFO nova.scheduler.client.report [req-8c7ebd55-ec2b-406d-9477-ad827fa8dabe dea6388496d84ded9ea39d81ccf1b86b ee30daca643d4b4795ae90a9b41abff3 - default default] Deleted allocations for instance cbf29805-797d-4378-a5ed-c6d7f20b7ba6
2022-02-22 02:28:47.940 7 INFO nova.compute.manager [-] [instance: f20f7315-f4da-4fe3-be89-764c12b05c72] VM Stopped (Lifecycle Event)
2022-02-22 02:28:56.943 7 INFO nova.compute.claims [req-d6ee8693-ea3f-4487-aeab-7c9e74e9092b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Claim successful on node rack08-server63
2022-02-22 02:28:57.319 7 INFO nova.virt.libvirt.driver [req-d6ee8693-ea3f-4487-aeab-7c9e74e9092b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Creating image
2022-02-22 02:28:58.494 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] VM Resumed (Lifecycle Event)
2022-02-22 02:28:58.502 7 INFO nova.virt.libvirt.driver [-] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Instance spawned successfully.
2022-02-22 02:28:58.503 7 INFO nova.compute.manager [req-d6ee8693-ea3f-4487-aeab-7c9e74e9092b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 02:28:58.553 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:28:58.553 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] VM Started (Lifecycle Event)
2022-02-22 02:28:58.592 7 INFO nova.compute.manager [req-d6ee8693-ea3f-4487-aeab-7c9e74e9092b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Took 1.69 seconds to build instance.
2022-02-22 02:29:00.786 7 INFO nova.compute.manager [-] [instance: cbf29805-797d-4378-a5ed-c6d7f20b7ba6] VM Stopped (Lifecycle Event)
2022-02-22 02:29:10.976 7 INFO nova.virt.libvirt.driver [req-34233155-3f99-4a06-8015-ed933ecbc311 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Ignoring supplied device name: /dev/vdb
2022-02-22 02:29:11.137 7 INFO nova.compute.manager [req-34233155-3f99-4a06-8015-ed933ecbc311 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Attaching volume e2f127e7-6dcb-4a0e-8b22-29afe0ae65a3 to /dev/vdb
2022-02-22 02:29:11.237 7 WARNING os_brick.initiator.connectors.nvmeof [req-34233155-3f99-4a06-8015-ed933ecbc311 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:29:12.583 7 INFO os_brick.initiator.connectors.lightos [req-34233155-3f99-4a06-8015-ed933ecbc311 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: connect_volume called for volume d445122b-f1af-4353-b8a6-3cbfb3f7beea, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd445122b-f1af-4353-b8a6-3cbfb3f7beea', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:29:12.587 7 INFO os_brick.initiator.connectors.lightos [req-34233155-3f99-4a06-8015-ed933ecbc311 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d445122b-f1af-4353-b8a6-3cbfb3f7beea
2022-02-22 02:29:26.836 7 INFO nova.compute.manager [req-eadd7433-e23a-42aa-be9a-cd77168f6192 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Detaching volume e2f127e7-6dcb-4a0e-8b22-29afe0ae65a3
2022-02-22 02:29:26.900 7 INFO nova.virt.block_device [req-eadd7433-e23a-42aa-be9a-cd77168f6192 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Attempting to driver detach volume e2f127e7-6dcb-4a0e-8b22-29afe0ae65a3 from mountpoint /dev/vdb
2022-02-22 02:29:26.920 7 INFO nova.virt.libvirt.driver [req-eadd7433-e23a-42aa-be9a-cd77168f6192 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Successfully detached device vdb from instance edfd99ed-16b8-4767-826a-f1da33c16971 from the persistent domain config.
2022-02-22 02:29:27.065 7 INFO nova.virt.libvirt.driver [req-eadd7433-e23a-42aa-be9a-cd77168f6192 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Successfully detached device vdb from instance edfd99ed-16b8-4767-826a-f1da33c16971 from the live domain config.
2022-02-22 02:29:27.068 7 INFO os_brick.initiator.connectors.lightos [req-eadd7433-e23a-42aa-be9a-cd77168f6192 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d445122b-f1af-4353-b8a6-3cbfb3f7beea
2022-02-22 02:29:29.090 7 INFO nova.compute.manager [req-de1207ab-ba71-40a4-a50c-a193d09be353 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Terminating instance
2022-02-22 02:29:29.431 7 INFO nova.virt.libvirt.driver [-] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Instance destroyed successfully.
2022-02-22 02:29:29.447 7 INFO nova.virt.libvirt.driver [req-de1207ab-ba71-40a4-a50c-a193d09be353 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Deleting instance files /var/lib/nova/instances/edfd99ed-16b8-4767-826a-f1da33c16971_del
2022-02-22 02:29:29.448 7 INFO nova.virt.libvirt.driver [req-de1207ab-ba71-40a4-a50c-a193d09be353 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Deletion of /var/lib/nova/instances/edfd99ed-16b8-4767-826a-f1da33c16971_del complete
2022-02-22 02:29:29.520 7 INFO nova.compute.manager [req-de1207ab-ba71-40a4-a50c-a193d09be353 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:29:29.584 7 INFO nova.compute.manager [-] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:29:29.774 7 INFO nova.scheduler.client.report [req-de1207ab-ba71-40a4-a50c-a193d09be353 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Deleted allocations for instance edfd99ed-16b8-4767-826a-f1da33c16971
2022-02-22 02:29:37.494 7 INFO nova.compute.claims [req-c4f87060-035f-4b08-9dae-5fecd2e935ce 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Claim successful on node rack08-server63
2022-02-22 02:29:37.895 7 INFO nova.virt.libvirt.driver [req-c4f87060-035f-4b08-9dae-5fecd2e935ce 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Creating image
2022-02-22 02:29:39.066 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] VM Resumed (Lifecycle Event)
2022-02-22 02:29:39.074 7 INFO nova.virt.libvirt.driver [-] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Instance spawned successfully.
2022-02-22 02:29:39.075 7 INFO nova.compute.manager [req-c4f87060-035f-4b08-9dae-5fecd2e935ce 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 02:29:39.122 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:29:39.122 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] VM Started (Lifecycle Event)
2022-02-22 02:29:39.164 7 INFO nova.compute.manager [req-c4f87060-035f-4b08-9dae-5fecd2e935ce 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Took 1.71 seconds to build instance.
2022-02-22 02:29:40.235 7 INFO nova.virt.libvirt.driver [req-7969fc2d-1f54-4d12-9cbf-21faf78d702b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Ignoring supplied device name: /dev/vdb
2022-02-22 02:29:40.406 7 INFO nova.compute.manager [req-7969fc2d-1f54-4d12-9cbf-21faf78d702b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Attaching volume 31e471c3-55f6-4035-99b1-4b9b46a0e0b4 to /dev/vdb
2022-02-22 02:29:40.499 7 WARNING os_brick.initiator.connectors.nvmeof [req-7969fc2d-1f54-4d12-9cbf-21faf78d702b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:29:41.846 7 INFO os_brick.initiator.connectors.lightos [req-7969fc2d-1f54-4d12-9cbf-21faf78d702b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: connect_volume called for volume c0dd6e51-0728-4024-a487-6cc45ffa6fac, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c0dd6e51-0728-4024-a487-6cc45ffa6fac', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:29:41.850 7 INFO os_brick.initiator.connectors.lightos [req-7969fc2d-1f54-4d12-9cbf-21faf78d702b 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c0dd6e51-0728-4024-a487-6cc45ffa6fac
2022-02-22 02:29:44.429 7 INFO nova.compute.manager [-] [instance: edfd99ed-16b8-4767-826a-f1da33c16971] VM Stopped (Lifecycle Event)
2022-02-22 02:29:50.675 7 INFO nova.compute.manager [req-97be3b68-10fe-49a9-abd8-3c74a2b8e8a5 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Detaching volume 31e471c3-55f6-4035-99b1-4b9b46a0e0b4
2022-02-22 02:29:50.737 7 INFO nova.virt.block_device [req-97be3b68-10fe-49a9-abd8-3c74a2b8e8a5 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Attempting to driver detach volume 31e471c3-55f6-4035-99b1-4b9b46a0e0b4 from mountpoint /dev/vdb
2022-02-22 02:29:50.756 7 INFO nova.virt.libvirt.driver [req-97be3b68-10fe-49a9-abd8-3c74a2b8e8a5 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Successfully detached device vdb from instance cda4e536-b926-4b46-8850-4dee5bf85b99 from the persistent domain config.
2022-02-22 02:29:50.909 7 INFO nova.virt.libvirt.driver [req-97be3b68-10fe-49a9-abd8-3c74a2b8e8a5 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Successfully detached device vdb from instance cda4e536-b926-4b46-8850-4dee5bf85b99 from the live domain config.
2022-02-22 02:29:50.912 7 INFO os_brick.initiator.connectors.lightos [req-97be3b68-10fe-49a9-abd8-3c74a2b8e8a5 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c0dd6e51-0728-4024-a487-6cc45ffa6fac
2022-02-22 02:29:52.919 7 INFO nova.compute.manager [req-6354084f-1fae-4e57-882e-0d87606a628c 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Terminating instance
2022-02-22 02:29:53.254 7 INFO nova.virt.libvirt.driver [-] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Instance destroyed successfully.
2022-02-22 02:29:53.270 7 INFO nova.virt.libvirt.driver [req-6354084f-1fae-4e57-882e-0d87606a628c 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Deleting instance files /var/lib/nova/instances/cda4e536-b926-4b46-8850-4dee5bf85b99_del
2022-02-22 02:29:53.271 7 INFO nova.virt.libvirt.driver [req-6354084f-1fae-4e57-882e-0d87606a628c 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Deletion of /var/lib/nova/instances/cda4e536-b926-4b46-8850-4dee5bf85b99_del complete
2022-02-22 02:29:53.335 7 INFO nova.compute.manager [req-6354084f-1fae-4e57-882e-0d87606a628c 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:29:53.399 7 INFO nova.compute.manager [-] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:29:53.603 7 INFO nova.scheduler.client.report [req-6354084f-1fae-4e57-882e-0d87606a628c 9fa3534685cc43a087dc591d97b187b8 2ca0987ea5734d4585fba5c4bc2a4ea7 - default default] Deleted allocations for instance cda4e536-b926-4b46-8850-4dee5bf85b99
2022-02-22 02:30:08.252 7 INFO nova.compute.manager [-] [instance: cda4e536-b926-4b46-8850-4dee5bf85b99] VM Stopped (Lifecycle Event)
2022-02-22 02:30:19.545 7 INFO nova.compute.claims [req-648790bc-7784-4884-a7e3-688dff51db61 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Claim successful on node rack08-server63
2022-02-22 02:30:19.942 7 INFO nova.virt.libvirt.driver [req-648790bc-7784-4884-a7e3-688dff51db61 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Creating image
2022-02-22 02:30:21.169 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: d159590e-a640-4c76-91b1-980c58c2800a] VM Resumed (Lifecycle Event)
2022-02-22 02:30:21.177 7 INFO nova.virt.libvirt.driver [-] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Instance spawned successfully.
2022-02-22 02:30:21.177 7 INFO nova.compute.manager [req-648790bc-7784-4884-a7e3-688dff51db61 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-22 02:30:21.225 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: d159590e-a640-4c76-91b1-980c58c2800a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:30:21.226 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: d159590e-a640-4c76-91b1-980c58c2800a] VM Started (Lifecycle Event)
2022-02-22 02:30:21.262 7 INFO nova.compute.manager [req-648790bc-7784-4884-a7e3-688dff51db61 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Took 1.76 seconds to build instance.
2022-02-22 02:30:22.758 7 INFO nova.compute.manager [req-99d48d96-36c6-4722-8c38-5737c8763349 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Terminating instance
2022-02-22 02:30:23.104 7 INFO nova.virt.libvirt.driver [-] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Instance destroyed successfully.
2022-02-22 02:30:23.121 7 INFO nova.virt.libvirt.driver [req-99d48d96-36c6-4722-8c38-5737c8763349 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Deleting instance files /var/lib/nova/instances/d159590e-a640-4c76-91b1-980c58c2800a_del
2022-02-22 02:30:23.122 7 INFO nova.virt.libvirt.driver [req-99d48d96-36c6-4722-8c38-5737c8763349 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Deletion of /var/lib/nova/instances/d159590e-a640-4c76-91b1-980c58c2800a_del complete
2022-02-22 02:30:23.187 7 INFO nova.compute.manager [req-99d48d96-36c6-4722-8c38-5737c8763349 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:30:23.254 7 INFO nova.compute.manager [-] [instance: d159590e-a640-4c76-91b1-980c58c2800a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:30:23.496 7 INFO nova.scheduler.client.report [req-99d48d96-36c6-4722-8c38-5737c8763349 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] Deleted allocations for instance d159590e-a640-4c76-91b1-980c58c2800a
2022-02-22 02:30:25.259 7 INFO nova.compute.claims [req-63e7c26e-dc09-4ab7-aa64-13b33f0fd529 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Claim successful on node rack08-server63
2022-02-22 02:30:25.661 7 INFO nova.virt.libvirt.driver [req-63e7c26e-dc09-4ab7-aa64-13b33f0fd529 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Creating image
2022-02-22 02:30:26.804 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] VM Resumed (Lifecycle Event)
2022-02-22 02:30:26.815 7 INFO nova.virt.libvirt.driver [-] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Instance spawned successfully.
2022-02-22 02:30:26.815 7 INFO nova.compute.manager [req-63e7c26e-dc09-4ab7-aa64-13b33f0fd529 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 02:30:26.865 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:30:26.866 7 INFO nova.compute.manager [req-a9c935f7-9dfd-482f-9650-da5fbdb0cc7f - - - - -] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] VM Started (Lifecycle Event)
2022-02-22 02:30:26.904 7 INFO nova.compute.manager [req-63e7c26e-dc09-4ab7-aa64-13b33f0fd529 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Took 1.68 seconds to build instance.
2022-02-22 02:30:28.568 7 INFO nova.compute.manager [req-c2c03695-be37-439f-a941-f80ddd4c3530 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Terminating instance
2022-02-22 02:30:28.909 7 INFO nova.virt.libvirt.driver [-] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Instance destroyed successfully.
2022-02-22 02:30:28.928 7 INFO nova.virt.libvirt.driver [req-c2c03695-be37-439f-a941-f80ddd4c3530 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Deleting instance files /var/lib/nova/instances/758a4a69-94e7-4505-8d7b-d0f31bb5d5f2_del
2022-02-22 02:30:28.929 7 INFO nova.virt.libvirt.driver [req-c2c03695-be37-439f-a941-f80ddd4c3530 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Deletion of /var/lib/nova/instances/758a4a69-94e7-4505-8d7b-d0f31bb5d5f2_del complete
2022-02-22 02:30:28.996 7 INFO nova.compute.manager [req-c2c03695-be37-439f-a941-f80ddd4c3530 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:30:29.068 7 INFO nova.compute.manager [-] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:30:29.264 7 INFO nova.scheduler.client.report [req-c2c03695-be37-439f-a941-f80ddd4c3530 c39e049a67364f23bbfc82b5ff6348d4 fdb6fb5b5b4249638516f76eb43da416 - default default] Deleted allocations for instance 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2
2022-02-22 02:30:38.102 7 INFO nova.compute.manager [-] [instance: d159590e-a640-4c76-91b1-980c58c2800a] VM Stopped (Lifecycle Event)
2022-02-22 02:30:43.906 7 INFO nova.compute.manager [-] [instance: 758a4a69-94e7-4505-8d7b-d0f31bb5d5f2] VM Stopped (Lifecycle Event)
