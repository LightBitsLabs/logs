Build Started 21_02_2022_15_52_06
2022-02-21 17:57:07.470 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-21 17:57:11.419 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-21 17:57:12.305 7 INFO nova.virt.driver [req-3558f698-da92-4a36-a4ef-51b82a068e34 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-21 17:57:12.699 7 INFO nova.compute.provider_config [req-3558f698-da92-4a36-a4ef-51b82a068e34 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-21 17:57:12.719 7 WARNING oslo_config.cfg [req-3558f698-da92-4a36-a4ef-51b82a068e34 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-21 17:57:12.739 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-21 17:57:12.753 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-21 17:57:12.788 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-21 17:57:12.896 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-21 17:57:12.911 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-21 17:57:12.914 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-21 17:57:13.307 7 INFO nova.compute.manager [req-3faa82ff-1f83-4269-9c6b-0a072f779249 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-21 17:57:13.451 7 INFO nova.service [req-3faa82ff-1f83-4269-9c6b-0a072f779249 - - - - -] Updating service version for nova-compute on rack08-server63 from 60 to 61
2022-02-21 17:57:15.188 7 INFO nova.virt.libvirt.host [req-3faa82ff-1f83-4269-9c6b-0a072f779249 - - - - -] kernel doesn't support AMD SEV
2022-02-21 17:58:06.345 7 INFO nova.compute.claims [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Claim successful on node rack08-server63
2022-02-21 17:58:06.790 7 INFO nova.virt.libvirt.driver [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Creating image
2022-02-21 17:58:06.796 7 INFO oslo.privsep.daemon [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpqdwh6nr2/privsep.sock']
2022-02-21 17:58:08.446 7 INFO oslo.privsep.daemon [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Spawned new privsep daemon via rootwrap
2022-02-21 17:58:08.285 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 17:58:08.291 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 17:58:08.297 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-21 17:58:08.297 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-21 17:58:09.670 7 INFO nova.compute.manager [-] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] VM Resumed (Lifecycle Event)
2022-02-21 17:58:09.678 7 INFO nova.virt.libvirt.driver [-] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Instance spawned successfully.
2022-02-21 17:58:09.679 7 INFO nova.compute.manager [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Took 2.89 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:09.721 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:09.721 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] VM Started (Lifecycle Event)
2022-02-21 17:58:09.767 7 INFO nova.compute.manager [req-bb9ef289-8253-4271-8d77-c19415790e02 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Took 3.46 seconds to build instance.
2022-02-21 17:58:13.051 7 INFO nova.compute.manager [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Attaching volume 80602a6c-6f77-4c86-9f8c-c809edd6dcd1 to /dev/vdb
2022-02-21 17:58:13.131 7 INFO oslo.privsep.daemon [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpuqw_5kzm/privsep.sock']
2022-02-21 17:58:13.995 7 INFO oslo.privsep.daemon [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Spawned new privsep daemon via rootwrap
2022-02-21 17:58:13.713 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 17:58:13.720 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 17:58:13.725 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-21 17:58:13.725 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-21 17:58:14.324 7 WARNING os_brick.initiator.connectors.nvmeof [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:58:15.740 7 INFO os_brick.initiator.connectors.lightos [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 2209a861-bc56-46a8-8ef9-ef1e950bbf99, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2209a861-bc56-46a8-8ef9-ef1e950bbf99', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:58:15.775 7 INFO os_brick.initiator.connectors.lightos [req-873d5cdc-62ad-4cb7-9f93-e648f6818554 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2209a861-bc56-46a8-8ef9-ef1e950bbf99
2022-02-21 17:58:17.749 7 INFO nova.compute.claims [req-68b58865-b3e4-4763-8e8b-caea70d288aa a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Claim successful on node rack08-server63
2022-02-21 17:58:18.151 7 INFO nova.virt.libvirt.driver [req-68b58865-b3e4-4763-8e8b-caea70d288aa a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Creating image
2022-02-21 17:58:19.283 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] VM Resumed (Lifecycle Event)
2022-02-21 17:58:19.291 7 INFO nova.virt.libvirt.driver [-] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Instance spawned successfully.
2022-02-21 17:58:19.292 7 INFO nova.compute.manager [req-68b58865-b3e4-4763-8e8b-caea70d288aa a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:19.341 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:19.342 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] VM Started (Lifecycle Event)
2022-02-21 17:58:19.380 7 INFO nova.compute.manager [req-68b58865-b3e4-4763-8e8b-caea70d288aa a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Took 1.67 seconds to build instance.
2022-02-21 17:58:20.447 7 INFO nova.compute.claims [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Claim successful on node rack08-server63
2022-02-21 17:58:20.714 7 INFO nova.virt.libvirt.driver [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 17:58:20.807 7 INFO nova.virt.block_device [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Booting with volume 9c5a0fdd-fc46-42b0-b8f4-b751f84f5797 at /dev/vda
2022-02-21 17:58:20.891 7 WARNING os_brick.initiator.connectors.nvmeof [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:58:20.897 7 INFO nova.compute.manager [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Detaching volume 80602a6c-6f77-4c86-9f8c-c809edd6dcd1
2022-02-21 17:58:20.976 7 INFO nova.virt.block_device [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Attempting to driver detach volume 80602a6c-6f77-4c86-9f8c-c809edd6dcd1 from mountpoint /dev/vdb
2022-02-21 17:58:20.999 7 INFO nova.virt.libvirt.driver [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance 6365ed6a-6aa8-456a-ac22-ecec61dcce17 from the persistent domain config.
2022-02-21 17:58:21.143 7 INFO nova.virt.libvirt.driver [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance 6365ed6a-6aa8-456a-ac22-ecec61dcce17 from the live domain config.
2022-02-21 17:58:21.146 7 INFO os_brick.initiator.connectors.lightos [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 2209a861-bc56-46a8-8ef9-ef1e950bbf99, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2209a861-bc56-46a8-8ef9-ef1e950bbf99', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 17:58:21.147 7 INFO os_brick.initiator.connectors.lightos [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2209a861-bc56-46a8-8ef9-ef1e950bbf99
2022-02-21 17:58:21.148 7 INFO os_brick.initiator.connectors.lightos [req-937e6c1b-b33d-41d1-ab9d-e7ffec340bf5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2209a861-bc56-46a8-8ef9-ef1e950bbf99
2022-02-21 17:58:22.415 7 INFO nova.virt.libvirt.driver [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Creating image
2022-02-21 17:58:22.425 7 INFO os_brick.initiator.connectors.lightos [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:58:22.428 7 INFO os_brick.initiator.connectors.lightos [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f
2022-02-21 17:58:23.267 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] VM Resumed (Lifecycle Event)
2022-02-21 17:58:23.274 7 INFO nova.virt.libvirt.driver [-] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Instance spawned successfully.
2022-02-21 17:58:23.275 7 INFO nova.compute.manager [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Took 0.86 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:23.323 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:23.324 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] VM Started (Lifecycle Event)
2022-02-21 17:58:23.356 7 INFO nova.compute.manager [req-1c4fcba9-5bcf-430f-8c95-26a1b00529a5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Took 2.95 seconds to build instance.
2022-02-21 17:58:24.448 7 INFO nova.compute.claims [req-1043d680-c012-41ac-8d6b-7f51188c2672 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Claim successful on node rack08-server63
2022-02-21 17:58:24.882 7 INFO nova.virt.libvirt.driver [req-1043d680-c012-41ac-8d6b-7f51188c2672 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Creating image
2022-02-21 17:58:25.560 7 INFO nova.compute.claims [req-8d62a9be-ecf5-48c4-b9ec-bb71e9c7eff1 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Claim successful on node rack08-server63
2022-02-21 17:58:25.926 7 INFO nova.virt.libvirt.driver [req-8d62a9be-ecf5-48c4-b9ec-bb71e9c7eff1 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Creating image
2022-02-21 17:58:26.070 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] VM Resumed (Lifecycle Event)
2022-02-21 17:58:26.075 7 INFO nova.virt.libvirt.driver [-] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Instance spawned successfully.
2022-02-21 17:58:26.076 7 INFO nova.compute.manager [req-1043d680-c012-41ac-8d6b-7f51188c2672 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:26.143 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:26.144 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] VM Started (Lifecycle Event)
2022-02-21 17:58:26.155 7 INFO nova.compute.manager [req-1043d680-c012-41ac-8d6b-7f51188c2672 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Took 1.75 seconds to build instance.
2022-02-21 17:58:26.178 7 INFO nova.compute.claims [req-3419d994-ebfd-4b16-8dd3-8106deeaeba5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Claim successful on node rack08-server63
2022-02-21 17:58:26.560 7 INFO nova.virt.libvirt.driver [req-3419d994-ebfd-4b16-8dd3-8106deeaeba5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Creating image
2022-02-21 17:58:27.078 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] VM Resumed (Lifecycle Event)
2022-02-21 17:58:27.089 7 INFO nova.virt.libvirt.driver [-] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Instance spawned successfully.
2022-02-21 17:58:27.089 7 INFO nova.compute.manager [req-8d62a9be-ecf5-48c4-b9ec-bb71e9c7eff1 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:27.135 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:27.136 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] VM Started (Lifecycle Event)
2022-02-21 17:58:27.177 7 INFO nova.compute.manager [req-8d62a9be-ecf5-48c4-b9ec-bb71e9c7eff1 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Took 1.65 seconds to build instance.
2022-02-21 17:58:27.732 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] VM Resumed (Lifecycle Event)
2022-02-21 17:58:27.738 7 INFO nova.virt.libvirt.driver [-] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Instance spawned successfully.
2022-02-21 17:58:27.738 7 INFO nova.compute.manager [req-3419d994-ebfd-4b16-8dd3-8106deeaeba5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:27.785 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:27.785 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] VM Started (Lifecycle Event)
2022-02-21 17:58:27.823 7 INFO nova.compute.manager [req-3419d994-ebfd-4b16-8dd3-8106deeaeba5 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Took 1.69 seconds to build instance.
2022-02-21 17:58:29.879 7 INFO nova.compute.manager [req-17b5e20c-6cc3-440b-a4e5-deaf32e15f3c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Attaching volume d98d553a-5114-4df8-bfe1-925910d6f233 to /dev/vdb
2022-02-21 17:58:29.944 7 INFO nova.compute.manager [req-07a4231f-81a8-4df3-b583-ea94a5996dc2 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Attaching volume 2e4c54f6-6076-41d8-abda-b91176a85ba3 to /dev/vdb
2022-02-21 17:58:29.968 7 WARNING os_brick.initiator.connectors.nvmeof [req-17b5e20c-6cc3-440b-a4e5-deaf32e15f3c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:58:30.027 7 WARNING os_brick.initiator.connectors.nvmeof [req-07a4231f-81a8-4df3-b583-ea94a5996dc2 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:58:31.366 7 INFO os_brick.initiator.connectors.lightos [req-17b5e20c-6cc3-440b-a4e5-deaf32e15f3c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 09ec2f7b-dc2b-46ad-b03d-445b14854521, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '09ec2f7b-dc2b-46ad-b03d-445b14854521', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:58:31.370 7 INFO os_brick.initiator.connectors.lightos [req-17b5e20c-6cc3-440b-a4e5-deaf32e15f3c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521
2022-02-21 17:58:31.381 7 INFO os_brick.initiator.connectors.lightos [req-07a4231f-81a8-4df3-b583-ea94a5996dc2 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 9cbe9069-0e28-4103-9a40-b91a16129c8f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9cbe9069-0e28-4103-9a40-b91a16129c8f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:58:31.383 7 INFO os_brick.initiator.connectors.lightos [req-07a4231f-81a8-4df3-b583-ea94a5996dc2 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9cbe9069-0e28-4103-9a40-b91a16129c8f
2022-02-21 17:58:32.365 7 INFO nova.compute.manager [req-40eeada3-dd31-46c6-85ca-70cadf3f18b3 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Attaching volume d98d553a-5114-4df8-bfe1-925910d6f233 to /dev/vdb
2022-02-21 17:58:32.452 7 WARNING os_brick.initiator.connectors.nvmeof [req-40eeada3-dd31-46c6-85ca-70cadf3f18b3 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:58:32.525 7 INFO nova.compute.manager [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Detaching volume 2e4c54f6-6076-41d8-abda-b91176a85ba3
2022-02-21 17:58:32.798 7 INFO nova.virt.block_device [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Attempting to driver detach volume 2e4c54f6-6076-41d8-abda-b91176a85ba3 from mountpoint /dev/vdb
2022-02-21 17:58:32.816 7 INFO nova.virt.libvirt.driver [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance bc35dd15-26e3-44be-860a-76ece85c0362 from the persistent domain config.
2022-02-21 17:58:32.957 7 INFO nova.virt.libvirt.driver [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance bc35dd15-26e3-44be-860a-76ece85c0362 from the live domain config.
2022-02-21 17:58:32.960 7 INFO os_brick.initiator.connectors.lightos [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 9cbe9069-0e28-4103-9a40-b91a16129c8f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9cbe9069-0e28-4103-9a40-b91a16129c8f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 17:58:32.961 7 INFO os_brick.initiator.connectors.lightos [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9cbe9069-0e28-4103-9a40-b91a16129c8f
2022-02-21 17:58:32.962 7 INFO os_brick.initiator.connectors.lightos [req-038d68d0-6573-4884-b693-2ea159aba1d5 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9cbe9069-0e28-4103-9a40-b91a16129c8f
2022-02-21 17:58:33.865 7 INFO os_brick.initiator.connectors.lightos [req-40eeada3-dd31-46c6-85ca-70cadf3f18b3 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 09ec2f7b-dc2b-46ad-b03d-445b14854521, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '09ec2f7b-dc2b-46ad-b03d-445b14854521', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:58:33.866 7 INFO os_brick.initiator.connectors.lightos [req-40eeada3-dd31-46c6-85ca-70cadf3f18b3 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521
2022-02-21 17:58:34.918 7 INFO nova.compute.manager [req-e44a6745-79fe-4c84-9067-224d6c233e66 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Detaching volume d98d553a-5114-4df8-bfe1-925910d6f233
2022-02-21 17:58:34.982 7 INFO nova.virt.block_device [req-e44a6745-79fe-4c84-9067-224d6c233e66 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Attempting to driver detach volume d98d553a-5114-4df8-bfe1-925910d6f233 from mountpoint /dev/vdb
2022-02-21 17:58:35.002 7 INFO nova.virt.libvirt.driver [req-e44a6745-79fe-4c84-9067-224d6c233e66 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Successfully detached device vdb from instance d48f6e02-e4fa-4422-8fb6-331b56299d19 from the persistent domain config.
2022-02-21 17:58:35.153 7 INFO nova.virt.libvirt.driver [req-e44a6745-79fe-4c84-9067-224d6c233e66 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Successfully detached device vdb from instance d48f6e02-e4fa-4422-8fb6-331b56299d19 from the live domain config.
2022-02-21 17:58:35.226 7 INFO nova.virt.libvirt.driver [req-e44a6745-79fe-4c84-9067-224d6c233e66 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Detected multiple connections on this host for volume: d98d553a-5114-4df8-bfe1-925910d6f233, skipping target disconnect.
2022-02-21 17:58:35.892 7 INFO nova.compute.claims [req-6df1606b-3c86-40ca-bd07-b30e6cb4ccff a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Claim successful on node rack08-server63
2022-02-21 17:58:36.281 7 INFO nova.virt.libvirt.driver [req-6df1606b-3c86-40ca-bd07-b30e6cb4ccff a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Creating image
2022-02-21 17:58:37.385 7 INFO nova.compute.manager [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Detaching volume d98d553a-5114-4df8-bfe1-925910d6f233
2022-02-21 17:58:37.437 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] VM Resumed (Lifecycle Event)
2022-02-21 17:58:37.445 7 INFO nova.virt.block_device [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Attempting to driver detach volume d98d553a-5114-4df8-bfe1-925910d6f233 from mountpoint /dev/vdb
2022-02-21 17:58:37.452 7 INFO nova.virt.libvirt.driver [-] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Instance spawned successfully.
2022-02-21 17:58:37.453 7 INFO nova.compute.manager [req-6df1606b-3c86-40ca-bd07-b30e6cb4ccff a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-21 17:58:37.478 7 INFO nova.virt.libvirt.driver [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Successfully detached device vdb from instance e24b6554-6132-4e26-8b5a-fbea6341aa87 from the persistent domain config.
2022-02-21 17:58:37.502 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:58:37.503 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] VM Started (Lifecycle Event)
2022-02-21 17:58:37.554 7 INFO nova.compute.manager [req-6df1606b-3c86-40ca-bd07-b30e6cb4ccff a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Took 1.70 seconds to build instance.
2022-02-21 17:58:37.646 7 INFO nova.virt.libvirt.driver [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Successfully detached device vdb from instance e24b6554-6132-4e26-8b5a-fbea6341aa87 from the live domain config.
2022-02-21 17:58:37.700 7 INFO os_brick.initiator.connectors.lightos [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 09ec2f7b-dc2b-46ad-b03d-445b14854521, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '09ec2f7b-dc2b-46ad-b03d-445b14854521', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 17:58:40.543 7 INFO nova.compute.manager [req-d6942899-b1e9-4cd2-875b-3dd9c1edc063 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Attaching volume 933e4c9e-530f-4ebe-ae20-c8a29f3f8b3b to /dev/vdb
2022-02-21 17:58:40.634 7 WARNING os_brick.initiator.connectors.nvmeof [req-d6942899-b1e9-4cd2-875b-3dd9c1edc063 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 17:59:25.206 7 INFO nova.compute.claims [req-7567ed76-d88b-420a-8d22-b22ab6c84703 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Claim successful on node rack08-server63
2022-02-21 17:59:25.620 7 INFO nova.virt.libvirt.driver [req-7567ed76-d88b-420a-8d22-b22ab6c84703 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Creating image
2022-02-21 17:59:26.797 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] VM Resumed (Lifecycle Event)
2022-02-21 17:59:26.806 7 INFO nova.virt.libvirt.driver [-] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Instance spawned successfully.
2022-02-21 17:59:26.807 7 INFO nova.compute.manager [req-7567ed76-d88b-420a-8d22-b22ab6c84703 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 17:59:26.859 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 17:59:26.859 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] VM Started (Lifecycle Event)
2022-02-21 17:59:26.892 7 INFO nova.compute.manager [req-7567ed76-d88b-420a-8d22-b22ab6c84703 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Took 1.73 seconds to build instance.
2022-02-21 17:59:31.821 7 INFO nova.compute.manager [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Terminating instance
2022-02-21 17:59:32.209 7 INFO nova.virt.libvirt.driver [-] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Instance destroyed successfully.
2022-02-21 17:59:32.230 7 INFO nova.virt.libvirt.driver [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Deleting instance files /var/lib/nova/instances/8ef12c94-07e9-48d5-844a-6360150fa9e3_del
2022-02-21 17:59:32.232 7 INFO nova.virt.libvirt.driver [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Deletion of /var/lib/nova/instances/8ef12c94-07e9-48d5-844a-6360150fa9e3_del complete
2022-02-21 17:59:32.299 7 INFO nova.virt.libvirt.host [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] UEFI support detected
2022-02-21 17:59:32.301 7 INFO nova.compute.manager [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 17:59:32.367 7 INFO nova.compute.manager [-] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] Took 0.07 seconds to deallocate network for instance.
2022-02-21 17:59:32.564 7 INFO nova.scheduler.client.report [req-71772197-909a-4786-a0ca-75949cb63188 068c9c7505244c26944958c4042ceded cfd52f7a64d8475d85d84be3cdecc332 - default default] Deleted allocations for instance 8ef12c94-07e9-48d5-844a-6360150fa9e3
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Failed to detach volume d98d553a-5114-4df8-bfe1-925910d6f233 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Traceback (most recent call last):
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2613, in detach_volume
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1879, in _disconnect_volume
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     return f(*args, **kwargs)
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     return f(*args, **kwargs)
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     raise exception.BrickException(message=msg)
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 17:59:37.890 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] 
2022-02-21 17:59:37.902 7 INFO os_brick.initiator.connectors.lightos [req-d6942899-b1e9-4cd2-875b-3dd9c1edc063 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 714c47d9-1cc5-44d3-ab85-7b101f6ae220, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '714c47d9-1cc5-44d3-ab85-7b101f6ae220', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 17:59:37.905 7 INFO os_brick.initiator.connectors.lightos [req-d6942899-b1e9-4cd2-875b-3dd9c1edc063 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 714c47d9-1cc5-44d3-ab85-7b101f6ae220
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server [req-88e140af-6052-4563-b4a8-34952816a488 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2613, in detach_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1879, in _disconnect_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 17:59:37.995 7 ERROR oslo_messaging.rpc.server 
2022-02-21 17:59:39.126 7 INFO nova.compute.manager [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Detaching volume 933e4c9e-530f-4ebe-ae20-c8a29f3f8b3b
2022-02-21 17:59:39.183 7 INFO nova.virt.block_device [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Attempting to driver detach volume 933e4c9e-530f-4ebe-ae20-c8a29f3f8b3b from mountpoint /dev/vdb
2022-02-21 17:59:39.202 7 INFO nova.virt.libvirt.driver [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance 1afc2362-5093-4e40-b31c-4deeca93d50f from the persistent domain config.
2022-02-21 17:59:39.355 7 INFO nova.virt.libvirt.driver [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Successfully detached device vdb from instance 1afc2362-5093-4e40-b31c-4deeca93d50f from the live domain config.
2022-02-21 17:59:39.358 7 INFO os_brick.initiator.connectors.lightos [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: connect_volume called for volume 714c47d9-1cc5-44d3-ab85-7b101f6ae220, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '714c47d9-1cc5-44d3-ab85-7b101f6ae220', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 17:59:39.359 7 INFO os_brick.initiator.connectors.lightos [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 714c47d9-1cc5-44d3-ab85-7b101f6ae220
2022-02-21 17:59:39.360 7 INFO os_brick.initiator.connectors.lightos [req-1405d9cd-9f58-48ef-9f8d-595e7d3a23c1 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 714c47d9-1cc5-44d3-ab85-7b101f6ae220
2022-02-21 17:59:42.557 7 INFO nova.compute.manager [req-74ec9281-c703-4597-b3d6-c82f9ca5b159 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Terminating instance
2022-02-21 17:59:42.900 7 INFO nova.virt.libvirt.driver [-] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Instance destroyed successfully.
2022-02-21 17:59:42.913 7 INFO nova.virt.libvirt.driver [req-74ec9281-c703-4597-b3d6-c82f9ca5b159 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Deleting instance files /var/lib/nova/instances/1afc2362-5093-4e40-b31c-4deeca93d50f_del
2022-02-21 17:59:42.915 7 INFO nova.virt.libvirt.driver [req-74ec9281-c703-4597-b3d6-c82f9ca5b159 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Deletion of /var/lib/nova/instances/1afc2362-5093-4e40-b31c-4deeca93d50f_del complete
2022-02-21 17:59:42.980 7 INFO nova.compute.manager [req-74ec9281-c703-4597-b3d6-c82f9ca5b159 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 17:59:43.047 7 INFO nova.compute.manager [-] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] Took 0.07 seconds to deallocate network for instance.
2022-02-21 17:59:43.239 7 INFO nova.scheduler.client.report [req-74ec9281-c703-4597-b3d6-c82f9ca5b159 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Deleted allocations for instance 1afc2362-5093-4e40-b31c-4deeca93d50f
2022-02-21 17:59:44.957 7 INFO nova.compute.manager [req-7954d16a-8484-4053-b2a8-7189dd77de28 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Terminating instance
2022-02-21 17:59:45.294 7 INFO nova.virt.libvirt.driver [-] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Instance destroyed successfully.
2022-02-21 17:59:45.312 7 INFO nova.virt.libvirt.driver [req-7954d16a-8484-4053-b2a8-7189dd77de28 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Deleting instance files /var/lib/nova/instances/bc35dd15-26e3-44be-860a-76ece85c0362_del
2022-02-21 17:59:45.314 7 INFO nova.virt.libvirt.driver [req-7954d16a-8484-4053-b2a8-7189dd77de28 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Deletion of /var/lib/nova/instances/bc35dd15-26e3-44be-860a-76ece85c0362_del complete
2022-02-21 17:59:45.381 7 INFO nova.compute.manager [req-7954d16a-8484-4053-b2a8-7189dd77de28 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 17:59:45.452 7 INFO nova.compute.manager [-] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] Took 0.07 seconds to deallocate network for instance.
2022-02-21 17:59:45.649 7 INFO nova.scheduler.client.report [req-7954d16a-8484-4053-b2a8-7189dd77de28 a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Deleted allocations for instance bc35dd15-26e3-44be-860a-76ece85c0362
2022-02-21 17:59:46.195 7 INFO nova.compute.manager [req-8ec55770-9539-436b-af52-6821155e436b a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Terminating instance
2022-02-21 17:59:46.546 7 INFO nova.virt.libvirt.driver [-] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Instance destroyed successfully.
2022-02-21 17:59:46.559 7 INFO nova.virt.libvirt.driver [req-8ec55770-9539-436b-af52-6821155e436b a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Deleting instance files /var/lib/nova/instances/f3fa1bbb-ba89-4e3b-8158-12cfa402555d_del
2022-02-21 17:59:46.560 7 INFO nova.virt.libvirt.driver [req-8ec55770-9539-436b-af52-6821155e436b a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Deletion of /var/lib/nova/instances/f3fa1bbb-ba89-4e3b-8158-12cfa402555d_del complete
2022-02-21 17:59:46.623 7 INFO nova.compute.manager [req-8ec55770-9539-436b-af52-6821155e436b a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 17:59:46.699 7 INFO nova.compute.manager [-] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] Took 0.08 seconds to deallocate network for instance.
2022-02-21 17:59:46.886 7 INFO nova.scheduler.client.report [req-8ec55770-9539-436b-af52-6821155e436b a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Deleted allocations for instance f3fa1bbb-ba89-4e3b-8158-12cfa402555d
2022-02-21 17:59:47.206 7 INFO nova.compute.manager [-] [instance: 8ef12c94-07e9-48d5-844a-6360150fa9e3] VM Stopped (Lifecycle Event)
2022-02-21 17:59:48.792 7 INFO nova.compute.manager [req-2724ce89-efe7-444c-b0a8-24b8e191c62c a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Terminating instance
2022-02-21 17:59:49.129 7 INFO nova.virt.libvirt.driver [-] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Instance destroyed successfully.
2022-02-21 17:59:49.145 7 INFO nova.virt.libvirt.driver [req-2724ce89-efe7-444c-b0a8-24b8e191c62c a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Deleting instance files /var/lib/nova/instances/6365ed6a-6aa8-456a-ac22-ecec61dcce17_del
2022-02-21 17:59:49.147 7 INFO nova.virt.libvirt.driver [req-2724ce89-efe7-444c-b0a8-24b8e191c62c a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Deletion of /var/lib/nova/instances/6365ed6a-6aa8-456a-ac22-ecec61dcce17_del complete
2022-02-21 17:59:49.212 7 INFO nova.compute.manager [req-2724ce89-efe7-444c-b0a8-24b8e191c62c a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 17:59:49.279 7 INFO nova.compute.manager [-] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] Took 0.07 seconds to deallocate network for instance.
2022-02-21 17:59:49.446 7 INFO nova.scheduler.client.report [req-2724ce89-efe7-444c-b0a8-24b8e191c62c a3752e29c2104b5ba5a5b57762590cdc 792cefc7c08743e190c02c30701c598e - default default] Deleted allocations for instance 6365ed6a-6aa8-456a-ac22-ecec61dcce17
2022-02-21 17:59:57.898 7 INFO nova.compute.manager [-] [instance: 1afc2362-5093-4e40-b31c-4deeca93d50f] VM Stopped (Lifecycle Event)
2022-02-21 18:00:00.291 7 INFO nova.compute.manager [-] [instance: bc35dd15-26e3-44be-860a-76ece85c0362] VM Stopped (Lifecycle Event)
2022-02-21 18:00:01.543 7 INFO nova.compute.manager [-] [instance: f3fa1bbb-ba89-4e3b-8158-12cfa402555d] VM Stopped (Lifecycle Event)
2022-02-21 18:00:04.128 7 INFO nova.compute.manager [-] [instance: 6365ed6a-6aa8-456a-ac22-ecec61dcce17] VM Stopped (Lifecycle Event)
2022-02-21 18:00:20.333 7 INFO nova.compute.claims [req-1da583eb-5138-4c0c-8e30-4f0064fc0f2b 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Claim successful on node rack08-server63
2022-02-21 18:00:20.700 7 INFO nova.virt.libvirt.driver [req-1da583eb-5138-4c0c-8e30-4f0064fc0f2b 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Creating image
2022-02-21 18:00:21.827 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] VM Resumed (Lifecycle Event)
2022-02-21 18:00:21.834 7 INFO nova.virt.libvirt.driver [-] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Instance spawned successfully.
2022-02-21 18:00:21.835 7 INFO nova.compute.manager [req-1da583eb-5138-4c0c-8e30-4f0064fc0f2b 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-21 18:00:21.883 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:00:21.884 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] VM Started (Lifecycle Event)
2022-02-21 18:00:21.925 7 INFO nova.compute.manager [req-1da583eb-5138-4c0c-8e30-4f0064fc0f2b 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Took 1.63 seconds to build instance.
2022-02-21 18:00:26.768 7 INFO nova.compute.manager [req-d924919a-24a2-4c49-869f-35a98e1b77d0 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Terminating instance
2022-02-21 18:00:27.115 7 INFO nova.virt.libvirt.driver [-] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Instance destroyed successfully.
2022-02-21 18:00:27.132 7 INFO nova.virt.libvirt.driver [req-d924919a-24a2-4c49-869f-35a98e1b77d0 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Deleting instance files /var/lib/nova/instances/fd116973-688a-43cf-96ad-86ca8b13cca4_del
2022-02-21 18:00:27.133 7 INFO nova.virt.libvirt.driver [req-d924919a-24a2-4c49-869f-35a98e1b77d0 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Deletion of /var/lib/nova/instances/fd116973-688a-43cf-96ad-86ca8b13cca4_del complete
2022-02-21 18:00:27.204 7 INFO nova.compute.manager [req-d924919a-24a2-4c49-869f-35a98e1b77d0 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:00:27.274 7 INFO nova.compute.manager [-] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:00:27.478 7 INFO nova.scheduler.client.report [req-d924919a-24a2-4c49-869f-35a98e1b77d0 2605cd8f321b44439ce7d5fd8b68ff81 7cfda224c60e47c1bd016c0ef4308277 - default default] Deleted allocations for instance fd116973-688a-43cf-96ad-86ca8b13cca4
2022-02-21 18:00:36.142 7 INFO nova.compute.claims [req-4a969153-49b1-40ee-acc6-da5253bc4fae 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Claim successful on node rack08-server63
2022-02-21 18:00:36.555 7 INFO nova.virt.libvirt.driver [req-4a969153-49b1-40ee-acc6-da5253bc4fae 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Creating image
2022-02-21 18:00:37.694 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] VM Resumed (Lifecycle Event)
2022-02-21 18:00:37.702 7 INFO nova.virt.libvirt.driver [-] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Instance spawned successfully.
2022-02-21 18:00:37.703 7 INFO nova.compute.manager [req-4a969153-49b1-40ee-acc6-da5253bc4fae 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-21 18:00:37.754 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:00:37.754 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] VM Started (Lifecycle Event)
2022-02-21 18:00:37.801 7 INFO nova.compute.manager [req-4a969153-49b1-40ee-acc6-da5253bc4fae 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Took 1.70 seconds to build instance.
2022-02-21 18:00:39.040 7 INFO nova.virt.libvirt.driver [req-91b3f5e9-8f36-4fee-96ae-6f2163ef35f4 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Ignoring supplied device name: /dev/vdb
2022-02-21 18:00:39.196 7 INFO nova.compute.manager [req-91b3f5e9-8f36-4fee-96ae-6f2163ef35f4 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Attaching volume c7f85295-e997-46ef-909d-d43f814059d4 to /dev/vdb
2022-02-21 18:00:39.288 7 WARNING os_brick.initiator.connectors.nvmeof [req-91b3f5e9-8f36-4fee-96ae-6f2163ef35f4 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 18:00:40.645 7 INFO os_brick.initiator.connectors.lightos [req-91b3f5e9-8f36-4fee-96ae-6f2163ef35f4 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] LIGHTOS: connect_volume called for volume 69575398-6510-4640-acd3-d371435ad1c7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '69575398-6510-4640-acd3-d371435ad1c7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 18:00:40.650 7 INFO os_brick.initiator.connectors.lightos [req-91b3f5e9-8f36-4fee-96ae-6f2163ef35f4 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69575398-6510-4640-acd3-d371435ad1c7
2022-02-21 18:00:42.113 7 INFO nova.compute.manager [-] [instance: fd116973-688a-43cf-96ad-86ca8b13cca4] VM Stopped (Lifecycle Event)
2022-02-21 18:00:42.765 7 INFO nova.compute.manager [req-b9854ab5-ab72-409c-a1d3-d1747faa9627 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Cinder extended volume c7f85295-e997-46ef-909d-d43f814059d4; extending it to detect new size
2022-02-21 18:00:42.837 7 INFO os_brick.initiator.connectors.lightos [req-b9854ab5-ab72-409c-a1d3-d1747faa9627 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69575398-6510-4640-acd3-d371435ad1c7
2022-02-21 18:00:43.382 7 INFO nova.compute.manager [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Detaching volume c7f85295-e997-46ef-909d-d43f814059d4
2022-02-21 18:00:43.436 7 INFO nova.virt.block_device [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Attempting to driver detach volume c7f85295-e997-46ef-909d-d43f814059d4 from mountpoint /dev/vdb
2022-02-21 18:00:43.456 7 INFO nova.virt.libvirt.driver [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] Successfully detached device vdb from instance a2f55f06-fd2a-40a8-bb9b-d5d6212686fa from the persistent domain config.
2022-02-21 18:00:43.597 7 INFO nova.virt.libvirt.driver [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] Successfully detached device vdb from instance a2f55f06-fd2a-40a8-bb9b-d5d6212686fa from the live domain config.
2022-02-21 18:00:43.600 7 INFO os_brick.initiator.connectors.lightos [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] LIGHTOS: connect_volume called for volume 69575398-6510-4640-acd3-d371435ad1c7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '69575398-6510-4640-acd3-d371435ad1c7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 18:00:43.600 7 INFO os_brick.initiator.connectors.lightos [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69575398-6510-4640-acd3-d371435ad1c7
2022-02-21 18:00:43.601 7 INFO os_brick.initiator.connectors.lightos [req-f0c2f665-3f4f-4869-bb16-c20d474a625a 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69575398-6510-4640-acd3-d371435ad1c7
2022-02-21 18:00:45.617 7 INFO nova.compute.manager [req-8dc56317-8417-4c9c-8948-98226f626098 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Terminating instance
2022-02-21 18:00:45.963 7 INFO nova.virt.libvirt.driver [-] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Instance destroyed successfully.
2022-02-21 18:00:45.978 7 INFO nova.virt.libvirt.driver [req-8dc56317-8417-4c9c-8948-98226f626098 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Deleting instance files /var/lib/nova/instances/a2f55f06-fd2a-40a8-bb9b-d5d6212686fa_del
2022-02-21 18:00:45.979 7 INFO nova.virt.libvirt.driver [req-8dc56317-8417-4c9c-8948-98226f626098 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Deletion of /var/lib/nova/instances/a2f55f06-fd2a-40a8-bb9b-d5d6212686fa_del complete
2022-02-21 18:00:46.048 7 INFO nova.compute.manager [req-8dc56317-8417-4c9c-8948-98226f626098 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:00:46.113 7 INFO nova.compute.manager [-] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] Took 0.06 seconds to deallocate network for instance.
2022-02-21 18:00:46.321 7 INFO nova.scheduler.client.report [req-8dc56317-8417-4c9c-8948-98226f626098 340172bdf9544b38afda2c8c33d32499 1d481bd193f94802bc7d33907913dbac - default default] Deleted allocations for instance a2f55f06-fd2a-40a8-bb9b-d5d6212686fa
2022-02-21 18:01:00.960 7 INFO nova.compute.manager [-] [instance: a2f55f06-fd2a-40a8-bb9b-d5d6212686fa] VM Stopped (Lifecycle Event)
2022-02-21 18:01:09.768 7 INFO nova.compute.claims [req-bbd78299-fb71-495f-b5bb-210458a0dc9a 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Claim successful on node rack08-server63
2022-02-21 18:01:10.164 7 INFO nova.virt.libvirt.driver [req-bbd78299-fb71-495f-b5bb-210458a0dc9a 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Creating image
2022-02-21 18:01:11.318 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] VM Resumed (Lifecycle Event)
2022-02-21 18:01:11.326 7 INFO nova.virt.libvirt.driver [-] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Instance spawned successfully.
2022-02-21 18:01:11.327 7 INFO nova.compute.manager [req-bbd78299-fb71-495f-b5bb-210458a0dc9a 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 18:01:11.373 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:01:11.374 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] VM Started (Lifecycle Event)
2022-02-21 18:01:11.414 7 INFO nova.compute.manager [req-bbd78299-fb71-495f-b5bb-210458a0dc9a 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Took 1.68 seconds to build instance.
2022-02-21 18:01:11.723 7 INFO nova.compute.manager [req-8ccfd8b1-cc0e-4519-972a-598dfd56b10b 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Terminating instance
2022-02-21 18:01:12.061 7 INFO nova.virt.libvirt.driver [-] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Instance destroyed successfully.
2022-02-21 18:01:12.076 7 INFO nova.virt.libvirt.driver [req-8ccfd8b1-cc0e-4519-972a-598dfd56b10b 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Deleting instance files /var/lib/nova/instances/9ddea6b9-1721-4970-99bb-0cfc31663b2d_del
2022-02-21 18:01:12.078 7 INFO nova.virt.libvirt.driver [req-8ccfd8b1-cc0e-4519-972a-598dfd56b10b 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Deletion of /var/lib/nova/instances/9ddea6b9-1721-4970-99bb-0cfc31663b2d_del complete
2022-02-21 18:01:12.147 7 INFO nova.compute.manager [req-8ccfd8b1-cc0e-4519-972a-598dfd56b10b 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:01:12.216 7 INFO nova.compute.manager [-] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:01:12.413 7 INFO nova.scheduler.client.report [req-8ccfd8b1-cc0e-4519-972a-598dfd56b10b 4dfb3b44f7514d2dafe74c6d4e88be5d 0bc9025c1dcd4afd9308b43e14823efc - default default] Deleted allocations for instance 9ddea6b9-1721-4970-99bb-0cfc31663b2d
2022-02-21 18:01:27.058 7 INFO nova.compute.manager [-] [instance: 9ddea6b9-1721-4970-99bb-0cfc31663b2d] VM Stopped (Lifecycle Event)
2022-02-21 18:02:46.831 7 INFO nova.compute.claims [req-50ed0ba4-fc30-49a4-b222-bffeeda06553 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Claim successful on node rack08-server63
2022-02-21 18:02:47.231 7 INFO nova.virt.libvirt.driver [req-50ed0ba4-fc30-49a4-b222-bffeeda06553 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Creating image
2022-02-21 18:02:48.419 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] VM Resumed (Lifecycle Event)
2022-02-21 18:02:48.427 7 INFO nova.virt.libvirt.driver [-] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Instance spawned successfully.
2022-02-21 18:02:48.428 7 INFO nova.compute.manager [req-50ed0ba4-fc30-49a4-b222-bffeeda06553 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-21 18:02:48.474 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:02:48.475 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] VM Started (Lifecycle Event)
2022-02-21 18:02:48.517 7 INFO nova.compute.manager [req-50ed0ba4-fc30-49a4-b222-bffeeda06553 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Took 1.73 seconds to build instance.
2022-02-21 18:02:49.077 7 INFO nova.compute.manager [req-1d4c2d2a-8bac-4b93-a861-c13d1fee1352 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Terminating instance
2022-02-21 18:02:49.425 7 INFO nova.virt.libvirt.driver [-] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Instance destroyed successfully.
2022-02-21 18:02:49.441 7 INFO nova.virt.libvirt.driver [req-1d4c2d2a-8bac-4b93-a861-c13d1fee1352 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Deleting instance files /var/lib/nova/instances/5869cbed-d482-41f8-b9c9-3bd3468c2636_del
2022-02-21 18:02:49.442 7 INFO nova.virt.libvirt.driver [req-1d4c2d2a-8bac-4b93-a861-c13d1fee1352 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Deletion of /var/lib/nova/instances/5869cbed-d482-41f8-b9c9-3bd3468c2636_del complete
2022-02-21 18:02:49.510 7 INFO nova.compute.manager [req-1d4c2d2a-8bac-4b93-a861-c13d1fee1352 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:02:49.579 7 INFO nova.compute.manager [-] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:02:49.786 7 INFO nova.scheduler.client.report [req-1d4c2d2a-8bac-4b93-a861-c13d1fee1352 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] Deleted allocations for instance 5869cbed-d482-41f8-b9c9-3bd3468c2636
2022-02-21 18:02:51.415 7 INFO nova.compute.claims [req-1e3d7c70-24fe-4098-84ab-8c9cd7d02da5 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Claim successful on node rack08-server63
2022-02-21 18:02:51.816 7 INFO nova.virt.libvirt.driver [req-1e3d7c70-24fe-4098-84ab-8c9cd7d02da5 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Creating image
2022-02-21 18:02:53.007 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] VM Resumed (Lifecycle Event)
2022-02-21 18:02:53.014 7 INFO nova.virt.libvirt.driver [-] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Instance spawned successfully.
2022-02-21 18:02:53.015 7 INFO nova.compute.manager [req-1e3d7c70-24fe-4098-84ab-8c9cd7d02da5 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-21 18:02:53.062 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:02:53.063 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] VM Started (Lifecycle Event)
2022-02-21 18:02:53.105 7 INFO nova.compute.manager [req-1e3d7c70-24fe-4098-84ab-8c9cd7d02da5 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Took 1.73 seconds to build instance.
2022-02-21 18:02:53.732 7 INFO nova.compute.manager [req-e70755b6-b4aa-47d0-85d1-16c51f90ecdc 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Terminating instance
2022-02-21 18:02:54.073 7 INFO nova.virt.libvirt.driver [-] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Instance destroyed successfully.
2022-02-21 18:02:54.096 7 INFO nova.virt.libvirt.driver [req-e70755b6-b4aa-47d0-85d1-16c51f90ecdc 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Deleting instance files /var/lib/nova/instances/bc1522cf-0486-4c08-9531-021a95bfc73c_del
2022-02-21 18:02:54.097 7 INFO nova.virt.libvirt.driver [req-e70755b6-b4aa-47d0-85d1-16c51f90ecdc 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Deletion of /var/lib/nova/instances/bc1522cf-0486-4c08-9531-021a95bfc73c_del complete
2022-02-21 18:02:54.181 7 INFO nova.compute.manager [req-e70755b6-b4aa-47d0-85d1-16c51f90ecdc 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Took 0.33 seconds to destroy the instance on the hypervisor.
2022-02-21 18:02:54.246 7 INFO nova.compute.manager [-] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] Took 0.06 seconds to deallocate network for instance.
2022-02-21 18:02:54.461 7 INFO nova.scheduler.client.report [req-e70755b6-b4aa-47d0-85d1-16c51f90ecdc 0d44c2a495dc40f4b06817e338739909 87f237f12d404bc2943d0b006647e2a3 - default default] Deleted allocations for instance bc1522cf-0486-4c08-9531-021a95bfc73c
2022-02-21 18:03:01.144 7 INFO nova.compute.claims [req-39fac567-38e3-4189-a19c-714a79f1f72d 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Claim successful on node rack08-server63
2022-02-21 18:03:01.533 7 INFO nova.virt.libvirt.driver [req-39fac567-38e3-4189-a19c-714a79f1f72d 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Creating image
2022-02-21 18:03:02.686 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a5aa531b-4869-471e-828d-0534e0731c48] VM Resumed (Lifecycle Event)
2022-02-21 18:03:02.694 7 INFO nova.virt.libvirt.driver [-] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Instance spawned successfully.
2022-02-21 18:03:02.695 7 INFO nova.compute.manager [req-39fac567-38e3-4189-a19c-714a79f1f72d 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 18:03:02.741 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a5aa531b-4869-471e-828d-0534e0731c48] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:03:02.741 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: a5aa531b-4869-471e-828d-0534e0731c48] VM Started (Lifecycle Event)
2022-02-21 18:03:02.786 7 INFO nova.compute.manager [req-39fac567-38e3-4189-a19c-714a79f1f72d 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Took 1.68 seconds to build instance.
2022-02-21 18:03:03.120 7 INFO nova.virt.libvirt.driver [req-93437667-aa6d-47b8-8638-e23b75e87341 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Ignoring supplied device name: /dev/vdb
2022-02-21 18:03:03.276 7 INFO nova.compute.manager [req-93437667-aa6d-47b8-8638-e23b75e87341 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Attaching volume 1a3f4622-bc59-4e45-889a-2f5979554753 to /dev/vdb
2022-02-21 18:03:03.368 7 WARNING os_brick.initiator.connectors.nvmeof [req-93437667-aa6d-47b8-8638-e23b75e87341 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 18:03:04.424 7 INFO nova.compute.manager [-] [instance: 5869cbed-d482-41f8-b9c9-3bd3468c2636] VM Stopped (Lifecycle Event)
2022-02-21 18:03:04.863 7 INFO os_brick.initiator.connectors.lightos [req-93437667-aa6d-47b8-8638-e23b75e87341 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] LIGHTOS: connect_volume called for volume 783b9fa3-4965-46ff-9aea-3c95235db92a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '783b9fa3-4965-46ff-9aea-3c95235db92a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 18:03:04.867 7 INFO os_brick.initiator.connectors.lightos [req-93437667-aa6d-47b8-8638-e23b75e87341 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 783b9fa3-4965-46ff-9aea-3c95235db92a
2022-02-21 18:03:09.071 7 INFO nova.compute.manager [-] [instance: bc1522cf-0486-4c08-9531-021a95bfc73c] VM Stopped (Lifecycle Event)
2022-02-21 18:03:10.130 7 INFO nova.compute.manager [req-e05e495b-26b2-4364-9bfe-aa7a52e3f2a7 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Cinder extended volume 1a3f4622-bc59-4e45-889a-2f5979554753; extending it to detect new size
2022-02-21 18:03:10.237 7 INFO os_brick.initiator.connectors.lightos [req-e05e495b-26b2-4364-9bfe-aa7a52e3f2a7 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 783b9fa3-4965-46ff-9aea-3c95235db92a
2022-02-21 18:03:11.284 7 INFO nova.compute.manager [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Detaching volume 1a3f4622-bc59-4e45-889a-2f5979554753
2022-02-21 18:03:11.345 7 INFO nova.virt.block_device [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Attempting to driver detach volume 1a3f4622-bc59-4e45-889a-2f5979554753 from mountpoint /dev/vdb
2022-02-21 18:03:11.363 7 INFO nova.virt.libvirt.driver [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] Successfully detached device vdb from instance a5aa531b-4869-471e-828d-0534e0731c48 from the persistent domain config.
2022-02-21 18:03:11.506 7 INFO nova.virt.libvirt.driver [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] Successfully detached device vdb from instance a5aa531b-4869-471e-828d-0534e0731c48 from the live domain config.
2022-02-21 18:03:11.510 7 INFO os_brick.initiator.connectors.lightos [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] LIGHTOS: connect_volume called for volume 783b9fa3-4965-46ff-9aea-3c95235db92a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '783b9fa3-4965-46ff-9aea-3c95235db92a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 18:03:11.511 7 INFO os_brick.initiator.connectors.lightos [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 783b9fa3-4965-46ff-9aea-3c95235db92a
2022-02-21 18:03:11.511 7 INFO os_brick.initiator.connectors.lightos [req-b12c1c80-1c99-409c-a2d2-58548099b2ae 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 783b9fa3-4965-46ff-9aea-3c95235db92a
2022-02-21 18:03:13.526 7 INFO nova.compute.manager [req-959fc964-497f-49b9-9eea-77f56bf2f39c 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Terminating instance
2022-02-21 18:03:14.032 7 INFO nova.virt.libvirt.driver [-] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Instance destroyed successfully.
2022-02-21 18:03:14.048 7 INFO nova.virt.libvirt.driver [req-959fc964-497f-49b9-9eea-77f56bf2f39c 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Deleting instance files /var/lib/nova/instances/a5aa531b-4869-471e-828d-0534e0731c48_del
2022-02-21 18:03:14.049 7 INFO nova.virt.libvirt.driver [req-959fc964-497f-49b9-9eea-77f56bf2f39c 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Deletion of /var/lib/nova/instances/a5aa531b-4869-471e-828d-0534e0731c48_del complete
2022-02-21 18:03:14.115 7 INFO nova.compute.manager [req-959fc964-497f-49b9-9eea-77f56bf2f39c 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:03:14.205 7 INFO nova.compute.manager [-] [instance: a5aa531b-4869-471e-828d-0534e0731c48] Took 0.09 seconds to deallocate network for instance.
2022-02-21 18:03:14.400 7 INFO nova.scheduler.client.report [req-959fc964-497f-49b9-9eea-77f56bf2f39c 151788dea8d143129fdab9b77b8cd8d7 0b2317d99f734eb9a994ef34f1e79a77 - default default] Deleted allocations for instance a5aa531b-4869-471e-828d-0534e0731c48
2022-02-21 18:03:14.492 7 WARNING nova.virt.libvirt.driver [req-7d947122-5cdd-4be4-befb-5d865e596a1d - - - - -] Error from libvirt while getting description of instance-000005cf: [Error Code 42] Domain not found: no domain with matching uuid 'a5aa531b-4869-471e-828d-0534e0731c48' (instance-000005cf): libvirt.libvirtError: Domain not found: no domain with matching uuid 'a5aa531b-4869-471e-828d-0534e0731c48' (instance-000005cf)
2022-02-21 18:03:29.028 7 INFO nova.compute.manager [-] [instance: a5aa531b-4869-471e-828d-0534e0731c48] VM Stopped (Lifecycle Event)
2022-02-21 18:03:38.274 7 INFO nova.compute.manager [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Detaching volume d98d553a-5114-4df8-bfe1-925910d6f233
2022-02-21 18:03:38.334 7 INFO nova.virt.block_device [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Attempting to driver detach volume d98d553a-5114-4df8-bfe1-925910d6f233 from mountpoint /dev/vdb
2022-02-21 18:03:38.344 7 INFO nova.virt.libvirt.driver [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Device vdb not found in instance.
2022-02-21 18:03:38.397 7 INFO os_brick.initiator.connectors.lightos [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 09ec2f7b-dc2b-46ad-b03d-445b14854521, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '09ec2f7b-dc2b-46ad-b03d-445b14854521', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 18:03:38.867 7 INFO nova.compute.claims [req-3e82d4c7-a100-405e-b970-5888d5f72ac7 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Claim successful on node rack08-server63
2022-02-21 18:03:39.269 7 INFO nova.virt.libvirt.driver [req-3e82d4c7-a100-405e-b970-5888d5f72ac7 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Creating image
2022-02-21 18:03:40.443 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] VM Resumed (Lifecycle Event)
2022-02-21 18:03:40.451 7 INFO nova.virt.libvirt.driver [-] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Instance spawned successfully.
2022-02-21 18:03:40.452 7 INFO nova.compute.manager [req-3e82d4c7-a100-405e-b970-5888d5f72ac7 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-21 18:03:40.498 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:03:40.498 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] VM Started (Lifecycle Event)
2022-02-21 18:03:40.543 7 INFO nova.compute.manager [req-3e82d4c7-a100-405e-b970-5888d5f72ac7 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Took 1.72 seconds to build instance.
2022-02-21 18:03:41.029 7 INFO nova.compute.manager [req-39e958fa-7ec0-4821-8752-19f1cf37e562 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Terminating instance
2022-02-21 18:03:41.370 7 INFO nova.virt.libvirt.driver [-] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Instance destroyed successfully.
2022-02-21 18:03:41.383 7 INFO nova.virt.libvirt.driver [req-39e958fa-7ec0-4821-8752-19f1cf37e562 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Deleting instance files /var/lib/nova/instances/b527f59b-8f4e-4a22-a841-78679c68fd7d_del
2022-02-21 18:03:41.385 7 INFO nova.virt.libvirt.driver [req-39e958fa-7ec0-4821-8752-19f1cf37e562 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Deletion of /var/lib/nova/instances/b527f59b-8f4e-4a22-a841-78679c68fd7d_del complete
2022-02-21 18:03:41.453 7 INFO nova.compute.manager [req-39e958fa-7ec0-4821-8752-19f1cf37e562 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 18:03:41.521 7 INFO nova.compute.manager [-] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:03:41.719 7 INFO nova.scheduler.client.report [req-39e958fa-7ec0-4821-8752-19f1cf37e562 fd0ea0cf0f77469f95ec5b2191dfcd18 7b1381f08df94a43ae6e6a226aee1cdc - default default] Deleted allocations for instance b527f59b-8f4e-4a22-a841-78679c68fd7d
2022-02-21 18:03:51.896 7 INFO nova.compute.claims [req-248bc3cb-42eb-4648-916d-6804e83d7415 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Claim successful on node rack08-server63
2022-02-21 18:03:52.326 7 INFO nova.virt.libvirt.driver [req-248bc3cb-42eb-4648-916d-6804e83d7415 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Creating image
2022-02-21 18:03:53.552 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] VM Resumed (Lifecycle Event)
2022-02-21 18:03:53.562 7 INFO nova.virt.libvirt.driver [-] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Instance spawned successfully.
2022-02-21 18:03:53.563 7 INFO nova.compute.manager [req-248bc3cb-42eb-4648-916d-6804e83d7415 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-21 18:03:53.609 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:03:53.610 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] VM Started (Lifecycle Event)
2022-02-21 18:03:53.657 7 INFO nova.compute.manager [req-248bc3cb-42eb-4648-916d-6804e83d7415 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Took 1.80 seconds to build instance.
2022-02-21 18:03:56.368 7 INFO nova.compute.manager [-] [instance: b527f59b-8f4e-4a22-a841-78679c68fd7d] VM Stopped (Lifecycle Event)
2022-02-21 18:04:10.002 7 INFO nova.virt.libvirt.driver [req-7afbb70d-2543-46f7-99dd-9212f439dde2 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Ignoring supplied device name: /dev/vdb
2022-02-21 18:04:10.171 7 INFO nova.compute.manager [req-7afbb70d-2543-46f7-99dd-9212f439dde2 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Attaching volume 5b4b0ec8-488a-4159-8c6d-0e9006d58949 to /dev/vdb
2022-02-21 18:04:10.267 7 WARNING os_brick.initiator.connectors.nvmeof [req-7afbb70d-2543-46f7-99dd-9212f439dde2 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Failed to detach volume d98d553a-5114-4df8-bfe1-925910d6f233 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Traceback (most recent call last):
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2613, in detach_volume
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1879, in _disconnect_volume
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     return f(*args, **kwargs)
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     return f(*args, **kwargs)
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87]     raise exception.BrickException(message=msg)
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 18:04:38.696 7 ERROR nova.virt.block_device [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] 
2022-02-21 18:04:38.703 7 INFO os_brick.initiator.connectors.lightos [req-7afbb70d-2543-46f7-99dd-9212f439dde2 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: connect_volume called for volume 4ab5c67b-140c-4316-b307-4f0b1a4e3d11, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4ab5c67b-140c-4316-b307-4f0b1a4e3d11', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 18:04:38.707 7 INFO os_brick.initiator.connectors.lightos [req-7afbb70d-2543-46f7-99dd-9212f439dde2 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4ab5c67b-140c-4316-b307-4f0b1a4e3d11
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server [req-2eb5366c-7234-4297-b676-b5f82780a575 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2613, in detach_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1879, in _disconnect_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 18:04:38.807 7 ERROR oslo_messaging.rpc.server 
2022-02-21 18:04:50.416 7 INFO nova.compute.manager [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Detaching volume 5b4b0ec8-488a-4159-8c6d-0e9006d58949
2022-02-21 18:04:50.481 7 INFO nova.virt.block_device [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Attempting to driver detach volume 5b4b0ec8-488a-4159-8c6d-0e9006d58949 from mountpoint /dev/vdb
2022-02-21 18:04:50.500 7 INFO nova.virt.libvirt.driver [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Successfully detached device vdb from instance 15311ea0-2fc4-407e-936a-04a893c14792 from the persistent domain config.
2022-02-21 18:04:50.642 7 INFO nova.virt.libvirt.driver [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Successfully detached device vdb from instance 15311ea0-2fc4-407e-936a-04a893c14792 from the live domain config.
2022-02-21 18:04:50.645 7 INFO os_brick.initiator.connectors.lightos [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: connect_volume called for volume 4ab5c67b-140c-4316-b307-4f0b1a4e3d11, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4ab5c67b-140c-4316-b307-4f0b1a4e3d11', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 18:04:50.646 7 INFO os_brick.initiator.connectors.lightos [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4ab5c67b-140c-4316-b307-4f0b1a4e3d11
2022-02-21 18:04:50.647 7 INFO os_brick.initiator.connectors.lightos [req-724107da-035a-4eb5-a7b9-ffa2ca54915e 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4ab5c67b-140c-4316-b307-4f0b1a4e3d11
2022-02-21 18:04:52.669 7 INFO nova.compute.manager [req-00d62259-580e-4a27-86f3-eb6ab7ed2fd7 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Terminating instance
2022-02-21 18:04:53.011 7 INFO nova.virt.libvirt.driver [-] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Instance destroyed successfully.
2022-02-21 18:04:53.027 7 INFO nova.virt.libvirt.driver [req-00d62259-580e-4a27-86f3-eb6ab7ed2fd7 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Deleting instance files /var/lib/nova/instances/15311ea0-2fc4-407e-936a-04a893c14792_del
2022-02-21 18:04:53.029 7 INFO nova.virt.libvirt.driver [req-00d62259-580e-4a27-86f3-eb6ab7ed2fd7 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Deletion of /var/lib/nova/instances/15311ea0-2fc4-407e-936a-04a893c14792_del complete
2022-02-21 18:04:53.105 7 INFO nova.compute.manager [req-00d62259-580e-4a27-86f3-eb6ab7ed2fd7 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-21 18:04:53.173 7 INFO nova.compute.manager [-] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:04:53.372 7 INFO nova.scheduler.client.report [req-00d62259-580e-4a27-86f3-eb6ab7ed2fd7 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Deleted allocations for instance 15311ea0-2fc4-407e-936a-04a893c14792
2022-02-21 18:05:01.312 7 INFO nova.compute.claims [req-7127e5e2-531b-4598-bc97-2ac205937785 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Claim successful on node rack08-server63
2022-02-21 18:05:01.720 7 INFO nova.virt.libvirt.driver [req-7127e5e2-531b-4598-bc97-2ac205937785 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Creating image
2022-02-21 18:05:02.886 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] VM Resumed (Lifecycle Event)
2022-02-21 18:05:02.894 7 INFO nova.virt.libvirt.driver [-] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Instance spawned successfully.
2022-02-21 18:05:02.894 7 INFO nova.compute.manager [req-7127e5e2-531b-4598-bc97-2ac205937785 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-21 18:05:02.942 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:05:02.942 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] VM Started (Lifecycle Event)
2022-02-21 18:05:02.986 7 INFO nova.compute.manager [req-7127e5e2-531b-4598-bc97-2ac205937785 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Took 1.71 seconds to build instance.
2022-02-21 18:05:03.202 7 INFO nova.virt.libvirt.driver [req-a0eecac2-7d04-4dba-9763-7b52aa60d06d 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Ignoring supplied device name: /dev/vdb
2022-02-21 18:05:03.377 7 INFO nova.compute.manager [req-a0eecac2-7d04-4dba-9763-7b52aa60d06d 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Attaching volume 0ba93251-109b-47d3-8bec-8b633fd292d7 to /dev/vdb
2022-02-21 18:05:03.465 7 WARNING os_brick.initiator.connectors.nvmeof [req-a0eecac2-7d04-4dba-9763-7b52aa60d06d 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 18:05:04.839 7 INFO os_brick.initiator.connectors.lightos [req-a0eecac2-7d04-4dba-9763-7b52aa60d06d 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: connect_volume called for volume d550e542-0196-4535-95f1-1de4099356b2, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd550e542-0196-4535-95f1-1de4099356b2', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 18:05:04.843 7 INFO os_brick.initiator.connectors.lightos [req-a0eecac2-7d04-4dba-9763-7b52aa60d06d 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d550e542-0196-4535-95f1-1de4099356b2
2022-02-21 18:05:08.009 7 INFO nova.compute.manager [-] [instance: 15311ea0-2fc4-407e-936a-04a893c14792] VM Stopped (Lifecycle Event)
2022-02-21 18:05:13.662 7 INFO nova.compute.manager [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Detaching volume 0ba93251-109b-47d3-8bec-8b633fd292d7
2022-02-21 18:05:13.721 7 INFO nova.virt.block_device [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Attempting to driver detach volume 0ba93251-109b-47d3-8bec-8b633fd292d7 from mountpoint /dev/vdb
2022-02-21 18:05:13.742 7 INFO nova.virt.libvirt.driver [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Successfully detached device vdb from instance 02f17436-1af4-464b-9ae2-5782b5d73fcb from the persistent domain config.
2022-02-21 18:05:13.891 7 INFO nova.virt.libvirt.driver [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Successfully detached device vdb from instance 02f17436-1af4-464b-9ae2-5782b5d73fcb from the live domain config.
2022-02-21 18:05:13.893 7 INFO os_brick.initiator.connectors.lightos [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: connect_volume called for volume d550e542-0196-4535-95f1-1de4099356b2, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd550e542-0196-4535-95f1-1de4099356b2', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 18:05:13.894 7 INFO os_brick.initiator.connectors.lightos [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d550e542-0196-4535-95f1-1de4099356b2
2022-02-21 18:05:13.895 7 INFO os_brick.initiator.connectors.lightos [req-883541b4-1c89-4514-9944-daf961327ad4 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d550e542-0196-4535-95f1-1de4099356b2
2022-02-21 18:05:16.765 7 INFO nova.compute.manager [req-5e1d2d2c-81ed-428e-a52f-979a568c07c9 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Terminating instance
2022-02-21 18:05:17.108 7 INFO nova.virt.libvirt.driver [-] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Instance destroyed successfully.
2022-02-21 18:05:17.124 7 INFO nova.virt.libvirt.driver [req-5e1d2d2c-81ed-428e-a52f-979a568c07c9 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Deleting instance files /var/lib/nova/instances/02f17436-1af4-464b-9ae2-5782b5d73fcb_del
2022-02-21 18:05:17.125 7 INFO nova.virt.libvirt.driver [req-5e1d2d2c-81ed-428e-a52f-979a568c07c9 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Deletion of /var/lib/nova/instances/02f17436-1af4-464b-9ae2-5782b5d73fcb_del complete
2022-02-21 18:05:17.193 7 INFO nova.compute.manager [req-5e1d2d2c-81ed-428e-a52f-979a568c07c9 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:05:17.295 7 INFO nova.compute.manager [-] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] Took 0.10 seconds to deallocate network for instance.
2022-02-21 18:05:17.471 7 INFO nova.scheduler.client.report [req-5e1d2d2c-81ed-428e-a52f-979a568c07c9 62c7e5282da64d9ea1ebcec7bf2b7660 99c4ec657dab4f4ca8d2af6ce100a400 - default default] Deleted allocations for instance 02f17436-1af4-464b-9ae2-5782b5d73fcb
2022-02-21 18:05:32.106 7 INFO nova.compute.manager [-] [instance: 02f17436-1af4-464b-9ae2-5782b5d73fcb] VM Stopped (Lifecycle Event)
2022-02-21 18:08:38.702 7 INFO nova.compute.manager [req-813cc703-41c5-4459-b74f-8f084432a1c2 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Get console output
2022-02-21 18:08:38.986 70 INFO nova.privsep.libvirt [-] Ignored error while reading from instance console pty: can't concat NoneType to bytes
2022-02-21 18:08:55.931 7 INFO nova.compute.claims [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Claim successful on node rack08-server63
2022-02-21 18:08:56.213 7 INFO nova.virt.libvirt.driver [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 18:08:56.309 7 INFO nova.virt.block_device [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Booting with volume 36b18c09-1ffb-4f65-b910-79815fb16ba9 at /dev/vda
2022-02-21 18:08:56.410 7 WARNING os_brick.initiator.connectors.nvmeof [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 18:08:57.921 7 INFO nova.virt.libvirt.driver [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Creating image
2022-02-21 18:08:57.933 7 INFO os_brick.initiator.connectors.lightos [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 5e8e8121-3979-45a9-8456-3eecdd883048, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5e8e8121-3979-45a9-8456-3eecdd883048', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 18:08:57.937 7 INFO os_brick.initiator.connectors.lightos [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5e8e8121-3979-45a9-8456-3eecdd883048
2022-02-21 18:08:58.745 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] VM Resumed (Lifecycle Event)
2022-02-21 18:08:58.752 7 INFO nova.virt.libvirt.driver [-] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Instance spawned successfully.
2022-02-21 18:08:58.753 7 INFO nova.compute.manager [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Took 0.83 seconds to spawn the instance on the hypervisor.
2022-02-21 18:08:58.801 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 18:08:58.802 7 INFO nova.compute.manager [req-82d698e5-7bc7-4cd0-bb00-bdfe312f25f7 - - - - -] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] VM Started (Lifecycle Event)
2022-02-21 18:08:58.845 7 INFO nova.compute.manager [req-08fc87e1-00f7-41b4-a964-7ce79493ca0c 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Took 2.95 seconds to build instance.
2022-02-21 18:09:00.060 7 INFO nova.compute.manager [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Terminating instance
2022-02-21 18:09:00.392 7 INFO nova.virt.libvirt.driver [-] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Instance destroyed successfully.
2022-02-21 18:09:00.500 7 INFO os_brick.initiator.connectors.lightos [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 5e8e8121-3979-45a9-8456-3eecdd883048, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5e8e8121-3979-45a9-8456-3eecdd883048', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 18:09:00.501 7 INFO os_brick.initiator.connectors.lightos [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5e8e8121-3979-45a9-8456-3eecdd883048
2022-02-21 18:09:00.502 7 INFO os_brick.initiator.connectors.lightos [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5e8e8121-3979-45a9-8456-3eecdd883048
2022-02-21 18:09:00.514 7 INFO nova.virt.libvirt.driver [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Deleting instance files /var/lib/nova/instances/5b707927-6974-491d-8f37-03f75ba0f834_del
2022-02-21 18:09:00.515 7 INFO nova.virt.libvirt.driver [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Deletion of /var/lib/nova/instances/5b707927-6974-491d-8f37-03f75ba0f834_del complete
2022-02-21 18:09:00.582 7 INFO nova.compute.manager [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Took 0.41 seconds to destroy the instance on the hypervisor.
2022-02-21 18:09:00.650 7 INFO nova.compute.manager [-] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:09:03.946 7 INFO nova.compute.manager [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] Took 3.30 seconds to detach 1 volumes for instance.
2022-02-21 18:09:04.147 7 INFO nova.scheduler.client.report [req-709d1702-bec8-486f-af72-a202c836534d 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Deleted allocations for instance 5b707927-6974-491d-8f37-03f75ba0f834
2022-02-21 18:09:15.391 7 INFO nova.compute.manager [-] [instance: 5b707927-6974-491d-8f37-03f75ba0f834] VM Stopped (Lifecycle Event)
2022-02-21 18:14:06.659 7 INFO nova.compute.manager [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Terminating instance
2022-02-21 18:14:07.000 7 INFO nova.virt.libvirt.driver [-] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Instance destroyed successfully.
2022-02-21 18:14:07.073 7 INFO os_brick.initiator.connectors.lightos [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume 09ec2f7b-dc2b-46ad-b03d-445b14854521, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '09ec2f7b-dc2b-46ad-b03d-445b14854521', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 18:14:21.997 7 INFO nova.compute.manager [-] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] VM Stopped (Lifecycle Event)
2022-02-21 18:14:22.054 7 INFO nova.compute.manager [req-ef008e05-f407-49b4-b289-0e94141b997c - - - - -] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] During sync_power_state the instance has a pending task (deleting). Skip.
2022-02-21 18:15:07.555 7 WARNING nova.virt.libvirt.driver [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Ignoring Volume Error on vol d98d553a-5114-4df8-bfe1-925910d6f233 during delete Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up: os_brick.exception.BrickException: Device with uuid 09ec2f7b-dc2b-46ad-b03d-445b14854521 did not show up
2022-02-21 18:15:07.561 7 INFO nova.virt.libvirt.driver [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Deleting instance files /var/lib/nova/instances/e24b6554-6132-4e26-8b5a-fbea6341aa87_del
2022-02-21 18:15:07.563 7 INFO nova.virt.libvirt.driver [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Deletion of /var/lib/nova/instances/e24b6554-6132-4e26-8b5a-fbea6341aa87_del complete
2022-02-21 18:15:07.641 7 INFO nova.compute.manager [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Took 60.86 seconds to destroy the instance on the hypervisor.
2022-02-21 18:15:07.710 7 INFO nova.compute.manager [-] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:15:08.961 7 INFO nova.compute.manager [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: e24b6554-6132-4e26-8b5a-fbea6341aa87] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-21 18:15:09.148 7 INFO nova.scheduler.client.report [req-f90283af-6742-43cf-a183-0b7de69e7712 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Deleted allocations for instance e24b6554-6132-4e26-8b5a-fbea6341aa87
2022-02-21 18:15:10.163 7 INFO nova.compute.manager [req-ec8e163c-ef03-443b-b348-8bd5371fb234 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Terminating instance
2022-02-21 18:15:10.507 7 INFO nova.virt.libvirt.driver [-] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Instance destroyed successfully.
2022-02-21 18:15:10.522 7 INFO nova.virt.libvirt.driver [req-ec8e163c-ef03-443b-b348-8bd5371fb234 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Deleting instance files /var/lib/nova/instances/d48f6e02-e4fa-4422-8fb6-331b56299d19_del
2022-02-21 18:15:10.524 7 INFO nova.virt.libvirt.driver [req-ec8e163c-ef03-443b-b348-8bd5371fb234 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Deletion of /var/lib/nova/instances/d48f6e02-e4fa-4422-8fb6-331b56299d19_del complete
2022-02-21 18:15:10.594 7 INFO nova.compute.manager [req-ec8e163c-ef03-443b-b348-8bd5371fb234 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 18:15:10.663 7 INFO nova.compute.manager [-] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:15:10.863 7 INFO nova.scheduler.client.report [req-ec8e163c-ef03-443b-b348-8bd5371fb234 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Deleted allocations for instance d48f6e02-e4fa-4422-8fb6-331b56299d19
2022-02-21 18:15:11.403 7 INFO nova.compute.manager [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Terminating instance
2022-02-21 18:15:11.751 7 INFO nova.virt.libvirt.driver [-] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Instance destroyed successfully.
2022-02-21 18:15:11.833 7 INFO os_brick.initiator.connectors.lightos [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: connect_volume called for volume ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 18:15:11.834 7 INFO os_brick.initiator.connectors.lightos [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f
2022-02-21 18:15:11.835 7 INFO os_brick.initiator.connectors.lightos [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ac960ebf-5a46-4bf0-9c2a-0b9ff2435e1f
2022-02-21 18:15:11.847 7 INFO nova.virt.libvirt.driver [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Deleting instance files /var/lib/nova/instances/ec3098f3-51ad-465d-86fb-10803bbe2b92_del
2022-02-21 18:15:11.848 7 INFO nova.virt.libvirt.driver [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Deletion of /var/lib/nova/instances/ec3098f3-51ad-465d-86fb-10803bbe2b92_del complete
2022-02-21 18:15:11.917 7 INFO nova.compute.manager [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-21 18:15:11.987 7 INFO nova.compute.manager [-] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Took 0.07 seconds to deallocate network for instance.
2022-02-21 18:15:13.277 7 INFO nova.compute.manager [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] Took 1.29 seconds to detach 1 volumes for instance.
2022-02-21 18:15:13.463 7 INFO nova.scheduler.client.report [req-22e6117a-8e0c-423f-b21a-478120f09e12 927f0190ff404d3393f133817b3c485a 8ef5586e07e44c38a555d1bd85ed70d0 - default default] Deleted allocations for instance ec3098f3-51ad-465d-86fb-10803bbe2b92
2022-02-21 18:15:25.506 7 INFO nova.compute.manager [-] [instance: d48f6e02-e4fa-4422-8fb6-331b56299d19] VM Stopped (Lifecycle Event)
2022-02-21 18:15:26.749 7 INFO nova.compute.manager [-] [instance: ec3098f3-51ad-465d-86fb-10803bbe2b92] VM Stopped (Lifecycle Event)
