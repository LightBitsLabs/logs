Build Started 22_02_2022_17_30_14
2022-02-22 19:32:15.541 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 19:32:19.490 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 19:32:20.412 7 INFO nova.virt.driver [req-aaf4c458-bfd1-4b86-8d61-9ec4053da1ab - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 19:32:20.798 7 INFO nova.compute.provider_config [req-aaf4c458-bfd1-4b86-8d61-9ec4053da1ab - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 19:32:20.818 7 WARNING oslo_config.cfg [req-aaf4c458-bfd1-4b86-8d61-9ec4053da1ab - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 19:32:20.839 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 19:32:20.851 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 19:32:20.888 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 19:32:20.985 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 19:32:21.000 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 19:32:21.003 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 19:32:21.414 7 INFO nova.compute.manager [req-0b31dfcf-437e-4f9a-b448-761b931c6a5d - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 19:32:23.212 7 INFO nova.virt.libvirt.host [req-0b31dfcf-437e-4f9a-b448-761b931c6a5d - - - - -] kernel doesn't support AMD SEV
2022-02-22 19:33:18.312 7 INFO nova.compute.claims [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Claim successful on node rack08-server63
2022-02-22 19:33:18.724 7 INFO nova.virt.libvirt.driver [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Creating image
2022-02-22 19:33:18.728 7 INFO oslo.privsep.daemon [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp6vymo93u/privsep.sock']
2022-02-22 19:33:20.371 7 INFO oslo.privsep.daemon [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Spawned new privsep daemon via rootwrap
2022-02-22 19:33:20.222 80 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 19:33:20.227 80 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 19:33:20.231 80 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 19:33:20.232 80 INFO oslo.privsep.daemon [-] privsep daemon running as pid 80
2022-02-22 19:33:21.642 7 INFO nova.compute.manager [-] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] VM Resumed (Lifecycle Event)
2022-02-22 19:33:21.651 7 INFO nova.virt.libvirt.driver [-] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Instance spawned successfully.
2022-02-22 19:33:21.652 7 INFO nova.compute.manager [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Took 2.93 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:21.704 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:21.705 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] VM Started (Lifecycle Event)
2022-02-22 19:33:21.761 7 INFO nova.compute.manager [req-8b4c40c0-936b-4b05-86bc-c0b220569794 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Took 3.49 seconds to build instance.
2022-02-22 19:33:25.667 7 INFO nova.compute.manager [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Attaching volume 8618d161-43a1-44ab-9bb1-5bdc52c1070c to /dev/vdb
2022-02-22 19:33:25.748 7 INFO oslo.privsep.daemon [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp50owz9dn/privsep.sock']
2022-02-22 19:33:26.417 7 INFO oslo.privsep.daemon [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Spawned new privsep daemon via rootwrap
2022-02-22 19:33:26.332 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 19:33:26.339 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 19:33:26.344 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 19:33:26.345 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-22 19:33:26.742 7 WARNING os_brick.initiator.connectors.nvmeof [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:33:28.136 7 INFO os_brick.initiator.connectors.lightos [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: connect_volume called for volume c9f1f55a-fb00-44be-b36c-aa1e65873395, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c9f1f55a-fb00-44be-b36c-aa1e65873395', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:33:28.169 7 INFO os_brick.initiator.connectors.lightos [req-00226c50-132f-4303-b614-a32422fc8a8e c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c9f1f55a-fb00-44be-b36c-aa1e65873395
2022-02-22 19:33:30.366 7 INFO nova.compute.claims [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Claim successful on node rack08-server63
2022-02-22 19:33:30.615 7 INFO nova.virt.libvirt.driver [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 19:33:30.678 7 INFO nova.compute.claims [req-14d86381-07db-46f1-85dc-a9bc6d33eb33 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Claim successful on node rack08-server63
2022-02-22 19:33:30.706 7 INFO nova.virt.block_device [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Booting with volume ac2e28a4-4a71-434f-8a19-f5da810364a0 at /dev/vda
2022-02-22 19:33:30.810 7 WARNING os_brick.initiator.connectors.nvmeof [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:33:31.075 7 INFO nova.virt.libvirt.driver [req-14d86381-07db-46f1-85dc-a9bc6d33eb33 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Creating image
2022-02-22 19:33:32.271 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] VM Resumed (Lifecycle Event)
2022-02-22 19:33:32.285 7 INFO nova.virt.libvirt.driver [-] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Instance spawned successfully.
2022-02-22 19:33:32.286 7 INFO nova.compute.manager [req-14d86381-07db-46f1-85dc-a9bc6d33eb33 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:32.325 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:32.325 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] VM Started (Lifecycle Event)
2022-02-22 19:33:32.348 7 INFO nova.virt.libvirt.driver [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Creating image
2022-02-22 19:33:32.368 7 INFO os_brick.initiator.connectors.lightos [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: connect_volume called for volume 5ca3cf5d-fbbf-48b9-9b88-d8f0bfcb1148, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5ca3cf5d-fbbf-48b9-9b88-d8f0bfcb1148', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:33:32.370 7 INFO nova.compute.manager [req-14d86381-07db-46f1-85dc-a9bc6d33eb33 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Took 1.73 seconds to build instance.
2022-02-22 19:33:32.372 7 INFO os_brick.initiator.connectors.lightos [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 5ca3cf5d-fbbf-48b9-9b88-d8f0bfcb1148
2022-02-22 19:33:33.157 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] VM Resumed (Lifecycle Event)
2022-02-22 19:33:33.163 7 INFO nova.virt.libvirt.driver [-] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Instance spawned successfully.
2022-02-22 19:33:33.164 7 INFO nova.compute.manager [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Took 0.82 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:33.210 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:33.211 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] VM Started (Lifecycle Event)
2022-02-22 19:33:33.248 7 INFO nova.compute.manager [req-2e94034b-2dc8-4ae6-bbb8-bb0bd4711cb7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Took 2.92 seconds to build instance.
2022-02-22 19:33:33.500 7 INFO nova.compute.manager [req-98dda25d-5b41-43a7-bffe-a90aea3259e2 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Detaching volume 8618d161-43a1-44ab-9bb1-5bdc52c1070c
2022-02-22 19:33:33.560 7 INFO nova.virt.block_device [req-98dda25d-5b41-43a7-bffe-a90aea3259e2 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Attempting to driver detach volume 8618d161-43a1-44ab-9bb1-5bdc52c1070c from mountpoint /dev/vdb
2022-02-22 19:33:33.578 7 INFO nova.virt.libvirt.driver [req-98dda25d-5b41-43a7-bffe-a90aea3259e2 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance 7643a34b-37bf-4fd8-8959-94eb3766525b from the persistent domain config.
2022-02-22 19:33:33.719 7 INFO nova.virt.libvirt.driver [req-98dda25d-5b41-43a7-bffe-a90aea3259e2 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance 7643a34b-37bf-4fd8-8959-94eb3766525b from the live domain config.
2022-02-22 19:33:33.722 7 INFO os_brick.initiator.connectors.lightos [req-98dda25d-5b41-43a7-bffe-a90aea3259e2 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c9f1f55a-fb00-44be-b36c-aa1e65873395
2022-02-22 19:33:35.509 7 INFO nova.compute.claims [req-68969b71-beba-451a-8e15-2fec5c0bf85f ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Claim successful on node rack08-server63
2022-02-22 19:33:35.915 7 INFO nova.virt.libvirt.driver [req-68969b71-beba-451a-8e15-2fec5c0bf85f ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Creating image
2022-02-22 19:33:36.133 7 INFO nova.compute.claims [req-f4c584a7-307d-41f1-a8bc-208430c78643 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Claim successful on node rack08-server63
2022-02-22 19:33:36.522 7 INFO nova.virt.libvirt.driver [req-f4c584a7-307d-41f1-a8bc-208430c78643 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Creating image
2022-02-22 19:33:36.824 7 INFO nova.compute.claims [req-88bbafad-a3d2-4978-91c4-a7471339d689 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Claim successful on node rack08-server63
2022-02-22 19:33:37.038 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] VM Resumed (Lifecycle Event)
2022-02-22 19:33:37.046 7 INFO nova.virt.libvirt.driver [-] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Instance spawned successfully.
2022-02-22 19:33:37.046 7 INFO nova.compute.manager [req-68969b71-beba-451a-8e15-2fec5c0bf85f ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Took 1.13 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:37.100 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:37.101 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] VM Started (Lifecycle Event)
2022-02-22 19:33:37.133 7 INFO nova.compute.manager [req-68969b71-beba-451a-8e15-2fec5c0bf85f ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Took 1.66 seconds to build instance.
2022-02-22 19:33:37.209 7 INFO nova.virt.libvirt.driver [req-88bbafad-a3d2-4978-91c4-a7471339d689 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Creating image
2022-02-22 19:33:37.694 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] VM Resumed (Lifecycle Event)
2022-02-22 19:33:37.702 7 INFO nova.virt.libvirt.driver [-] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Instance spawned successfully.
2022-02-22 19:33:37.703 7 INFO nova.compute.manager [req-f4c584a7-307d-41f1-a8bc-208430c78643 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:37.749 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:37.750 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] VM Started (Lifecycle Event)
2022-02-22 19:33:37.790 7 INFO nova.compute.manager [req-f4c584a7-307d-41f1-a8bc-208430c78643 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Took 1.70 seconds to build instance.
2022-02-22 19:33:38.331 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] VM Resumed (Lifecycle Event)
2022-02-22 19:33:38.338 7 INFO nova.virt.libvirt.driver [-] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Instance spawned successfully.
2022-02-22 19:33:38.338 7 INFO nova.compute.manager [req-88bbafad-a3d2-4978-91c4-a7471339d689 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Took 1.13 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:38.393 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:38.394 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] VM Started (Lifecycle Event)
2022-02-22 19:33:38.441 7 INFO nova.compute.manager [req-88bbafad-a3d2-4978-91c4-a7471339d689 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Took 1.66 seconds to build instance.
2022-02-22 19:33:40.361 7 INFO nova.compute.manager [req-e5ee3436-2180-4dbe-988a-375ef5248864 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Attaching volume f178483d-3c4e-42c2-b55b-7bf3cddbcb56 to /dev/vdb
2022-02-22 19:33:40.446 7 WARNING os_brick.initiator.connectors.nvmeof [req-e5ee3436-2180-4dbe-988a-375ef5248864 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:33:41.496 7 INFO nova.compute.manager [req-a2fddce7-59d6-4e0e-93b2-a2adae391a18 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Attaching volume a501c815-2c92-49b2-afad-78bd66d38c75 to /dev/vdb
2022-02-22 19:33:41.718 7 WARNING os_brick.initiator.connectors.nvmeof [req-a2fddce7-59d6-4e0e-93b2-a2adae391a18 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:33:41.779 7 INFO os_brick.initiator.connectors.lightos [req-e5ee3436-2180-4dbe-988a-375ef5248864 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: connect_volume called for volume 6187ec75-8835-4467-8ede-adf32e29ec67, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6187ec75-8835-4467-8ede-adf32e29ec67', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:33:41.783 7 INFO os_brick.initiator.connectors.lightos [req-e5ee3436-2180-4dbe-988a-375ef5248864 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6187ec75-8835-4467-8ede-adf32e29ec67
2022-02-22 19:33:42.978 7 INFO nova.compute.manager [req-176117f6-23ac-4465-a392-a09d9146aa66 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Detaching volume f178483d-3c4e-42c2-b55b-7bf3cddbcb56
2022-02-22 19:33:43.042 7 INFO nova.virt.block_device [req-176117f6-23ac-4465-a392-a09d9146aa66 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Attempting to driver detach volume f178483d-3c4e-42c2-b55b-7bf3cddbcb56 from mountpoint /dev/vdb
2022-02-22 19:33:43.073 7 INFO nova.virt.libvirt.driver [req-176117f6-23ac-4465-a392-a09d9146aa66 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance 640de850-bfcc-4ab3-a3c3-218f43a7b022 from the persistent domain config.
2022-02-22 19:33:43.078 7 INFO os_brick.initiator.connectors.lightos [req-a2fddce7-59d6-4e0e-93b2-a2adae391a18 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: connect_volume called for volume 52db475b-e3c3-43f7-9b6b-b522973f7f30, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '52db475b-e3c3-43f7-9b6b-b522973f7f30', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:33:43.081 7 INFO os_brick.initiator.connectors.lightos [req-a2fddce7-59d6-4e0e-93b2-a2adae391a18 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 52db475b-e3c3-43f7-9b6b-b522973f7f30
2022-02-22 19:33:43.214 7 INFO nova.virt.libvirt.driver [req-176117f6-23ac-4465-a392-a09d9146aa66 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance 640de850-bfcc-4ab3-a3c3-218f43a7b022 from the live domain config.
2022-02-22 19:33:43.222 7 INFO os_brick.initiator.connectors.lightos [req-176117f6-23ac-4465-a392-a09d9146aa66 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6187ec75-8835-4467-8ede-adf32e29ec67
2022-02-22 19:33:43.972 7 INFO nova.compute.manager [req-6d7340f1-f637-4964-97cd-1261ae38be9c ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Attaching volume a501c815-2c92-49b2-afad-78bd66d38c75 to /dev/vdb
2022-02-22 19:33:44.068 7 WARNING os_brick.initiator.connectors.nvmeof [req-6d7340f1-f637-4964-97cd-1261ae38be9c ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:33:45.418 7 INFO os_brick.initiator.connectors.lightos [req-6d7340f1-f637-4964-97cd-1261ae38be9c ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: connect_volume called for volume 52db475b-e3c3-43f7-9b6b-b522973f7f30, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '52db475b-e3c3-43f7-9b6b-b522973f7f30', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:33:45.420 7 INFO os_brick.initiator.connectors.lightos [req-6d7340f1-f637-4964-97cd-1261ae38be9c ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 52db475b-e3c3-43f7-9b6b-b522973f7f30
2022-02-22 19:33:46.433 7 INFO nova.compute.claims [req-1e4d4d6b-a948-45fd-b3e2-b42ec6bbea58 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Claim successful on node rack08-server63
2022-02-22 19:33:46.554 7 INFO nova.compute.manager [req-27ced160-2d91-4673-8eda-19eb1bd86fce ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Detaching volume a501c815-2c92-49b2-afad-78bd66d38c75
2022-02-22 19:33:46.620 7 INFO nova.virt.block_device [req-27ced160-2d91-4673-8eda-19eb1bd86fce ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Attempting to driver detach volume a501c815-2c92-49b2-afad-78bd66d38c75 from mountpoint /dev/vdb
2022-02-22 19:33:46.637 7 INFO nova.virt.libvirt.driver [req-27ced160-2d91-4673-8eda-19eb1bd86fce ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Successfully detached device vdb from instance db152671-f219-457f-a8db-8551bf0c2bdd from the persistent domain config.
2022-02-22 19:33:46.787 7 INFO nova.virt.libvirt.driver [req-27ced160-2d91-4673-8eda-19eb1bd86fce ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Successfully detached device vdb from instance db152671-f219-457f-a8db-8551bf0c2bdd from the live domain config.
2022-02-22 19:33:46.845 7 INFO nova.virt.libvirt.driver [req-1e4d4d6b-a948-45fd-b3e2-b42ec6bbea58 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Creating image
2022-02-22 19:33:46.871 7 INFO nova.virt.libvirt.driver [req-27ced160-2d91-4673-8eda-19eb1bd86fce ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Detected multiple connections on this host for volume: a501c815-2c92-49b2-afad-78bd66d38c75, skipping target disconnect.
2022-02-22 19:33:48.090 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] VM Resumed (Lifecycle Event)
2022-02-22 19:33:48.099 7 INFO nova.virt.libvirt.driver [-] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Instance spawned successfully.
2022-02-22 19:33:48.100 7 INFO nova.compute.manager [req-1e4d4d6b-a948-45fd-b3e2-b42ec6bbea58 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-22 19:33:48.144 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:33:48.145 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] VM Started (Lifecycle Event)
2022-02-22 19:33:48.181 7 INFO nova.compute.manager [req-1e4d4d6b-a948-45fd-b3e2-b42ec6bbea58 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Took 1.79 seconds to build instance.
2022-02-22 19:33:49.022 7 INFO nova.compute.manager [req-9e346227-7725-4a05-89bf-88953736f019 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Detaching volume a501c815-2c92-49b2-afad-78bd66d38c75
2022-02-22 19:33:49.079 7 INFO nova.virt.block_device [req-9e346227-7725-4a05-89bf-88953736f019 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Attempting to driver detach volume a501c815-2c92-49b2-afad-78bd66d38c75 from mountpoint /dev/vdb
2022-02-22 19:33:49.096 7 INFO nova.virt.libvirt.driver [req-9e346227-7725-4a05-89bf-88953736f019 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Successfully detached device vdb from instance 706de5d7-dcd8-4559-aa63-57549037faad from the persistent domain config.
2022-02-22 19:33:49.286 7 INFO nova.virt.libvirt.driver [req-9e346227-7725-4a05-89bf-88953736f019 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Successfully detached device vdb from instance 706de5d7-dcd8-4559-aa63-57549037faad from the live domain config.
2022-02-22 19:33:50.958 7 INFO nova.compute.manager [req-7490de60-a994-47eb-bc1a-253b455e540d c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Attaching volume 1ec0d124-e7de-4408-a105-20057e372ac6 to /dev/vdb
2022-02-22 19:33:51.046 7 WARNING os_brick.initiator.connectors.nvmeof [req-7490de60-a994-47eb-bc1a-253b455e540d c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:34:49.529 7 INFO os_brick.initiator.connectors.lightos [req-7490de60-a994-47eb-bc1a-253b455e540d c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: connect_volume called for volume 94ce5936-15b5-4c69-bb7e-d65b7844bbf4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '94ce5936-15b5-4c69-bb7e-d65b7844bbf4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:34:49.533 7 INFO os_brick.initiator.connectors.lightos [req-7490de60-a994-47eb-bc1a-253b455e540d c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 94ce5936-15b5-4c69-bb7e-d65b7844bbf4
2022-02-22 19:34:50.698 7 INFO nova.compute.manager [req-2d671731-0320-4a7d-aae6-af03dff77ba1 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Detaching volume 1ec0d124-e7de-4408-a105-20057e372ac6
2022-02-22 19:34:50.758 7 INFO nova.virt.block_device [req-2d671731-0320-4a7d-aae6-af03dff77ba1 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Attempting to driver detach volume 1ec0d124-e7de-4408-a105-20057e372ac6 from mountpoint /dev/vdb
2022-02-22 19:34:50.780 7 INFO nova.virt.libvirt.driver [req-2d671731-0320-4a7d-aae6-af03dff77ba1 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance b24a302b-3d31-4903-a707-2b8f31f61f5d from the persistent domain config.
2022-02-22 19:34:50.920 7 INFO nova.virt.libvirt.driver [req-2d671731-0320-4a7d-aae6-af03dff77ba1 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Successfully detached device vdb from instance b24a302b-3d31-4903-a707-2b8f31f61f5d from the live domain config.
2022-02-22 19:34:50.924 7 INFO os_brick.initiator.connectors.lightos [req-2d671731-0320-4a7d-aae6-af03dff77ba1 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 94ce5936-15b5-4c69-bb7e-d65b7844bbf4
2022-02-22 19:34:54.151 7 INFO nova.compute.manager [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Terminating instance
2022-02-22 19:34:54.490 7 INFO nova.virt.libvirt.driver [-] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Instance destroyed successfully.
2022-02-22 19:34:54.506 7 INFO nova.virt.libvirt.driver [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Deleting instance files /var/lib/nova/instances/b24a302b-3d31-4903-a707-2b8f31f61f5d_del
2022-02-22 19:34:54.508 7 INFO nova.virt.libvirt.driver [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Deletion of /var/lib/nova/instances/b24a302b-3d31-4903-a707-2b8f31f61f5d_del complete
2022-02-22 19:34:54.574 7 INFO nova.virt.libvirt.host [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] UEFI support detected
2022-02-22 19:34:54.576 7 INFO nova.compute.manager [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:34:54.644 7 INFO nova.compute.manager [-] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:34:54.829 7 INFO nova.scheduler.client.report [req-cba431b1-b8a5-4707-9d62-853439a3ed34 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Deleted allocations for instance b24a302b-3d31-4903-a707-2b8f31f61f5d
2022-02-22 19:34:56.555 7 INFO nova.compute.manager [req-2a84c28d-e10c-4a5b-ae7a-fc5c1839699c c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Terminating instance
2022-02-22 19:34:56.892 7 INFO nova.virt.libvirt.driver [-] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Instance destroyed successfully.
2022-02-22 19:34:56.911 7 INFO nova.virt.libvirt.driver [req-2a84c28d-e10c-4a5b-ae7a-fc5c1839699c c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Deleting instance files /var/lib/nova/instances/640de850-bfcc-4ab3-a3c3-218f43a7b022_del
2022-02-22 19:34:56.913 7 INFO nova.virt.libvirt.driver [req-2a84c28d-e10c-4a5b-ae7a-fc5c1839699c c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Deletion of /var/lib/nova/instances/640de850-bfcc-4ab3-a3c3-218f43a7b022_del complete
2022-02-22 19:34:56.979 7 INFO nova.compute.manager [req-2a84c28d-e10c-4a5b-ae7a-fc5c1839699c c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:34:57.047 7 INFO nova.compute.manager [-] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:34:57.242 7 INFO nova.scheduler.client.report [req-2a84c28d-e10c-4a5b-ae7a-fc5c1839699c c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Deleted allocations for instance 640de850-bfcc-4ab3-a3c3-218f43a7b022
2022-02-22 19:34:57.812 7 INFO nova.compute.manager [req-4c4dee0d-c376-4691-a19a-52d8b6855f89 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Terminating instance
2022-02-22 19:34:58.163 7 INFO nova.virt.libvirt.driver [-] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Instance destroyed successfully.
2022-02-22 19:34:58.178 7 INFO nova.virt.libvirt.driver [req-4c4dee0d-c376-4691-a19a-52d8b6855f89 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Deleting instance files /var/lib/nova/instances/317e36a9-07ef-40d8-8335-f9b6929a15c4_del
2022-02-22 19:34:58.180 7 INFO nova.virt.libvirt.driver [req-4c4dee0d-c376-4691-a19a-52d8b6855f89 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Deletion of /var/lib/nova/instances/317e36a9-07ef-40d8-8335-f9b6929a15c4_del complete
2022-02-22 19:34:58.248 7 INFO nova.compute.manager [req-4c4dee0d-c376-4691-a19a-52d8b6855f89 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:34:58.314 7 INFO nova.compute.manager [-] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:34:58.510 7 INFO nova.scheduler.client.report [req-4c4dee0d-c376-4691-a19a-52d8b6855f89 c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Deleted allocations for instance 317e36a9-07ef-40d8-8335-f9b6929a15c4
2022-02-22 19:35:00.196 7 INFO nova.compute.manager [req-0e94ec4e-93f1-43c9-8cd5-2a3c5f6caa9f c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Terminating instance
2022-02-22 19:35:00.545 7 INFO nova.virt.libvirt.driver [-] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Instance destroyed successfully.
2022-02-22 19:35:00.561 7 INFO nova.virt.libvirt.driver [req-0e94ec4e-93f1-43c9-8cd5-2a3c5f6caa9f c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Deleting instance files /var/lib/nova/instances/7643a34b-37bf-4fd8-8959-94eb3766525b_del
2022-02-22 19:35:00.563 7 INFO nova.virt.libvirt.driver [req-0e94ec4e-93f1-43c9-8cd5-2a3c5f6caa9f c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Deletion of /var/lib/nova/instances/7643a34b-37bf-4fd8-8959-94eb3766525b_del complete
2022-02-22 19:35:00.632 7 INFO nova.compute.manager [req-0e94ec4e-93f1-43c9-8cd5-2a3c5f6caa9f c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:35:00.695 7 INFO nova.compute.manager [-] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] Took 0.06 seconds to deallocate network for instance.
2022-02-22 19:35:00.893 7 INFO nova.scheduler.client.report [req-0e94ec4e-93f1-43c9-8cd5-2a3c5f6caa9f c477e8b1ba4d40988a493cc1a8eb8b42 804c210a6bc54f319325cde1fce24a6d - default default] Deleted allocations for instance 7643a34b-37bf-4fd8-8959-94eb3766525b
2022-02-22 19:35:06.123 7 INFO nova.compute.claims [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Claim successful on node rack08-server63
2022-02-22 19:35:06.387 7 INFO nova.virt.libvirt.driver [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 19:35:06.476 7 INFO nova.virt.block_device [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Booting with volume beff743a-f78e-44b8-8497-7aaca1876de4 at /dev/vda
2022-02-22 19:35:06.565 7 WARNING os_brick.initiator.connectors.nvmeof [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:35:08.079 7 INFO nova.virt.libvirt.driver [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Creating image
2022-02-22 19:35:08.092 7 INFO os_brick.initiator.connectors.lightos [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: connect_volume called for volume 6545e589-cc86-437d-aa03-7de53ba25c73, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6545e589-cc86-437d-aa03-7de53ba25c73', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:35:08.095 7 INFO os_brick.initiator.connectors.lightos [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6545e589-cc86-437d-aa03-7de53ba25c73
2022-02-22 19:35:08.938 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1646d54e-524e-4128-88ce-027166b0890e] VM Resumed (Lifecycle Event)
2022-02-22 19:35:08.946 7 INFO nova.virt.libvirt.driver [-] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Instance spawned successfully.
2022-02-22 19:35:08.947 7 INFO nova.compute.manager [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Took 0.87 seconds to spawn the instance on the hypervisor.
2022-02-22 19:35:08.992 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1646d54e-524e-4128-88ce-027166b0890e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:35:08.993 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1646d54e-524e-4128-88ce-027166b0890e] VM Started (Lifecycle Event)
2022-02-22 19:35:09.028 7 INFO nova.compute.manager [req-62dc2d31-e5a9-4c86-8cdb-46c843cc4854 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Took 2.95 seconds to build instance.
2022-02-22 19:35:09.489 7 INFO nova.compute.manager [-] [instance: b24a302b-3d31-4903-a707-2b8f31f61f5d] VM Stopped (Lifecycle Event)
2022-02-22 19:35:11.327 7 INFO nova.compute.manager [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Terminating instance
2022-02-22 19:35:11.657 7 INFO nova.virt.libvirt.driver [-] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Instance destroyed successfully.
2022-02-22 19:35:11.734 7 INFO os_brick.initiator.connectors.lightos [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6545e589-cc86-437d-aa03-7de53ba25c73
2022-02-22 19:35:11.745 7 INFO nova.virt.libvirt.driver [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Deleting instance files /var/lib/nova/instances/1646d54e-524e-4128-88ce-027166b0890e_del
2022-02-22 19:35:11.746 7 INFO nova.virt.libvirt.driver [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Deletion of /var/lib/nova/instances/1646d54e-524e-4128-88ce-027166b0890e_del complete
2022-02-22 19:35:11.814 7 INFO nova.compute.manager [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 19:35:11.878 7 INFO nova.compute.manager [-] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Took 0.06 seconds to deallocate network for instance.
2022-02-22 19:35:11.891 7 INFO nova.compute.manager [-] [instance: 640de850-bfcc-4ab3-a3c3-218f43a7b022] VM Stopped (Lifecycle Event)
2022-02-22 19:35:13.138 7 INFO nova.compute.manager [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 1646d54e-524e-4128-88ce-027166b0890e] Took 1.26 seconds to detach 1 volumes for instance.
2022-02-22 19:35:13.160 7 INFO nova.compute.manager [-] [instance: 317e36a9-07ef-40d8-8335-f9b6929a15c4] VM Stopped (Lifecycle Event)
2022-02-22 19:35:13.337 7 INFO nova.scheduler.client.report [req-38ae1c1e-f190-4656-8820-9edffd0096c7 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Deleted allocations for instance 1646d54e-524e-4128-88ce-027166b0890e
2022-02-22 19:35:15.543 7 INFO nova.compute.manager [-] [instance: 7643a34b-37bf-4fd8-8959-94eb3766525b] VM Stopped (Lifecycle Event)
2022-02-22 19:35:16.229 7 INFO nova.compute.manager [req-63d5295a-fec5-4935-9e29-2553daedc259 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Terminating instance
2022-02-22 19:35:16.574 7 INFO nova.virt.libvirt.driver [-] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Instance destroyed successfully.
2022-02-22 19:35:16.593 7 INFO nova.virt.libvirt.driver [req-63d5295a-fec5-4935-9e29-2553daedc259 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Deleting instance files /var/lib/nova/instances/706de5d7-dcd8-4559-aa63-57549037faad_del
2022-02-22 19:35:16.595 7 INFO nova.virt.libvirt.driver [req-63d5295a-fec5-4935-9e29-2553daedc259 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Deletion of /var/lib/nova/instances/706de5d7-dcd8-4559-aa63-57549037faad_del complete
2022-02-22 19:35:16.665 7 INFO nova.compute.manager [req-63d5295a-fec5-4935-9e29-2553daedc259 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:35:16.735 7 INFO nova.compute.manager [-] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:35:16.938 7 INFO nova.scheduler.client.report [req-63d5295a-fec5-4935-9e29-2553daedc259 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Deleted allocations for instance 706de5d7-dcd8-4559-aa63-57549037faad
2022-02-22 19:35:17.483 7 INFO nova.compute.manager [req-cc17fe07-d957-4919-8a2f-0a6abff02437 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Terminating instance
2022-02-22 19:35:17.841 7 INFO nova.virt.libvirt.driver [-] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Instance destroyed successfully.
2022-02-22 19:35:17.855 7 INFO nova.virt.libvirt.driver [req-cc17fe07-d957-4919-8a2f-0a6abff02437 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Deleting instance files /var/lib/nova/instances/db152671-f219-457f-a8db-8551bf0c2bdd_del
2022-02-22 19:35:17.857 7 INFO nova.virt.libvirt.driver [req-cc17fe07-d957-4919-8a2f-0a6abff02437 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Deletion of /var/lib/nova/instances/db152671-f219-457f-a8db-8551bf0c2bdd_del complete
2022-02-22 19:35:17.926 7 INFO nova.compute.manager [req-cc17fe07-d957-4919-8a2f-0a6abff02437 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:35:17.998 7 INFO nova.compute.manager [-] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:35:18.198 7 INFO nova.scheduler.client.report [req-cc17fe07-d957-4919-8a2f-0a6abff02437 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Deleted allocations for instance db152671-f219-457f-a8db-8551bf0c2bdd
2022-02-22 19:35:18.742 7 INFO nova.compute.manager [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Terminating instance
2022-02-22 19:35:19.087 7 INFO nova.virt.libvirt.driver [-] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Instance destroyed successfully.
2022-02-22 19:35:19.154 7 INFO os_brick.initiator.connectors.lightos [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 5ca3cf5d-fbbf-48b9-9b88-d8f0bfcb1148
2022-02-22 19:35:19.165 7 INFO nova.virt.libvirt.driver [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Deleting instance files /var/lib/nova/instances/04c91337-8532-4be5-81ec-98b456b53b9b_del
2022-02-22 19:35:19.165 7 INFO nova.virt.libvirt.driver [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Deletion of /var/lib/nova/instances/04c91337-8532-4be5-81ec-98b456b53b9b_del complete
2022-02-22 19:35:19.242 7 INFO nova.compute.manager [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 19:35:19.313 7 INFO nova.compute.manager [-] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:35:20.548 7 INFO nova.compute.manager [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] Took 1.23 seconds to detach 1 volumes for instance.
2022-02-22 19:35:20.739 7 INFO nova.scheduler.client.report [req-5d0842ce-b409-4ad5-9f95-b27240866b23 ec08f247c4d24206965dcdf61a601461 e6ae686d86da4caaaf9250a8b93b64f6 - default default] Deleted allocations for instance 04c91337-8532-4be5-81ec-98b456b53b9b
2022-02-22 19:35:27.085 7 INFO nova.compute.manager [-] [instance: 1646d54e-524e-4128-88ce-027166b0890e] VM Stopped (Lifecycle Event)
2022-02-22 19:35:31.572 7 INFO nova.compute.manager [-] [instance: 706de5d7-dcd8-4559-aa63-57549037faad] VM Stopped (Lifecycle Event)
2022-02-22 19:35:32.839 7 INFO nova.compute.manager [-] [instance: db152671-f219-457f-a8db-8551bf0c2bdd] VM Stopped (Lifecycle Event)
2022-02-22 19:35:34.085 7 INFO nova.compute.manager [-] [instance: 04c91337-8532-4be5-81ec-98b456b53b9b] VM Stopped (Lifecycle Event)
2022-02-22 19:36:02.793 7 INFO nova.compute.claims [req-47e28fc5-4c0a-426f-bc8b-efb46aa9ffd0 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Claim successful on node rack08-server63
2022-02-22 19:36:03.183 7 INFO nova.virt.libvirt.driver [req-47e28fc5-4c0a-426f-bc8b-efb46aa9ffd0 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Creating image
2022-02-22 19:36:04.368 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] VM Resumed (Lifecycle Event)
2022-02-22 19:36:04.376 7 INFO nova.virt.libvirt.driver [-] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Instance spawned successfully.
2022-02-22 19:36:04.377 7 INFO nova.compute.manager [req-47e28fc5-4c0a-426f-bc8b-efb46aa9ffd0 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 19:36:04.422 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:36:04.423 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] VM Started (Lifecycle Event)
2022-02-22 19:36:04.463 7 INFO nova.compute.manager [req-47e28fc5-4c0a-426f-bc8b-efb46aa9ffd0 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Took 1.70 seconds to build instance.
2022-02-22 19:36:05.079 7 INFO nova.compute.manager [req-650379ef-7b03-414d-a04c-f6f05a6eec46 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Terminating instance
2022-02-22 19:36:05.424 7 INFO nova.virt.libvirt.driver [-] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Instance destroyed successfully.
2022-02-22 19:36:05.439 7 INFO nova.virt.libvirt.driver [req-650379ef-7b03-414d-a04c-f6f05a6eec46 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Deleting instance files /var/lib/nova/instances/d95362c2-18fe-4260-9872-ba21aea14e81_del
2022-02-22 19:36:05.440 7 INFO nova.virt.libvirt.driver [req-650379ef-7b03-414d-a04c-f6f05a6eec46 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Deletion of /var/lib/nova/instances/d95362c2-18fe-4260-9872-ba21aea14e81_del complete
2022-02-22 19:36:05.507 7 INFO nova.compute.manager [req-650379ef-7b03-414d-a04c-f6f05a6eec46 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 19:36:05.583 7 INFO nova.compute.manager [-] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] Took 0.08 seconds to deallocate network for instance.
2022-02-22 19:36:05.782 7 INFO nova.scheduler.client.report [req-650379ef-7b03-414d-a04c-f6f05a6eec46 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] Deleted allocations for instance d95362c2-18fe-4260-9872-ba21aea14e81
2022-02-22 19:36:07.413 7 INFO nova.compute.claims [req-d75e5f0f-4176-400b-914a-1a89cffbd5e6 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Claim successful on node rack08-server63
2022-02-22 19:36:07.795 7 INFO nova.virt.libvirt.driver [req-d75e5f0f-4176-400b-914a-1a89cffbd5e6 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Creating image
2022-02-22 19:36:08.930 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] VM Resumed (Lifecycle Event)
2022-02-22 19:36:08.938 7 INFO nova.virt.libvirt.driver [-] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Instance spawned successfully.
2022-02-22 19:36:08.938 7 INFO nova.compute.manager [req-d75e5f0f-4176-400b-914a-1a89cffbd5e6 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 19:36:08.985 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:36:08.986 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] VM Started (Lifecycle Event)
2022-02-22 19:36:09.020 7 INFO nova.compute.manager [req-d75e5f0f-4176-400b-914a-1a89cffbd5e6 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Took 1.64 seconds to build instance.
2022-02-22 19:36:09.692 7 INFO nova.compute.manager [req-692cf946-748e-43e5-a3cd-8e1e00abcc7e 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Terminating instance
2022-02-22 19:36:10.041 7 INFO nova.virt.libvirt.driver [-] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Instance destroyed successfully.
2022-02-22 19:36:10.057 7 INFO nova.virt.libvirt.driver [req-692cf946-748e-43e5-a3cd-8e1e00abcc7e 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Deleting instance files /var/lib/nova/instances/4fbc1e32-878f-4953-879b-3be67b3306b3_del
2022-02-22 19:36:10.058 7 INFO nova.virt.libvirt.driver [req-692cf946-748e-43e5-a3cd-8e1e00abcc7e 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Deletion of /var/lib/nova/instances/4fbc1e32-878f-4953-879b-3be67b3306b3_del complete
2022-02-22 19:36:10.128 7 INFO nova.compute.manager [req-692cf946-748e-43e5-a3cd-8e1e00abcc7e 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:36:10.194 7 INFO nova.compute.manager [-] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:36:10.391 7 INFO nova.scheduler.client.report [req-692cf946-748e-43e5-a3cd-8e1e00abcc7e 094fd9b37d01487596043b5d83db7ba0 727752b1d7ae4450a12d55aa8e849045 - default default] Deleted allocations for instance 4fbc1e32-878f-4953-879b-3be67b3306b3
2022-02-22 19:36:20.422 7 INFO nova.compute.manager [-] [instance: d95362c2-18fe-4260-9872-ba21aea14e81] VM Stopped (Lifecycle Event)
2022-02-22 19:36:25.039 7 INFO nova.compute.manager [-] [instance: 4fbc1e32-878f-4953-879b-3be67b3306b3] VM Stopped (Lifecycle Event)
2022-02-22 19:36:50.960 7 INFO nova.compute.claims [req-db9d7d33-41ec-404a-b027-0fcbc795e771 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Claim successful on node rack08-server63
2022-02-22 19:36:51.349 7 INFO nova.virt.libvirt.driver [req-db9d7d33-41ec-404a-b027-0fcbc795e771 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Creating image
2022-02-22 19:36:52.453 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] VM Resumed (Lifecycle Event)
2022-02-22 19:36:52.461 7 INFO nova.virt.libvirt.driver [-] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Instance spawned successfully.
2022-02-22 19:36:52.462 7 INFO nova.compute.manager [req-db9d7d33-41ec-404a-b027-0fcbc795e771 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Took 1.11 seconds to spawn the instance on the hypervisor.
2022-02-22 19:36:52.507 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:36:52.508 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] VM Started (Lifecycle Event)
2022-02-22 19:36:52.547 7 INFO nova.compute.manager [req-db9d7d33-41ec-404a-b027-0fcbc795e771 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Took 1.63 seconds to build instance.
2022-02-22 19:36:56.338 7 INFO nova.compute.manager [req-e2e12c13-fec8-49a6-a647-d59be33d5a95 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Terminating instance
2022-02-22 19:36:56.695 7 INFO nova.virt.libvirt.driver [-] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Instance destroyed successfully.
2022-02-22 19:36:56.709 7 INFO nova.virt.libvirt.driver [req-e2e12c13-fec8-49a6-a647-d59be33d5a95 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Deleting instance files /var/lib/nova/instances/b1431a31-6591-4afd-9df6-be810d16eb6a_del
2022-02-22 19:36:56.710 7 INFO nova.virt.libvirt.driver [req-e2e12c13-fec8-49a6-a647-d59be33d5a95 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Deletion of /var/lib/nova/instances/b1431a31-6591-4afd-9df6-be810d16eb6a_del complete
2022-02-22 19:36:56.779 7 INFO nova.compute.manager [req-e2e12c13-fec8-49a6-a647-d59be33d5a95 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 19:36:56.846 7 INFO nova.compute.manager [-] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:36:57.041 7 INFO nova.scheduler.client.report [req-e2e12c13-fec8-49a6-a647-d59be33d5a95 45f74ebff6f642799bfcde1a9937678a fca6b67aeb4f4e91972c8eabcdb3afc6 - default default] Deleted allocations for instance b1431a31-6591-4afd-9df6-be810d16eb6a
2022-02-22 19:37:06.173 7 INFO nova.compute.claims [req-46061056-8da8-4064-856e-f8984f99b53e 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Claim successful on node rack08-server63
2022-02-22 19:37:06.579 7 INFO nova.virt.libvirt.driver [req-46061056-8da8-4064-856e-f8984f99b53e 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Creating image
2022-02-22 19:37:07.706 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] VM Resumed (Lifecycle Event)
2022-02-22 19:37:07.713 7 INFO nova.virt.libvirt.driver [-] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Instance spawned successfully.
2022-02-22 19:37:07.714 7 INFO nova.compute.manager [req-46061056-8da8-4064-856e-f8984f99b53e 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 19:37:07.763 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:37:07.764 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] VM Started (Lifecycle Event)
2022-02-22 19:37:07.799 7 INFO nova.compute.manager [req-46061056-8da8-4064-856e-f8984f99b53e 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Took 1.67 seconds to build instance.
2022-02-22 19:37:08.175 7 INFO nova.compute.manager [req-9e9c320a-3cee-4b73-8eba-b7927069c841 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Terminating instance
2022-02-22 19:37:08.516 7 INFO nova.virt.libvirt.driver [-] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Instance destroyed successfully.
2022-02-22 19:37:08.532 7 INFO nova.virt.libvirt.driver [req-9e9c320a-3cee-4b73-8eba-b7927069c841 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Deleting instance files /var/lib/nova/instances/27dd8de0-3e51-4162-9f33-ae08af33df04_del
2022-02-22 19:37:08.533 7 INFO nova.virt.libvirt.driver [req-9e9c320a-3cee-4b73-8eba-b7927069c841 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Deletion of /var/lib/nova/instances/27dd8de0-3e51-4162-9f33-ae08af33df04_del complete
2022-02-22 19:37:08.601 7 INFO nova.compute.manager [req-9e9c320a-3cee-4b73-8eba-b7927069c841 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:37:08.668 7 INFO nova.compute.manager [-] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:37:08.867 7 INFO nova.scheduler.client.report [req-9e9c320a-3cee-4b73-8eba-b7927069c841 292654bc13f84d40b2cd9ed286e0657a 089f4ee5ec9f4735a708f5f36ef49bc8 - default default] Deleted allocations for instance 27dd8de0-3e51-4162-9f33-ae08af33df04
2022-02-22 19:37:11.694 7 INFO nova.compute.manager [-] [instance: b1431a31-6591-4afd-9df6-be810d16eb6a] VM Stopped (Lifecycle Event)
2022-02-22 19:37:19.571 7 INFO nova.compute.claims [req-3e1c22de-902a-43b2-885c-33d34ca8ccdc 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Claim successful on node rack08-server63
2022-02-22 19:37:19.971 7 INFO nova.virt.libvirt.driver [req-3e1c22de-902a-43b2-885c-33d34ca8ccdc 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Creating image
2022-02-22 19:37:21.171 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] VM Resumed (Lifecycle Event)
2022-02-22 19:37:21.178 7 INFO nova.virt.libvirt.driver [-] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Instance spawned successfully.
2022-02-22 19:37:21.178 7 INFO nova.compute.manager [req-3e1c22de-902a-43b2-885c-33d34ca8ccdc 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 19:37:21.227 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:37:21.227 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] VM Started (Lifecycle Event)
2022-02-22 19:37:21.263 7 INFO nova.compute.manager [req-3e1c22de-902a-43b2-885c-33d34ca8ccdc 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Took 1.73 seconds to build instance.
2022-02-22 19:37:23.513 7 INFO nova.compute.manager [-] [instance: 27dd8de0-3e51-4162-9f33-ae08af33df04] VM Stopped (Lifecycle Event)
2022-02-22 19:37:33.673 7 INFO nova.virt.libvirt.driver [req-b87dafa2-2a9a-43ca-a30a-078c5d48bcb7 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Ignoring supplied device name: /dev/vdb
2022-02-22 19:37:33.845 7 INFO nova.compute.manager [req-b87dafa2-2a9a-43ca-a30a-078c5d48bcb7 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Attaching volume 81e4b662-b838-4c5a-959d-694dde76a64d to /dev/vdb
2022-02-22 19:37:33.934 7 WARNING os_brick.initiator.connectors.nvmeof [req-b87dafa2-2a9a-43ca-a30a-078c5d48bcb7 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:37:35.302 7 INFO os_brick.initiator.connectors.lightos [req-b87dafa2-2a9a-43ca-a30a-078c5d48bcb7 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: connect_volume called for volume c7fe82ed-b18b-4a2b-8fe8-dce23fe630a9, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c7fe82ed-b18b-4a2b-8fe8-dce23fe630a9', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:37:35.306 7 INFO os_brick.initiator.connectors.lightos [req-b87dafa2-2a9a-43ca-a30a-078c5d48bcb7 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c7fe82ed-b18b-4a2b-8fe8-dce23fe630a9
2022-02-22 19:37:46.459 7 INFO nova.compute.manager [req-a48db6b4-6c32-4e35-8bbc-94d6625782bd 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Detaching volume 81e4b662-b838-4c5a-959d-694dde76a64d
2022-02-22 19:37:46.523 7 INFO nova.virt.block_device [req-a48db6b4-6c32-4e35-8bbc-94d6625782bd 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Attempting to driver detach volume 81e4b662-b838-4c5a-959d-694dde76a64d from mountpoint /dev/vdb
2022-02-22 19:37:46.542 7 INFO nova.virt.libvirt.driver [req-a48db6b4-6c32-4e35-8bbc-94d6625782bd 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Successfully detached device vdb from instance 7aab49dd-f812-4aed-940b-2d82fd2b84ee from the persistent domain config.
2022-02-22 19:37:46.699 7 INFO nova.virt.libvirt.driver [req-a48db6b4-6c32-4e35-8bbc-94d6625782bd 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Successfully detached device vdb from instance 7aab49dd-f812-4aed-940b-2d82fd2b84ee from the live domain config.
2022-02-22 19:37:46.702 7 INFO os_brick.initiator.connectors.lightos [req-a48db6b4-6c32-4e35-8bbc-94d6625782bd 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c7fe82ed-b18b-4a2b-8fe8-dce23fe630a9
2022-02-22 19:37:48.725 7 INFO nova.compute.manager [req-308b35c7-b204-4f90-a940-5a6a96a1d180 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Terminating instance
2022-02-22 19:37:49.074 7 INFO nova.virt.libvirt.driver [-] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Instance destroyed successfully.
2022-02-22 19:37:49.088 7 INFO nova.virt.libvirt.driver [req-308b35c7-b204-4f90-a940-5a6a96a1d180 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Deleting instance files /var/lib/nova/instances/7aab49dd-f812-4aed-940b-2d82fd2b84ee_del
2022-02-22 19:37:49.089 7 INFO nova.virt.libvirt.driver [req-308b35c7-b204-4f90-a940-5a6a96a1d180 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Deletion of /var/lib/nova/instances/7aab49dd-f812-4aed-940b-2d82fd2b84ee_del complete
2022-02-22 19:37:49.154 7 INFO nova.compute.manager [req-308b35c7-b204-4f90-a940-5a6a96a1d180 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 19:37:49.220 7 INFO nova.compute.manager [-] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] Took 0.06 seconds to deallocate network for instance.
2022-02-22 19:37:49.414 7 INFO nova.scheduler.client.report [req-308b35c7-b204-4f90-a940-5a6a96a1d180 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Deleted allocations for instance 7aab49dd-f812-4aed-940b-2d82fd2b84ee
2022-02-22 19:37:54.721 7 INFO nova.compute.claims [req-97c03a90-4839-43f0-bc18-7bdb81d1c90e 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Claim successful on node rack08-server63
2022-02-22 19:37:55.108 7 INFO nova.virt.libvirt.driver [req-97c03a90-4839-43f0-bc18-7bdb81d1c90e 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Creating image
2022-02-22 19:37:56.263 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] VM Resumed (Lifecycle Event)
2022-02-22 19:37:56.271 7 INFO nova.virt.libvirt.driver [-] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Instance spawned successfully.
2022-02-22 19:37:56.272 7 INFO nova.compute.manager [req-97c03a90-4839-43f0-bc18-7bdb81d1c90e 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 19:37:56.320 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:37:56.321 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] VM Started (Lifecycle Event)
2022-02-22 19:37:56.354 7 INFO nova.compute.manager [req-97c03a90-4839-43f0-bc18-7bdb81d1c90e 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Took 1.67 seconds to build instance.
2022-02-22 19:37:56.663 7 INFO nova.virt.libvirt.driver [req-1a154eca-dc09-4859-bd20-7d27329fe21f 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Ignoring supplied device name: /dev/vdb
2022-02-22 19:37:56.826 7 INFO nova.compute.manager [req-1a154eca-dc09-4859-bd20-7d27329fe21f 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Attaching volume 9d62daa9-cafc-4bd4-aed6-3d130c273376 to /dev/vdb
2022-02-22 19:37:56.874 7 INFO nova.compute.claims [req-34ba0da0-6236-4f1f-84d6-320424327358 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Claim successful on node rack08-server63
2022-02-22 19:37:56.925 7 WARNING os_brick.initiator.connectors.nvmeof [req-1a154eca-dc09-4859-bd20-7d27329fe21f 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:37:57.289 7 INFO nova.virt.libvirt.driver [req-34ba0da0-6236-4f1f-84d6-320424327358 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Creating image
2022-02-22 19:37:58.275 7 INFO os_brick.initiator.connectors.lightos [req-1a154eca-dc09-4859-bd20-7d27329fe21f 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] LIGHTOS: connect_volume called for volume 26ea804e-5e36-45f7-b389-119e30f68618, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '26ea804e-5e36-45f7-b389-119e30f68618', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:37:58.279 7 INFO os_brick.initiator.connectors.lightos [req-1a154eca-dc09-4859-bd20-7d27329fe21f 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26ea804e-5e36-45f7-b389-119e30f68618
2022-02-22 19:37:58.432 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] VM Resumed (Lifecycle Event)
2022-02-22 19:37:58.437 7 INFO nova.virt.libvirt.driver [-] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Instance spawned successfully.
2022-02-22 19:37:58.438 7 INFO nova.compute.manager [req-34ba0da0-6236-4f1f-84d6-320424327358 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 19:37:58.495 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 19:37:58.496 7 INFO nova.compute.manager [req-2a8345e1-e3b7-4a1f-8c4a-3f6acdaa583c - - - - -] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] VM Started (Lifecycle Event)
2022-02-22 19:37:58.520 7 INFO nova.compute.manager [req-34ba0da0-6236-4f1f-84d6-320424327358 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Took 1.68 seconds to build instance.
2022-02-22 19:37:58.851 7 INFO nova.virt.libvirt.driver [req-20551c8e-9773-460d-8910-13e35f24de81 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Ignoring supplied device name: /dev/vdb
2022-02-22 19:37:59.007 7 INFO nova.compute.manager [req-20551c8e-9773-460d-8910-13e35f24de81 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Attaching volume 5f01fa22-eae0-458b-8065-ce4bf8367f4f to /dev/vdb
2022-02-22 19:37:59.084 7 WARNING os_brick.initiator.connectors.nvmeof [req-20551c8e-9773-460d-8910-13e35f24de81 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 19:38:00.083 7 INFO nova.compute.manager [req-6b8d1b1b-0009-4a16-b882-35f3c393a11e e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Cinder extended volume 9d62daa9-cafc-4bd4-aed6-3d130c273376; extending it to detect new size
2022-02-22 19:38:00.150 7 INFO os_brick.initiator.connectors.lightos [req-6b8d1b1b-0009-4a16-b882-35f3c393a11e e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26ea804e-5e36-45f7-b389-119e30f68618
2022-02-22 19:38:00.467 7 INFO os_brick.initiator.connectors.lightos [req-20551c8e-9773-460d-8910-13e35f24de81 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: connect_volume called for volume 21ecc0de-3e51-4c5c-b78c-c93fec966aa1, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '21ecc0de-3e51-4c5c-b78c-c93fec966aa1', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 19:38:00.471 7 INFO os_brick.initiator.connectors.lightos [req-20551c8e-9773-460d-8910-13e35f24de81 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 21ecc0de-3e51-4c5c-b78c-c93fec966aa1
2022-02-22 19:38:00.753 7 INFO nova.compute.manager [req-32754994-44a3-4ed1-a8e8-311ce5833bd8 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Detaching volume 9d62daa9-cafc-4bd4-aed6-3d130c273376
2022-02-22 19:38:00.810 7 INFO nova.virt.block_device [req-32754994-44a3-4ed1-a8e8-311ce5833bd8 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Attempting to driver detach volume 9d62daa9-cafc-4bd4-aed6-3d130c273376 from mountpoint /dev/vdb
2022-02-22 19:38:00.829 7 INFO nova.virt.libvirt.driver [req-32754994-44a3-4ed1-a8e8-311ce5833bd8 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] Successfully detached device vdb from instance 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb from the persistent domain config.
2022-02-22 19:38:00.968 7 INFO nova.virt.libvirt.driver [req-32754994-44a3-4ed1-a8e8-311ce5833bd8 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] Successfully detached device vdb from instance 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb from the live domain config.
2022-02-22 19:38:00.971 7 INFO os_brick.initiator.connectors.lightos [req-32754994-44a3-4ed1-a8e8-311ce5833bd8 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26ea804e-5e36-45f7-b389-119e30f68618
2022-02-22 19:38:03.024 7 INFO nova.compute.manager [req-38fe5182-f5fe-45ee-ba03-e71f28b51250 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Terminating instance
2022-02-22 19:38:03.381 7 INFO nova.virt.libvirt.driver [-] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Instance destroyed successfully.
2022-02-22 19:38:03.397 7 INFO nova.virt.libvirt.driver [req-38fe5182-f5fe-45ee-ba03-e71f28b51250 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Deleting instance files /var/lib/nova/instances/9bff86e6-b8a7-4a16-b8c0-9effd68d67eb_del
2022-02-22 19:38:03.398 7 INFO nova.virt.libvirt.driver [req-38fe5182-f5fe-45ee-ba03-e71f28b51250 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Deletion of /var/lib/nova/instances/9bff86e6-b8a7-4a16-b8c0-9effd68d67eb_del complete
2022-02-22 19:38:03.469 7 INFO nova.compute.manager [req-38fe5182-f5fe-45ee-ba03-e71f28b51250 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 19:38:03.543 7 INFO nova.compute.manager [-] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:38:03.740 7 INFO nova.scheduler.client.report [req-38fe5182-f5fe-45ee-ba03-e71f28b51250 02335ccd5605469ab36ca612d0fac07a 49957d6363bd48e6986841e7fc124ac1 - default default] Deleted allocations for instance 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb
2022-02-22 19:38:04.072 7 INFO nova.compute.manager [-] [instance: 7aab49dd-f812-4aed-940b-2d82fd2b84ee] VM Stopped (Lifecycle Event)
2022-02-22 19:38:09.314 7 INFO nova.compute.manager [req-a308f48d-9a7a-490d-b80e-48569c251887 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Detaching volume 5f01fa22-eae0-458b-8065-ce4bf8367f4f
2022-02-22 19:38:09.373 7 INFO nova.virt.block_device [req-a308f48d-9a7a-490d-b80e-48569c251887 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Attempting to driver detach volume 5f01fa22-eae0-458b-8065-ce4bf8367f4f from mountpoint /dev/vdb
2022-02-22 19:38:09.395 7 INFO nova.virt.libvirt.driver [req-a308f48d-9a7a-490d-b80e-48569c251887 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Successfully detached device vdb from instance 1b04775a-6e0a-4d74-a743-d147270af36a from the persistent domain config.
2022-02-22 19:38:09.544 7 INFO nova.virt.libvirt.driver [req-a308f48d-9a7a-490d-b80e-48569c251887 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Successfully detached device vdb from instance 1b04775a-6e0a-4d74-a743-d147270af36a from the live domain config.
2022-02-22 19:38:09.547 7 INFO os_brick.initiator.connectors.lightos [req-a308f48d-9a7a-490d-b80e-48569c251887 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 21ecc0de-3e51-4c5c-b78c-c93fec966aa1
2022-02-22 19:38:11.586 7 INFO nova.compute.manager [req-cf6f2250-99c7-4bd0-b0bb-f133644a49e4 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Terminating instance
2022-02-22 19:38:11.926 7 INFO nova.virt.libvirt.driver [-] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Instance destroyed successfully.
2022-02-22 19:38:11.940 7 INFO nova.virt.libvirt.driver [req-cf6f2250-99c7-4bd0-b0bb-f133644a49e4 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Deleting instance files /var/lib/nova/instances/1b04775a-6e0a-4d74-a743-d147270af36a_del
2022-02-22 19:38:11.941 7 INFO nova.virt.libvirt.driver [req-cf6f2250-99c7-4bd0-b0bb-f133644a49e4 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Deletion of /var/lib/nova/instances/1b04775a-6e0a-4d74-a743-d147270af36a_del complete
2022-02-22 19:38:12.007 7 INFO nova.compute.manager [req-cf6f2250-99c7-4bd0-b0bb-f133644a49e4 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 19:38:12.076 7 INFO nova.compute.manager [-] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 19:38:12.272 7 INFO nova.scheduler.client.report [req-cf6f2250-99c7-4bd0-b0bb-f133644a49e4 6e7adb53e1f649cd9608c95a64f4c03d 5100a42ff6cf4fa0ab58630838ac9c1a - default default] Deleted allocations for instance 1b04775a-6e0a-4d74-a743-d147270af36a
2022-02-22 19:38:18.379 7 INFO nova.compute.manager [-] [instance: 9bff86e6-b8a7-4a16-b8c0-9effd68d67eb] VM Stopped (Lifecycle Event)
2022-02-22 19:38:26.924 7 INFO nova.compute.manager [-] [instance: 1b04775a-6e0a-4d74-a743-d147270af36a] VM Stopped (Lifecycle Event)
