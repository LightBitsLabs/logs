Build Started 21_02_2022_18_01_04
2022-02-21 20:04:15.963 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-21 20:04:19.949 8 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-21 20:04:20.831 8 INFO nova.virt.driver [req-0916d6a3-1f4c-41af-b6d3-7a79b54c34f1 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-21 20:04:21.218 8 INFO nova.compute.provider_config [req-0916d6a3-1f4c-41af-b6d3-7a79b54c34f1 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-21 20:04:21.237 8 WARNING oslo_config.cfg [req-0916d6a3-1f4c-41af-b6d3-7a79b54c34f1 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-21 20:04:21.258 8 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-21 20:04:21.269 8 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-21 20:04:21.304 8 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-21 20:04:21.401 8 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-21 20:04:21.414 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-21 20:04:21.416 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-21 20:04:21.820 8 INFO nova.compute.manager [req-b355a539-1bd4-47e1-af8f-40a7f2b6649c - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-21 20:04:23.664 8 INFO nova.virt.libvirt.host [req-b355a539-1bd4-47e1-af8f-40a7f2b6649c - - - - -] kernel doesn't support AMD SEV
2022-02-21 20:05:17.646 8 INFO nova.compute.claims [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Claim successful on node rack08-server63
2022-02-21 20:05:18.050 8 INFO nova.virt.libvirt.driver [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Creating image
2022-02-21 20:05:18.055 8 INFO oslo.privsep.daemon [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpq8ki8mnn/privsep.sock']
2022-02-21 20:05:19.677 8 INFO oslo.privsep.daemon [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Spawned new privsep daemon via rootwrap
2022-02-21 20:05:19.534 81 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 20:05:19.540 81 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 20:05:19.545 81 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-21 20:05:19.545 81 INFO oslo.privsep.daemon [-] privsep daemon running as pid 81
2022-02-21 20:05:20.948 8 INFO nova.compute.manager [-] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] VM Resumed (Lifecycle Event)
2022-02-21 20:05:20.962 8 INFO nova.virt.libvirt.driver [-] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Instance spawned successfully.
2022-02-21 20:05:20.962 8 INFO nova.compute.manager [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Took 2.91 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:21.003 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:21.004 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] VM Started (Lifecycle Event)
2022-02-21 20:05:21.046 8 INFO nova.compute.manager [req-79278f72-77b1-43b0-832d-4536294beefc afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Took 3.44 seconds to build instance.
2022-02-21 20:05:24.837 8 INFO nova.compute.manager [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Attaching volume bc55793f-2820-4f0b-b537-d2c04b8fcc1a to /dev/vdb
2022-02-21 20:05:24.918 8 INFO oslo.privsep.daemon [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp6ki74iyz/privsep.sock']
2022-02-21 20:05:25.578 8 INFO oslo.privsep.daemon [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Spawned new privsep daemon via rootwrap
2022-02-21 20:05:25.499 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 20:05:25.507 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 20:05:25.510 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-21 20:05:25.510 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-21 20:05:25.906 8 WARNING os_brick.initiator.connectors.nvmeof [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:27.302 8 INFO os_brick.initiator.connectors.lightos [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume f30246b3-deed-40b3-82c0-482ae6b85ff0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f30246b3-deed-40b3-82c0-482ae6b85ff0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:27.337 8 INFO os_brick.initiator.connectors.lightos [req-1b6626f5-6530-4ee2-bc0e-ec531ee0d9c2 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f30246b3-deed-40b3-82c0-482ae6b85ff0
2022-02-21 20:05:29.561 8 INFO nova.compute.claims [req-8235df28-a2bf-40ae-b545-59b4da9a9115 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Claim successful on node rack08-server63
2022-02-21 20:05:29.962 8 INFO nova.virt.libvirt.driver [req-8235df28-a2bf-40ae-b545-59b4da9a9115 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Creating image
2022-02-21 20:05:31.090 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] VM Resumed (Lifecycle Event)
2022-02-21 20:05:31.097 8 INFO nova.virt.libvirt.driver [-] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Instance spawned successfully.
2022-02-21 20:05:31.098 8 INFO nova.compute.manager [req-8235df28-a2bf-40ae-b545-59b4da9a9115 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:31.146 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:31.146 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] VM Started (Lifecycle Event)
2022-02-21 20:05:31.205 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:31.207 8 INFO nova.compute.manager [req-8235df28-a2bf-40ae-b545-59b4da9a9115 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Took 1.69 seconds to build instance.
2022-02-21 20:05:32.681 8 INFO nova.compute.manager [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Detaching volume bc55793f-2820-4f0b-b537-d2c04b8fcc1a
2022-02-21 20:05:32.740 8 INFO nova.virt.block_device [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Attempting to driver detach volume bc55793f-2820-4f0b-b537-d2c04b8fcc1a from mountpoint /dev/vdb
2022-02-21 20:05:32.756 8 INFO nova.virt.libvirt.driver [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6 from the persistent domain config.
2022-02-21 20:05:32.896 8 INFO nova.virt.libvirt.driver [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6 from the live domain config.
2022-02-21 20:05:32.899 8 INFO os_brick.initiator.connectors.lightos [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume f30246b3-deed-40b3-82c0-482ae6b85ff0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f30246b3-deed-40b3-82c0-482ae6b85ff0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 20:05:32.900 8 INFO os_brick.initiator.connectors.lightos [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f30246b3-deed-40b3-82c0-482ae6b85ff0
2022-02-21 20:05:32.901 8 INFO os_brick.initiator.connectors.lightos [req-48eed918-6a4d-42b8-9f74-c36374a93f54 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f30246b3-deed-40b3-82c0-482ae6b85ff0
2022-02-21 20:05:33.691 8 INFO nova.compute.claims [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Claim successful on node rack08-server63
2022-02-21 20:05:33.947 8 INFO nova.virt.libvirt.driver [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 20:05:34.029 8 INFO nova.virt.block_device [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Booting with volume e68f97bb-e81d-4cbd-bdbe-0288b59b351e at /dev/vda
2022-02-21 20:05:34.122 8 WARNING os_brick.initiator.connectors.nvmeof [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:35.622 8 INFO nova.virt.libvirt.driver [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Creating image
2022-02-21 20:05:35.633 8 INFO os_brick.initiator.connectors.lightos [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 4bad1557-e892-4d06-860a-d1bb96a55331, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4bad1557-e892-4d06-860a-d1bb96a55331', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:35.635 8 INFO os_brick.initiator.connectors.lightos [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4bad1557-e892-4d06-860a-d1bb96a55331
2022-02-21 20:05:36.171 8 INFO nova.compute.claims [req-26e2c58b-9f6c-4e02-bcd2-960a355f7d08 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Claim successful on node rack08-server63
2022-02-21 20:05:36.454 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] VM Resumed (Lifecycle Event)
2022-02-21 20:05:36.462 8 INFO nova.virt.libvirt.driver [-] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Instance spawned successfully.
2022-02-21 20:05:36.462 8 INFO nova.compute.manager [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Took 0.84 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:36.508 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:36.508 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] VM Started (Lifecycle Event)
2022-02-21 20:05:36.555 8 INFO nova.virt.libvirt.driver [req-26e2c58b-9f6c-4e02-bcd2-960a355f7d08 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Creating image
2022-02-21 20:05:36.575 8 INFO nova.compute.manager [req-5fa61616-f496-494c-abb6-6f59b7c5feaa b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Took 2.92 seconds to build instance.
2022-02-21 20:05:37.699 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] VM Resumed (Lifecycle Event)
2022-02-21 20:05:37.709 8 INFO nova.virt.libvirt.driver [-] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Instance spawned successfully.
2022-02-21 20:05:37.709 8 INFO nova.compute.manager [req-26e2c58b-9f6c-4e02-bcd2-960a355f7d08 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:37.753 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:37.754 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] VM Started (Lifecycle Event)
2022-02-21 20:05:37.793 8 INFO nova.compute.manager [req-26e2c58b-9f6c-4e02-bcd2-960a355f7d08 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Took 1.66 seconds to build instance.
2022-02-21 20:05:38.861 8 INFO nova.compute.claims [req-12bd5c41-2675-4752-9aa2-e1f10d4ad7cf b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Claim successful on node rack08-server63
2022-02-21 20:05:39.271 8 INFO nova.virt.libvirt.driver [req-12bd5c41-2675-4752-9aa2-e1f10d4ad7cf b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Creating image
2022-02-21 20:05:39.352 8 INFO nova.compute.claims [req-e2310348-f31e-4544-800c-7dfa4978f594 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Claim successful on node rack08-server63
2022-02-21 20:05:39.746 8 INFO nova.virt.libvirt.driver [req-e2310348-f31e-4544-800c-7dfa4978f594 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Creating image
2022-02-21 20:05:40.458 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] VM Resumed (Lifecycle Event)
2022-02-21 20:05:40.464 8 INFO nova.virt.libvirt.driver [-] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Instance spawned successfully.
2022-02-21 20:05:40.465 8 INFO nova.compute.manager [req-12bd5c41-2675-4752-9aa2-e1f10d4ad7cf b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:40.512 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:40.512 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] VM Started (Lifecycle Event)
2022-02-21 20:05:40.546 8 INFO nova.compute.manager [req-12bd5c41-2675-4752-9aa2-e1f10d4ad7cf b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Took 1.73 seconds to build instance.
2022-02-21 20:05:40.596 8 INFO nova.compute.manager [req-a7284549-f904-4d0a-9501-5142ad738c00 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Attaching volume 9f9655d1-462c-4ee2-bbd9-2629203c54fd to /dev/vdb
2022-02-21 20:05:40.683 8 WARNING os_brick.initiator.connectors.nvmeof [req-a7284549-f904-4d0a-9501-5142ad738c00 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:40.913 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] VM Resumed (Lifecycle Event)
2022-02-21 20:05:40.922 8 INFO nova.virt.libvirt.driver [-] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Instance spawned successfully.
2022-02-21 20:05:40.922 8 INFO nova.compute.manager [req-e2310348-f31e-4544-800c-7dfa4978f594 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:40.965 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:40.966 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] VM Started (Lifecycle Event)
2022-02-21 20:05:41.005 8 INFO nova.compute.manager [req-e2310348-f31e-4544-800c-7dfa4978f594 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Took 1.70 seconds to build instance.
2022-02-21 20:05:42.028 8 INFO os_brick.initiator.connectors.lightos [req-a7284549-f904-4d0a-9501-5142ad738c00 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume d855fa65-5d08-4d2e-a0c9-55cc95d05eb4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd855fa65-5d08-4d2e-a0c9-55cc95d05eb4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:42.031 8 INFO os_brick.initiator.connectors.lightos [req-a7284549-f904-4d0a-9501-5142ad738c00 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid d855fa65-5d08-4d2e-a0c9-55cc95d05eb4
2022-02-21 20:05:43.166 8 INFO nova.compute.manager [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Detaching volume 9f9655d1-462c-4ee2-bbd9-2629203c54fd
2022-02-21 20:05:43.221 8 INFO nova.virt.block_device [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Attempting to driver detach volume 9f9655d1-462c-4ee2-bbd9-2629203c54fd from mountpoint /dev/vdb
2022-02-21 20:05:43.241 8 INFO nova.virt.libvirt.driver [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance f5bbd28d-82d4-4057-97a1-a1a8f56d78fe from the persistent domain config.
2022-02-21 20:05:43.382 8 INFO nova.virt.libvirt.driver [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance f5bbd28d-82d4-4057-97a1-a1a8f56d78fe from the live domain config.
2022-02-21 20:05:43.385 8 INFO os_brick.initiator.connectors.lightos [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume d855fa65-5d08-4d2e-a0c9-55cc95d05eb4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd855fa65-5d08-4d2e-a0c9-55cc95d05eb4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:05:43.385 8 INFO os_brick.initiator.connectors.lightos [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid d855fa65-5d08-4d2e-a0c9-55cc95d05eb4
2022-02-21 20:05:43.386 8 INFO os_brick.initiator.connectors.lightos [req-b7765f62-9660-4457-b6a1-6e03235293bd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid d855fa65-5d08-4d2e-a0c9-55cc95d05eb4
2022-02-21 20:05:44.040 8 INFO nova.compute.manager [req-72503942-c1f1-44de-b7d5-4758ffca53a7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Attaching volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 to /dev/vdb
2022-02-21 20:05:44.133 8 WARNING os_brick.initiator.connectors.nvmeof [req-72503942-c1f1-44de-b7d5-4758ffca53a7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:45.493 8 INFO os_brick.initiator.connectors.lightos [req-72503942-c1f1-44de-b7d5-4758ffca53a7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 480ad775-5d0c-4f88-964d-4c1de1246bce, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '480ad775-5d0c-4f88-964d-4c1de1246bce', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:45.497 8 INFO os_brick.initiator.connectors.lightos [req-72503942-c1f1-44de-b7d5-4758ffca53a7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 480ad775-5d0c-4f88-964d-4c1de1246bce
2022-02-21 20:05:46.508 8 INFO nova.compute.manager [req-69ee372a-09e2-4349-98f7-f64da605ebe7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Attaching volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 to /dev/vdb
2022-02-21 20:05:46.547 8 INFO nova.compute.claims [req-159166b5-d83f-46f1-8489-b1477c0b9b40 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Claim successful on node rack08-server63
2022-02-21 20:05:46.607 8 WARNING os_brick.initiator.connectors.nvmeof [req-69ee372a-09e2-4349-98f7-f64da605ebe7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:46.975 8 INFO nova.virt.libvirt.driver [req-159166b5-d83f-46f1-8489-b1477c0b9b40 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Creating image
2022-02-21 20:05:47.964 8 INFO os_brick.initiator.connectors.lightos [req-69ee372a-09e2-4349-98f7-f64da605ebe7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 480ad775-5d0c-4f88-964d-4c1de1246bce, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '480ad775-5d0c-4f88-964d-4c1de1246bce', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:47.965 8 INFO os_brick.initiator.connectors.lightos [req-69ee372a-09e2-4349-98f7-f64da605ebe7 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 480ad775-5d0c-4f88-964d-4c1de1246bce
2022-02-21 20:05:48.127 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] VM Resumed (Lifecycle Event)
2022-02-21 20:05:48.140 8 INFO nova.virt.libvirt.driver [-] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Instance spawned successfully.
2022-02-21 20:05:48.141 8 INFO nova.compute.manager [req-159166b5-d83f-46f1-8489-b1477c0b9b40 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-21 20:05:48.178 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:05:48.179 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] VM Started (Lifecycle Event)
2022-02-21 20:05:48.221 8 INFO nova.compute.manager [req-159166b5-d83f-46f1-8489-b1477c0b9b40 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Took 1.72 seconds to build instance.
2022-02-21 20:05:49.066 8 INFO nova.compute.manager [req-b58f2988-1ce2-4b75-a220-6437edc700d8 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Detaching volume 99abfd2a-adbe-4e94-aee2-127e437b8d97
2022-02-21 20:05:49.133 8 INFO nova.virt.block_device [req-b58f2988-1ce2-4b75-a220-6437edc700d8 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Attempting to driver detach volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 from mountpoint /dev/vdb
2022-02-21 20:05:49.150 8 INFO nova.virt.libvirt.driver [req-b58f2988-1ce2-4b75-a220-6437edc700d8 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Successfully detached device vdb from instance 89865d90-5ce1-49bc-bb70-e75e719e4840 from the persistent domain config.
2022-02-21 20:05:49.295 8 INFO nova.virt.libvirt.driver [req-b58f2988-1ce2-4b75-a220-6437edc700d8 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Successfully detached device vdb from instance 89865d90-5ce1-49bc-bb70-e75e719e4840 from the live domain config.
2022-02-21 20:05:49.364 8 INFO nova.virt.libvirt.driver [req-b58f2988-1ce2-4b75-a220-6437edc700d8 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Detected multiple connections on this host for volume: 99abfd2a-adbe-4e94-aee2-127e437b8d97, skipping target disconnect.
2022-02-21 20:05:50.038 8 INFO nova.compute.manager [req-b3ae7a5f-6468-4ec2-a6c0-2ccda384bcf8 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Attaching volume 9d2337fb-6841-4912-a4bb-8df654c463aa to /dev/vdb
2022-02-21 20:05:50.119 8 WARNING os_brick.initiator.connectors.nvmeof [req-b3ae7a5f-6468-4ec2-a6c0-2ccda384bcf8 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:05:51.454 8 INFO os_brick.initiator.connectors.lightos [req-b3ae7a5f-6468-4ec2-a6c0-2ccda384bcf8 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume b752338e-36b7-4503-99a9-401de36ae85a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'b752338e-36b7-4503-99a9-401de36ae85a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:05:51.458 8 INFO os_brick.initiator.connectors.lightos [req-b3ae7a5f-6468-4ec2-a6c0-2ccda384bcf8 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid b752338e-36b7-4503-99a9-401de36ae85a
2022-02-21 20:05:51.527 8 INFO nova.compute.manager [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Detaching volume 99abfd2a-adbe-4e94-aee2-127e437b8d97
2022-02-21 20:05:51.585 8 INFO nova.virt.block_device [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Attempting to driver detach volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 from mountpoint /dev/vdb
2022-02-21 20:05:51.612 8 INFO nova.virt.libvirt.driver [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Successfully detached device vdb from instance db7f9d78-e7bd-41d7-a101-54703579b795 from the persistent domain config.
2022-02-21 20:05:51.790 8 INFO nova.virt.libvirt.driver [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Successfully detached device vdb from instance db7f9d78-e7bd-41d7-a101-54703579b795 from the live domain config.
2022-02-21 20:05:51.843 8 INFO os_brick.initiator.connectors.lightos [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 480ad775-5d0c-4f88-964d-4c1de1246bce, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '480ad775-5d0c-4f88-964d-4c1de1246bce', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:05:52.568 8 INFO nova.compute.manager [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Detaching volume 9d2337fb-6841-4912-a4bb-8df654c463aa
2022-02-21 20:05:52.630 8 INFO nova.virt.block_device [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Attempting to driver detach volume 9d2337fb-6841-4912-a4bb-8df654c463aa from mountpoint /dev/vdb
2022-02-21 20:05:52.648 8 INFO nova.virt.libvirt.driver [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance c03a1af6-d532-4d64-9faf-c1ba15d56b4b from the persistent domain config.
2022-02-21 20:05:52.791 8 INFO nova.virt.libvirt.driver [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Successfully detached device vdb from instance c03a1af6-d532-4d64-9faf-c1ba15d56b4b from the live domain config.
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Failed to detach volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Traceback (most recent call last):
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     return f(*args, **kwargs)
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     return f(*args, **kwargs)
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     raise exception.BrickException(message=msg)
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:06:52.151 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] 
2022-02-21 20:06:52.164 8 INFO os_brick.initiator.connectors.lightos [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: connect_volume called for volume b752338e-36b7-4503-99a9-401de36ae85a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'b752338e-36b7-4503-99a9-401de36ae85a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 20:06:52.164 8 INFO os_brick.initiator.connectors.lightos [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid b752338e-36b7-4503-99a9-401de36ae85a
2022-02-21 20:06:52.165 8 INFO os_brick.initiator.connectors.lightos [req-61026507-a7d3-4424-84bb-b088efe866af afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid b752338e-36b7-4503-99a9-401de36ae85a
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server [req-818f76ab-d264-4f72-8be7-7d8808bac053 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:06:52.255 8 ERROR oslo_messaging.rpc.server 
2022-02-21 20:06:54.999 8 INFO nova.compute.manager [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Terminating instance
2022-02-21 20:06:55.341 8 INFO nova.virt.libvirt.driver [-] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Instance destroyed successfully.
2022-02-21 20:06:55.355 8 INFO nova.virt.libvirt.driver [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Deleting instance files /var/lib/nova/instances/c03a1af6-d532-4d64-9faf-c1ba15d56b4b_del
2022-02-21 20:06:55.356 8 INFO nova.virt.libvirt.driver [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Deletion of /var/lib/nova/instances/c03a1af6-d532-4d64-9faf-c1ba15d56b4b_del complete
2022-02-21 20:06:55.423 8 INFO nova.virt.libvirt.host [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] UEFI support detected
2022-02-21 20:06:55.425 8 INFO nova.compute.manager [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:06:55.490 8 INFO nova.compute.manager [-] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] Took 0.06 seconds to deallocate network for instance.
2022-02-21 20:06:55.679 8 INFO nova.scheduler.client.report [req-ec72d60b-4805-4772-998d-5bbc2060e7c6 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Deleted allocations for instance c03a1af6-d532-4d64-9faf-c1ba15d56b4b
2022-02-21 20:06:57.369 8 INFO nova.compute.manager [req-07302a86-b6bf-4404-94a9-582bd3805434 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Terminating instance
2022-02-21 20:06:57.732 8 INFO nova.virt.libvirt.driver [-] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Instance destroyed successfully.
2022-02-21 20:06:57.748 8 INFO nova.virt.libvirt.driver [req-07302a86-b6bf-4404-94a9-582bd3805434 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Deleting instance files /var/lib/nova/instances/f5bbd28d-82d4-4057-97a1-a1a8f56d78fe_del
2022-02-21 20:06:57.750 8 INFO nova.virt.libvirt.driver [req-07302a86-b6bf-4404-94a9-582bd3805434 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Deletion of /var/lib/nova/instances/f5bbd28d-82d4-4057-97a1-a1a8f56d78fe_del complete
2022-02-21 20:06:57.821 8 INFO nova.compute.manager [req-07302a86-b6bf-4404-94a9-582bd3805434 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:06:57.889 8 INFO nova.compute.manager [-] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:06:58.087 8 INFO nova.scheduler.client.report [req-07302a86-b6bf-4404-94a9-582bd3805434 afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Deleted allocations for instance f5bbd28d-82d4-4057-97a1-a1a8f56d78fe
2022-02-21 20:06:58.620 8 INFO nova.compute.manager [req-148929e0-bb67-4a56-aff2-3f972faed9fd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Terminating instance
2022-02-21 20:06:58.956 8 INFO nova.virt.libvirt.driver [-] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Instance destroyed successfully.
2022-02-21 20:06:58.973 8 INFO nova.virt.libvirt.driver [req-148929e0-bb67-4a56-aff2-3f972faed9fd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Deleting instance files /var/lib/nova/instances/3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa_del
2022-02-21 20:06:58.975 8 INFO nova.virt.libvirt.driver [req-148929e0-bb67-4a56-aff2-3f972faed9fd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Deletion of /var/lib/nova/instances/3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa_del complete
2022-02-21 20:06:59.040 8 INFO nova.compute.manager [req-148929e0-bb67-4a56-aff2-3f972faed9fd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 20:06:59.110 8 INFO nova.compute.manager [-] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:06:59.307 8 INFO nova.scheduler.client.report [req-148929e0-bb67-4a56-aff2-3f972faed9fd afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Deleted allocations for instance 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa
2022-02-21 20:07:01.007 8 INFO nova.compute.manager [req-04c62016-0f16-4846-8d54-f12278c3d61d afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Terminating instance
2022-02-21 20:07:01.365 8 INFO nova.virt.libvirt.driver [-] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Instance destroyed successfully.
2022-02-21 20:07:01.381 8 INFO nova.virt.libvirt.driver [req-04c62016-0f16-4846-8d54-f12278c3d61d afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Deleting instance files /var/lib/nova/instances/7eaf9d9b-83de-4bcb-b60d-fab67f994ca6_del
2022-02-21 20:07:01.383 8 INFO nova.virt.libvirt.driver [req-04c62016-0f16-4846-8d54-f12278c3d61d afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Deletion of /var/lib/nova/instances/7eaf9d9b-83de-4bcb-b60d-fab67f994ca6_del complete
2022-02-21 20:07:01.450 8 INFO nova.compute.manager [req-04c62016-0f16-4846-8d54-f12278c3d61d afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:07:01.518 8 INFO nova.compute.manager [-] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:07:01.714 8 INFO nova.scheduler.client.report [req-04c62016-0f16-4846-8d54-f12278c3d61d afdbb7b5424e4480b00802c183fc2716 96efb2c803a54de091a9f9777a4470f3 - default default] Deleted allocations for instance 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6
2022-02-21 20:07:10.339 8 INFO nova.compute.manager [-] [instance: c03a1af6-d532-4d64-9faf-c1ba15d56b4b] VM Stopped (Lifecycle Event)
2022-02-21 20:07:12.730 8 INFO nova.compute.manager [-] [instance: f5bbd28d-82d4-4057-97a1-a1a8f56d78fe] VM Stopped (Lifecycle Event)
2022-02-21 20:07:13.953 8 INFO nova.compute.manager [-] [instance: 3a8d1bbb-e624-4bac-b26d-9fcf6dc7dcfa] VM Stopped (Lifecycle Event)
2022-02-21 20:07:16.364 8 INFO nova.compute.manager [-] [instance: 7eaf9d9b-83de-4bcb-b60d-fab67f994ca6] VM Stopped (Lifecycle Event)
2022-02-21 20:08:21.264 8 INFO nova.compute.claims [req-5190c6d8-1d95-4b64-8a49-914054a661f8 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Claim successful on node rack08-server63
2022-02-21 20:08:21.698 8 INFO nova.virt.libvirt.driver [req-5190c6d8-1d95-4b64-8a49-914054a661f8 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Creating image
2022-02-21 20:08:22.948 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] VM Resumed (Lifecycle Event)
2022-02-21 20:08:22.958 8 INFO nova.virt.libvirt.driver [-] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Instance spawned successfully.
2022-02-21 20:08:22.958 8 INFO nova.compute.manager [req-5190c6d8-1d95-4b64-8a49-914054a661f8 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-21 20:08:23.009 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:08:23.010 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] VM Started (Lifecycle Event)
2022-02-21 20:08:23.043 8 INFO nova.compute.manager [req-5190c6d8-1d95-4b64-8a49-914054a661f8 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Took 1.82 seconds to build instance.
2022-02-21 20:08:24.312 8 INFO nova.virt.libvirt.driver [req-9fdab887-6847-476d-9a82-0109aa00c906 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Ignoring supplied device name: /dev/vdb
2022-02-21 20:08:24.477 8 INFO nova.compute.manager [req-9fdab887-6847-476d-9a82-0109aa00c906 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Attaching volume 50f93cb1-af8b-4024-a9cc-ffcecacd7800 to /dev/vdb
2022-02-21 20:08:24.565 8 WARNING os_brick.initiator.connectors.nvmeof [req-9fdab887-6847-476d-9a82-0109aa00c906 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:08:25.917 8 INFO os_brick.initiator.connectors.lightos [req-9fdab887-6847-476d-9a82-0109aa00c906 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] LIGHTOS: connect_volume called for volume 8dc8a492-55d5-44de-a39e-80e65a0f7505, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8dc8a492-55d5-44de-a39e-80e65a0f7505', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:08:25.922 8 INFO os_brick.initiator.connectors.lightos [req-9fdab887-6847-476d-9a82-0109aa00c906 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8dc8a492-55d5-44de-a39e-80e65a0f7505
2022-02-21 20:08:28.585 8 INFO nova.compute.manager [req-527b0baa-6122-4034-bd86-e095500c203e e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Cinder extended volume 50f93cb1-af8b-4024-a9cc-ffcecacd7800; extending it to detect new size
2022-02-21 20:08:28.669 8 INFO os_brick.initiator.connectors.lightos [req-527b0baa-6122-4034-bd86-e095500c203e e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8dc8a492-55d5-44de-a39e-80e65a0f7505
2022-02-21 20:08:29.536 8 INFO nova.compute.manager [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Detaching volume 50f93cb1-af8b-4024-a9cc-ffcecacd7800
2022-02-21 20:08:29.594 8 INFO nova.virt.block_device [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Attempting to driver detach volume 50f93cb1-af8b-4024-a9cc-ffcecacd7800 from mountpoint /dev/vdb
2022-02-21 20:08:29.613 8 INFO nova.virt.libvirt.driver [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] Successfully detached device vdb from instance f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8 from the persistent domain config.
2022-02-21 20:08:29.755 8 INFO nova.virt.libvirt.driver [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] Successfully detached device vdb from instance f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8 from the live domain config.
2022-02-21 20:08:29.758 8 INFO os_brick.initiator.connectors.lightos [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] LIGHTOS: connect_volume called for volume 8dc8a492-55d5-44de-a39e-80e65a0f7505, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8dc8a492-55d5-44de-a39e-80e65a0f7505', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:08:29.759 8 INFO os_brick.initiator.connectors.lightos [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8dc8a492-55d5-44de-a39e-80e65a0f7505
2022-02-21 20:08:29.760 8 INFO os_brick.initiator.connectors.lightos [req-51522dcd-826e-4361-9319-66cfc182c067 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8dc8a492-55d5-44de-a39e-80e65a0f7505
2022-02-21 20:08:31.778 8 INFO nova.compute.manager [req-696e0daf-59f8-4349-950a-89f9c4663a3f 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Terminating instance
2022-02-21 20:08:32.128 8 INFO nova.virt.libvirt.driver [-] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Instance destroyed successfully.
2022-02-21 20:08:32.144 8 INFO nova.virt.libvirt.driver [req-696e0daf-59f8-4349-950a-89f9c4663a3f 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Deleting instance files /var/lib/nova/instances/f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8_del
2022-02-21 20:08:32.145 8 INFO nova.virt.libvirt.driver [req-696e0daf-59f8-4349-950a-89f9c4663a3f 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Deletion of /var/lib/nova/instances/f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8_del complete
2022-02-21 20:08:32.208 8 INFO nova.compute.manager [req-696e0daf-59f8-4349-950a-89f9c4663a3f 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 20:08:32.274 8 INFO nova.compute.manager [-] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:08:32.479 8 INFO nova.scheduler.client.report [req-696e0daf-59f8-4349-950a-89f9c4663a3f 82b99c0d61114c96a705db2e74aa0908 3530818a3327412baf4051b11f5d59a5 - default default] Deleted allocations for instance f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8
2022-02-21 20:08:47.125 8 INFO nova.compute.manager [-] [instance: f2fc1508-d1ce-44a1-9a5c-c8c0b383d6b8] VM Stopped (Lifecycle Event)
2022-02-21 20:09:38.010 8 INFO nova.compute.claims [req-0809102b-ac32-4d78-b44b-b6567ff96b0d 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Claim successful on node rack08-server63
2022-02-21 20:09:38.412 8 INFO nova.virt.libvirt.driver [req-0809102b-ac32-4d78-b44b-b6567ff96b0d 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Creating image
2022-02-21 20:09:39.588 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] VM Resumed (Lifecycle Event)
2022-02-21 20:09:39.595 8 INFO nova.virt.libvirt.driver [-] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Instance spawned successfully.
2022-02-21 20:09:39.596 8 INFO nova.compute.manager [req-0809102b-ac32-4d78-b44b-b6567ff96b0d 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 20:09:39.646 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:09:39.646 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] VM Started (Lifecycle Event)
2022-02-21 20:09:39.686 8 INFO nova.compute.manager [req-0809102b-ac32-4d78-b44b-b6567ff96b0d 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Took 1.71 seconds to build instance.
2022-02-21 20:09:44.568 8 INFO nova.compute.manager [req-42291082-9fe5-4361-8f89-f398c92f18b0 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Terminating instance
2022-02-21 20:09:44.926 8 INFO nova.virt.libvirt.driver [-] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Instance destroyed successfully.
2022-02-21 20:09:44.943 8 INFO nova.virt.libvirt.driver [req-42291082-9fe5-4361-8f89-f398c92f18b0 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Deleting instance files /var/lib/nova/instances/2d4a2001-bb97-47e6-8d33-65da4bd65e4c_del
2022-02-21 20:09:44.944 8 INFO nova.virt.libvirt.driver [req-42291082-9fe5-4361-8f89-f398c92f18b0 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Deletion of /var/lib/nova/instances/2d4a2001-bb97-47e6-8d33-65da4bd65e4c_del complete
2022-02-21 20:09:45.012 8 INFO nova.compute.manager [req-42291082-9fe5-4361-8f89-f398c92f18b0 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:09:45.083 8 INFO nova.compute.manager [-] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:09:45.287 8 INFO nova.scheduler.client.report [req-42291082-9fe5-4361-8f89-f398c92f18b0 99c33f9fca2b40d386337c2922851d2c 8356d4ecfa504f71a36ea90016cde93b - default default] Deleted allocations for instance 2d4a2001-bb97-47e6-8d33-65da4bd65e4c
2022-02-21 20:09:59.924 8 INFO nova.compute.manager [-] [instance: 2d4a2001-bb97-47e6-8d33-65da4bd65e4c] VM Stopped (Lifecycle Event)
2022-02-21 20:10:02.809 8 INFO nova.compute.claims [req-e399d6e0-f679-4e4b-b6be-903c0a725894 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Claim successful on node rack08-server63
2022-02-21 20:10:03.214 8 INFO nova.virt.libvirt.driver [req-e399d6e0-f679-4e4b-b6be-903c0a725894 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Creating image
2022-02-21 20:10:04.358 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] VM Resumed (Lifecycle Event)
2022-02-21 20:10:04.365 8 INFO nova.virt.libvirt.driver [-] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Instance spawned successfully.
2022-02-21 20:10:04.366 8 INFO nova.compute.manager [req-e399d6e0-f679-4e4b-b6be-903c0a725894 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-21 20:10:04.410 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:10:04.411 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] VM Started (Lifecycle Event)
2022-02-21 20:10:04.458 8 INFO nova.compute.manager [req-e399d6e0-f679-4e4b-b6be-903c0a725894 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Took 1.69 seconds to build instance.
2022-02-21 20:10:04.754 8 INFO nova.compute.manager [req-5bda7692-9018-44bd-9881-4dd63fa293e6 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Terminating instance
2022-02-21 20:10:05.096 8 INFO nova.virt.libvirt.driver [-] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Instance destroyed successfully.
2022-02-21 20:10:05.111 8 INFO nova.virt.libvirt.driver [req-5bda7692-9018-44bd-9881-4dd63fa293e6 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Deleting instance files /var/lib/nova/instances/ee936629-85a0-4176-ac9e-d519f879ad72_del
2022-02-21 20:10:05.112 8 INFO nova.virt.libvirt.driver [req-5bda7692-9018-44bd-9881-4dd63fa293e6 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Deletion of /var/lib/nova/instances/ee936629-85a0-4176-ac9e-d519f879ad72_del complete
2022-02-21 20:10:05.184 8 INFO nova.compute.manager [req-5bda7692-9018-44bd-9881-4dd63fa293e6 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:10:05.254 8 INFO nova.compute.manager [-] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:10:05.455 8 INFO nova.scheduler.client.report [req-5bda7692-9018-44bd-9881-4dd63fa293e6 818dea96ca1540e7a547982438e94957 9eaea38e8a1c4ce1a600eacfc70479ad - default default] Deleted allocations for instance ee936629-85a0-4176-ac9e-d519f879ad72
2022-02-21 20:10:15.080 8 INFO nova.compute.claims [req-cfd36ec6-f0f2-4987-bcbe-4156a3a71971 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Claim successful on node rack08-server63
2022-02-21 20:10:15.481 8 INFO nova.virt.libvirt.driver [req-cfd36ec6-f0f2-4987-bcbe-4156a3a71971 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Creating image
2022-02-21 20:10:16.630 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] VM Resumed (Lifecycle Event)
2022-02-21 20:10:16.638 8 INFO nova.virt.libvirt.driver [-] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Instance spawned successfully.
2022-02-21 20:10:16.639 8 INFO nova.compute.manager [req-cfd36ec6-f0f2-4987-bcbe-4156a3a71971 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 20:10:16.685 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:10:16.686 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] VM Started (Lifecycle Event)
2022-02-21 20:10:16.722 8 INFO nova.compute.manager [req-cfd36ec6-f0f2-4987-bcbe-4156a3a71971 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Took 1.68 seconds to build instance.
2022-02-21 20:10:20.093 8 INFO nova.compute.manager [-] [instance: ee936629-85a0-4176-ac9e-d519f879ad72] VM Stopped (Lifecycle Event)
2022-02-21 20:10:30.224 8 INFO nova.virt.libvirt.driver [req-c434559d-e40a-468a-af4f-4c07494c1fa0 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Ignoring supplied device name: /dev/vdb
2022-02-21 20:10:30.389 8 INFO nova.compute.manager [req-c434559d-e40a-468a-af4f-4c07494c1fa0 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Attaching volume a2c2470a-eaf0-4481-88d9-f8ffda7c9a0e to /dev/vdb
2022-02-21 20:10:30.484 8 WARNING os_brick.initiator.connectors.nvmeof [req-c434559d-e40a-468a-af4f-4c07494c1fa0 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:10:31.861 8 INFO os_brick.initiator.connectors.lightos [req-c434559d-e40a-468a-af4f-4c07494c1fa0 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: connect_volume called for volume efe81bf4-741e-4342-be98-f7c35c45c4c4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'efe81bf4-741e-4342-be98-f7c35c45c4c4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:10:31.866 8 INFO os_brick.initiator.connectors.lightos [req-c434559d-e40a-468a-af4f-4c07494c1fa0 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid efe81bf4-741e-4342-be98-f7c35c45c4c4
2022-02-21 20:10:43.078 8 INFO nova.compute.manager [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Detaching volume a2c2470a-eaf0-4481-88d9-f8ffda7c9a0e
2022-02-21 20:10:43.141 8 INFO nova.virt.block_device [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Attempting to driver detach volume a2c2470a-eaf0-4481-88d9-f8ffda7c9a0e from mountpoint /dev/vdb
2022-02-21 20:10:43.159 8 INFO nova.virt.libvirt.driver [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Successfully detached device vdb from instance 0afb536d-9ccf-4a05-9f97-0478c677f394 from the persistent domain config.
2022-02-21 20:10:43.303 8 INFO nova.virt.libvirt.driver [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Successfully detached device vdb from instance 0afb536d-9ccf-4a05-9f97-0478c677f394 from the live domain config.
2022-02-21 20:10:43.306 8 INFO os_brick.initiator.connectors.lightos [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: connect_volume called for volume efe81bf4-741e-4342-be98-f7c35c45c4c4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'efe81bf4-741e-4342-be98-f7c35c45c4c4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:10:43.307 8 INFO os_brick.initiator.connectors.lightos [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid efe81bf4-741e-4342-be98-f7c35c45c4c4
2022-02-21 20:10:43.307 8 INFO os_brick.initiator.connectors.lightos [req-65b61964-90d8-4fe0-8812-6d5ee8fde640 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid efe81bf4-741e-4342-be98-f7c35c45c4c4
2022-02-21 20:10:45.337 8 INFO nova.compute.manager [req-90cc39e5-87c7-4819-9ffc-678c7b826f41 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Terminating instance
2022-02-21 20:10:45.681 8 INFO nova.virt.libvirt.driver [-] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Instance destroyed successfully.
2022-02-21 20:10:45.697 8 INFO nova.virt.libvirt.driver [req-90cc39e5-87c7-4819-9ffc-678c7b826f41 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Deleting instance files /var/lib/nova/instances/0afb536d-9ccf-4a05-9f97-0478c677f394_del
2022-02-21 20:10:45.698 8 INFO nova.virt.libvirt.driver [req-90cc39e5-87c7-4819-9ffc-678c7b826f41 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Deletion of /var/lib/nova/instances/0afb536d-9ccf-4a05-9f97-0478c677f394_del complete
2022-02-21 20:10:45.765 8 INFO nova.compute.manager [req-90cc39e5-87c7-4819-9ffc-678c7b826f41 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 20:10:45.830 8 INFO nova.compute.manager [-] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] Took 0.06 seconds to deallocate network for instance.
2022-02-21 20:10:45.997 8 INFO nova.scheduler.client.report [req-90cc39e5-87c7-4819-9ffc-678c7b826f41 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Deleted allocations for instance 0afb536d-9ccf-4a05-9f97-0478c677f394
2022-02-21 20:10:52.094 8 INFO nova.compute.manager [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Detaching volume 99abfd2a-adbe-4e94-aee2-127e437b8d97
2022-02-21 20:10:52.150 8 INFO nova.virt.block_device [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Attempting to driver detach volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 from mountpoint /dev/vdb
2022-02-21 20:10:52.161 8 INFO nova.virt.libvirt.driver [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Device vdb not found in instance.
2022-02-21 20:10:52.210 8 INFO os_brick.initiator.connectors.lightos [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 480ad775-5d0c-4f88-964d-4c1de1246bce, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '480ad775-5d0c-4f88-964d-4c1de1246bce', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:10:53.680 8 INFO nova.compute.claims [req-3d89ec7f-332d-4084-a9e4-4f45edd8ebe3 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Claim successful on node rack08-server63
2022-02-21 20:10:54.073 8 INFO nova.virt.libvirt.driver [req-3d89ec7f-332d-4084-a9e4-4f45edd8ebe3 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Creating image
2022-02-21 20:10:55.201 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] VM Resumed (Lifecycle Event)
2022-02-21 20:10:55.210 8 INFO nova.virt.libvirt.driver [-] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Instance spawned successfully.
2022-02-21 20:10:55.212 8 INFO nova.compute.manager [req-3d89ec7f-332d-4084-a9e4-4f45edd8ebe3 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-21 20:10:55.255 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:10:55.256 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] VM Started (Lifecycle Event)
2022-02-21 20:10:55.300 8 INFO nova.compute.manager [req-3d89ec7f-332d-4084-a9e4-4f45edd8ebe3 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Took 1.66 seconds to build instance.
2022-02-21 20:10:55.713 8 INFO nova.virt.libvirt.driver [req-284a3908-a0f8-45c3-8038-6f1ca5cd8253 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Ignoring supplied device name: /dev/vdb
2022-02-21 20:10:55.874 8 INFO nova.compute.manager [req-284a3908-a0f8-45c3-8038-6f1ca5cd8253 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Attaching volume dab31f5f-49bf-4f72-bb40-1c48c277be92 to /dev/vdb
2022-02-21 20:10:55.969 8 WARNING os_brick.initiator.connectors.nvmeof [req-284a3908-a0f8-45c3-8038-6f1ca5cd8253 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:11:00.680 8 INFO nova.compute.manager [-] [instance: 0afb536d-9ccf-4a05-9f97-0478c677f394] VM Stopped (Lifecycle Event)
2022-02-21 20:11:25.249 8 INFO nova.compute.claims [req-40dc3843-1334-44b1-89d7-16ec2dcb9e7f 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Claim successful on node rack08-server63
2022-02-21 20:11:25.659 8 INFO nova.virt.libvirt.driver [req-40dc3843-1334-44b1-89d7-16ec2dcb9e7f 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Creating image
2022-02-21 20:11:26.789 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] VM Resumed (Lifecycle Event)
2022-02-21 20:11:26.794 8 INFO nova.virt.libvirt.driver [-] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Instance spawned successfully.
2022-02-21 20:11:26.795 8 INFO nova.compute.manager [req-40dc3843-1334-44b1-89d7-16ec2dcb9e7f 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-21 20:11:26.839 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:11:26.840 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] VM Started (Lifecycle Event)
2022-02-21 20:11:26.882 8 INFO nova.compute.manager [req-40dc3843-1334-44b1-89d7-16ec2dcb9e7f 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Took 1.68 seconds to build instance.
2022-02-21 20:11:28.436 8 INFO nova.compute.manager [req-439991be-0d8d-4507-87aa-10cb9f608817 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Terminating instance
2022-02-21 20:11:28.797 8 INFO nova.virt.libvirt.driver [-] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Instance destroyed successfully.
2022-02-21 20:11:28.812 8 INFO nova.virt.libvirt.driver [req-439991be-0d8d-4507-87aa-10cb9f608817 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Deleting instance files /var/lib/nova/instances/3d8255c1-a540-41fc-9e2e-f2d9b0ded483_del
2022-02-21 20:11:28.814 8 INFO nova.virt.libvirt.driver [req-439991be-0d8d-4507-87aa-10cb9f608817 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Deletion of /var/lib/nova/instances/3d8255c1-a540-41fc-9e2e-f2d9b0ded483_del complete
2022-02-21 20:11:28.885 8 INFO nova.compute.manager [req-439991be-0d8d-4507-87aa-10cb9f608817 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:11:28.958 8 INFO nova.compute.manager [-] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:11:29.160 8 INFO nova.scheduler.client.report [req-439991be-0d8d-4507-87aa-10cb9f608817 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] Deleted allocations for instance 3d8255c1-a540-41fc-9e2e-f2d9b0ded483
2022-02-21 20:11:31.431 8 INFO nova.compute.claims [req-518e6495-0c10-4f6f-b90d-e2c07f623fda 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Claim successful on node rack08-server63
2022-02-21 20:11:31.813 8 INFO nova.virt.libvirt.driver [req-518e6495-0c10-4f6f-b90d-e2c07f623fda 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Creating image
2022-02-21 20:11:32.987 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] VM Resumed (Lifecycle Event)
2022-02-21 20:11:32.994 8 INFO nova.virt.libvirt.driver [-] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Instance spawned successfully.
2022-02-21 20:11:32.995 8 INFO nova.compute.manager [req-518e6495-0c10-4f6f-b90d-e2c07f623fda 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-21 20:11:33.043 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:11:33.044 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] VM Started (Lifecycle Event)
2022-02-21 20:11:33.103 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:11:33.130 8 INFO nova.compute.manager [req-518e6495-0c10-4f6f-b90d-e2c07f623fda 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Took 1.87 seconds to build instance.
2022-02-21 20:11:34.192 8 INFO nova.compute.manager [req-c88e0bc0-0339-4f5b-a81e-3f7bc7b45abd 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Terminating instance
2022-02-21 20:11:34.548 8 INFO nova.virt.libvirt.driver [-] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Instance destroyed successfully.
2022-02-21 20:11:34.563 8 INFO nova.virt.libvirt.driver [req-c88e0bc0-0339-4f5b-a81e-3f7bc7b45abd 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Deleting instance files /var/lib/nova/instances/b185139b-0c43-4f89-8926-d1ac21ce1000_del
2022-02-21 20:11:34.564 8 INFO nova.virt.libvirt.driver [req-c88e0bc0-0339-4f5b-a81e-3f7bc7b45abd 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Deletion of /var/lib/nova/instances/b185139b-0c43-4f89-8926-d1ac21ce1000_del complete
2022-02-21 20:11:34.638 8 INFO nova.compute.manager [req-c88e0bc0-0339-4f5b-a81e-3f7bc7b45abd 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:11:34.708 8 INFO nova.compute.manager [-] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:11:34.907 8 INFO nova.scheduler.client.report [req-c88e0bc0-0339-4f5b-a81e-3f7bc7b45abd 50c540480cd9473e90a99e97161f7d68 970e1e5facf54af093ee2db204235dae - default default] Deleted allocations for instance b185139b-0c43-4f89-8926-d1ac21ce1000
2022-02-21 20:11:43.794 8 INFO nova.compute.manager [-] [instance: 3d8255c1-a540-41fc-9e2e-f2d9b0ded483] VM Stopped (Lifecycle Event)
2022-02-21 20:11:49.546 8 INFO nova.compute.manager [-] [instance: b185139b-0c43-4f89-8926-d1ac21ce1000] VM Stopped (Lifecycle Event)
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Failed to detach volume 99abfd2a-adbe-4e94-aee2-127e437b8d97 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Traceback (most recent call last):
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     return f(*args, **kwargs)
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     return f(*args, **kwargs)
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795]     raise exception.BrickException(message=msg)
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:11:52.235 8 ERROR nova.virt.block_device [instance: db7f9d78-e7bd-41d7-a101-54703579b795] 
2022-02-21 20:11:52.243 8 INFO os_brick.initiator.connectors.lightos [req-284a3908-a0f8-45c3-8038-6f1ca5cd8253 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: connect_volume called for volume ca5c156c-80c6-4478-b18a-a8758f8b09cf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ca5c156c-80c6-4478-b18a-a8758f8b09cf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:11:52.246 8 INFO os_brick.initiator.connectors.lightos [req-284a3908-a0f8-45c3-8038-6f1ca5cd8253 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ca5c156c-80c6-4478-b18a-a8758f8b09cf
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server [req-0c2288c1-5c7a-4e9d-ba54-68678a4e715c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:11:52.330 8 ERROR oslo_messaging.rpc.server 
2022-02-21 20:12:01.224 8 INFO nova.compute.manager [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Detaching volume dab31f5f-49bf-4f72-bb40-1c48c277be92
2022-02-21 20:12:01.279 8 INFO nova.virt.block_device [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Attempting to driver detach volume dab31f5f-49bf-4f72-bb40-1c48c277be92 from mountpoint /dev/vdb
2022-02-21 20:12:01.298 8 INFO nova.virt.libvirt.driver [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Successfully detached device vdb from instance bb8bf7b2-6298-4ed7-9e34-05cf19473356 from the persistent domain config.
2022-02-21 20:12:01.450 8 INFO nova.virt.libvirt.driver [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Successfully detached device vdb from instance bb8bf7b2-6298-4ed7-9e34-05cf19473356 from the live domain config.
2022-02-21 20:12:01.453 8 INFO os_brick.initiator.connectors.lightos [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: connect_volume called for volume ca5c156c-80c6-4478-b18a-a8758f8b09cf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ca5c156c-80c6-4478-b18a-a8758f8b09cf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:12:01.454 8 INFO os_brick.initiator.connectors.lightos [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ca5c156c-80c6-4478-b18a-a8758f8b09cf
2022-02-21 20:12:01.455 8 INFO os_brick.initiator.connectors.lightos [req-866dd89a-a32f-4312-b9b5-3a7791b37f89 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ca5c156c-80c6-4478-b18a-a8758f8b09cf
2022-02-21 20:12:03.478 8 INFO nova.compute.manager [req-c4ccf914-5f59-4a3c-a128-08f6b67de5df 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Terminating instance
2022-02-21 20:12:03.824 8 INFO nova.virt.libvirt.driver [-] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Instance destroyed successfully.
2022-02-21 20:12:03.839 8 INFO nova.virt.libvirt.driver [req-c4ccf914-5f59-4a3c-a128-08f6b67de5df 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Deleting instance files /var/lib/nova/instances/bb8bf7b2-6298-4ed7-9e34-05cf19473356_del
2022-02-21 20:12:03.840 8 INFO nova.virt.libvirt.driver [req-c4ccf914-5f59-4a3c-a128-08f6b67de5df 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Deletion of /var/lib/nova/instances/bb8bf7b2-6298-4ed7-9e34-05cf19473356_del complete
2022-02-21 20:12:03.912 8 INFO nova.compute.manager [req-c4ccf914-5f59-4a3c-a128-08f6b67de5df 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 20:12:03.981 8 INFO nova.compute.manager [-] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:12:04.179 8 INFO nova.scheduler.client.report [req-c4ccf914-5f59-4a3c-a128-08f6b67de5df 3d2d16ffb6ac4aee8654099e014c2427 4aacf9b582184fd5a17706ef7bc30104 - default default] Deleted allocations for instance bb8bf7b2-6298-4ed7-9e34-05cf19473356
2022-02-21 20:12:18.822 8 INFO nova.compute.manager [-] [instance: bb8bf7b2-6298-4ed7-9e34-05cf19473356] VM Stopped (Lifecycle Event)
2022-02-21 20:15:52.435 8 INFO nova.compute.manager [req-3c933db6-98bb-47d2-85d8-ee0813c97d1d b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Get console output
2022-02-21 20:15:52.718 81 INFO nova.privsep.libvirt [-] Ignored error while reading from instance console pty: can't concat NoneType to bytes
2022-02-21 20:16:09.873 8 INFO nova.compute.claims [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Claim successful on node rack08-server63
2022-02-21 20:16:10.137 8 INFO nova.virt.libvirt.driver [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 20:16:10.225 8 INFO nova.virt.block_device [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Booting with volume 65452532-6c9d-43e6-bf97-19f566bd8d89 at /dev/vda
2022-02-21 20:16:10.315 8 WARNING os_brick.initiator.connectors.nvmeof [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 20:16:11.829 8 INFO nova.virt.libvirt.driver [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Creating image
2022-02-21 20:16:11.840 8 INFO os_brick.initiator.connectors.lightos [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 6100afbf-5143-4d75-b71c-0a18ac1a214a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6100afbf-5143-4d75-b71c-0a18ac1a214a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 20:16:11.843 8 INFO os_brick.initiator.connectors.lightos [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6100afbf-5143-4d75-b71c-0a18ac1a214a
2022-02-21 20:16:12.743 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] VM Resumed (Lifecycle Event)
2022-02-21 20:16:12.750 8 INFO nova.virt.libvirt.driver [-] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Instance spawned successfully.
2022-02-21 20:16:12.751 8 INFO nova.compute.manager [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Took 0.92 seconds to spawn the instance on the hypervisor.
2022-02-21 20:16:12.799 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 20:16:12.800 8 INFO nova.compute.manager [req-b1499cf7-c1ab-4c31-a21e-d27efde573d4 - - - - -] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] VM Started (Lifecycle Event)
2022-02-21 20:16:12.841 8 INFO nova.compute.manager [req-1bec047e-c55d-464c-ad3a-4c2309e6249c b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Took 3.01 seconds to build instance.
2022-02-21 20:16:14.352 8 INFO nova.compute.manager [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Terminating instance
2022-02-21 20:16:14.697 8 INFO nova.virt.libvirt.driver [-] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Instance destroyed successfully.
2022-02-21 20:16:14.769 8 INFO os_brick.initiator.connectors.lightos [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 6100afbf-5143-4d75-b71c-0a18ac1a214a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6100afbf-5143-4d75-b71c-0a18ac1a214a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:16:14.770 8 INFO os_brick.initiator.connectors.lightos [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6100afbf-5143-4d75-b71c-0a18ac1a214a
2022-02-21 20:16:14.771 8 INFO os_brick.initiator.connectors.lightos [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6100afbf-5143-4d75-b71c-0a18ac1a214a
2022-02-21 20:16:14.782 8 INFO nova.virt.libvirt.driver [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Deleting instance files /var/lib/nova/instances/3efbc451-ea9d-404e-8a73-7ef4ea6be924_del
2022-02-21 20:16:14.783 8 INFO nova.virt.libvirt.driver [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Deletion of /var/lib/nova/instances/3efbc451-ea9d-404e-8a73-7ef4ea6be924_del complete
2022-02-21 20:16:14.854 8 INFO nova.compute.manager [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-21 20:16:14.920 8 INFO nova.compute.manager [-] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:16:18.211 8 INFO nova.compute.manager [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] Took 3.29 seconds to detach 1 volumes for instance.
2022-02-21 20:16:18.418 8 INFO nova.scheduler.client.report [req-66ea4d22-138f-4394-8407-bc575ff8d707 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Deleted allocations for instance 3efbc451-ea9d-404e-8a73-7ef4ea6be924
2022-02-21 20:16:29.696 8 INFO nova.compute.manager [-] [instance: 3efbc451-ea9d-404e-8a73-7ef4ea6be924] VM Stopped (Lifecycle Event)
2022-02-21 20:21:20.880 8 INFO nova.compute.manager [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Terminating instance
2022-02-21 20:21:21.227 8 INFO nova.virt.libvirt.driver [-] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Instance destroyed successfully.
2022-02-21 20:21:21.300 8 INFO os_brick.initiator.connectors.lightos [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 480ad775-5d0c-4f88-964d-4c1de1246bce, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '480ad775-5d0c-4f88-964d-4c1de1246bce', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 20:21:36.225 8 INFO nova.compute.manager [-] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] VM Stopped (Lifecycle Event)
2022-02-21 20:21:36.282 8 INFO nova.compute.manager [req-0cf018fd-0aca-4531-bc23-06153d7f2ca5 - - - - -] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] During sync_power_state the instance has a pending task (deleting). Skip.
2022-02-21 20:22:22.005 8 WARNING nova.virt.libvirt.driver [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Ignoring Volume Error on vol 99abfd2a-adbe-4e94-aee2-127e437b8d97 during delete Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up: os_brick.exception.BrickException: Device with uuid 480ad775-5d0c-4f88-964d-4c1de1246bce did not show up
2022-02-21 20:22:22.007 8 INFO nova.virt.libvirt.driver [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Deleting instance files /var/lib/nova/instances/db7f9d78-e7bd-41d7-a101-54703579b795_del
2022-02-21 20:22:22.009 8 INFO nova.virt.libvirt.driver [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Deletion of /var/lib/nova/instances/db7f9d78-e7bd-41d7-a101-54703579b795_del complete
2022-02-21 20:22:22.079 8 INFO nova.compute.manager [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Took 61.08 seconds to destroy the instance on the hypervisor.
2022-02-21 20:22:22.154 8 INFO nova.compute.manager [-] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:22:23.433 8 INFO nova.compute.manager [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: db7f9d78-e7bd-41d7-a101-54703579b795] Took 1.28 seconds to detach 1 volumes for instance.
2022-02-21 20:22:23.629 8 INFO nova.scheduler.client.report [req-2945a4f9-685a-4c53-9152-bdd380aad142 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Deleted allocations for instance db7f9d78-e7bd-41d7-a101-54703579b795
2022-02-21 20:22:24.278 8 INFO nova.compute.manager [req-b3206864-1f7b-4a24-9407-5a463c00d2c0 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Terminating instance
2022-02-21 20:22:24.619 8 INFO nova.virt.libvirt.driver [-] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Instance destroyed successfully.
2022-02-21 20:22:24.639 8 INFO nova.virt.libvirt.driver [req-b3206864-1f7b-4a24-9407-5a463c00d2c0 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Deleting instance files /var/lib/nova/instances/89865d90-5ce1-49bc-bb70-e75e719e4840_del
2022-02-21 20:22:24.641 8 INFO nova.virt.libvirt.driver [req-b3206864-1f7b-4a24-9407-5a463c00d2c0 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Deletion of /var/lib/nova/instances/89865d90-5ce1-49bc-bb70-e75e719e4840_del complete
2022-02-21 20:22:24.713 8 INFO nova.compute.manager [req-b3206864-1f7b-4a24-9407-5a463c00d2c0 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-21 20:22:24.782 8 INFO nova.compute.manager [-] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:22:24.987 8 INFO nova.scheduler.client.report [req-b3206864-1f7b-4a24-9407-5a463c00d2c0 b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Deleted allocations for instance 89865d90-5ce1-49bc-bb70-e75e719e4840
2022-02-21 20:22:25.519 8 INFO nova.compute.manager [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Terminating instance
2022-02-21 20:22:25.871 8 INFO nova.virt.libvirt.driver [-] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Instance destroyed successfully.
2022-02-21 20:22:25.950 8 INFO os_brick.initiator.connectors.lightos [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: connect_volume called for volume 4bad1557-e892-4d06-860a-d1bb96a55331, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4bad1557-e892-4d06-860a-d1bb96a55331', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 20:22:25.951 8 INFO os_brick.initiator.connectors.lightos [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4bad1557-e892-4d06-860a-d1bb96a55331
2022-02-21 20:22:25.952 8 INFO os_brick.initiator.connectors.lightos [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4bad1557-e892-4d06-860a-d1bb96a55331
2022-02-21 20:22:25.964 8 INFO nova.virt.libvirt.driver [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Deleting instance files /var/lib/nova/instances/7de1a055-382a-4a30-96a8-644aaf12a9f3_del
2022-02-21 20:22:25.965 8 INFO nova.virt.libvirt.driver [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Deletion of /var/lib/nova/instances/7de1a055-382a-4a30-96a8-644aaf12a9f3_del complete
2022-02-21 20:22:26.033 8 INFO nova.compute.manager [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-21 20:22:26.103 8 INFO nova.compute.manager [-] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Took 0.07 seconds to deallocate network for instance.
2022-02-21 20:22:27.344 8 INFO nova.compute.manager [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-21 20:22:27.539 8 INFO nova.scheduler.client.report [req-d80c1758-4aa8-48c8-aea3-bb3c0fd4596b b3badf9c591749508101ca330d4de4c4 4145ddcee582455395764b3655dde188 - default default] Deleted allocations for instance 7de1a055-382a-4a30-96a8-644aaf12a9f3
2022-02-21 20:22:39.617 8 INFO nova.compute.manager [-] [instance: 89865d90-5ce1-49bc-bb70-e75e719e4840] VM Stopped (Lifecycle Event)
2022-02-21 20:22:40.868 8 INFO nova.compute.manager [-] [instance: 7de1a055-382a-4a30-96a8-644aaf12a9f3] VM Stopped (Lifecycle Event)
