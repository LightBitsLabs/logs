Build Started 23_02_2022_16_14_47
2022-02-23 18:16:38.208 7 INFO nova.virt.libvirt.imagecache [req-1e23e51d-2e73-464f-b465-68ad1d57b416 - - - - -] image 54b95c78-b439-4b0b-8e00-3a7cc508dc31 at (/var/lib/nova/instances/_base/f26e4543eb5697d89d40a430f4bf0ab5380c1b8b): checking
2022-02-23 18:16:38.369 7 INFO nova.virt.libvirt.imagecache [req-1e23e51d-2e73-464f-b465-68ad1d57b416 - - - - -] Active base files: /var/lib/nova/instances/_base/f26e4543eb5697d89d40a430f4bf0ab5380c1b8b
2022-02-23 18:18:22.975 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-23 18:18:26.992 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-23 18:18:27.925 7 INFO nova.virt.driver [req-607e9be8-f87d-43d1-9c6c-18beb313352e - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-23 18:18:28.310 7 INFO nova.compute.provider_config [req-607e9be8-f87d-43d1-9c6c-18beb313352e - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-23 18:18:28.330 7 WARNING oslo_config.cfg [req-607e9be8-f87d-43d1-9c6c-18beb313352e - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-23 18:18:28.351 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-23 18:18:28.364 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-23 18:18:28.404 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-23 18:18:28.501 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-23 18:18:28.517 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-23 18:18:28.519 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-23 18:18:28.921 7 INFO nova.compute.manager [req-867db2f0-a945-4c28-bf13-f862d6c6d551 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-23 18:18:30.748 7 INFO nova.virt.libvirt.host [req-867db2f0-a945-4c28-bf13-f862d6c6d551 - - - - -] kernel doesn't support AMD SEV
2022-02-23 18:19:21.370 7 INFO nova.compute.claims [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Claim successful on node rack08-server63
2022-02-23 18:19:21.763 7 INFO nova.virt.libvirt.driver [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Creating image
2022-02-23 18:19:21.767 7 INFO oslo.privsep.daemon [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpdt5kkrxg/privsep.sock']
2022-02-23 18:19:23.401 7 INFO oslo.privsep.daemon [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Spawned new privsep daemon via rootwrap
2022-02-23 18:19:23.247 69 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 18:19:23.253 69 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 18:19:23.258 69 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-23 18:19:23.259 69 INFO oslo.privsep.daemon [-] privsep daemon running as pid 69
2022-02-23 18:19:23.851 7 WARNING nova.compute.manager [req-ce239088-bb6a-4165-8957-71d4d38aaf60 - - - - -] While synchronizing instance power states, found 4 instances in the database and 3 instances on the hypervisor.
2022-02-23 18:19:24.643 7 INFO nova.compute.manager [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] VM Resumed (Lifecycle Event)
2022-02-23 18:19:24.650 7 INFO nova.virt.libvirt.driver [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Instance spawned successfully.
2022-02-23 18:19:24.651 7 INFO nova.compute.manager [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Took 2.89 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:24.697 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:24.697 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] VM Started (Lifecycle Event)
2022-02-23 18:19:24.738 7 INFO nova.compute.manager [req-0d342913-ae9e-4960-a94b-8a7db78259ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Took 3.41 seconds to build instance.
2022-02-23 18:19:24.757 7 INFO nova.compute.manager [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:29.798 7 INFO nova.compute.manager [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Attaching volume cc16b4b6-c590-46e8-854b-e1318220b3a0 to /dev/vdb
2022-02-23 18:19:29.886 7 INFO oslo.privsep.daemon [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpjyemid3j/privsep.sock']
2022-02-23 18:19:30.547 7 INFO oslo.privsep.daemon [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Spawned new privsep daemon via rootwrap
2022-02-23 18:19:30.471 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 18:19:30.478 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 18:19:30.482 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-23 18:19:30.482 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-23 18:19:30.870 7 WARNING os_brick.initiator.connectors.nvmeof [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:19:32.252 7 INFO os_brick.initiator.connectors.lightos [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: connect_volume called for volume d428c59b-dafc-4f6d-89cd-48c3a2ea4aa8, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd428c59b-dafc-4f6d-89cd-48c3a2ea4aa8', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:19:32.286 7 INFO os_brick.initiator.connectors.lightos [req-dfe79b78-4a38-4997-82fe-eb612b06b7ee 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d428c59b-dafc-4f6d-89cd-48c3a2ea4aa8
2022-02-23 18:19:34.729 7 INFO nova.compute.claims [req-884258e4-2f6a-47ab-89f8-56753de7b626 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Claim successful on node rack08-server63
2022-02-23 18:19:35.134 7 INFO nova.virt.libvirt.driver [req-884258e4-2f6a-47ab-89f8-56753de7b626 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Creating image
2022-02-23 18:19:36.296 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] VM Resumed (Lifecycle Event)
2022-02-23 18:19:36.304 7 INFO nova.virt.libvirt.driver [-] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Instance spawned successfully.
2022-02-23 18:19:36.305 7 INFO nova.compute.manager [req-884258e4-2f6a-47ab-89f8-56753de7b626 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:36.350 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:36.351 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] VM Started (Lifecycle Event)
2022-02-23 18:19:36.408 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:36.411 7 INFO nova.compute.manager [req-884258e4-2f6a-47ab-89f8-56753de7b626 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Took 1.72 seconds to build instance.
2022-02-23 18:19:36.797 7 INFO nova.compute.claims [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Claim successful on node rack08-server63
2022-02-23 18:19:37.067 7 INFO nova.virt.libvirt.driver [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 18:19:37.156 7 INFO nova.virt.block_device [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Booting with volume 0a5fe282-85b4-49ae-b0d5-d81c1d8b4d06 at /dev/vda
2022-02-23 18:19:37.248 7 WARNING os_brick.initiator.connectors.nvmeof [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:19:37.918 7 INFO nova.compute.manager [req-d3c0e3da-f2ef-4185-87b6-d0f040f5a40e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Detaching volume cc16b4b6-c590-46e8-854b-e1318220b3a0
2022-02-23 18:19:37.977 7 INFO nova.virt.block_device [req-d3c0e3da-f2ef-4185-87b6-d0f040f5a40e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Attempting to driver detach volume cc16b4b6-c590-46e8-854b-e1318220b3a0 from mountpoint /dev/vdb
2022-02-23 18:19:37.996 7 INFO nova.virt.libvirt.driver [req-d3c0e3da-f2ef-4185-87b6-d0f040f5a40e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance ecf7f396-989e-4e10-96dd-46143e6b540e from the persistent domain config.
2022-02-23 18:19:38.136 7 INFO nova.virt.libvirt.driver [req-d3c0e3da-f2ef-4185-87b6-d0f040f5a40e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance ecf7f396-989e-4e10-96dd-46143e6b540e from the live domain config.
2022-02-23 18:19:38.139 7 INFO os_brick.initiator.connectors.lightos [req-d3c0e3da-f2ef-4185-87b6-d0f040f5a40e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d428c59b-dafc-4f6d-89cd-48c3a2ea4aa8
2022-02-23 18:19:38.758 7 INFO nova.virt.libvirt.driver [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Creating image
2022-02-23 18:19:38.768 7 INFO os_brick.initiator.connectors.lightos [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: connect_volume called for volume 1acc9c94-8318-4357-9116-204ad041333d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1acc9c94-8318-4357-9116-204ad041333d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:19:38.770 7 INFO os_brick.initiator.connectors.lightos [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 1acc9c94-8318-4357-9116-204ad041333d
2022-02-23 18:19:39.591 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] VM Resumed (Lifecycle Event)
2022-02-23 18:19:39.599 7 INFO nova.virt.libvirt.driver [-] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Instance spawned successfully.
2022-02-23 18:19:39.599 7 INFO nova.compute.manager [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Took 0.84 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:39.651 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:39.651 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] VM Started (Lifecycle Event)
2022-02-23 18:19:39.683 7 INFO nova.compute.manager [req-72810c8c-e5aa-441e-bfa2-9b727c6003ca 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Took 2.92 seconds to build instance.
2022-02-23 18:19:41.357 7 INFO nova.compute.claims [req-b1b55935-7cfa-4d8c-a432-4a036a619902 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Claim successful on node rack08-server63
2022-02-23 18:19:41.766 7 INFO nova.virt.libvirt.driver [req-b1b55935-7cfa-4d8c-a432-4a036a619902 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Creating image
2022-02-23 18:19:42.021 7 INFO nova.compute.claims [req-036be1a3-fcdb-44a6-82d6-a5c4dbbc9b8a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Claim successful on node rack08-server63
2022-02-23 18:19:42.405 7 INFO nova.virt.libvirt.driver [req-036be1a3-fcdb-44a6-82d6-a5c4dbbc9b8a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Creating image
2022-02-23 18:19:42.563 7 INFO nova.compute.claims [req-953248ec-5a2c-4fa0-a6d5-4cc91f606447 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Claim successful on node rack08-server63
2022-02-23 18:19:42.899 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] VM Resumed (Lifecycle Event)
2022-02-23 18:19:42.907 7 INFO nova.virt.libvirt.driver [-] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Instance spawned successfully.
2022-02-23 18:19:42.908 7 INFO nova.compute.manager [req-b1b55935-7cfa-4d8c-a432-4a036a619902 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:42.950 7 INFO nova.virt.libvirt.driver [req-953248ec-5a2c-4fa0-a6d5-4cc91f606447 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Creating image
2022-02-23 18:19:42.953 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:42.954 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] VM Started (Lifecycle Event)
2022-02-23 18:19:42.989 7 INFO nova.compute.manager [req-b1b55935-7cfa-4d8c-a432-4a036a619902 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Took 1.67 seconds to build instance.
2022-02-23 18:19:43.525 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 17d92220-84c8-4d1a-932d-962af293a013] VM Resumed (Lifecycle Event)
2022-02-23 18:19:43.532 7 INFO nova.virt.libvirt.driver [-] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Instance spawned successfully.
2022-02-23 18:19:43.533 7 INFO nova.compute.manager [req-036be1a3-fcdb-44a6-82d6-a5c4dbbc9b8a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Took 1.13 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:43.584 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 17d92220-84c8-4d1a-932d-962af293a013] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:43.584 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 17d92220-84c8-4d1a-932d-962af293a013] VM Started (Lifecycle Event)
2022-02-23 18:19:43.621 7 INFO nova.compute.manager [req-036be1a3-fcdb-44a6-82d6-a5c4dbbc9b8a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Took 1.64 seconds to build instance.
2022-02-23 18:19:44.087 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] VM Resumed (Lifecycle Event)
2022-02-23 18:19:44.093 7 INFO nova.virt.libvirt.driver [-] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Instance spawned successfully.
2022-02-23 18:19:44.093 7 INFO nova.compute.manager [req-953248ec-5a2c-4fa0-a6d5-4cc91f606447 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:44.142 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:44.143 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] VM Started (Lifecycle Event)
2022-02-23 18:19:44.181 7 INFO nova.compute.manager [req-953248ec-5a2c-4fa0-a6d5-4cc91f606447 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Took 1.66 seconds to build instance.
2022-02-23 18:19:44.806 7 INFO nova.compute.manager [req-8b5d51ca-bf53-4a76-9848-800e4b091d79 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Attaching volume ac91be5e-07e7-4694-b699-1425ce48964e to /dev/vdb
2022-02-23 18:19:44.887 7 WARNING os_brick.initiator.connectors.nvmeof [req-8b5d51ca-bf53-4a76-9848-800e4b091d79 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:19:46.226 7 INFO nova.compute.manager [req-8b0c8996-ee1c-4ed5-8bab-3ea955cacad4 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Attaching volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288 to /dev/vdb
2022-02-23 18:19:46.373 7 INFO os_brick.initiator.connectors.lightos [req-8b5d51ca-bf53-4a76-9848-800e4b091d79 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: connect_volume called for volume df4429c2-55b4-40d1-b1b2-c25e6fd3919d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'df4429c2-55b4-40d1-b1b2-c25e6fd3919d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:19:46.375 7 INFO os_brick.initiator.connectors.lightos [req-8b5d51ca-bf53-4a76-9848-800e4b091d79 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid df4429c2-55b4-40d1-b1b2-c25e6fd3919d
2022-02-23 18:19:46.449 7 WARNING os_brick.initiator.connectors.nvmeof [req-8b0c8996-ee1c-4ed5-8bab-3ea955cacad4 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:19:47.392 7 INFO nova.compute.manager [req-cb943290-6e4f-467b-b099-587cad655a29 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Detaching volume ac91be5e-07e7-4694-b699-1425ce48964e
2022-02-23 18:19:47.450 7 INFO nova.virt.block_device [req-cb943290-6e4f-467b-b099-587cad655a29 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Attempting to driver detach volume ac91be5e-07e7-4694-b699-1425ce48964e from mountpoint /dev/vdb
2022-02-23 18:19:47.477 7 INFO nova.virt.libvirt.driver [req-cb943290-6e4f-467b-b099-587cad655a29 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance 8af72143-7902-4a1a-afb5-aaeb5b989a96 from the persistent domain config.
2022-02-23 18:19:47.620 7 INFO nova.virt.libvirt.driver [req-cb943290-6e4f-467b-b099-587cad655a29 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance 8af72143-7902-4a1a-afb5-aaeb5b989a96 from the live domain config.
2022-02-23 18:19:47.623 7 INFO os_brick.initiator.connectors.lightos [req-cb943290-6e4f-467b-b099-587cad655a29 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid df4429c2-55b4-40d1-b1b2-c25e6fd3919d
2022-02-23 18:19:47.798 7 INFO os_brick.initiator.connectors.lightos [req-8b0c8996-ee1c-4ed5-8bab-3ea955cacad4 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: connect_volume called for volume fbff5dc6-4be7-42b3-80f5-d6b718d46c00, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'fbff5dc6-4be7-42b3-80f5-d6b718d46c00', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:19:47.801 7 INFO os_brick.initiator.connectors.lightos [req-8b0c8996-ee1c-4ed5-8bab-3ea955cacad4 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid fbff5dc6-4be7-42b3-80f5-d6b718d46c00
2022-02-23 18:19:48.721 7 INFO nova.compute.manager [req-be0411df-4216-4e71-9e12-33e41124a79f 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Attaching volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288 to /dev/vdb
2022-02-23 18:19:48.815 7 WARNING os_brick.initiator.connectors.nvmeof [req-be0411df-4216-4e71-9e12-33e41124a79f 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:19:50.182 7 INFO os_brick.initiator.connectors.lightos [req-be0411df-4216-4e71-9e12-33e41124a79f 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: connect_volume called for volume fbff5dc6-4be7-42b3-80f5-d6b718d46c00, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'fbff5dc6-4be7-42b3-80f5-d6b718d46c00', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:19:50.183 7 INFO os_brick.initiator.connectors.lightos [req-be0411df-4216-4e71-9e12-33e41124a79f 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid fbff5dc6-4be7-42b3-80f5-d6b718d46c00
2022-02-23 18:19:50.757 7 INFO nova.compute.claims [req-ac0416ec-e34c-4f92-adde-23d6ac24d08f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Claim successful on node rack08-server63
2022-02-23 18:19:51.139 7 INFO nova.virt.libvirt.driver [req-ac0416ec-e34c-4f92-adde-23d6ac24d08f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Creating image
2022-02-23 18:19:51.293 7 INFO nova.compute.manager [req-7575f353-86e1-4b2c-a88f-38adde9ba935 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Detaching volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288
2022-02-23 18:19:51.370 7 INFO nova.virt.block_device [req-7575f353-86e1-4b2c-a88f-38adde9ba935 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Attempting to driver detach volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288 from mountpoint /dev/vdb
2022-02-23 18:19:51.388 7 INFO nova.virt.libvirt.driver [req-7575f353-86e1-4b2c-a88f-38adde9ba935 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Successfully detached device vdb from instance 17d92220-84c8-4d1a-932d-962af293a013 from the persistent domain config.
2022-02-23 18:19:51.530 7 INFO nova.virt.libvirt.driver [req-7575f353-86e1-4b2c-a88f-38adde9ba935 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Successfully detached device vdb from instance 17d92220-84c8-4d1a-932d-962af293a013 from the live domain config.
2022-02-23 18:19:51.607 7 INFO nova.virt.libvirt.driver [req-7575f353-86e1-4b2c-a88f-38adde9ba935 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Detected multiple connections on this host for volume: d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288, skipping target disconnect.
2022-02-23 18:19:52.291 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] VM Resumed (Lifecycle Event)
2022-02-23 18:19:52.298 7 INFO nova.virt.libvirt.driver [-] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Instance spawned successfully.
2022-02-23 18:19:52.299 7 INFO nova.compute.manager [req-ac0416ec-e34c-4f92-adde-23d6ac24d08f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-23 18:19:52.348 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:19:52.349 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] VM Started (Lifecycle Event)
2022-02-23 18:19:52.383 7 INFO nova.compute.manager [req-ac0416ec-e34c-4f92-adde-23d6ac24d08f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Took 1.67 seconds to build instance.
2022-02-23 18:19:53.773 7 INFO nova.compute.manager [req-0406c26d-7e96-46c4-b799-1c25a8d34bb0 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Detaching volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288
2022-02-23 18:19:53.838 7 INFO nova.virt.block_device [req-0406c26d-7e96-46c4-b799-1c25a8d34bb0 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Attempting to driver detach volume d45bbf1f-e7ef-4bfd-a44c-2c71beb4a288 from mountpoint /dev/vdb
2022-02-23 18:19:53.855 7 INFO nova.virt.libvirt.driver [req-0406c26d-7e96-46c4-b799-1c25a8d34bb0 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Successfully detached device vdb from instance b6b8434c-7113-4b72-b42d-a06925666d81 from the persistent domain config.
2022-02-23 18:19:54.036 7 INFO nova.virt.libvirt.driver [req-0406c26d-7e96-46c4-b799-1c25a8d34bb0 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Successfully detached device vdb from instance b6b8434c-7113-4b72-b42d-a06925666d81 from the live domain config.
2022-02-23 18:19:55.396 7 INFO nova.compute.manager [req-af256e63-c52c-4fc5-a358-c967deda2dc7 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Attaching volume d85951b4-6d42-49ca-8f61-977336d6091a to /dev/vdb
2022-02-23 18:19:55.484 7 WARNING os_brick.initiator.connectors.nvmeof [req-af256e63-c52c-4fc5-a358-c967deda2dc7 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:20:54.578 7 INFO os_brick.initiator.connectors.lightos [req-af256e63-c52c-4fc5-a358-c967deda2dc7 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: connect_volume called for volume a218b017-f1ab-4065-af17-eb3ea8a4e1cc, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a218b017-f1ab-4065-af17-eb3ea8a4e1cc', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:20:54.582 7 INFO os_brick.initiator.connectors.lightos [req-af256e63-c52c-4fc5-a358-c967deda2dc7 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a218b017-f1ab-4065-af17-eb3ea8a4e1cc
2022-02-23 18:20:56.191 7 INFO nova.compute.manager [req-204ba2da-a274-4eb7-bb30-b0a23b858c07 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Detaching volume d85951b4-6d42-49ca-8f61-977336d6091a
2022-02-23 18:20:56.254 7 INFO nova.virt.block_device [req-204ba2da-a274-4eb7-bb30-b0a23b858c07 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Attempting to driver detach volume d85951b4-6d42-49ca-8f61-977336d6091a from mountpoint /dev/vdb
2022-02-23 18:20:56.273 7 INFO nova.virt.libvirt.driver [req-204ba2da-a274-4eb7-bb30-b0a23b858c07 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance 13006581-6a51-455a-8d7f-273e3fff3c79 from the persistent domain config.
2022-02-23 18:20:56.417 7 INFO nova.virt.libvirt.driver [req-204ba2da-a274-4eb7-bb30-b0a23b858c07 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Successfully detached device vdb from instance 13006581-6a51-455a-8d7f-273e3fff3c79 from the live domain config.
2022-02-23 18:20:56.420 7 INFO os_brick.initiator.connectors.lightos [req-204ba2da-a274-4eb7-bb30-b0a23b858c07 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a218b017-f1ab-4065-af17-eb3ea8a4e1cc
2022-02-23 18:20:59.704 7 INFO nova.compute.manager [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Terminating instance
2022-02-23 18:21:00.054 7 INFO nova.virt.libvirt.driver [-] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Instance destroyed successfully.
2022-02-23 18:21:00.070 7 INFO nova.virt.libvirt.driver [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Deleting instance files /var/lib/nova/instances/13006581-6a51-455a-8d7f-273e3fff3c79_del
2022-02-23 18:21:00.071 7 INFO nova.virt.libvirt.driver [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Deletion of /var/lib/nova/instances/13006581-6a51-455a-8d7f-273e3fff3c79_del complete
2022-02-23 18:21:00.136 7 INFO nova.virt.libvirt.host [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] UEFI support detected
2022-02-23 18:21:00.138 7 INFO nova.compute.manager [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:00.199 7 INFO nova.compute.manager [-] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:21:00.370 7 INFO nova.scheduler.client.report [req-7f7a8f1f-b75a-4076-b689-c56e057fece8 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Deleted allocations for instance 13006581-6a51-455a-8d7f-273e3fff3c79
2022-02-23 18:21:02.105 7 INFO nova.compute.manager [req-1633d7ca-77f9-42fc-9c9c-ef8e53df334f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Terminating instance
2022-02-23 18:21:02.459 7 INFO nova.virt.libvirt.driver [-] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Instance destroyed successfully.
2022-02-23 18:21:02.474 7 INFO nova.virt.libvirt.driver [req-1633d7ca-77f9-42fc-9c9c-ef8e53df334f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Deleting instance files /var/lib/nova/instances/8af72143-7902-4a1a-afb5-aaeb5b989a96_del
2022-02-23 18:21:02.476 7 INFO nova.virt.libvirt.driver [req-1633d7ca-77f9-42fc-9c9c-ef8e53df334f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Deletion of /var/lib/nova/instances/8af72143-7902-4a1a-afb5-aaeb5b989a96_del complete
2022-02-23 18:21:02.548 7 INFO nova.compute.manager [req-1633d7ca-77f9-42fc-9c9c-ef8e53df334f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:02.613 7 INFO nova.compute.manager [-] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:21:02.815 7 INFO nova.scheduler.client.report [req-1633d7ca-77f9-42fc-9c9c-ef8e53df334f 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Deleted allocations for instance 8af72143-7902-4a1a-afb5-aaeb5b989a96
2022-02-23 18:21:03.353 7 INFO nova.compute.manager [req-c8670ff4-2720-4e4a-b951-679798b778c3 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Terminating instance
2022-02-23 18:21:03.691 7 INFO nova.virt.libvirt.driver [-] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Instance destroyed successfully.
2022-02-23 18:21:03.707 7 INFO nova.virt.libvirt.driver [req-c8670ff4-2720-4e4a-b951-679798b778c3 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Deleting instance files /var/lib/nova/instances/02188fb4-3086-42cd-8b52-f87bfdd24da1_del
2022-02-23 18:21:03.708 7 INFO nova.virt.libvirt.driver [req-c8670ff4-2720-4e4a-b951-679798b778c3 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Deletion of /var/lib/nova/instances/02188fb4-3086-42cd-8b52-f87bfdd24da1_del complete
2022-02-23 18:21:03.777 7 INFO nova.compute.manager [req-c8670ff4-2720-4e4a-b951-679798b778c3 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:03.857 7 INFO nova.compute.manager [-] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] Took 0.08 seconds to deallocate network for instance.
2022-02-23 18:21:04.050 7 INFO nova.scheduler.client.report [req-c8670ff4-2720-4e4a-b951-679798b778c3 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Deleted allocations for instance 02188fb4-3086-42cd-8b52-f87bfdd24da1
2022-02-23 18:21:05.750 7 INFO nova.compute.manager [req-e862898e-3e8e-417e-b854-d5badd9ef65e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Terminating instance
2022-02-23 18:21:06.115 7 INFO nova.virt.libvirt.driver [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Instance destroyed successfully.
2022-02-23 18:21:06.135 7 INFO nova.virt.libvirt.driver [req-e862898e-3e8e-417e-b854-d5badd9ef65e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Deleting instance files /var/lib/nova/instances/ecf7f396-989e-4e10-96dd-46143e6b540e_del
2022-02-23 18:21:06.137 7 INFO nova.virt.libvirt.driver [req-e862898e-3e8e-417e-b854-d5badd9ef65e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Deletion of /var/lib/nova/instances/ecf7f396-989e-4e10-96dd-46143e6b540e_del complete
2022-02-23 18:21:06.204 7 INFO nova.compute.manager [req-e862898e-3e8e-417e-b854-d5badd9ef65e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:06.269 7 INFO nova.compute.manager [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:21:06.465 7 INFO nova.scheduler.client.report [req-e862898e-3e8e-417e-b854-d5badd9ef65e 977728908a6c406481af12a1bff8fa9a e6642cbcd391440591343025504d73bc - default default] Deleted allocations for instance ecf7f396-989e-4e10-96dd-46143e6b540e
2022-02-23 18:21:13.109 7 INFO nova.compute.claims [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Claim successful on node rack08-server63
2022-02-23 18:21:13.378 7 INFO nova.virt.libvirt.driver [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 18:21:13.471 7 INFO nova.virt.block_device [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Booting with volume 4188071b-e031-46a3-a421-495231ffc982 at /dev/vda
2022-02-23 18:21:13.591 7 WARNING os_brick.initiator.connectors.nvmeof [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:21:15.053 7 INFO nova.compute.manager [-] [instance: 13006581-6a51-455a-8d7f-273e3fff3c79] VM Stopped (Lifecycle Event)
2022-02-23 18:21:15.127 7 INFO nova.virt.libvirt.driver [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Creating image
2022-02-23 18:21:15.139 7 INFO os_brick.initiator.connectors.lightos [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: connect_volume called for volume 13265b12-6e73-4e12-a0b3-cf9c4bc89bd0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '13265b12-6e73-4e12-a0b3-cf9c4bc89bd0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:21:15.142 7 INFO os_brick.initiator.connectors.lightos [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 13265b12-6e73-4e12-a0b3-cf9c4bc89bd0
2022-02-23 18:21:15.973 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] VM Resumed (Lifecycle Event)
2022-02-23 18:21:15.980 7 INFO nova.virt.libvirt.driver [-] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Instance spawned successfully.
2022-02-23 18:21:15.981 7 INFO nova.compute.manager [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Took 0.86 seconds to spawn the instance on the hypervisor.
2022-02-23 18:21:16.028 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:21:16.028 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] VM Started (Lifecycle Event)
2022-02-23 18:21:16.077 7 INFO nova.compute.manager [req-f6e387fd-0942-42f9-a8a1-6e50e304635b 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Took 3.01 seconds to build instance.
2022-02-23 18:21:17.457 7 INFO nova.compute.manager [-] [instance: 8af72143-7902-4a1a-afb5-aaeb5b989a96] VM Stopped (Lifecycle Event)
2022-02-23 18:21:18.605 7 INFO nova.compute.manager [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Terminating instance
2022-02-23 18:21:18.689 7 INFO nova.compute.manager [-] [instance: 02188fb4-3086-42cd-8b52-f87bfdd24da1] VM Stopped (Lifecycle Event)
2022-02-23 18:21:18.943 7 INFO nova.virt.libvirt.driver [-] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Instance destroyed successfully.
2022-02-23 18:21:19.010 7 INFO os_brick.initiator.connectors.lightos [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 13265b12-6e73-4e12-a0b3-cf9c4bc89bd0
2022-02-23 18:21:19.021 7 INFO nova.virt.libvirt.driver [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Deleting instance files /var/lib/nova/instances/d48d47f3-4b31-425b-b258-ad7a4f4c5155_del
2022-02-23 18:21:19.022 7 INFO nova.virt.libvirt.driver [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Deletion of /var/lib/nova/instances/d48d47f3-4b31-425b-b258-ad7a4f4c5155_del complete
2022-02-23 18:21:19.087 7 INFO nova.compute.manager [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:19.153 7 INFO nova.compute.manager [-] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:21:20.389 7 INFO nova.compute.manager [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-23 18:21:20.581 7 INFO nova.scheduler.client.report [req-52a4b576-888d-426f-9b1a-b51a687831f3 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Deleted allocations for instance d48d47f3-4b31-425b-b258-ad7a4f4c5155
2022-02-23 18:21:21.113 7 INFO nova.compute.manager [-] [instance: ecf7f396-989e-4e10-96dd-46143e6b540e] VM Stopped (Lifecycle Event)
2022-02-23 18:21:23.528 7 INFO nova.compute.manager [req-d86c1b2f-e8ad-43f9-a694-5dfced85392a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Terminating instance
2022-02-23 18:21:23.881 7 INFO nova.virt.libvirt.driver [-] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Instance destroyed successfully.
2022-02-23 18:21:23.897 7 INFO nova.virt.libvirt.driver [req-d86c1b2f-e8ad-43f9-a694-5dfced85392a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Deleting instance files /var/lib/nova/instances/b6b8434c-7113-4b72-b42d-a06925666d81_del
2022-02-23 18:21:23.898 7 INFO nova.virt.libvirt.driver [req-d86c1b2f-e8ad-43f9-a694-5dfced85392a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Deletion of /var/lib/nova/instances/b6b8434c-7113-4b72-b42d-a06925666d81_del complete
2022-02-23 18:21:23.972 7 INFO nova.compute.manager [req-d86c1b2f-e8ad-43f9-a694-5dfced85392a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:24.038 7 INFO nova.compute.manager [-] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:21:24.225 7 INFO nova.scheduler.client.report [req-d86c1b2f-e8ad-43f9-a694-5dfced85392a 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Deleted allocations for instance b6b8434c-7113-4b72-b42d-a06925666d81
2022-02-23 18:21:24.787 7 INFO nova.compute.manager [req-7dd8bb23-eec1-4466-bb86-68ab8cd0ff5d 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Terminating instance
2022-02-23 18:21:25.125 7 INFO nova.virt.libvirt.driver [-] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Instance destroyed successfully.
2022-02-23 18:21:25.140 7 INFO nova.virt.libvirt.driver [req-7dd8bb23-eec1-4466-bb86-68ab8cd0ff5d 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Deleting instance files /var/lib/nova/instances/17d92220-84c8-4d1a-932d-962af293a013_del
2022-02-23 18:21:25.141 7 INFO nova.virt.libvirt.driver [req-7dd8bb23-eec1-4466-bb86-68ab8cd0ff5d 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Deletion of /var/lib/nova/instances/17d92220-84c8-4d1a-932d-962af293a013_del complete
2022-02-23 18:21:25.206 7 INFO nova.compute.manager [req-7dd8bb23-eec1-4466-bb86-68ab8cd0ff5d 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:25.275 7 INFO nova.compute.manager [-] [instance: 17d92220-84c8-4d1a-932d-962af293a013] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:21:25.477 7 INFO nova.scheduler.client.report [req-7dd8bb23-eec1-4466-bb86-68ab8cd0ff5d 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Deleted allocations for instance 17d92220-84c8-4d1a-932d-962af293a013
2022-02-23 18:21:26.021 7 INFO nova.compute.manager [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Terminating instance
2022-02-23 18:21:26.360 7 INFO nova.virt.libvirt.driver [-] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Instance destroyed successfully.
2022-02-23 18:21:26.428 7 INFO os_brick.initiator.connectors.lightos [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 1acc9c94-8318-4357-9116-204ad041333d
2022-02-23 18:21:26.440 7 INFO nova.virt.libvirt.driver [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Deleting instance files /var/lib/nova/instances/a5bfdd1d-a476-46f9-bb63-348d44cf94f2_del
2022-02-23 18:21:26.441 7 INFO nova.virt.libvirt.driver [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Deletion of /var/lib/nova/instances/a5bfdd1d-a476-46f9-bb63-348d44cf94f2_del complete
2022-02-23 18:21:26.513 7 INFO nova.compute.manager [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-23 18:21:26.589 7 INFO nova.compute.manager [-] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Took 0.08 seconds to deallocate network for instance.
2022-02-23 18:21:27.827 7 INFO nova.compute.manager [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-23 18:21:28.023 7 INFO nova.scheduler.client.report [req-04b18dd9-9815-43a4-8e69-24a5fcc4e6dd 224d20056a864e129c9df97d201d4639 519c2487f0d3498c919b1e879a9baba7 - default default] Deleted allocations for instance a5bfdd1d-a476-46f9-bb63-348d44cf94f2
2022-02-23 18:21:34.322 7 INFO nova.compute.manager [-] [instance: d48d47f3-4b31-425b-b258-ad7a4f4c5155] VM Stopped (Lifecycle Event)
2022-02-23 18:21:38.879 7 INFO nova.compute.manager [-] [instance: b6b8434c-7113-4b72-b42d-a06925666d81] VM Stopped (Lifecycle Event)
2022-02-23 18:21:40.122 7 INFO nova.compute.manager [-] [instance: 17d92220-84c8-4d1a-932d-962af293a013] VM Stopped (Lifecycle Event)
2022-02-23 18:21:41.359 7 INFO nova.compute.manager [-] [instance: a5bfdd1d-a476-46f9-bb63-348d44cf94f2] VM Stopped (Lifecycle Event)
2022-02-23 18:22:18.168 7 INFO nova.compute.claims [req-9c2ea56d-3fd1-492d-9714-15530968e61d 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Claim successful on node rack08-server63
2022-02-23 18:22:18.560 7 INFO nova.virt.libvirt.driver [req-9c2ea56d-3fd1-492d-9714-15530968e61d 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Creating image
2022-02-23 18:22:19.775 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] VM Resumed (Lifecycle Event)
2022-02-23 18:22:19.783 7 INFO nova.virt.libvirt.driver [-] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Instance spawned successfully.
2022-02-23 18:22:19.784 7 INFO nova.compute.manager [req-9c2ea56d-3fd1-492d-9714-15530968e61d 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-23 18:22:19.829 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:22:19.829 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] VM Started (Lifecycle Event)
2022-02-23 18:22:19.871 7 INFO nova.compute.manager [req-9c2ea56d-3fd1-492d-9714-15530968e61d 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Took 1.74 seconds to build instance.
2022-02-23 18:22:20.431 7 INFO nova.compute.manager [req-5d9f2a9f-d648-4775-b166-a5823a654cfc 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Terminating instance
2022-02-23 18:22:20.783 7 INFO nova.virt.libvirt.driver [-] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Instance destroyed successfully.
2022-02-23 18:22:20.798 7 INFO nova.virt.libvirt.driver [req-5d9f2a9f-d648-4775-b166-a5823a654cfc 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Deleting instance files /var/lib/nova/instances/9510fe79-d88c-41ad-9dfb-7347b899241a_del
2022-02-23 18:22:20.800 7 INFO nova.virt.libvirt.driver [req-5d9f2a9f-d648-4775-b166-a5823a654cfc 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Deletion of /var/lib/nova/instances/9510fe79-d88c-41ad-9dfb-7347b899241a_del complete
2022-02-23 18:22:20.864 7 INFO nova.compute.manager [req-5d9f2a9f-d648-4775-b166-a5823a654cfc 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 18:22:20.926 7 INFO nova.compute.manager [-] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:22:21.121 7 INFO nova.scheduler.client.report [req-5d9f2a9f-d648-4775-b166-a5823a654cfc 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] Deleted allocations for instance 9510fe79-d88c-41ad-9dfb-7347b899241a
2022-02-23 18:22:22.751 7 INFO nova.compute.claims [req-0ce29c52-a1e0-4dad-9c6e-225dea0ca020 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Claim successful on node rack08-server63
2022-02-23 18:22:23.166 7 INFO nova.virt.libvirt.driver [req-0ce29c52-a1e0-4dad-9c6e-225dea0ca020 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Creating image
2022-02-23 18:22:24.305 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] VM Resumed (Lifecycle Event)
2022-02-23 18:22:24.313 7 INFO nova.virt.libvirt.driver [-] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Instance spawned successfully.
2022-02-23 18:22:24.314 7 INFO nova.compute.manager [req-0ce29c52-a1e0-4dad-9c6e-225dea0ca020 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-23 18:22:24.360 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:22:24.360 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] VM Started (Lifecycle Event)
2022-02-23 18:22:24.397 7 INFO nova.compute.manager [req-0ce29c52-a1e0-4dad-9c6e-225dea0ca020 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Took 1.68 seconds to build instance.
2022-02-23 18:22:25.085 7 INFO nova.compute.manager [req-1b63a22a-e0ae-41c6-b39b-477f41830c83 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Terminating instance
2022-02-23 18:22:25.421 7 INFO nova.virt.libvirt.driver [-] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Instance destroyed successfully.
2022-02-23 18:22:25.436 7 INFO nova.virt.libvirt.driver [req-1b63a22a-e0ae-41c6-b39b-477f41830c83 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Deleting instance files /var/lib/nova/instances/6977ad43-6b10-43bf-b194-2a5690e2144c_del
2022-02-23 18:22:25.437 7 INFO nova.virt.libvirt.driver [req-1b63a22a-e0ae-41c6-b39b-477f41830c83 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Deletion of /var/lib/nova/instances/6977ad43-6b10-43bf-b194-2a5690e2144c_del complete
2022-02-23 18:22:25.506 7 INFO nova.compute.manager [req-1b63a22a-e0ae-41c6-b39b-477f41830c83 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:22:25.571 7 INFO nova.compute.manager [-] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] Took 0.06 seconds to deallocate network for instance.
2022-02-23 18:22:25.766 7 INFO nova.scheduler.client.report [req-1b63a22a-e0ae-41c6-b39b-477f41830c83 3c64caeaf8034b10856ae78bfdea3c8e 2c760e73e93d44849430771609a1ff5e - default default] Deleted allocations for instance 6977ad43-6b10-43bf-b194-2a5690e2144c
2022-02-23 18:22:35.781 7 INFO nova.compute.manager [-] [instance: 9510fe79-d88c-41ad-9dfb-7347b899241a] VM Stopped (Lifecycle Event)
2022-02-23 18:22:40.419 7 INFO nova.compute.manager [-] [instance: 6977ad43-6b10-43bf-b194-2a5690e2144c] VM Stopped (Lifecycle Event)
2022-02-23 18:23:02.720 7 INFO nova.compute.claims [req-863eafb8-066f-4ff0-a8a7-358d5d3740de f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Claim successful on node rack08-server63
2022-02-23 18:23:03.123 7 INFO nova.virt.libvirt.driver [req-863eafb8-066f-4ff0-a8a7-358d5d3740de f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Creating image
2022-02-23 18:23:04.337 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] VM Resumed (Lifecycle Event)
2022-02-23 18:23:04.345 7 INFO nova.virt.libvirt.driver [-] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Instance spawned successfully.
2022-02-23 18:23:04.346 7 INFO nova.compute.manager [req-863eafb8-066f-4ff0-a8a7-358d5d3740de f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-23 18:23:04.393 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:23:04.394 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] VM Started (Lifecycle Event)
2022-02-23 18:23:04.438 7 INFO nova.compute.manager [req-863eafb8-066f-4ff0-a8a7-358d5d3740de f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Took 1.76 seconds to build instance.
2022-02-23 18:23:09.276 7 INFO nova.compute.manager [req-24ea43df-25bc-43bb-8e1e-1c610fd9e9fd f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Terminating instance
2022-02-23 18:23:09.621 7 INFO nova.virt.libvirt.driver [-] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Instance destroyed successfully.
2022-02-23 18:23:09.635 7 INFO nova.virt.libvirt.driver [req-24ea43df-25bc-43bb-8e1e-1c610fd9e9fd f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Deleting instance files /var/lib/nova/instances/3cf608c8-8ad9-4191-99ad-488ef3d66269_del
2022-02-23 18:23:09.636 7 INFO nova.virt.libvirt.driver [req-24ea43df-25bc-43bb-8e1e-1c610fd9e9fd f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Deletion of /var/lib/nova/instances/3cf608c8-8ad9-4191-99ad-488ef3d66269_del complete
2022-02-23 18:23:09.706 7 INFO nova.compute.manager [req-24ea43df-25bc-43bb-8e1e-1c610fd9e9fd f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:23:09.776 7 INFO nova.compute.manager [-] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:23:09.980 7 INFO nova.scheduler.client.report [req-24ea43df-25bc-43bb-8e1e-1c610fd9e9fd f48e7d86dd0949dda1e3d669e0161096 131c9392339d4ac68304b3ba298ee7fa - default default] Deleted allocations for instance 3cf608c8-8ad9-4191-99ad-488ef3d66269
2022-02-23 18:23:24.619 7 INFO nova.compute.manager [-] [instance: 3cf608c8-8ad9-4191-99ad-488ef3d66269] VM Stopped (Lifecycle Event)
2022-02-23 18:23:33.447 7 INFO nova.compute.claims [req-5f4e5320-caf1-4193-9289-0714eed20f39 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Claim successful on node rack08-server63
2022-02-23 18:23:33.827 7 INFO nova.virt.libvirt.driver [req-5f4e5320-caf1-4193-9289-0714eed20f39 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Creating image
2022-02-23 18:23:35.067 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] VM Resumed (Lifecycle Event)
2022-02-23 18:23:35.074 7 INFO nova.virt.libvirt.driver [-] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Instance spawned successfully.
2022-02-23 18:23:35.075 7 INFO nova.compute.manager [req-5f4e5320-caf1-4193-9289-0714eed20f39 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-23 18:23:35.120 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:23:35.121 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] VM Started (Lifecycle Event)
2022-02-23 18:23:35.163 7 INFO nova.compute.manager [req-5f4e5320-caf1-4193-9289-0714eed20f39 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Took 2.17 seconds to build instance.
2022-02-23 18:23:35.380 7 INFO nova.compute.manager [req-1b58d6f4-74b0-4820-80b1-0a1f128bb0c8 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Terminating instance
2022-02-23 18:23:35.728 7 INFO nova.virt.libvirt.driver [-] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Instance destroyed successfully.
2022-02-23 18:23:35.744 7 INFO nova.virt.libvirt.driver [req-1b58d6f4-74b0-4820-80b1-0a1f128bb0c8 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Deleting instance files /var/lib/nova/instances/ef74f39f-cef3-4bb0-b9ca-03fd714c810f_del
2022-02-23 18:23:35.745 7 INFO nova.virt.libvirt.driver [req-1b58d6f4-74b0-4820-80b1-0a1f128bb0c8 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Deletion of /var/lib/nova/instances/ef74f39f-cef3-4bb0-b9ca-03fd714c810f_del complete
2022-02-23 18:23:35.809 7 INFO nova.compute.manager [req-1b58d6f4-74b0-4820-80b1-0a1f128bb0c8 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 18:23:35.881 7 INFO nova.compute.manager [-] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:23:36.085 7 INFO nova.scheduler.client.report [req-1b58d6f4-74b0-4820-80b1-0a1f128bb0c8 996bc47d42094c0d80071adf2c754e0f 945750a77b954f4a8f8f60f27ebbf23c - default default] Deleted allocations for instance ef74f39f-cef3-4bb0-b9ca-03fd714c810f
2022-02-23 18:23:47.103 7 INFO nova.compute.claims [req-5f08af31-96d2-49bd-9c69-0dca7bced992 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Claim successful on node rack08-server63
2022-02-23 18:23:47.500 7 INFO nova.virt.libvirt.driver [req-5f08af31-96d2-49bd-9c69-0dca7bced992 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Creating image
2022-02-23 18:23:48.642 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] VM Resumed (Lifecycle Event)
2022-02-23 18:23:48.649 7 INFO nova.virt.libvirt.driver [-] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Instance spawned successfully.
2022-02-23 18:23:48.650 7 INFO nova.compute.manager [req-5f08af31-96d2-49bd-9c69-0dca7bced992 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-23 18:23:48.699 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:23:48.699 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] VM Started (Lifecycle Event)
2022-02-23 18:23:48.734 7 INFO nova.compute.manager [req-5f08af31-96d2-49bd-9c69-0dca7bced992 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Took 1.67 seconds to build instance.
2022-02-23 18:23:50.726 7 INFO nova.compute.manager [-] [instance: ef74f39f-cef3-4bb0-b9ca-03fd714c810f] VM Stopped (Lifecycle Event)
2022-02-23 18:24:01.113 7 INFO nova.virt.libvirt.driver [req-b2ad6a77-bdfa-443f-9761-df986578ebd8 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Ignoring supplied device name: /dev/vdb
2022-02-23 18:24:01.285 7 INFO nova.compute.manager [req-b2ad6a77-bdfa-443f-9761-df986578ebd8 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Attaching volume f6ede936-b7f0-4cd4-b0be-9e842ed40099 to /dev/vdb
2022-02-23 18:24:01.385 7 WARNING os_brick.initiator.connectors.nvmeof [req-b2ad6a77-bdfa-443f-9761-df986578ebd8 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:24:02.759 7 INFO os_brick.initiator.connectors.lightos [req-b2ad6a77-bdfa-443f-9761-df986578ebd8 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: connect_volume called for volume 69656d2d-824c-45ec-b048-eeed03561e49, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '69656d2d-824c-45ec-b048-eeed03561e49', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:24:02.764 7 INFO os_brick.initiator.connectors.lightos [req-b2ad6a77-bdfa-443f-9761-df986578ebd8 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69656d2d-824c-45ec-b048-eeed03561e49
2022-02-23 18:24:03.615 7 INFO nova.compute.claims [req-65725883-081c-472e-be74-64f85b0da4fd 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Claim successful on node rack08-server63
2022-02-23 18:24:04.011 7 INFO nova.virt.libvirt.driver [req-65725883-081c-472e-be74-64f85b0da4fd 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Creating image
2022-02-23 18:24:05.154 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] VM Resumed (Lifecycle Event)
2022-02-23 18:24:05.162 7 INFO nova.virt.libvirt.driver [-] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Instance spawned successfully.
2022-02-23 18:24:05.163 7 INFO nova.compute.manager [req-65725883-081c-472e-be74-64f85b0da4fd 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-23 18:24:05.214 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:24:05.215 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] VM Started (Lifecycle Event)
2022-02-23 18:24:05.249 7 INFO nova.compute.manager [req-65725883-081c-472e-be74-64f85b0da4fd 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Took 1.67 seconds to build instance.
2022-02-23 18:24:05.585 7 INFO nova.virt.libvirt.driver [req-7ec1b868-980f-4c6f-bd07-45e94cbb9944 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Ignoring supplied device name: /dev/vdb
2022-02-23 18:24:05.743 7 INFO nova.compute.manager [req-7ec1b868-980f-4c6f-bd07-45e94cbb9944 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Attaching volume 1c4d24aa-cb17-47cc-8aa9-94aa8849cbd8 to /dev/vdb
2022-02-23 18:24:05.829 7 WARNING os_brick.initiator.connectors.nvmeof [req-7ec1b868-980f-4c6f-bd07-45e94cbb9944 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:24:07.204 7 INFO os_brick.initiator.connectors.lightos [req-7ec1b868-980f-4c6f-bd07-45e94cbb9944 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] LIGHTOS: connect_volume called for volume 9cfa8807-ea16-4356-bc43-c79ee5f261ae, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9cfa8807-ea16-4356-bc43-c79ee5f261ae', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:24:07.208 7 INFO os_brick.initiator.connectors.lightos [req-7ec1b868-980f-4c6f-bd07-45e94cbb9944 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 9cfa8807-ea16-4356-bc43-c79ee5f261ae
2022-02-23 18:24:08.951 7 INFO nova.compute.manager [req-e0a5b7b4-cda5-4ebe-89c7-4cec25049029 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Cinder extended volume 1c4d24aa-cb17-47cc-8aa9-94aa8849cbd8; extending it to detect new size
2022-02-23 18:24:09.027 7 INFO os_brick.initiator.connectors.lightos [req-e0a5b7b4-cda5-4ebe-89c7-4cec25049029 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 9cfa8807-ea16-4356-bc43-c79ee5f261ae
2022-02-23 18:24:09.672 7 INFO nova.compute.manager [req-0b040060-72ee-4218-a2cb-a757ad03a318 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Detaching volume 1c4d24aa-cb17-47cc-8aa9-94aa8849cbd8
2022-02-23 18:24:09.741 7 INFO nova.virt.block_device [req-0b040060-72ee-4218-a2cb-a757ad03a318 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Attempting to driver detach volume 1c4d24aa-cb17-47cc-8aa9-94aa8849cbd8 from mountpoint /dev/vdb
2022-02-23 18:24:09.760 7 INFO nova.virt.libvirt.driver [req-0b040060-72ee-4218-a2cb-a757ad03a318 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] Successfully detached device vdb from instance 4d4a886c-0761-4c1d-8a38-91509cf80450 from the persistent domain config.
2022-02-23 18:24:09.907 7 INFO nova.virt.libvirt.driver [req-0b040060-72ee-4218-a2cb-a757ad03a318 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] Successfully detached device vdb from instance 4d4a886c-0761-4c1d-8a38-91509cf80450 from the live domain config.
2022-02-23 18:24:09.909 7 INFO os_brick.initiator.connectors.lightos [req-0b040060-72ee-4218-a2cb-a757ad03a318 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 9cfa8807-ea16-4356-bc43-c79ee5f261ae
2022-02-23 18:24:11.924 7 INFO nova.compute.manager [req-3a81dd77-6bb1-4040-9e0d-0d4f0d012005 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Terminating instance
2022-02-23 18:24:12.260 7 INFO nova.virt.libvirt.driver [-] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Instance destroyed successfully.
2022-02-23 18:24:12.276 7 INFO nova.virt.libvirt.driver [req-3a81dd77-6bb1-4040-9e0d-0d4f0d012005 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Deleting instance files /var/lib/nova/instances/4d4a886c-0761-4c1d-8a38-91509cf80450_del
2022-02-23 18:24:12.277 7 INFO nova.virt.libvirt.driver [req-3a81dd77-6bb1-4040-9e0d-0d4f0d012005 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Deletion of /var/lib/nova/instances/4d4a886c-0761-4c1d-8a38-91509cf80450_del complete
2022-02-23 18:24:12.346 7 INFO nova.compute.manager [req-3a81dd77-6bb1-4040-9e0d-0d4f0d012005 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:24:12.414 7 INFO nova.compute.manager [-] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:24:12.602 7 INFO nova.scheduler.client.report [req-3a81dd77-6bb1-4040-9e0d-0d4f0d012005 97398829ea6642ceb40c06ca7c8b886a 3b1a29b176eb4ff0bbc974e3e2638c9e - default default] Deleted allocations for instance 4d4a886c-0761-4c1d-8a38-91509cf80450
2022-02-23 18:24:13.877 7 INFO nova.compute.manager [req-7580eb77-b243-435e-936b-85d127db60d6 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Detaching volume f6ede936-b7f0-4cd4-b0be-9e842ed40099
2022-02-23 18:24:13.937 7 INFO nova.virt.block_device [req-7580eb77-b243-435e-936b-85d127db60d6 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Attempting to driver detach volume f6ede936-b7f0-4cd4-b0be-9e842ed40099 from mountpoint /dev/vdb
2022-02-23 18:24:13.956 7 INFO nova.virt.libvirt.driver [req-7580eb77-b243-435e-936b-85d127db60d6 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Successfully detached device vdb from instance a6a8b2ce-d6a0-40cf-9084-058406513c34 from the persistent domain config.
2022-02-23 18:24:14.099 7 INFO nova.virt.libvirt.driver [req-7580eb77-b243-435e-936b-85d127db60d6 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Successfully detached device vdb from instance a6a8b2ce-d6a0-40cf-9084-058406513c34 from the live domain config.
2022-02-23 18:24:14.102 7 INFO os_brick.initiator.connectors.lightos [req-7580eb77-b243-435e-936b-85d127db60d6 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 69656d2d-824c-45ec-b048-eeed03561e49
2022-02-23 18:24:16.134 7 INFO nova.compute.manager [req-740d2094-1813-41c8-a4b9-9c1e8a97e1b9 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Terminating instance
2022-02-23 18:24:16.476 7 INFO nova.virt.libvirt.driver [-] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Instance destroyed successfully.
2022-02-23 18:24:16.490 7 INFO nova.virt.libvirt.driver [req-740d2094-1813-41c8-a4b9-9c1e8a97e1b9 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Deleting instance files /var/lib/nova/instances/a6a8b2ce-d6a0-40cf-9084-058406513c34_del
2022-02-23 18:24:16.491 7 INFO nova.virt.libvirt.driver [req-740d2094-1813-41c8-a4b9-9c1e8a97e1b9 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Deletion of /var/lib/nova/instances/a6a8b2ce-d6a0-40cf-9084-058406513c34_del complete
2022-02-23 18:24:16.560 7 INFO nova.compute.manager [req-740d2094-1813-41c8-a4b9-9c1e8a97e1b9 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:24:16.640 7 INFO nova.compute.manager [-] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] Took 0.08 seconds to deallocate network for instance.
2022-02-23 18:24:16.834 7 INFO nova.scheduler.client.report [req-740d2094-1813-41c8-a4b9-9c1e8a97e1b9 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Deleted allocations for instance a6a8b2ce-d6a0-40cf-9084-058406513c34
2022-02-23 18:24:24.563 7 INFO nova.compute.claims [req-0fd23ebb-c470-45a2-9a5f-b1b620758128 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Claim successful on node rack08-server63
2022-02-23 18:24:24.957 7 INFO nova.virt.libvirt.driver [req-0fd23ebb-c470-45a2-9a5f-b1b620758128 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Creating image
2022-02-23 18:24:26.133 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] VM Resumed (Lifecycle Event)
2022-02-23 18:24:26.140 7 INFO nova.virt.libvirt.driver [-] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Instance spawned successfully.
2022-02-23 18:24:26.141 7 INFO nova.compute.manager [req-0fd23ebb-c470-45a2-9a5f-b1b620758128 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-23 18:24:26.185 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 18:24:26.186 7 INFO nova.compute.manager [req-93b37d5b-74f9-4a7a-b11b-db5d87aa616d - - - - -] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] VM Started (Lifecycle Event)
2022-02-23 18:24:26.229 7 INFO nova.compute.manager [req-0fd23ebb-c470-45a2-9a5f-b1b620758128 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Took 1.71 seconds to build instance.
2022-02-23 18:24:27.080 7 INFO nova.virt.libvirt.driver [req-e8740e60-f28f-41de-a23a-17b80a12ac11 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Ignoring supplied device name: /dev/vdb
2022-02-23 18:24:27.258 7 INFO nova.compute.manager [-] [instance: 4d4a886c-0761-4c1d-8a38-91509cf80450] VM Stopped (Lifecycle Event)
2022-02-23 18:24:27.967 7 INFO nova.compute.manager [req-e8740e60-f28f-41de-a23a-17b80a12ac11 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Attaching volume 79653d84-13c6-44e4-80c0-54978f1e8536 to /dev/vdb
2022-02-23 18:24:28.059 7 WARNING os_brick.initiator.connectors.nvmeof [req-e8740e60-f28f-41de-a23a-17b80a12ac11 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 18:24:29.417 7 INFO os_brick.initiator.connectors.lightos [req-e8740e60-f28f-41de-a23a-17b80a12ac11 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: connect_volume called for volume 8163f9f3-71a3-4a2f-90c0-6f53bb27442c, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8163f9f3-71a3-4a2f-90c0-6f53bb27442c', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 18:24:29.421 7 INFO os_brick.initiator.connectors.lightos [req-e8740e60-f28f-41de-a23a-17b80a12ac11 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8163f9f3-71a3-4a2f-90c0-6f53bb27442c
2022-02-23 18:24:31.474 7 INFO nova.compute.manager [-] [instance: a6a8b2ce-d6a0-40cf-9084-058406513c34] VM Stopped (Lifecycle Event)
2022-02-23 18:24:38.290 7 INFO nova.compute.manager [req-f8febd27-344c-4b0e-83af-856358100e89 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Detaching volume 79653d84-13c6-44e4-80c0-54978f1e8536
2022-02-23 18:24:38.358 7 INFO nova.virt.block_device [req-f8febd27-344c-4b0e-83af-856358100e89 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Attempting to driver detach volume 79653d84-13c6-44e4-80c0-54978f1e8536 from mountpoint /dev/vdb
2022-02-23 18:24:38.378 7 INFO nova.virt.libvirt.driver [req-f8febd27-344c-4b0e-83af-856358100e89 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Successfully detached device vdb from instance 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0 from the persistent domain config.
2022-02-23 18:24:38.523 7 INFO nova.virt.libvirt.driver [req-f8febd27-344c-4b0e-83af-856358100e89 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Successfully detached device vdb from instance 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0 from the live domain config.
2022-02-23 18:24:38.526 7 INFO os_brick.initiator.connectors.lightos [req-f8febd27-344c-4b0e-83af-856358100e89 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8163f9f3-71a3-4a2f-90c0-6f53bb27442c
2022-02-23 18:24:40.551 7 INFO nova.compute.manager [req-ac843eb7-4c99-4765-b627-bc76d779c0f4 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Terminating instance
2022-02-23 18:24:40.894 7 INFO nova.virt.libvirt.driver [-] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Instance destroyed successfully.
2022-02-23 18:24:40.912 7 INFO nova.virt.libvirt.driver [req-ac843eb7-4c99-4765-b627-bc76d779c0f4 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Deleting instance files /var/lib/nova/instances/3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0_del
2022-02-23 18:24:40.913 7 INFO nova.virt.libvirt.driver [req-ac843eb7-4c99-4765-b627-bc76d779c0f4 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Deletion of /var/lib/nova/instances/3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0_del complete
2022-02-23 18:24:40.986 7 INFO nova.compute.manager [req-ac843eb7-4c99-4765-b627-bc76d779c0f4 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 18:24:41.053 7 INFO nova.compute.manager [-] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] Took 0.07 seconds to deallocate network for instance.
2022-02-23 18:24:41.233 7 INFO nova.scheduler.client.report [req-ac843eb7-4c99-4765-b627-bc76d779c0f4 ef15c7ad329b4317813b48e6793fb6ee c0972ad33be042d6b46af121248013ab - default default] Deleted allocations for instance 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0
2022-02-23 18:24:55.892 7 INFO nova.compute.manager [-] [instance: 3d2813f1-f6d7-41d0-9b91-2bbe7f18c6e0] VM Stopped (Lifecycle Event)
