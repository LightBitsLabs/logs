Build Started 21_02_2022_17_38_21
2022-02-21 19:40:29.116 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-21 19:40:33.105 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-21 19:40:34.055 7 INFO nova.virt.driver [req-ceda9419-1247-42c9-96ff-243c0af617d9 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-21 19:40:34.446 7 INFO nova.compute.provider_config [req-ceda9419-1247-42c9-96ff-243c0af617d9 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-21 19:40:34.466 7 WARNING oslo_config.cfg [req-ceda9419-1247-42c9-96ff-243c0af617d9 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-21 19:40:34.488 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-21 19:40:34.502 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-21 19:40:34.518 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-21 19:40:34.628 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-21 19:40:34.641 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-21 19:40:34.643 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-21 19:40:35.054 7 INFO nova.compute.manager [req-916c2f97-642e-4d96-87a0-17f392abedb4 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-21 19:40:36.852 7 INFO nova.virt.libvirt.host [req-916c2f97-642e-4d96-87a0-17f392abedb4 - - - - -] kernel doesn't support AMD SEV
2022-02-21 19:41:30.879 7 INFO nova.compute.claims [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Claim successful on node rack08-server63
2022-02-21 19:41:31.284 7 INFO nova.virt.libvirt.driver [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Creating image
2022-02-21 19:41:31.288 7 INFO oslo.privsep.daemon [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpftpqs2zs/privsep.sock']
2022-02-21 19:41:32.913 7 INFO oslo.privsep.daemon [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Spawned new privsep daemon via rootwrap
2022-02-21 19:41:32.762 79 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 19:41:32.768 79 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 19:41:32.773 79 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-21 19:41:32.773 79 INFO oslo.privsep.daemon [-] privsep daemon running as pid 79
2022-02-21 19:41:34.162 7 INFO nova.compute.manager [-] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] VM Resumed (Lifecycle Event)
2022-02-21 19:41:34.171 7 INFO nova.virt.libvirt.driver [-] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Instance spawned successfully.
2022-02-21 19:41:34.172 7 INFO nova.compute.manager [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Took 2.89 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:34.235 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:34.236 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] VM Started (Lifecycle Event)
2022-02-21 19:41:34.273 7 INFO nova.compute.manager [req-e3654453-7d4e-4896-bbdd-a0666f964ff9 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Took 3.44 seconds to build instance.
2022-02-21 19:41:37.418 7 INFO nova.compute.manager [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Attaching volume 60318cf5-5546-4b54-af12-31e1f6bc4bee to /dev/vdb
2022-02-21 19:41:37.498 7 INFO oslo.privsep.daemon [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpyaq41srx/privsep.sock']
2022-02-21 19:41:38.160 7 INFO oslo.privsep.daemon [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Spawned new privsep daemon via rootwrap
2022-02-21 19:41:38.084 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-21 19:41:38.091 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-21 19:41:38.096 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-21 19:41:38.097 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-21 19:41:38.485 7 WARNING os_brick.initiator.connectors.nvmeof [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:41:39.894 7 INFO os_brick.initiator.connectors.lightos [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume 6110d734-9cda-47fb-9454-75bb00f595d4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6110d734-9cda-47fb-9454-75bb00f595d4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:41:39.930 7 INFO os_brick.initiator.connectors.lightos [req-2e5b8833-89d3-42b6-861e-c459b65710c1 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6110d734-9cda-47fb-9454-75bb00f595d4
2022-02-21 19:41:42.025 7 INFO nova.compute.claims [req-0b76f41e-fc45-43dd-9a5e-d0db13eb458d 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Claim successful on node rack08-server63
2022-02-21 19:41:42.421 7 INFO nova.virt.libvirt.driver [req-0b76f41e-fc45-43dd-9a5e-d0db13eb458d 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Creating image
2022-02-21 19:41:43.442 7 INFO nova.compute.claims [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Claim successful on node rack08-server63
2022-02-21 19:41:43.607 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] VM Resumed (Lifecycle Event)
2022-02-21 19:41:43.613 7 INFO nova.virt.libvirt.driver [-] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Instance spawned successfully.
2022-02-21 19:41:43.613 7 INFO nova.compute.manager [req-0b76f41e-fc45-43dd-9a5e-d0db13eb458d 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:43.659 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:43.660 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] VM Started (Lifecycle Event)
2022-02-21 19:41:43.698 7 INFO nova.compute.manager [req-0b76f41e-fc45-43dd-9a5e-d0db13eb458d 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Took 1.72 seconds to build instance.
2022-02-21 19:41:43.730 7 INFO nova.virt.libvirt.driver [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 19:41:43.810 7 INFO nova.virt.block_device [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Booting with volume 2b83ae1d-103e-4b54-b952-f24cb3ddf059 at /dev/vda
2022-02-21 19:41:43.900 7 WARNING os_brick.initiator.connectors.nvmeof [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:41:44.226 7 INFO nova.compute.manager [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Detaching volume 60318cf5-5546-4b54-af12-31e1f6bc4bee
2022-02-21 19:41:44.281 7 INFO nova.virt.block_device [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Attempting to driver detach volume 60318cf5-5546-4b54-af12-31e1f6bc4bee from mountpoint /dev/vdb
2022-02-21 19:41:44.300 7 INFO nova.virt.libvirt.driver [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance 26898748-c0e9-428d-bcaf-0c9518bb0cb0 from the persistent domain config.
2022-02-21 19:41:44.444 7 INFO nova.virt.libvirt.driver [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance 26898748-c0e9-428d-bcaf-0c9518bb0cb0 from the live domain config.
2022-02-21 19:41:44.447 7 INFO os_brick.initiator.connectors.lightos [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume 6110d734-9cda-47fb-9454-75bb00f595d4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6110d734-9cda-47fb-9454-75bb00f595d4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:41:44.448 7 INFO os_brick.initiator.connectors.lightos [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6110d734-9cda-47fb-9454-75bb00f595d4
2022-02-21 19:41:44.448 7 INFO os_brick.initiator.connectors.lightos [req-67b0868b-9b64-49b9-bb35-db2d99e91b37 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6110d734-9cda-47fb-9454-75bb00f595d4
2022-02-21 19:41:45.407 7 INFO nova.virt.libvirt.driver [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Creating image
2022-02-21 19:41:45.416 7 INFO os_brick.initiator.connectors.lightos [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume c26b065f-3523-4171-a076-a740d5456f49, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c26b065f-3523-4171-a076-a740d5456f49', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:41:45.419 7 INFO os_brick.initiator.connectors.lightos [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid c26b065f-3523-4171-a076-a740d5456f49
2022-02-21 19:41:46.375 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] VM Resumed (Lifecycle Event)
2022-02-21 19:41:46.383 7 INFO nova.virt.libvirt.driver [-] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Instance spawned successfully.
2022-02-21 19:41:46.383 7 INFO nova.compute.manager [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Took 0.98 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:46.432 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:46.433 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] VM Started (Lifecycle Event)
2022-02-21 19:41:46.474 7 INFO nova.compute.manager [req-aea09cb2-021d-469f-b263-813b6e7dba08 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Took 3.07 seconds to build instance.
2022-02-21 19:41:48.246 7 INFO nova.compute.claims [req-15c88d59-b43e-4c37-bf73-94ddcfd92310 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Claim successful on node rack08-server63
2022-02-21 19:41:48.622 7 INFO nova.virt.libvirt.driver [req-15c88d59-b43e-4c37-bf73-94ddcfd92310 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Creating image
2022-02-21 19:41:48.776 7 INFO nova.compute.claims [req-e589f95e-2ee2-4461-82aa-f52e4897fe6d d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Claim successful on node rack08-server63
2022-02-21 19:41:49.185 7 INFO nova.virt.libvirt.driver [req-e589f95e-2ee2-4461-82aa-f52e4897fe6d d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Creating image
2022-02-21 19:41:49.268 7 INFO nova.compute.claims [req-2b6f1bd1-66dd-4033-8018-e3443928ae83 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Claim successful on node rack08-server63
2022-02-21 19:41:49.679 7 INFO nova.virt.libvirt.driver [req-2b6f1bd1-66dd-4033-8018-e3443928ae83 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Creating image
2022-02-21 19:41:49.833 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] VM Resumed (Lifecycle Event)
2022-02-21 19:41:49.870 7 INFO nova.virt.libvirt.driver [-] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Instance spawned successfully.
2022-02-21 19:41:49.872 7 INFO nova.compute.manager [req-15c88d59-b43e-4c37-bf73-94ddcfd92310 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:49.908 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:49.909 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] VM Started (Lifecycle Event)
2022-02-21 19:41:49.977 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:49.994 7 INFO nova.compute.manager [req-15c88d59-b43e-4c37-bf73-94ddcfd92310 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Took 1.78 seconds to build instance.
2022-02-21 19:41:50.379 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] VM Resumed (Lifecycle Event)
2022-02-21 19:41:50.386 7 INFO nova.virt.libvirt.driver [-] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Instance spawned successfully.
2022-02-21 19:41:50.387 7 INFO nova.compute.manager [req-e589f95e-2ee2-4461-82aa-f52e4897fe6d d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:50.436 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:50.437 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] VM Started (Lifecycle Event)
2022-02-21 19:41:50.471 7 INFO nova.compute.manager [req-e589f95e-2ee2-4461-82aa-f52e4897fe6d d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Took 1.73 seconds to build instance.
2022-02-21 19:41:50.882 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] VM Resumed (Lifecycle Event)
2022-02-21 19:41:50.889 7 INFO nova.virt.libvirt.driver [-] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Instance spawned successfully.
2022-02-21 19:41:50.890 7 INFO nova.compute.manager [req-2b6f1bd1-66dd-4033-8018-e3443928ae83 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-21 19:41:50.934 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:41:50.935 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] VM Started (Lifecycle Event)
2022-02-21 19:41:50.973 7 INFO nova.compute.manager [req-2b6f1bd1-66dd-4033-8018-e3443928ae83 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Took 1.75 seconds to build instance.
2022-02-21 19:41:53.245 7 INFO nova.compute.manager [req-ee9f18e3-8f99-4b60-8b2f-49e7187c074c 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Attaching volume 7b827de6-90d2-4f9c-9cfa-1f0cc65de6eb to /dev/vdb
2022-02-21 19:41:53.338 7 WARNING os_brick.initiator.connectors.nvmeof [req-ee9f18e3-8f99-4b60-8b2f-49e7187c074c 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:41:53.984 7 INFO nova.compute.manager [req-b8eb0f09-e6ae-4596-90e3-462e118b729f d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Attaching volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 to /dev/vdb
2022-02-21 19:41:54.074 7 WARNING os_brick.initiator.connectors.nvmeof [req-b8eb0f09-e6ae-4596-90e3-462e118b729f d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:41:54.691 7 INFO os_brick.initiator.connectors.lightos [req-ee9f18e3-8f99-4b60-8b2f-49e7187c074c 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume c76e1f0d-7372-433e-b516-9cc9fe940bb7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c76e1f0d-7372-433e-b516-9cc9fe940bb7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:41:54.695 7 INFO os_brick.initiator.connectors.lightos [req-ee9f18e3-8f99-4b60-8b2f-49e7187c074c 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c76e1f0d-7372-433e-b516-9cc9fe940bb7
2022-02-21 19:41:55.408 7 INFO os_brick.initiator.connectors.lightos [req-b8eb0f09-e6ae-4596-90e3-462e118b729f d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a65c0f7-90a5-4cad-9c1c-638803c3fe6f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:41:55.411 7 INFO os_brick.initiator.connectors.lightos [req-b8eb0f09-e6ae-4596-90e3-462e118b729f d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f
2022-02-21 19:41:55.838 7 INFO nova.compute.manager [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Detaching volume 7b827de6-90d2-4f9c-9cfa-1f0cc65de6eb
2022-02-21 19:41:55.899 7 INFO nova.virt.block_device [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Attempting to driver detach volume 7b827de6-90d2-4f9c-9cfa-1f0cc65de6eb from mountpoint /dev/vdb
2022-02-21 19:41:55.917 7 INFO nova.virt.libvirt.driver [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance cf59371d-fa6d-4ecc-9a88-35157d86ba9f from the persistent domain config.
2022-02-21 19:41:56.062 7 INFO nova.virt.libvirt.driver [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance cf59371d-fa6d-4ecc-9a88-35157d86ba9f from the live domain config.
2022-02-21 19:41:56.065 7 INFO os_brick.initiator.connectors.lightos [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume c76e1f0d-7372-433e-b516-9cc9fe940bb7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c76e1f0d-7372-433e-b516-9cc9fe940bb7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:41:56.066 7 INFO os_brick.initiator.connectors.lightos [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c76e1f0d-7372-433e-b516-9cc9fe940bb7
2022-02-21 19:41:56.067 7 INFO os_brick.initiator.connectors.lightos [req-e1b796c9-8d67-4a46-9c26-2a7fff18099a 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c76e1f0d-7372-433e-b516-9cc9fe940bb7
2022-02-21 19:41:56.483 7 INFO nova.compute.manager [req-3c4d1dd1-1607-4528-a4cf-ca096c35b02b d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Attaching volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 to /dev/vdb
2022-02-21 19:41:56.572 7 WARNING os_brick.initiator.connectors.nvmeof [req-3c4d1dd1-1607-4528-a4cf-ca096c35b02b d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:41:57.937 7 INFO os_brick.initiator.connectors.lightos [req-3c4d1dd1-1607-4528-a4cf-ca096c35b02b d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a65c0f7-90a5-4cad-9c1c-638803c3fe6f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:41:57.938 7 INFO os_brick.initiator.connectors.lightos [req-3c4d1dd1-1607-4528-a4cf-ca096c35b02b d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f
2022-02-21 19:41:59.052 7 INFO nova.compute.manager [req-3e0d9f1e-dd21-4208-8504-b93e3b2cdb43 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Detaching volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495
2022-02-21 19:41:59.114 7 INFO nova.virt.block_device [req-3e0d9f1e-dd21-4208-8504-b93e3b2cdb43 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Attempting to driver detach volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 from mountpoint /dev/vdb
2022-02-21 19:41:59.139 7 INFO nova.virt.libvirt.driver [req-3e0d9f1e-dd21-4208-8504-b93e3b2cdb43 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Successfully detached device vdb from instance 4837f36f-4c3e-444c-9700-dd377f4fb458 from the persistent domain config.
2022-02-21 19:41:59.241 7 INFO nova.compute.claims [req-11413311-4233-4e84-bc4d-7b1e0e68b42e 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Claim successful on node rack08-server63
2022-02-21 19:41:59.288 7 INFO nova.virt.libvirt.driver [req-3e0d9f1e-dd21-4208-8504-b93e3b2cdb43 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Successfully detached device vdb from instance 4837f36f-4c3e-444c-9700-dd377f4fb458 from the live domain config.
2022-02-21 19:41:59.359 7 INFO nova.virt.libvirt.driver [req-3e0d9f1e-dd21-4208-8504-b93e3b2cdb43 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Detected multiple connections on this host for volume: 778f7d0d-e7a8-4dde-b0cb-b7a57c364495, skipping target disconnect.
2022-02-21 19:41:59.648 7 INFO nova.virt.libvirt.driver [req-11413311-4233-4e84-bc4d-7b1e0e68b42e 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Creating image
2022-02-21 19:42:00.798 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] VM Resumed (Lifecycle Event)
2022-02-21 19:42:00.806 7 INFO nova.virt.libvirt.driver [-] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Instance spawned successfully.
2022-02-21 19:42:00.807 7 INFO nova.compute.manager [req-11413311-4233-4e84-bc4d-7b1e0e68b42e 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 19:42:00.853 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:42:00.854 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] VM Started (Lifecycle Event)
2022-02-21 19:42:00.894 7 INFO nova.compute.manager [req-11413311-4233-4e84-bc4d-7b1e0e68b42e 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Took 1.70 seconds to build instance.
2022-02-21 19:42:01.524 7 INFO nova.compute.manager [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Detaching volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495
2022-02-21 19:42:01.585 7 INFO nova.virt.block_device [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Attempting to driver detach volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 from mountpoint /dev/vdb
2022-02-21 19:42:01.603 7 INFO nova.virt.libvirt.driver [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Successfully detached device vdb from instance 3b8e1131-8bd7-4941-849d-710198d41c35 from the persistent domain config.
2022-02-21 19:42:01.774 7 INFO nova.virt.libvirt.driver [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Successfully detached device vdb from instance 3b8e1131-8bd7-4941-849d-710198d41c35 from the live domain config.
2022-02-21 19:42:01.827 7 INFO os_brick.initiator.connectors.lightos [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a65c0f7-90a5-4cad-9c1c-638803c3fe6f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 19:42:03.831 7 INFO nova.compute.manager [req-73d8310e-78f5-4d30-ac03-56f00af573d7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Attaching volume 639f8ce7-6dae-47d3-8f2e-e4cdc4acc942 to /dev/vdb
2022-02-21 19:42:03.919 7 WARNING os_brick.initiator.connectors.nvmeof [req-73d8310e-78f5-4d30-ac03-56f00af573d7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Failed to detach volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Traceback (most recent call last):
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     return f(*args, **kwargs)
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     return f(*args, **kwargs)
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     raise exception.BrickException(message=msg)
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:43:02.657 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] 
2022-02-21 19:43:02.669 7 INFO os_brick.initiator.connectors.lightos [req-73d8310e-78f5-4d30-ac03-56f00af573d7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume 19fbe6ed-c9c5-4e51-b70b-9aed6966ea35, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '19fbe6ed-c9c5-4e51-b70b-9aed6966ea35', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:43:02.672 7 INFO os_brick.initiator.connectors.lightos [req-73d8310e-78f5-4d30-ac03-56f00af573d7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 19fbe6ed-c9c5-4e51-b70b-9aed6966ea35
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server [req-a284834e-2a78-4296-a669-9b7b9bd6eb45 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:43:02.762 7 ERROR oslo_messaging.rpc.server 
2022-02-21 19:43:03.507 7 INFO nova.compute.manager [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Detaching volume 639f8ce7-6dae-47d3-8f2e-e4cdc4acc942
2022-02-21 19:43:03.566 7 INFO nova.virt.block_device [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Attempting to driver detach volume 639f8ce7-6dae-47d3-8f2e-e4cdc4acc942 from mountpoint /dev/vdb
2022-02-21 19:43:03.585 7 INFO nova.virt.libvirt.driver [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance e8264049-36b5-4cc2-8294-c30958c73f35 from the persistent domain config.
2022-02-21 19:43:03.726 7 INFO nova.virt.libvirt.driver [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Successfully detached device vdb from instance e8264049-36b5-4cc2-8294-c30958c73f35 from the live domain config.
2022-02-21 19:43:03.729 7 INFO os_brick.initiator.connectors.lightos [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: connect_volume called for volume 19fbe6ed-c9c5-4e51-b70b-9aed6966ea35, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '19fbe6ed-c9c5-4e51-b70b-9aed6966ea35', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:43:03.730 7 INFO os_brick.initiator.connectors.lightos [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 19fbe6ed-c9c5-4e51-b70b-9aed6966ea35
2022-02-21 19:43:03.731 7 INFO os_brick.initiator.connectors.lightos [req-6012aa22-57d8-4785-85b4-682f85fabd35 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 19fbe6ed-c9c5-4e51-b70b-9aed6966ea35
2022-02-21 19:43:06.977 7 INFO nova.compute.manager [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Terminating instance
2022-02-21 19:43:07.329 7 INFO nova.virt.libvirt.driver [-] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Instance destroyed successfully.
2022-02-21 19:43:07.345 7 INFO nova.virt.libvirt.driver [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Deleting instance files /var/lib/nova/instances/e8264049-36b5-4cc2-8294-c30958c73f35_del
2022-02-21 19:43:07.347 7 INFO nova.virt.libvirt.driver [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Deletion of /var/lib/nova/instances/e8264049-36b5-4cc2-8294-c30958c73f35_del complete
2022-02-21 19:43:07.408 7 INFO nova.virt.libvirt.host [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] UEFI support detected
2022-02-21 19:43:07.410 7 INFO nova.compute.manager [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 19:43:07.486 7 INFO nova.compute.manager [-] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:43:07.686 7 INFO nova.scheduler.client.report [req-74c71e6c-1b6f-4e53-9301-9747498140f7 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Deleted allocations for instance e8264049-36b5-4cc2-8294-c30958c73f35
2022-02-21 19:43:09.360 7 INFO nova.compute.manager [req-1b2ea1b8-413e-429c-9bc1-bbe56d861407 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Terminating instance
2022-02-21 19:43:09.705 7 INFO nova.virt.libvirt.driver [-] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Instance destroyed successfully.
2022-02-21 19:43:09.720 7 INFO nova.virt.libvirt.driver [req-1b2ea1b8-413e-429c-9bc1-bbe56d861407 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Deleting instance files /var/lib/nova/instances/cf59371d-fa6d-4ecc-9a88-35157d86ba9f_del
2022-02-21 19:43:09.722 7 INFO nova.virt.libvirt.driver [req-1b2ea1b8-413e-429c-9bc1-bbe56d861407 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Deletion of /var/lib/nova/instances/cf59371d-fa6d-4ecc-9a88-35157d86ba9f_del complete
2022-02-21 19:43:09.790 7 INFO nova.compute.manager [req-1b2ea1b8-413e-429c-9bc1-bbe56d861407 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:43:09.861 7 INFO nova.compute.manager [-] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:43:10.060 7 INFO nova.scheduler.client.report [req-1b2ea1b8-413e-429c-9bc1-bbe56d861407 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Deleted allocations for instance cf59371d-fa6d-4ecc-9a88-35157d86ba9f
2022-02-21 19:43:10.594 7 INFO nova.compute.manager [req-ba37b620-424b-4f34-be89-11dd390dcfbc 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Terminating instance
2022-02-21 19:43:10.952 7 INFO nova.virt.libvirt.driver [-] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Instance destroyed successfully.
2022-02-21 19:43:10.969 7 INFO nova.virt.libvirt.driver [req-ba37b620-424b-4f34-be89-11dd390dcfbc 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Deleting instance files /var/lib/nova/instances/ffe23a50-3c9c-48b9-8b05-11b3ea99bf24_del
2022-02-21 19:43:10.970 7 INFO nova.virt.libvirt.driver [req-ba37b620-424b-4f34-be89-11dd390dcfbc 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Deletion of /var/lib/nova/instances/ffe23a50-3c9c-48b9-8b05-11b3ea99bf24_del complete
2022-02-21 19:43:11.037 7 INFO nova.compute.manager [req-ba37b620-424b-4f34-be89-11dd390dcfbc 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:43:11.104 7 INFO nova.compute.manager [-] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:43:11.302 7 INFO nova.scheduler.client.report [req-ba37b620-424b-4f34-be89-11dd390dcfbc 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Deleted allocations for instance ffe23a50-3c9c-48b9-8b05-11b3ea99bf24
2022-02-21 19:43:12.995 7 INFO nova.compute.manager [req-c18e5b6c-9903-4d38-bb9f-e8d6c3c6b3bb 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Terminating instance
2022-02-21 19:43:13.348 7 INFO nova.virt.libvirt.driver [-] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Instance destroyed successfully.
2022-02-21 19:43:13.366 7 INFO nova.virt.libvirt.driver [req-c18e5b6c-9903-4d38-bb9f-e8d6c3c6b3bb 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Deleting instance files /var/lib/nova/instances/26898748-c0e9-428d-bcaf-0c9518bb0cb0_del
2022-02-21 19:43:13.368 7 INFO nova.virt.libvirt.driver [req-c18e5b6c-9903-4d38-bb9f-e8d6c3c6b3bb 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Deletion of /var/lib/nova/instances/26898748-c0e9-428d-bcaf-0c9518bb0cb0_del complete
2022-02-21 19:43:13.438 7 INFO nova.compute.manager [req-c18e5b6c-9903-4d38-bb9f-e8d6c3c6b3bb 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:43:13.508 7 INFO nova.compute.manager [-] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:43:13.712 7 INFO nova.scheduler.client.report [req-c18e5b6c-9903-4d38-bb9f-e8d6c3c6b3bb 5c3eced1147547c6b6f4594bd587cc0a c52592a4b40f4cac9f21fb2c58dfb05f - default default] Deleted allocations for instance 26898748-c0e9-428d-bcaf-0c9518bb0cb0
2022-02-21 19:43:22.326 7 INFO nova.compute.manager [-] [instance: e8264049-36b5-4cc2-8294-c30958c73f35] VM Stopped (Lifecycle Event)
2022-02-21 19:43:24.702 7 INFO nova.compute.manager [-] [instance: cf59371d-fa6d-4ecc-9a88-35157d86ba9f] VM Stopped (Lifecycle Event)
2022-02-21 19:43:25.950 7 INFO nova.compute.manager [-] [instance: ffe23a50-3c9c-48b9-8b05-11b3ea99bf24] VM Stopped (Lifecycle Event)
2022-02-21 19:43:28.346 7 INFO nova.compute.manager [-] [instance: 26898748-c0e9-428d-bcaf-0c9518bb0cb0] VM Stopped (Lifecycle Event)
2022-02-21 19:43:38.728 7 INFO nova.compute.claims [req-a8e0fadd-bbe5-4b12-8f01-a8e547c2bf0f 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Claim successful on node rack08-server63
2022-02-21 19:43:39.164 7 INFO nova.virt.libvirt.driver [req-a8e0fadd-bbe5-4b12-8f01-a8e547c2bf0f 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Creating image
2022-02-21 19:43:40.574 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] VM Resumed (Lifecycle Event)
2022-02-21 19:43:40.586 7 INFO nova.virt.libvirt.driver [-] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Instance spawned successfully.
2022-02-21 19:43:40.587 7 INFO nova.compute.manager [req-a8e0fadd-bbe5-4b12-8f01-a8e547c2bf0f 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Took 1.42 seconds to spawn the instance on the hypervisor.
2022-02-21 19:43:40.624 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:43:40.625 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] VM Started (Lifecycle Event)
2022-02-21 19:43:40.675 7 INFO nova.compute.manager [req-a8e0fadd-bbe5-4b12-8f01-a8e547c2bf0f 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Took 1.99 seconds to build instance.
2022-02-21 19:43:46.265 7 INFO nova.compute.manager [req-b0f00a2b-4738-4c3f-ab78-b3e78eeaeb84 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Terminating instance
2022-02-21 19:43:46.604 7 INFO nova.virt.libvirt.driver [-] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Instance destroyed successfully.
2022-02-21 19:43:46.619 7 INFO nova.virt.libvirt.driver [req-b0f00a2b-4738-4c3f-ab78-b3e78eeaeb84 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Deleting instance files /var/lib/nova/instances/f0062f0e-5021-496e-bdea-da2c587eeffe_del
2022-02-21 19:43:46.620 7 INFO nova.virt.libvirt.driver [req-b0f00a2b-4738-4c3f-ab78-b3e78eeaeb84 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Deletion of /var/lib/nova/instances/f0062f0e-5021-496e-bdea-da2c587eeffe_del complete
2022-02-21 19:43:46.689 7 INFO nova.compute.manager [req-b0f00a2b-4738-4c3f-ab78-b3e78eeaeb84 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:43:46.758 7 INFO nova.compute.manager [-] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:43:46.961 7 INFO nova.scheduler.client.report [req-b0f00a2b-4738-4c3f-ab78-b3e78eeaeb84 12ea7fd6aeb5441e950798b4b0039dc7 2d84cee598fb4b2a8fa57af4973acf24 - default default] Deleted allocations for instance f0062f0e-5021-496e-bdea-da2c587eeffe
2022-02-21 19:44:01.602 7 INFO nova.compute.manager [-] [instance: f0062f0e-5021-496e-bdea-da2c587eeffe] VM Stopped (Lifecycle Event)
2022-02-21 19:46:37.525 7 INFO nova.compute.claims [req-a8f67ce9-0ae9-41d6-bea4-c27629d4dd3f 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Claim successful on node rack08-server63
2022-02-21 19:46:37.922 7 INFO nova.virt.libvirt.driver [req-a8f67ce9-0ae9-41d6-bea4-c27629d4dd3f 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Creating image
2022-02-21 19:46:39.103 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] VM Resumed (Lifecycle Event)
2022-02-21 19:46:39.110 7 INFO nova.virt.libvirt.driver [-] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Instance spawned successfully.
2022-02-21 19:46:39.111 7 INFO nova.compute.manager [req-a8f67ce9-0ae9-41d6-bea4-c27629d4dd3f 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-21 19:46:39.160 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:46:39.160 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] VM Started (Lifecycle Event)
2022-02-21 19:46:39.199 7 INFO nova.compute.manager [req-a8f67ce9-0ae9-41d6-bea4-c27629d4dd3f 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Took 1.71 seconds to build instance.
2022-02-21 19:46:40.076 7 INFO nova.compute.manager [req-ce4a59de-1c70-48cb-a89f-9719ac20cc33 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Terminating instance
2022-02-21 19:46:40.542 7 INFO nova.virt.libvirt.driver [-] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Instance destroyed successfully.
2022-02-21 19:46:40.561 7 INFO nova.virt.libvirt.driver [req-ce4a59de-1c70-48cb-a89f-9719ac20cc33 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Deleting instance files /var/lib/nova/instances/af0dd25d-50d3-4315-b847-48d226e7ff03_del
2022-02-21 19:46:40.563 7 INFO nova.virt.libvirt.driver [req-ce4a59de-1c70-48cb-a89f-9719ac20cc33 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Deletion of /var/lib/nova/instances/af0dd25d-50d3-4315-b847-48d226e7ff03_del complete
2022-02-21 19:46:40.635 7 INFO nova.compute.manager [req-ce4a59de-1c70-48cb-a89f-9719ac20cc33 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-21 19:46:40.706 7 INFO nova.compute.manager [-] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:46:40.898 7 INFO nova.scheduler.client.report [req-ce4a59de-1c70-48cb-a89f-9719ac20cc33 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] Deleted allocations for instance af0dd25d-50d3-4315-b847-48d226e7ff03
2022-02-21 19:46:42.422 7 INFO nova.compute.claims [req-edb1048c-a4a8-4db1-94f2-be47d148b92e 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Claim successful on node rack08-server63
2022-02-21 19:46:42.789 7 INFO nova.virt.libvirt.driver [req-edb1048c-a4a8-4db1-94f2-be47d148b92e 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Creating image
2022-02-21 19:46:43.979 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: be364184-c876-4673-a050-232d7504a77a] VM Resumed (Lifecycle Event)
2022-02-21 19:46:43.986 7 INFO nova.virt.libvirt.driver [-] [instance: be364184-c876-4673-a050-232d7504a77a] Instance spawned successfully.
2022-02-21 19:46:43.986 7 INFO nova.compute.manager [req-edb1048c-a4a8-4db1-94f2-be47d148b92e 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-21 19:46:44.031 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: be364184-c876-4673-a050-232d7504a77a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:46:44.031 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: be364184-c876-4673-a050-232d7504a77a] VM Started (Lifecycle Event)
2022-02-21 19:46:44.071 7 INFO nova.compute.manager [req-edb1048c-a4a8-4db1-94f2-be47d148b92e 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Took 1.72 seconds to build instance.
2022-02-21 19:46:45.065 7 INFO nova.compute.manager [req-d8890b32-90d9-481b-bfd1-681c95f8d3d1 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Terminating instance
2022-02-21 19:46:45.409 7 INFO nova.virt.libvirt.driver [-] [instance: be364184-c876-4673-a050-232d7504a77a] Instance destroyed successfully.
2022-02-21 19:46:45.426 7 INFO nova.virt.libvirt.driver [req-d8890b32-90d9-481b-bfd1-681c95f8d3d1 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Deleting instance files /var/lib/nova/instances/be364184-c876-4673-a050-232d7504a77a_del
2022-02-21 19:46:45.427 7 INFO nova.virt.libvirt.driver [req-d8890b32-90d9-481b-bfd1-681c95f8d3d1 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Deletion of /var/lib/nova/instances/be364184-c876-4673-a050-232d7504a77a_del complete
2022-02-21 19:46:45.493 7 INFO nova.compute.manager [req-d8890b32-90d9-481b-bfd1-681c95f8d3d1 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] [instance: be364184-c876-4673-a050-232d7504a77a] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:46:45.565 7 INFO nova.compute.manager [-] [instance: be364184-c876-4673-a050-232d7504a77a] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:46:45.770 7 INFO nova.scheduler.client.report [req-d8890b32-90d9-481b-bfd1-681c95f8d3d1 5d99f2de575e4b97824d676247c650db daedebb71bf0439abc620b7d0d8381d2 - default default] Deleted allocations for instance be364184-c876-4673-a050-232d7504a77a
2022-02-21 19:46:48.675 7 INFO nova.compute.claims [req-3b7b9aba-3c40-41f2-b211-0f3510824ed1 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Claim successful on node rack08-server63
2022-02-21 19:46:49.077 7 INFO nova.virt.libvirt.driver [req-3b7b9aba-3c40-41f2-b211-0f3510824ed1 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Creating image
2022-02-21 19:46:50.337 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] VM Resumed (Lifecycle Event)
2022-02-21 19:46:50.344 7 INFO nova.virt.libvirt.driver [-] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Instance spawned successfully.
2022-02-21 19:46:50.345 7 INFO nova.compute.manager [req-3b7b9aba-3c40-41f2-b211-0f3510824ed1 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-21 19:46:50.390 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:46:50.391 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] VM Started (Lifecycle Event)
2022-02-21 19:46:50.435 7 INFO nova.compute.manager [req-3b7b9aba-3c40-41f2-b211-0f3510824ed1 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Took 1.80 seconds to build instance.
2022-02-21 19:46:51.700 7 INFO nova.compute.manager [req-d6c41034-6542-4b3c-b547-4958cc6cd8da 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Terminating instance
2022-02-21 19:46:52.054 7 INFO nova.virt.libvirt.driver [-] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Instance destroyed successfully.
2022-02-21 19:46:52.070 7 INFO nova.virt.libvirt.driver [req-d6c41034-6542-4b3c-b547-4958cc6cd8da 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Deleting instance files /var/lib/nova/instances/d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73_del
2022-02-21 19:46:52.071 7 INFO nova.virt.libvirt.driver [req-d6c41034-6542-4b3c-b547-4958cc6cd8da 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Deletion of /var/lib/nova/instances/d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73_del complete
2022-02-21 19:46:52.140 7 INFO nova.compute.manager [req-d6c41034-6542-4b3c-b547-4958cc6cd8da 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:46:52.209 7 INFO nova.compute.manager [-] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:46:52.407 7 INFO nova.scheduler.client.report [req-d6c41034-6542-4b3c-b547-4958cc6cd8da 2581296fa6f142b59445609c6f281d29 4f5f697bea124c55a9ff8d030b6ce45a - default default] Deleted allocations for instance d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73
2022-02-21 19:46:55.538 7 INFO nova.compute.manager [-] [instance: af0dd25d-50d3-4315-b847-48d226e7ff03] VM Stopped (Lifecycle Event)
2022-02-21 19:47:00.408 7 INFO nova.compute.manager [-] [instance: be364184-c876-4673-a050-232d7504a77a] VM Stopped (Lifecycle Event)
2022-02-21 19:47:01.657 7 INFO nova.compute.manager [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Detaching volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495
2022-02-21 19:47:01.716 7 INFO nova.virt.block_device [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Attempting to driver detach volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 from mountpoint /dev/vdb
2022-02-21 19:47:01.726 7 INFO nova.virt.libvirt.driver [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Device vdb not found in instance.
2022-02-21 19:47:01.774 7 INFO os_brick.initiator.connectors.lightos [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a65c0f7-90a5-4cad-9c1c-638803c3fe6f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 19:47:03.511 7 INFO nova.compute.claims [req-85a81b73-d5a3-4fe1-9956-cb6b09ea52c7 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Claim successful on node rack08-server63
2022-02-21 19:47:03.911 7 INFO nova.virt.libvirt.driver [req-85a81b73-d5a3-4fe1-9956-cb6b09ea52c7 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Creating image
2022-02-21 19:47:05.157 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] VM Resumed (Lifecycle Event)
2022-02-21 19:47:05.165 7 INFO nova.virt.libvirt.driver [-] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Instance spawned successfully.
2022-02-21 19:47:05.166 7 INFO nova.compute.manager [req-85a81b73-d5a3-4fe1-9956-cb6b09ea52c7 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-21 19:47:05.212 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:47:05.213 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] VM Started (Lifecycle Event)
2022-02-21 19:47:05.251 7 INFO nova.compute.manager [req-85a81b73-d5a3-4fe1-9956-cb6b09ea52c7 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Took 1.79 seconds to build instance.
2022-02-21 19:47:07.053 7 INFO nova.compute.manager [-] [instance: d74f65ba-dd88-42cc-a3a7-95ccaf8a4c73] VM Stopped (Lifecycle Event)
2022-02-21 19:47:21.689 7 INFO nova.virt.libvirt.driver [req-648dc8d9-1096-4c6c-95e6-251014c64903 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Ignoring supplied device name: /dev/vdb
2022-02-21 19:47:21.860 7 INFO nova.compute.manager [req-648dc8d9-1096-4c6c-95e6-251014c64903 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Attaching volume b413c9c4-2990-4378-87a5-b97bbb2fb6f4 to /dev/vdb
2022-02-21 19:47:21.957 7 WARNING os_brick.initiator.connectors.nvmeof [req-648dc8d9-1096-4c6c-95e6-251014c64903 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:47:45.125 7 INFO nova.compute.claims [req-20226828-198e-46bd-a6f7-b1f12ad1e4f7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Claim successful on node rack08-server63
2022-02-21 19:47:45.516 7 INFO nova.virt.libvirt.driver [req-20226828-198e-46bd-a6f7-b1f12ad1e4f7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Creating image
2022-02-21 19:47:46.663 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d2c04897-012f-4e60-a180-40c21df7045d] VM Resumed (Lifecycle Event)
2022-02-21 19:47:46.670 7 INFO nova.virt.libvirt.driver [-] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Instance spawned successfully.
2022-02-21 19:47:46.671 7 INFO nova.compute.manager [req-20226828-198e-46bd-a6f7-b1f12ad1e4f7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-21 19:47:46.716 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d2c04897-012f-4e60-a180-40c21df7045d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:47:46.717 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: d2c04897-012f-4e60-a180-40c21df7045d] VM Started (Lifecycle Event)
2022-02-21 19:47:46.760 7 INFO nova.compute.manager [req-20226828-198e-46bd-a6f7-b1f12ad1e4f7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Took 1.68 seconds to build instance.
2022-02-21 19:47:47.966 7 INFO nova.virt.libvirt.driver [req-f1c3c0a1-c445-408f-ac0f-bba8840c33a7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Ignoring supplied device name: /dev/vdb
2022-02-21 19:47:48.128 7 INFO nova.compute.manager [req-f1c3c0a1-c445-408f-ac0f-bba8840c33a7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Attaching volume c31c1433-a218-446b-9130-b7652ae8c301 to /dev/vdb
2022-02-21 19:47:48.219 7 WARNING os_brick.initiator.connectors.nvmeof [req-f1c3c0a1-c445-408f-ac0f-bba8840c33a7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Failed to detach volume 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 from /dev/vdb: os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Traceback (most recent call last):
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     self._disconnect_volume(context, connection_info, instance,
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     return f(*args, **kwargs)
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     return f(*args, **kwargs)
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35]     raise exception.BrickException(message=msg)
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:48:02.378 7 ERROR nova.virt.block_device [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] 
2022-02-21 19:48:02.389 7 INFO os_brick.initiator.connectors.lightos [req-648dc8d9-1096-4c6c-95e6-251014c64903 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: connect_volume called for volume 6f66dda9-6090-4f89-a586-cd8ead861e72, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6f66dda9-6090-4f89-a586-cd8ead861e72', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:48:02.392 7 INFO os_brick.initiator.connectors.lightos [req-648dc8d9-1096-4c6c-95e6-251014c64903 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6f66dda9-6090-4f89-a586-cd8ead861e72
2022-02-21 19:48:02.393 7 INFO os_brick.initiator.connectors.lightos [req-f1c3c0a1-c445-408f-ac0f-bba8840c33a7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] LIGHTOS: connect_volume called for volume e557a024-5009-4f25-9eda-a915683563da, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'e557a024-5009-4f25-9eda-a915683563da', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:48:02.395 7 INFO os_brick.initiator.connectors.lightos [req-f1c3c0a1-c445-408f-ac0f-bba8840c33a7 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid e557a024-5009-4f25-9eda-a915683563da
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server [req-0a23ab37-04e1-4dfb-a589-417ceccd1430 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Exception during message handling: os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server Traceback (most recent call last):
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/server.py", line 165, in _process_incoming
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 309, in dispatch
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_messaging/rpc/dispatcher.py", line 229, in _do_dispatch
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 71, in wrapped
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     _emit_versioned_exception_notification(
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/exception_wrapper.py", line 63, in wrapped
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/utils.py", line 1437, in decorated_function
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 211, in decorated_function
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     compute_utils.add_instance_fault_from_exc(context,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 200, in decorated_function
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7207, in detach_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     do_detach_volume(context, volume_id, instance, attachment_id)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7204, in do_detach_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self._detach_volume(context, bdm, instance,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/compute/manager.py", line 7155, in _detach_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     driver_bdm.detach(context, instance, self.volume_api, self.driver,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 473, in detach
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self._do_detach(context, instance, volume_api, virt_driver,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 394, in _do_detach
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self.driver_detach(context, instance, volume_api, virt_driver)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 333, in driver_detach
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     volume_api.roll_detaching(context, volume_id)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 227, in __exit__
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self.force_reraise()
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_utils/excutils.py", line 200, in force_reraise
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     raise self.value
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/block_device.py", line 314, in driver_detach
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     virt_driver.detach_volume(context, connection_info, instance, mp,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 2611, in detach_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     self._disconnect_volume(context, connection_info, instance,
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/driver.py", line 1877, in _disconnect_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     vol_driver.disconnect_volume(connection_info, instance)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/nova/virt/libvirt/volume/lightos.py", line 47, in disconnect_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     device_info = self.connector.connect_volume(connection_info['data'])
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/utils.py", line 164, in trace_logging_wrapper
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/oslo_concurrency/lockutils.py", line 391, in inner
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server   File "/var/lib/kolla/venv/lib/python3.8/site-packages/os_brick/initiator/connectors/lightos.py", line 283, in connect_volume
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server     raise exception.BrickException(message=msg)
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:48:02.481 7 ERROR oslo_messaging.rpc.server 
2022-02-21 19:48:04.083 7 INFO nova.compute.manager [req-0673b39b-bdb8-4bef-875f-f7941f7c25eb e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Cinder extended volume c31c1433-a218-446b-9130-b7652ae8c301; extending it to detect new size
2022-02-21 19:48:04.168 7 INFO os_brick.initiator.connectors.lightos [req-0673b39b-bdb8-4bef-875f-f7941f7c25eb e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid e557a024-5009-4f25-9eda-a915683563da
2022-02-21 19:48:04.819 7 INFO nova.compute.manager [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Detaching volume c31c1433-a218-446b-9130-b7652ae8c301
2022-02-21 19:48:04.880 7 INFO nova.virt.block_device [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Attempting to driver detach volume c31c1433-a218-446b-9130-b7652ae8c301 from mountpoint /dev/vdb
2022-02-21 19:48:04.899 7 INFO nova.virt.libvirt.driver [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] Successfully detached device vdb from instance d2c04897-012f-4e60-a180-40c21df7045d from the persistent domain config.
2022-02-21 19:48:05.040 7 INFO nova.virt.libvirt.driver [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] Successfully detached device vdb from instance d2c04897-012f-4e60-a180-40c21df7045d from the live domain config.
2022-02-21 19:48:05.043 7 INFO os_brick.initiator.connectors.lightos [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] LIGHTOS: connect_volume called for volume e557a024-5009-4f25-9eda-a915683563da, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'e557a024-5009-4f25-9eda-a915683563da', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 19:48:05.044 7 INFO os_brick.initiator.connectors.lightos [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid e557a024-5009-4f25-9eda-a915683563da
2022-02-21 19:48:05.045 7 INFO os_brick.initiator.connectors.lightos [req-4302b302-3d2a-4f1e-bcf3-050ca6bcf178 a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid e557a024-5009-4f25-9eda-a915683563da
2022-02-21 19:48:07.056 7 INFO nova.compute.manager [req-ef15bdea-bd28-4df4-b641-310ddaffdb5b a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Terminating instance
2022-02-21 19:48:07.400 7 INFO nova.virt.libvirt.driver [-] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Instance destroyed successfully.
2022-02-21 19:48:07.414 7 INFO nova.virt.libvirt.driver [req-ef15bdea-bd28-4df4-b641-310ddaffdb5b a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Deleting instance files /var/lib/nova/instances/d2c04897-012f-4e60-a180-40c21df7045d_del
2022-02-21 19:48:07.416 7 INFO nova.virt.libvirt.driver [req-ef15bdea-bd28-4df4-b641-310ddaffdb5b a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Deletion of /var/lib/nova/instances/d2c04897-012f-4e60-a180-40c21df7045d_del complete
2022-02-21 19:48:07.485 7 INFO nova.compute.manager [req-ef15bdea-bd28-4df4-b641-310ddaffdb5b a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:48:07.558 7 INFO nova.compute.manager [-] [instance: d2c04897-012f-4e60-a180-40c21df7045d] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:48:07.729 7 INFO nova.scheduler.client.report [req-ef15bdea-bd28-4df4-b641-310ddaffdb5b a2ec51f4a4af470ba43db52acad6dc92 206805dea2f1479f8b09c6e8148371ee - default default] Deleted allocations for instance d2c04897-012f-4e60-a180-40c21df7045d
2022-02-21 19:48:13.785 7 INFO nova.compute.manager [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Detaching volume b413c9c4-2990-4378-87a5-b97bbb2fb6f4
2022-02-21 19:48:13.853 7 INFO nova.virt.block_device [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Attempting to driver detach volume b413c9c4-2990-4378-87a5-b97bbb2fb6f4 from mountpoint /dev/vdb
2022-02-21 19:48:13.872 7 INFO nova.virt.libvirt.driver [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Successfully detached device vdb from instance 4462130b-b34f-4da1-a97a-546b68695a7a from the persistent domain config.
2022-02-21 19:48:14.014 7 INFO nova.virt.libvirt.driver [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Successfully detached device vdb from instance 4462130b-b34f-4da1-a97a-546b68695a7a from the live domain config.
2022-02-21 19:48:14.017 7 INFO os_brick.initiator.connectors.lightos [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: connect_volume called for volume 6f66dda9-6090-4f89-a586-cd8ead861e72, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6f66dda9-6090-4f89-a586-cd8ead861e72', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:48:14.018 7 INFO os_brick.initiator.connectors.lightos [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6f66dda9-6090-4f89-a586-cd8ead861e72
2022-02-21 19:48:14.019 7 INFO os_brick.initiator.connectors.lightos [req-c4108538-08fd-433a-92bd-5b2b7b4b136c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6f66dda9-6090-4f89-a586-cd8ead861e72
2022-02-21 19:48:16.050 7 INFO nova.compute.manager [req-d68b0cd9-776e-4f50-b843-e4149f82ffd4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Terminating instance
2022-02-21 19:48:16.393 7 INFO nova.virt.libvirt.driver [-] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Instance destroyed successfully.
2022-02-21 19:48:16.408 7 INFO nova.virt.libvirt.driver [req-d68b0cd9-776e-4f50-b843-e4149f82ffd4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Deleting instance files /var/lib/nova/instances/4462130b-b34f-4da1-a97a-546b68695a7a_del
2022-02-21 19:48:16.410 7 INFO nova.virt.libvirt.driver [req-d68b0cd9-776e-4f50-b843-e4149f82ffd4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Deletion of /var/lib/nova/instances/4462130b-b34f-4da1-a97a-546b68695a7a_del complete
2022-02-21 19:48:16.476 7 INFO nova.compute.manager [req-d68b0cd9-776e-4f50-b843-e4149f82ffd4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-21 19:48:16.545 7 INFO nova.compute.manager [-] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:48:16.742 7 INFO nova.scheduler.client.report [req-d68b0cd9-776e-4f50-b843-e4149f82ffd4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Deleted allocations for instance 4462130b-b34f-4da1-a97a-546b68695a7a
2022-02-21 19:48:22.398 7 INFO nova.compute.manager [-] [instance: d2c04897-012f-4e60-a180-40c21df7045d] VM Stopped (Lifecycle Event)
2022-02-21 19:48:24.841 7 INFO nova.compute.claims [req-8ce87536-e5b6-4807-827b-e6a1934a7505 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Claim successful on node rack08-server63
2022-02-21 19:48:25.250 7 INFO nova.virt.libvirt.driver [req-8ce87536-e5b6-4807-827b-e6a1934a7505 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Creating image
2022-02-21 19:48:26.443 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 681068ca-1fc5-4143-80e8-716459d84786] VM Resumed (Lifecycle Event)
2022-02-21 19:48:26.452 7 INFO nova.virt.libvirt.driver [-] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Instance spawned successfully.
2022-02-21 19:48:26.453 7 INFO nova.compute.manager [req-8ce87536-e5b6-4807-827b-e6a1934a7505 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-21 19:48:26.500 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 681068ca-1fc5-4143-80e8-716459d84786] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:48:26.500 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: 681068ca-1fc5-4143-80e8-716459d84786] VM Started (Lifecycle Event)
2022-02-21 19:48:26.545 7 INFO nova.compute.manager [req-8ce87536-e5b6-4807-827b-e6a1934a7505 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Took 1.75 seconds to build instance.
2022-02-21 19:48:27.288 7 INFO nova.virt.libvirt.driver [req-4a5abea5-f21e-48a2-8eb2-1aabe1bc2e3c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Ignoring supplied device name: /dev/vdb
2022-02-21 19:48:27.452 7 INFO nova.compute.manager [req-4a5abea5-f21e-48a2-8eb2-1aabe1bc2e3c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Attaching volume a8b47e5f-e842-4b26-b76b-6ff6b6f345ac to /dev/vdb
2022-02-21 19:48:27.538 7 WARNING os_brick.initiator.connectors.nvmeof [req-4a5abea5-f21e-48a2-8eb2-1aabe1bc2e3c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:48:28.882 7 INFO os_brick.initiator.connectors.lightos [req-4a5abea5-f21e-48a2-8eb2-1aabe1bc2e3c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: connect_volume called for volume 26745ef8-897a-40d5-8eb7-65d391e1c20d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '26745ef8-897a-40d5-8eb7-65d391e1c20d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:48:28.887 7 INFO os_brick.initiator.connectors.lightos [req-4a5abea5-f21e-48a2-8eb2-1aabe1bc2e3c 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26745ef8-897a-40d5-8eb7-65d391e1c20d
2022-02-21 19:48:31.391 7 INFO nova.compute.manager [-] [instance: 4462130b-b34f-4da1-a97a-546b68695a7a] VM Stopped (Lifecycle Event)
2022-02-21 19:48:37.772 7 INFO nova.compute.manager [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Detaching volume a8b47e5f-e842-4b26-b76b-6ff6b6f345ac
2022-02-21 19:48:37.830 7 INFO nova.virt.block_device [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Attempting to driver detach volume a8b47e5f-e842-4b26-b76b-6ff6b6f345ac from mountpoint /dev/vdb
2022-02-21 19:48:37.850 7 INFO nova.virt.libvirt.driver [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Successfully detached device vdb from instance 681068ca-1fc5-4143-80e8-716459d84786 from the persistent domain config.
2022-02-21 19:48:37.992 7 INFO nova.virt.libvirt.driver [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Successfully detached device vdb from instance 681068ca-1fc5-4143-80e8-716459d84786 from the live domain config.
2022-02-21 19:48:37.995 7 INFO os_brick.initiator.connectors.lightos [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: connect_volume called for volume 26745ef8-897a-40d5-8eb7-65d391e1c20d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '26745ef8-897a-40d5-8eb7-65d391e1c20d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:48:37.996 7 INFO os_brick.initiator.connectors.lightos [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26745ef8-897a-40d5-8eb7-65d391e1c20d
2022-02-21 19:48:37.997 7 INFO os_brick.initiator.connectors.lightos [req-c2754159-6c94-4fcc-8610-6ca60e7c5b85 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 26745ef8-897a-40d5-8eb7-65d391e1c20d
2022-02-21 19:48:40.025 7 INFO nova.compute.manager [req-76f5fd35-db4b-408e-88d4-f7b84190f3c4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Terminating instance
2022-02-21 19:48:40.369 7 INFO nova.virt.libvirt.driver [-] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Instance destroyed successfully.
2022-02-21 19:48:40.384 7 INFO nova.virt.libvirt.driver [req-76f5fd35-db4b-408e-88d4-f7b84190f3c4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Deleting instance files /var/lib/nova/instances/681068ca-1fc5-4143-80e8-716459d84786_del
2022-02-21 19:48:40.385 7 INFO nova.virt.libvirt.driver [req-76f5fd35-db4b-408e-88d4-f7b84190f3c4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Deletion of /var/lib/nova/instances/681068ca-1fc5-4143-80e8-716459d84786_del complete
2022-02-21 19:48:40.454 7 INFO nova.compute.manager [req-76f5fd35-db4b-408e-88d4-f7b84190f3c4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:48:40.519 7 INFO nova.compute.manager [-] [instance: 681068ca-1fc5-4143-80e8-716459d84786] Took 0.06 seconds to deallocate network for instance.
2022-02-21 19:48:40.710 7 INFO nova.scheduler.client.report [req-76f5fd35-db4b-408e-88d4-f7b84190f3c4 64ea3b2187be4d22912f5b948e706751 c9815c9d230b4971a43f2fa10af554db - default default] Deleted allocations for instance 681068ca-1fc5-4143-80e8-716459d84786
2022-02-21 19:48:55.367 7 INFO nova.compute.manager [-] [instance: 681068ca-1fc5-4143-80e8-716459d84786] VM Stopped (Lifecycle Event)
2022-02-21 19:52:01.960 7 INFO nova.compute.manager [req-35d4df64-53e7-47a4-ba61-b71730648984 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Get console output
2022-02-21 19:52:02.241 79 INFO nova.privsep.libvirt [-] Ignored error while reading from instance console pty: can't concat NoneType to bytes
2022-02-21 19:52:18.340 7 INFO nova.compute.claims [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Claim successful on node rack08-server63
2022-02-21 19:52:18.615 7 INFO nova.virt.libvirt.driver [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-21 19:52:18.713 7 INFO nova.virt.block_device [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Booting with volume 59de3ce1-f0d4-4fab-a2b6-1777159c20ca at /dev/vda
2022-02-21 19:52:18.804 7 WARNING os_brick.initiator.connectors.nvmeof [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-21 19:52:20.339 7 INFO nova.virt.libvirt.driver [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Creating image
2022-02-21 19:52:20.351 7 INFO os_brick.initiator.connectors.lightos [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 75eb3deb-9759-4acb-a6ca-8bc8110bfa6c, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '75eb3deb-9759-4acb-a6ca-8bc8110bfa6c', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-21 19:52:20.354 7 INFO os_brick.initiator.connectors.lightos [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 75eb3deb-9759-4acb-a6ca-8bc8110bfa6c
2022-02-21 19:52:21.194 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] VM Resumed (Lifecycle Event)
2022-02-21 19:52:21.201 7 INFO nova.virt.libvirt.driver [-] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Instance spawned successfully.
2022-02-21 19:52:21.202 7 INFO nova.compute.manager [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Took 0.86 seconds to spawn the instance on the hypervisor.
2022-02-21 19:52:21.251 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-21 19:52:21.252 7 INFO nova.compute.manager [req-7f6e79c2-9052-4743-946b-6157bf960902 - - - - -] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] VM Started (Lifecycle Event)
2022-02-21 19:52:21.291 7 INFO nova.compute.manager [req-971114ef-072d-41b4-a324-806d3f4c10ab d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Took 2.99 seconds to build instance.
2022-02-21 19:52:22.553 7 INFO nova.compute.manager [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Terminating instance
2022-02-21 19:52:22.903 7 INFO nova.virt.libvirt.driver [-] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Instance destroyed successfully.
2022-02-21 19:52:22.983 7 INFO os_brick.initiator.connectors.lightos [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 75eb3deb-9759-4acb-a6ca-8bc8110bfa6c, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '75eb3deb-9759-4acb-a6ca-8bc8110bfa6c', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n1'}
2022-02-21 19:52:22.983 7 INFO os_brick.initiator.connectors.lightos [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 75eb3deb-9759-4acb-a6ca-8bc8110bfa6c
2022-02-21 19:52:22.984 7 INFO os_brick.initiator.connectors.lightos [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 75eb3deb-9759-4acb-a6ca-8bc8110bfa6c
2022-02-21 19:52:22.996 7 INFO nova.virt.libvirt.driver [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Deleting instance files /var/lib/nova/instances/a6258e0a-82d8-43ea-b98f-6a94a10a1e13_del
2022-02-21 19:52:22.997 7 INFO nova.virt.libvirt.driver [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Deletion of /var/lib/nova/instances/a6258e0a-82d8-43ea-b98f-6a94a10a1e13_del complete
2022-02-21 19:52:23.065 7 INFO nova.compute.manager [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-21 19:52:23.134 7 INFO nova.compute.manager [-] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:52:26.442 7 INFO nova.compute.manager [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] Took 3.31 seconds to detach 1 volumes for instance.
2022-02-21 19:52:26.642 7 INFO nova.scheduler.client.report [req-49bfb1a7-5354-4d62-9f0b-662ac1b908d3 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Deleted allocations for instance a6258e0a-82d8-43ea-b98f-6a94a10a1e13
2022-02-21 19:52:37.902 7 INFO nova.compute.manager [-] [instance: a6258e0a-82d8-43ea-b98f-6a94a10a1e13] VM Stopped (Lifecycle Event)
2022-02-21 19:57:29.163 7 INFO nova.compute.manager [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Terminating instance
2022-02-21 19:57:29.502 7 INFO nova.virt.libvirt.driver [-] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Instance destroyed successfully.
2022-02-21 19:57:29.573 7 INFO os_brick.initiator.connectors.lightos [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a65c0f7-90a5-4cad-9c1c-638803c3fe6f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n4'}
2022-02-21 19:57:44.500 7 INFO nova.compute.manager [-] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] VM Stopped (Lifecycle Event)
2022-02-21 19:57:44.555 7 INFO nova.compute.manager [req-0e7d4f99-3dbf-4cee-a602-30e696bdf097 - - - - -] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] During sync_power_state the instance has a pending task (deleting). Skip.
2022-02-21 19:58:30.247 7 WARNING nova.virt.libvirt.driver [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Ignoring Volume Error on vol 778f7d0d-e7a8-4dde-b0cb-b7a57c364495 during delete Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up: os_brick.exception.BrickException: Device with uuid 9a65c0f7-90a5-4cad-9c1c-638803c3fe6f did not show up
2022-02-21 19:58:30.249 7 INFO nova.virt.libvirt.driver [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Deleting instance files /var/lib/nova/instances/3b8e1131-8bd7-4941-849d-710198d41c35_del
2022-02-21 19:58:30.251 7 INFO nova.virt.libvirt.driver [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Deletion of /var/lib/nova/instances/3b8e1131-8bd7-4941-849d-710198d41c35_del complete
2022-02-21 19:58:30.322 7 INFO nova.compute.manager [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Took 61.04 seconds to destroy the instance on the hypervisor.
2022-02-21 19:58:30.398 7 INFO nova.compute.manager [-] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:58:31.645 7 INFO nova.compute.manager [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 3b8e1131-8bd7-4941-849d-710198d41c35] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-21 19:58:31.860 7 INFO nova.scheduler.client.report [req-06b11a74-21e4-482c-b5e7-91b6ceae4a6c d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Deleted allocations for instance 3b8e1131-8bd7-4941-849d-710198d41c35
2022-02-21 19:58:32.798 7 INFO nova.compute.manager [req-8e8dea89-04c9-4341-8bcb-0f317989feae d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Terminating instance
2022-02-21 19:58:33.150 7 INFO nova.virt.libvirt.driver [-] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Instance destroyed successfully.
2022-02-21 19:58:33.165 7 INFO nova.virt.libvirt.driver [req-8e8dea89-04c9-4341-8bcb-0f317989feae d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Deleting instance files /var/lib/nova/instances/4837f36f-4c3e-444c-9700-dd377f4fb458_del
2022-02-21 19:58:33.167 7 INFO nova.virt.libvirt.driver [req-8e8dea89-04c9-4341-8bcb-0f317989feae d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Deletion of /var/lib/nova/instances/4837f36f-4c3e-444c-9700-dd377f4fb458_del complete
2022-02-21 19:58:33.234 7 INFO nova.compute.manager [req-8e8dea89-04c9-4341-8bcb-0f317989feae d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-21 19:58:33.306 7 INFO nova.compute.manager [-] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:58:33.502 7 INFO nova.scheduler.client.report [req-8e8dea89-04c9-4341-8bcb-0f317989feae d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Deleted allocations for instance 4837f36f-4c3e-444c-9700-dd377f4fb458
2022-02-21 19:58:34.034 7 INFO nova.compute.manager [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Terminating instance
2022-02-21 19:58:34.384 7 INFO nova.virt.libvirt.driver [-] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Instance destroyed successfully.
2022-02-21 19:58:34.468 7 INFO os_brick.initiator.connectors.lightos [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: connect_volume called for volume c26b065f-3523-4171-a076-a740d5456f49, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c26b065f-3523-4171-a076-a740d5456f49', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False, 'device_path': '/dev/nvme0n3'}
2022-02-21 19:58:34.470 7 INFO os_brick.initiator.connectors.lightos [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid c26b065f-3523-4171-a076-a740d5456f49
2022-02-21 19:58:34.471 7 INFO os_brick.initiator.connectors.lightos [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid c26b065f-3523-4171-a076-a740d5456f49
2022-02-21 19:58:34.481 7 INFO nova.virt.libvirt.driver [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Deleting instance files /var/lib/nova/instances/ef247fae-e361-4390-ba0e-c17bbb53f470_del
2022-02-21 19:58:34.482 7 INFO nova.virt.libvirt.driver [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Deletion of /var/lib/nova/instances/ef247fae-e361-4390-ba0e-c17bbb53f470_del complete
2022-02-21 19:58:34.549 7 INFO nova.compute.manager [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-21 19:58:34.618 7 INFO nova.compute.manager [-] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Took 0.07 seconds to deallocate network for instance.
2022-02-21 19:58:35.869 7 INFO nova.compute.manager [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-21 19:58:36.068 7 INFO nova.scheduler.client.report [req-44c7ef97-31e8-4425-b521-0e70ce2c6b23 d921843d111f4dac82d8502ce54474af a21144bc01574a6e9c1987cf64905983 - default default] Deleted allocations for instance ef247fae-e361-4390-ba0e-c17bbb53f470
2022-02-21 19:58:48.148 7 INFO nova.compute.manager [-] [instance: 4837f36f-4c3e-444c-9700-dd377f4fb458] VM Stopped (Lifecycle Event)
2022-02-21 19:58:49.382 7 INFO nova.compute.manager [-] [instance: ef247fae-e361-4390-ba0e-c17bbb53f470] VM Stopped (Lifecycle Event)
