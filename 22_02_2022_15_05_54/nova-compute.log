Build Started 22_02_2022_15_05_54
2022-02-22 17:08:26.429 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 17:08:30.378 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 17:08:31.322 7 INFO nova.virt.driver [req-2c557942-7798-45ea-b441-26eea500a0bc - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 17:08:31.707 7 INFO nova.compute.provider_config [req-2c557942-7798-45ea-b441-26eea500a0bc - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 17:08:31.726 7 WARNING oslo_config.cfg [req-2c557942-7798-45ea-b441-26eea500a0bc - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 17:08:31.747 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 17:08:31.764 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 17:08:31.800 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 17:08:31.898 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 17:08:31.912 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 17:08:31.915 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 17:08:32.316 7 INFO nova.compute.manager [req-488b3def-89b6-4894-98da-55f21e384985 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 17:08:34.188 7 INFO nova.virt.libvirt.host [req-488b3def-89b6-4894-98da-55f21e384985 - - - - -] kernel doesn't support AMD SEV
2022-02-22 17:09:24.980 7 INFO nova.compute.claims [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Claim successful on node rack08-server63
2022-02-22 17:09:25.385 7 INFO nova.virt.libvirt.driver [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Creating image
2022-02-22 17:09:25.389 7 INFO oslo.privsep.daemon [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpz42p50bg/privsep.sock']
2022-02-22 17:09:27.020 7 INFO oslo.privsep.daemon [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 17:09:26.867 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 17:09:26.873 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 17:09:26.878 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 17:09:26.878 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-22 17:09:28.250 7 INFO nova.compute.manager [-] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] VM Resumed (Lifecycle Event)
2022-02-22 17:09:28.260 7 INFO nova.virt.libvirt.driver [-] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Instance spawned successfully.
2022-02-22 17:09:28.261 7 INFO nova.compute.manager [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Took 2.88 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:28.306 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:28.307 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] VM Started (Lifecycle Event)
2022-02-22 17:09:28.348 7 INFO nova.compute.manager [req-6ad6d1cf-813d-40fb-95a7-7ae1fd62b83a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Took 3.41 seconds to build instance.
2022-02-22 17:09:33.221 7 INFO nova.compute.manager [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Attaching volume 61ead47e-7d90-4a5f-8877-7ae8fc66603f to /dev/vdb
2022-02-22 17:09:33.296 7 INFO oslo.privsep.daemon [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp7twldgou/privsep.sock']
2022-02-22 17:09:33.964 7 INFO oslo.privsep.daemon [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 17:09:33.885 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 17:09:33.892 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 17:09:33.897 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 17:09:33.897 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-22 17:09:34.287 7 WARNING os_brick.initiator.connectors.nvmeof [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:09:35.676 7 INFO os_brick.initiator.connectors.lightos [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: connect_volume called for volume 8e558c84-00b3-40cc-a1ad-b531d10a4c05, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8e558c84-00b3-40cc-a1ad-b531d10a4c05', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:09:35.710 7 INFO os_brick.initiator.connectors.lightos [req-7d53f5fd-02da-4f82-953d-dfd42f61fbe3 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e558c84-00b3-40cc-a1ad-b531d10a4c05
2022-02-22 17:09:37.832 7 INFO nova.compute.claims [req-6c8c1aec-e673-4aa3-adff-730b3470225a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Claim successful on node rack08-server63
2022-02-22 17:09:38.229 7 INFO nova.virt.libvirt.driver [req-6c8c1aec-e673-4aa3-adff-730b3470225a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Creating image
2022-02-22 17:09:39.392 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] VM Resumed (Lifecycle Event)
2022-02-22 17:09:39.399 7 INFO nova.virt.libvirt.driver [-] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Instance spawned successfully.
2022-02-22 17:09:39.399 7 INFO nova.compute.manager [req-6c8c1aec-e673-4aa3-adff-730b3470225a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:39.446 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:39.447 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] VM Started (Lifecycle Event)
2022-02-22 17:09:39.491 7 INFO nova.compute.manager [req-6c8c1aec-e673-4aa3-adff-730b3470225a a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Took 1.70 seconds to build instance.
2022-02-22 17:09:40.074 7 INFO nova.compute.claims [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Claim successful on node rack08-server63
2022-02-22 17:09:40.389 7 INFO nova.virt.libvirt.driver [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 17:09:40.482 7 INFO nova.virt.block_device [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Booting with volume 4676d314-6db3-4118-8251-15cdbed57e6c at /dev/vda
2022-02-22 17:09:40.602 7 WARNING os_brick.initiator.connectors.nvmeof [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:09:41.009 7 INFO nova.compute.manager [req-442491e8-62fc-4536-8d4e-c0310ccdb9f2 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Detaching volume 61ead47e-7d90-4a5f-8877-7ae8fc66603f
2022-02-22 17:09:41.069 7 INFO nova.virt.block_device [req-442491e8-62fc-4536-8d4e-c0310ccdb9f2 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Attempting to driver detach volume 61ead47e-7d90-4a5f-8877-7ae8fc66603f from mountpoint /dev/vdb
2022-02-22 17:09:41.088 7 INFO nova.virt.libvirt.driver [req-442491e8-62fc-4536-8d4e-c0310ccdb9f2 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance db0092be-8035-476d-97d1-9a8daf38f5e1 from the persistent domain config.
2022-02-22 17:09:41.229 7 INFO nova.virt.libvirt.driver [req-442491e8-62fc-4536-8d4e-c0310ccdb9f2 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance db0092be-8035-476d-97d1-9a8daf38f5e1 from the live domain config.
2022-02-22 17:09:41.232 7 INFO os_brick.initiator.connectors.lightos [req-442491e8-62fc-4536-8d4e-c0310ccdb9f2 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e558c84-00b3-40cc-a1ad-b531d10a4c05
2022-02-22 17:09:42.138 7 INFO nova.virt.libvirt.driver [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Creating image
2022-02-22 17:09:42.149 7 INFO os_brick.initiator.connectors.lightos [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: connect_volume called for volume 8619e60a-4903-46a8-ae8d-eb7907ad012e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8619e60a-4903-46a8-ae8d-eb7907ad012e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:09:42.152 7 INFO os_brick.initiator.connectors.lightos [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8619e60a-4903-46a8-ae8d-eb7907ad012e
2022-02-22 17:09:42.962 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] VM Resumed (Lifecycle Event)
2022-02-22 17:09:42.971 7 INFO nova.virt.libvirt.driver [-] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Instance spawned successfully.
2022-02-22 17:09:42.972 7 INFO nova.compute.manager [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Took 0.84 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:43.018 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:43.019 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] VM Started (Lifecycle Event)
2022-02-22 17:09:43.064 7 INFO nova.compute.manager [req-50d435d1-a877-4941-9e5d-4286e7a0ca49 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Took 3.03 seconds to build instance.
2022-02-22 17:09:44.594 7 INFO nova.compute.claims [req-335e7e68-c3a8-4484-82f7-6f200f36022b a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Claim successful on node rack08-server63
2022-02-22 17:09:44.982 7 INFO nova.virt.libvirt.driver [req-335e7e68-c3a8-4484-82f7-6f200f36022b a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Creating image
2022-02-22 17:09:45.248 7 INFO nova.compute.claims [req-a1e614b9-2098-4bcf-95c3-1f2837ea7b6b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Claim successful on node rack08-server63
2022-02-22 17:09:45.632 7 INFO nova.virt.libvirt.driver [req-a1e614b9-2098-4bcf-95c3-1f2837ea7b6b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Creating image
2022-02-22 17:09:45.697 7 INFO nova.compute.claims [req-d191f231-d7db-45c9-9384-a5a8448f7211 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Claim successful on node rack08-server63
2022-02-22 17:09:46.125 7 INFO nova.virt.libvirt.driver [req-d191f231-d7db-45c9-9384-a5a8448f7211 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Creating image
2022-02-22 17:09:46.169 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] VM Resumed (Lifecycle Event)
2022-02-22 17:09:46.179 7 INFO nova.virt.libvirt.driver [-] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Instance spawned successfully.
2022-02-22 17:09:46.180 7 INFO nova.compute.manager [req-335e7e68-c3a8-4484-82f7-6f200f36022b a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:46.227 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:46.228 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] VM Started (Lifecycle Event)
2022-02-22 17:09:46.267 7 INFO nova.compute.manager [req-335e7e68-c3a8-4484-82f7-6f200f36022b a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Took 1.71 seconds to build instance.
2022-02-22 17:09:46.840 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] VM Resumed (Lifecycle Event)
2022-02-22 17:09:46.847 7 INFO nova.virt.libvirt.driver [-] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Instance spawned successfully.
2022-02-22 17:09:46.848 7 INFO nova.compute.manager [req-a1e614b9-2098-4bcf-95c3-1f2837ea7b6b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:46.897 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:46.898 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] VM Started (Lifecycle Event)
2022-02-22 17:09:46.938 7 INFO nova.compute.manager [req-a1e614b9-2098-4bcf-95c3-1f2837ea7b6b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Took 1.73 seconds to build instance.
2022-02-22 17:09:47.267 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] VM Resumed (Lifecycle Event)
2022-02-22 17:09:47.274 7 INFO nova.virt.libvirt.driver [-] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Instance spawned successfully.
2022-02-22 17:09:47.274 7 INFO nova.compute.manager [req-d191f231-d7db-45c9-9384-a5a8448f7211 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:47.322 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:47.323 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] VM Started (Lifecycle Event)
2022-02-22 17:09:47.366 7 INFO nova.compute.manager [req-d191f231-d7db-45c9-9384-a5a8448f7211 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Took 1.71 seconds to build instance.
2022-02-22 17:09:49.409 7 INFO nova.compute.manager [req-56f6b5f3-4c9c-4676-b97b-67bdc9b61a71 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Attaching volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f to /dev/vdb
2022-02-22 17:09:49.494 7 WARNING os_brick.initiator.connectors.nvmeof [req-56f6b5f3-4c9c-4676-b97b-67bdc9b61a71 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:09:50.137 7 INFO nova.compute.manager [req-1dd0230b-8938-4daf-a9f7-8bf10f4fabc6 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Attaching volume 85e27706-0b59-47ae-99f7-88e0258582ff to /dev/vdb
2022-02-22 17:09:50.227 7 WARNING os_brick.initiator.connectors.nvmeof [req-1dd0230b-8938-4daf-a9f7-8bf10f4fabc6 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:09:50.845 7 INFO os_brick.initiator.connectors.lightos [req-56f6b5f3-4c9c-4676-b97b-67bdc9b61a71 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: connect_volume called for volume 32147bab-d794-4e61-9340-28dd08d6de24, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '32147bab-d794-4e61-9340-28dd08d6de24', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:09:50.849 7 INFO os_brick.initiator.connectors.lightos [req-56f6b5f3-4c9c-4676-b97b-67bdc9b61a71 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 32147bab-d794-4e61-9340-28dd08d6de24
2022-02-22 17:09:51.563 7 INFO os_brick.initiator.connectors.lightos [req-1dd0230b-8938-4daf-a9f7-8bf10f4fabc6 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: connect_volume called for volume f69c4a9a-69b3-4d84-b6cb-d064c950b93f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f69c4a9a-69b3-4d84-b6cb-d064c950b93f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:09:51.566 7 INFO os_brick.initiator.connectors.lightos [req-1dd0230b-8938-4daf-a9f7-8bf10f4fabc6 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid f69c4a9a-69b3-4d84-b6cb-d064c950b93f
2022-02-22 17:09:51.889 7 INFO nova.compute.manager [req-68abdfec-34d6-4539-a125-4089661f74aa 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Attaching volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f to /dev/vdb
2022-02-22 17:09:51.985 7 WARNING os_brick.initiator.connectors.nvmeof [req-68abdfec-34d6-4539-a125-4089661f74aa 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:09:52.731 7 INFO nova.compute.manager [req-5c7d8d88-b2e0-4ab4-94cd-1a6d3335c21e a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Detaching volume 85e27706-0b59-47ae-99f7-88e0258582ff
2022-02-22 17:09:52.933 7 INFO nova.virt.block_device [req-5c7d8d88-b2e0-4ab4-94cd-1a6d3335c21e a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Attempting to driver detach volume 85e27706-0b59-47ae-99f7-88e0258582ff from mountpoint /dev/vdb
2022-02-22 17:09:52.953 7 INFO nova.virt.libvirt.driver [req-5c7d8d88-b2e0-4ab4-94cd-1a6d3335c21e a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance fcc441fc-332b-4fb1-a57c-41e06243e05e from the persistent domain config.
2022-02-22 17:09:53.094 7 INFO nova.virt.libvirt.driver [req-5c7d8d88-b2e0-4ab4-94cd-1a6d3335c21e a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance fcc441fc-332b-4fb1-a57c-41e06243e05e from the live domain config.
2022-02-22 17:09:53.097 7 INFO os_brick.initiator.connectors.lightos [req-5c7d8d88-b2e0-4ab4-94cd-1a6d3335c21e a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid f69c4a9a-69b3-4d84-b6cb-d064c950b93f
2022-02-22 17:09:53.365 7 INFO os_brick.initiator.connectors.lightos [req-68abdfec-34d6-4539-a125-4089661f74aa 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: connect_volume called for volume 32147bab-d794-4e61-9340-28dd08d6de24, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '32147bab-d794-4e61-9340-28dd08d6de24', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:09:53.365 7 INFO os_brick.initiator.connectors.lightos [req-68abdfec-34d6-4539-a125-4089661f74aa 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 32147bab-d794-4e61-9340-28dd08d6de24
2022-02-22 17:09:54.470 7 INFO nova.compute.manager [req-b845f89f-4565-49c9-828c-19bbaea71f3f 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Detaching volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f
2022-02-22 17:09:54.534 7 INFO nova.virt.block_device [req-b845f89f-4565-49c9-828c-19bbaea71f3f 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Attempting to driver detach volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f from mountpoint /dev/vdb
2022-02-22 17:09:54.553 7 INFO nova.virt.libvirt.driver [req-b845f89f-4565-49c9-828c-19bbaea71f3f 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Successfully detached device vdb from instance 690fb8ed-9df1-449d-98bd-8bb96be2dd64 from the persistent domain config.
2022-02-22 17:09:54.704 7 INFO nova.virt.libvirt.driver [req-b845f89f-4565-49c9-828c-19bbaea71f3f 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Successfully detached device vdb from instance 690fb8ed-9df1-449d-98bd-8bb96be2dd64 from the live domain config.
2022-02-22 17:09:54.778 7 INFO nova.virt.libvirt.driver [req-b845f89f-4565-49c9-828c-19bbaea71f3f 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Detected multiple connections on this host for volume: b9a10a41-0b29-40d5-a7ed-bf777254ce8f, skipping target disconnect.
2022-02-22 17:09:56.078 7 INFO nova.compute.claims [req-e3819bb4-8c41-4143-a55f-7d3c11b5e142 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Claim successful on node rack08-server63
2022-02-22 17:09:56.498 7 INFO nova.virt.libvirt.driver [req-e3819bb4-8c41-4143-a55f-7d3c11b5e142 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Creating image
2022-02-22 17:09:56.982 7 INFO nova.compute.manager [req-540f784b-3b2f-4fa8-8e43-89c3d86d3b47 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Detaching volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f
2022-02-22 17:09:57.047 7 INFO nova.virt.block_device [req-540f784b-3b2f-4fa8-8e43-89c3d86d3b47 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Attempting to driver detach volume b9a10a41-0b29-40d5-a7ed-bf777254ce8f from mountpoint /dev/vdb
2022-02-22 17:09:57.068 7 INFO nova.virt.libvirt.driver [req-540f784b-3b2f-4fa8-8e43-89c3d86d3b47 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Successfully detached device vdb from instance 4e9ed0f4-168a-489d-984f-5769605fcd93 from the persistent domain config.
2022-02-22 17:09:57.239 7 INFO nova.virt.libvirt.driver [req-540f784b-3b2f-4fa8-8e43-89c3d86d3b47 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Successfully detached device vdb from instance 4e9ed0f4-168a-489d-984f-5769605fcd93 from the live domain config.
2022-02-22 17:09:57.671 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] VM Resumed (Lifecycle Event)
2022-02-22 17:09:57.678 7 INFO nova.virt.libvirt.driver [-] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Instance spawned successfully.
2022-02-22 17:09:57.679 7 INFO nova.compute.manager [req-e3819bb4-8c41-4143-a55f-7d3c11b5e142 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 17:09:57.724 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:09:57.725 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] VM Started (Lifecycle Event)
2022-02-22 17:09:57.774 7 INFO nova.compute.manager [req-e3819bb4-8c41-4143-a55f-7d3c11b5e142 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Took 1.73 seconds to build instance.
2022-02-22 17:09:59.655 7 INFO nova.compute.manager [req-08bbb1a5-3c57-4400-8e69-e85ced91cff5 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Attaching volume 0717510f-1334-470c-8a41-9c254fb41b83 to /dev/vdb
2022-02-22 17:09:59.738 7 WARNING os_brick.initiator.connectors.nvmeof [req-08bbb1a5-3c57-4400-8e69-e85ced91cff5 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:10:57.889 7 INFO os_brick.initiator.connectors.lightos [req-08bbb1a5-3c57-4400-8e69-e85ced91cff5 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: connect_volume called for volume 88e6678b-1d7b-4884-982f-aacfa7868f53, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '88e6678b-1d7b-4884-982f-aacfa7868f53', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:10:57.893 7 INFO os_brick.initiator.connectors.lightos [req-08bbb1a5-3c57-4400-8e69-e85ced91cff5 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 88e6678b-1d7b-4884-982f-aacfa7868f53
2022-02-22 17:10:59.488 7 INFO nova.compute.manager [req-fca9e99f-c19f-4643-ac35-838603b507f0 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Detaching volume 0717510f-1334-470c-8a41-9c254fb41b83
2022-02-22 17:10:59.542 7 INFO nova.virt.block_device [req-fca9e99f-c19f-4643-ac35-838603b507f0 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Attempting to driver detach volume 0717510f-1334-470c-8a41-9c254fb41b83 from mountpoint /dev/vdb
2022-02-22 17:10:59.561 7 INFO nova.virt.libvirt.driver [req-fca9e99f-c19f-4643-ac35-838603b507f0 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance 1818efef-12e0-41cb-b5d5-052a9a6d82a9 from the persistent domain config.
2022-02-22 17:10:59.703 7 INFO nova.virt.libvirt.driver [req-fca9e99f-c19f-4643-ac35-838603b507f0 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Successfully detached device vdb from instance 1818efef-12e0-41cb-b5d5-052a9a6d82a9 from the live domain config.
2022-02-22 17:10:59.706 7 INFO os_brick.initiator.connectors.lightos [req-fca9e99f-c19f-4643-ac35-838603b507f0 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 88e6678b-1d7b-4884-982f-aacfa7868f53
2022-02-22 17:11:02.915 7 INFO nova.compute.manager [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Terminating instance
2022-02-22 17:11:03.267 7 INFO nova.virt.libvirt.driver [-] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Instance destroyed successfully.
2022-02-22 17:11:03.283 7 INFO nova.virt.libvirt.driver [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Deleting instance files /var/lib/nova/instances/1818efef-12e0-41cb-b5d5-052a9a6d82a9_del
2022-02-22 17:11:03.284 7 INFO nova.virt.libvirt.driver [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Deletion of /var/lib/nova/instances/1818efef-12e0-41cb-b5d5-052a9a6d82a9_del complete
2022-02-22 17:11:03.349 7 INFO nova.virt.libvirt.host [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] UEFI support detected
2022-02-22 17:11:03.351 7 INFO nova.compute.manager [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:03.417 7 INFO nova.compute.manager [-] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:11:03.618 7 INFO nova.scheduler.client.report [req-cf83aba0-7d9c-4a7a-847a-894da9707789 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Deleted allocations for instance 1818efef-12e0-41cb-b5d5-052a9a6d82a9
2022-02-22 17:11:05.308 7 INFO nova.compute.manager [req-01f39b13-5f3c-4d89-9e2c-91e782dbc94f a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Terminating instance
2022-02-22 17:11:05.647 7 INFO nova.virt.libvirt.driver [-] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Instance destroyed successfully.
2022-02-22 17:11:05.662 7 INFO nova.virt.libvirt.driver [req-01f39b13-5f3c-4d89-9e2c-91e782dbc94f a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Deleting instance files /var/lib/nova/instances/fcc441fc-332b-4fb1-a57c-41e06243e05e_del
2022-02-22 17:11:05.664 7 INFO nova.virt.libvirt.driver [req-01f39b13-5f3c-4d89-9e2c-91e782dbc94f a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Deletion of /var/lib/nova/instances/fcc441fc-332b-4fb1-a57c-41e06243e05e_del complete
2022-02-22 17:11:05.728 7 INFO nova.compute.manager [req-01f39b13-5f3c-4d89-9e2c-91e782dbc94f a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:05.792 7 INFO nova.compute.manager [-] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:11:05.989 7 INFO nova.scheduler.client.report [req-01f39b13-5f3c-4d89-9e2c-91e782dbc94f a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Deleted allocations for instance fcc441fc-332b-4fb1-a57c-41e06243e05e
2022-02-22 17:11:06.546 7 INFO nova.compute.manager [req-bdf24c11-8c09-4add-a28b-2d1c876a7bc9 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Terminating instance
2022-02-22 17:11:06.886 7 INFO nova.virt.libvirt.driver [-] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Instance destroyed successfully.
2022-02-22 17:11:06.908 7 INFO nova.virt.libvirt.driver [req-bdf24c11-8c09-4add-a28b-2d1c876a7bc9 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Deleting instance files /var/lib/nova/instances/0e3fc636-9e1f-4bea-ad0b-3b88163cf320_del
2022-02-22 17:11:06.910 7 INFO nova.virt.libvirt.driver [req-bdf24c11-8c09-4add-a28b-2d1c876a7bc9 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Deletion of /var/lib/nova/instances/0e3fc636-9e1f-4bea-ad0b-3b88163cf320_del complete
2022-02-22 17:11:06.980 7 INFO nova.compute.manager [req-bdf24c11-8c09-4add-a28b-2d1c876a7bc9 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:07.049 7 INFO nova.compute.manager [-] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:11:07.250 7 INFO nova.scheduler.client.report [req-bdf24c11-8c09-4add-a28b-2d1c876a7bc9 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Deleted allocations for instance 0e3fc636-9e1f-4bea-ad0b-3b88163cf320
2022-02-22 17:11:08.942 7 INFO nova.compute.manager [req-145fec1a-23c2-4bdc-a34f-3577686cc116 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Terminating instance
2022-02-22 17:11:09.283 7 INFO nova.virt.libvirt.driver [-] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Instance destroyed successfully.
2022-02-22 17:11:09.297 7 INFO nova.virt.libvirt.driver [req-145fec1a-23c2-4bdc-a34f-3577686cc116 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Deleting instance files /var/lib/nova/instances/db0092be-8035-476d-97d1-9a8daf38f5e1_del
2022-02-22 17:11:09.299 7 INFO nova.virt.libvirt.driver [req-145fec1a-23c2-4bdc-a34f-3577686cc116 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Deletion of /var/lib/nova/instances/db0092be-8035-476d-97d1-9a8daf38f5e1_del complete
2022-02-22 17:11:09.367 7 INFO nova.compute.manager [req-145fec1a-23c2-4bdc-a34f-3577686cc116 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:09.435 7 INFO nova.compute.manager [-] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:11:09.635 7 INFO nova.scheduler.client.report [req-145fec1a-23c2-4bdc-a34f-3577686cc116 a35391ed34784f8f9c12db76eeff7575 b6602d618c644b988f47265716011500 - default default] Deleted allocations for instance db0092be-8035-476d-97d1-9a8daf38f5e1
2022-02-22 17:11:15.154 7 INFO nova.compute.claims [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Claim successful on node rack08-server63
2022-02-22 17:11:15.424 7 INFO nova.virt.libvirt.driver [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 17:11:15.510 7 INFO nova.virt.block_device [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Booting with volume 6c7cdd93-f33d-40c5-8149-39f0fb1f7191 at /dev/vda
2022-02-22 17:11:15.598 7 WARNING os_brick.initiator.connectors.nvmeof [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:11:17.132 7 INFO nova.virt.libvirt.driver [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Creating image
2022-02-22 17:11:17.143 7 INFO os_brick.initiator.connectors.lightos [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: connect_volume called for volume 65aa27f8-244d-4d78-84f6-661bdfafaf81, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '65aa27f8-244d-4d78-84f6-661bdfafaf81', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:11:17.146 7 INFO os_brick.initiator.connectors.lightos [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 65aa27f8-244d-4d78-84f6-661bdfafaf81
2022-02-22 17:11:17.971 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] VM Resumed (Lifecycle Event)
2022-02-22 17:11:17.978 7 INFO nova.virt.libvirt.driver [-] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Instance spawned successfully.
2022-02-22 17:11:17.979 7 INFO nova.compute.manager [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Took 0.85 seconds to spawn the instance on the hypervisor.
2022-02-22 17:11:18.027 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:11:18.028 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] VM Started (Lifecycle Event)
2022-02-22 17:11:18.069 7 INFO nova.compute.manager [req-6861f2bd-5fa1-4a5c-aae9-28901ebcf53d 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Took 2.96 seconds to build instance.
2022-02-22 17:11:18.265 7 INFO nova.compute.manager [-] [instance: 1818efef-12e0-41cb-b5d5-052a9a6d82a9] VM Stopped (Lifecycle Event)
2022-02-22 17:11:20.388 7 INFO nova.compute.manager [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Terminating instance
2022-02-22 17:11:20.646 7 INFO nova.compute.manager [-] [instance: fcc441fc-332b-4fb1-a57c-41e06243e05e] VM Stopped (Lifecycle Event)
2022-02-22 17:11:20.724 7 INFO nova.virt.libvirt.driver [-] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Instance destroyed successfully.
2022-02-22 17:11:20.799 7 INFO os_brick.initiator.connectors.lightos [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 65aa27f8-244d-4d78-84f6-661bdfafaf81
2022-02-22 17:11:20.811 7 INFO nova.virt.libvirt.driver [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Deleting instance files /var/lib/nova/instances/d14e8ec0-51cc-4e94-861b-2670ef675c74_del
2022-02-22 17:11:20.812 7 INFO nova.virt.libvirt.driver [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Deletion of /var/lib/nova/instances/d14e8ec0-51cc-4e94-861b-2670ef675c74_del complete
2022-02-22 17:11:20.883 7 INFO nova.compute.manager [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:20.949 7 INFO nova.compute.manager [-] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:11:21.881 7 INFO nova.compute.manager [-] [instance: 0e3fc636-9e1f-4bea-ad0b-3b88163cf320] VM Stopped (Lifecycle Event)
2022-02-22 17:11:22.189 7 INFO nova.compute.manager [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 17:11:22.387 7 INFO nova.scheduler.client.report [req-2339ee95-ca17-4845-a6a3-0d493b3cf3d8 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Deleted allocations for instance d14e8ec0-51cc-4e94-861b-2670ef675c74
2022-02-22 17:11:24.282 7 INFO nova.compute.manager [-] [instance: db0092be-8035-476d-97d1-9a8daf38f5e1] VM Stopped (Lifecycle Event)
2022-02-22 17:11:25.296 7 INFO nova.compute.manager [req-66037182-ace6-44ae-969a-3983733287c6 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Terminating instance
2022-02-22 17:11:25.645 7 INFO nova.virt.libvirt.driver [-] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Instance destroyed successfully.
2022-02-22 17:11:25.660 7 INFO nova.virt.libvirt.driver [req-66037182-ace6-44ae-969a-3983733287c6 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Deleting instance files /var/lib/nova/instances/4e9ed0f4-168a-489d-984f-5769605fcd93_del
2022-02-22 17:11:25.662 7 INFO nova.virt.libvirt.driver [req-66037182-ace6-44ae-969a-3983733287c6 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Deletion of /var/lib/nova/instances/4e9ed0f4-168a-489d-984f-5769605fcd93_del complete
2022-02-22 17:11:25.729 7 INFO nova.compute.manager [req-66037182-ace6-44ae-969a-3983733287c6 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:25.794 7 INFO nova.compute.manager [-] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:11:25.986 7 INFO nova.scheduler.client.report [req-66037182-ace6-44ae-969a-3983733287c6 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Deleted allocations for instance 4e9ed0f4-168a-489d-984f-5769605fcd93
2022-02-22 17:11:26.555 7 INFO nova.compute.manager [req-b1bf8018-57b3-4bb2-9c91-5fe76788739b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Terminating instance
2022-02-22 17:11:26.890 7 INFO nova.virt.libvirt.driver [-] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Instance destroyed successfully.
2022-02-22 17:11:26.906 7 INFO nova.virt.libvirt.driver [req-b1bf8018-57b3-4bb2-9c91-5fe76788739b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Deleting instance files /var/lib/nova/instances/690fb8ed-9df1-449d-98bd-8bb96be2dd64_del
2022-02-22 17:11:26.908 7 INFO nova.virt.libvirt.driver [req-b1bf8018-57b3-4bb2-9c91-5fe76788739b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Deletion of /var/lib/nova/instances/690fb8ed-9df1-449d-98bd-8bb96be2dd64_del complete
2022-02-22 17:11:26.974 7 INFO nova.compute.manager [req-b1bf8018-57b3-4bb2-9c91-5fe76788739b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:27.039 7 INFO nova.compute.manager [-] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:11:27.259 7 INFO nova.scheduler.client.report [req-b1bf8018-57b3-4bb2-9c91-5fe76788739b 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Deleted allocations for instance 690fb8ed-9df1-449d-98bd-8bb96be2dd64
2022-02-22 17:11:27.816 7 INFO nova.compute.manager [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Terminating instance
2022-02-22 17:11:28.157 7 INFO nova.virt.libvirt.driver [-] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Instance destroyed successfully.
2022-02-22 17:11:28.239 7 INFO os_brick.initiator.connectors.lightos [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 8619e60a-4903-46a8-ae8d-eb7907ad012e
2022-02-22 17:11:28.250 7 INFO nova.virt.libvirt.driver [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Deleting instance files /var/lib/nova/instances/4591b3a7-e583-4635-aeaa-5fe7b0511353_del
2022-02-22 17:11:28.251 7 INFO nova.virt.libvirt.driver [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Deletion of /var/lib/nova/instances/4591b3a7-e583-4635-aeaa-5fe7b0511353_del complete
2022-02-22 17:11:28.318 7 INFO nova.compute.manager [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:28.382 7 INFO nova.compute.manager [-] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:11:29.627 7 INFO nova.compute.manager [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 17:11:29.832 7 INFO nova.scheduler.client.report [req-f66e1ba0-e05d-40ae-a3a6-43e457ec7fdd 5070ea2188c14d2994be67da7581d8d1 24945b08301047c6a0c03bfff171f495 - default default] Deleted allocations for instance 4591b3a7-e583-4635-aeaa-5fe7b0511353
2022-02-22 17:11:34.570 7 INFO nova.compute.claims [req-54f5f1f1-4680-48b5-b01d-fb9eb01987fb 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Claim successful on node rack08-server63
2022-02-22 17:11:34.972 7 INFO nova.virt.libvirt.driver [req-54f5f1f1-4680-48b5-b01d-fb9eb01987fb 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Creating image
2022-02-22 17:11:35.721 7 INFO nova.compute.manager [-] [instance: d14e8ec0-51cc-4e94-861b-2670ef675c74] VM Stopped (Lifecycle Event)
2022-02-22 17:11:36.137 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] VM Resumed (Lifecycle Event)
2022-02-22 17:11:36.147 7 INFO nova.virt.libvirt.driver [-] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Instance spawned successfully.
2022-02-22 17:11:36.147 7 INFO nova.compute.manager [req-54f5f1f1-4680-48b5-b01d-fb9eb01987fb 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 17:11:36.190 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:11:36.191 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] VM Started (Lifecycle Event)
2022-02-22 17:11:36.237 7 INFO nova.compute.manager [req-54f5f1f1-4680-48b5-b01d-fb9eb01987fb 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Took 1.71 seconds to build instance.
2022-02-22 17:11:36.845 7 INFO nova.compute.manager [req-6ce23e06-cb33-42bb-aa22-4d44f13b059c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Terminating instance
2022-02-22 17:11:37.835 7 INFO nova.virt.libvirt.driver [-] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Instance destroyed successfully.
2022-02-22 17:11:37.850 7 INFO nova.virt.libvirt.driver [req-6ce23e06-cb33-42bb-aa22-4d44f13b059c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Deleting instance files /var/lib/nova/instances/7e4121ab-8c52-48f9-a343-5522e1dc4e23_del
2022-02-22 17:11:37.851 7 INFO nova.virt.libvirt.driver [req-6ce23e06-cb33-42bb-aa22-4d44f13b059c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Deletion of /var/lib/nova/instances/7e4121ab-8c52-48f9-a343-5522e1dc4e23_del complete
2022-02-22 17:11:37.916 7 INFO nova.compute.manager [req-6ce23e06-cb33-42bb-aa22-4d44f13b059c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:37.988 7 INFO nova.compute.manager [-] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:11:38.156 7 INFO nova.scheduler.client.report [req-6ce23e06-cb33-42bb-aa22-4d44f13b059c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] Deleted allocations for instance 7e4121ab-8c52-48f9-a343-5522e1dc4e23
2022-02-22 17:11:40.297 7 INFO nova.compute.claims [req-8510c10f-ecb5-4ac9-b58d-a4c7a835214c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Claim successful on node rack08-server63
2022-02-22 17:11:40.642 7 INFO nova.compute.manager [-] [instance: 4e9ed0f4-168a-489d-984f-5769605fcd93] VM Stopped (Lifecycle Event)
2022-02-22 17:11:40.700 7 INFO nova.virt.libvirt.driver [req-8510c10f-ecb5-4ac9-b58d-a4c7a835214c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Creating image
2022-02-22 17:11:41.888 7 INFO nova.compute.manager [-] [instance: 690fb8ed-9df1-449d-98bd-8bb96be2dd64] VM Stopped (Lifecycle Event)
2022-02-22 17:11:41.916 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] VM Resumed (Lifecycle Event)
2022-02-22 17:11:41.924 7 INFO nova.virt.libvirt.driver [-] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Instance spawned successfully.
2022-02-22 17:11:41.925 7 INFO nova.compute.manager [req-8510c10f-ecb5-4ac9-b58d-a4c7a835214c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-22 17:11:41.969 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:11:41.970 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] VM Started (Lifecycle Event)
2022-02-22 17:11:42.012 7 INFO nova.compute.manager [req-8510c10f-ecb5-4ac9-b58d-a4c7a835214c 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Took 1.75 seconds to build instance.
2022-02-22 17:11:42.610 7 INFO nova.compute.manager [req-ffd7bb38-4e43-4bad-8585-98fce27efed8 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Terminating instance
2022-02-22 17:11:42.970 7 INFO nova.virt.libvirt.driver [-] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Instance destroyed successfully.
2022-02-22 17:11:42.986 7 INFO nova.virt.libvirt.driver [req-ffd7bb38-4e43-4bad-8585-98fce27efed8 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Deleting instance files /var/lib/nova/instances/2bb5f913-c0cf-41ba-90db-dc3b6cd53075_del
2022-02-22 17:11:42.987 7 INFO nova.virt.libvirt.driver [req-ffd7bb38-4e43-4bad-8585-98fce27efed8 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Deletion of /var/lib/nova/instances/2bb5f913-c0cf-41ba-90db-dc3b6cd53075_del complete
2022-02-22 17:11:43.056 7 INFO nova.compute.manager [req-ffd7bb38-4e43-4bad-8585-98fce27efed8 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:11:43.127 7 INFO nova.compute.manager [-] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:11:43.155 7 INFO nova.compute.manager [-] [instance: 4591b3a7-e583-4635-aeaa-5fe7b0511353] VM Stopped (Lifecycle Event)
2022-02-22 17:11:43.316 7 INFO nova.scheduler.client.report [req-ffd7bb38-4e43-4bad-8585-98fce27efed8 8ad34041108e4a8189462cd3cd70b065 2e563344d96f4798965f10228237e489 - default default] Deleted allocations for instance 2bb5f913-c0cf-41ba-90db-dc3b6cd53075
2022-02-22 17:11:52.832 7 INFO nova.compute.manager [-] [instance: 7e4121ab-8c52-48f9-a343-5522e1dc4e23] VM Stopped (Lifecycle Event)
2022-02-22 17:11:57.967 7 INFO nova.compute.manager [-] [instance: 2bb5f913-c0cf-41ba-90db-dc3b6cd53075] VM Stopped (Lifecycle Event)
2022-02-22 17:12:43.018 7 INFO nova.compute.claims [req-43d6d361-2de5-4bd1-b06e-47e7ea782197 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Claim successful on node rack08-server63
2022-02-22 17:12:43.423 7 INFO nova.virt.libvirt.driver [req-43d6d361-2de5-4bd1-b06e-47e7ea782197 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Creating image
2022-02-22 17:12:44.572 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] VM Resumed (Lifecycle Event)
2022-02-22 17:12:44.581 7 INFO nova.virt.libvirt.driver [-] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Instance spawned successfully.
2022-02-22 17:12:44.581 7 INFO nova.compute.manager [req-43d6d361-2de5-4bd1-b06e-47e7ea782197 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 17:12:44.629 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:12:44.630 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] VM Started (Lifecycle Event)
2022-02-22 17:12:44.665 7 INFO nova.compute.manager [req-43d6d361-2de5-4bd1-b06e-47e7ea782197 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Took 1.69 seconds to build instance.
2022-02-22 17:12:44.976 7 INFO nova.compute.manager [req-570bbaaa-0776-47e9-ad96-cc7465195f42 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Terminating instance
2022-02-22 17:12:45.335 7 INFO nova.virt.libvirt.driver [-] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Instance destroyed successfully.
2022-02-22 17:12:45.353 7 INFO nova.virt.libvirt.driver [req-570bbaaa-0776-47e9-ad96-cc7465195f42 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Deleting instance files /var/lib/nova/instances/750aebda-8c39-4fd7-a1ea-dfe22133ef4b_del
2022-02-22 17:12:45.354 7 INFO nova.virt.libvirt.driver [req-570bbaaa-0776-47e9-ad96-cc7465195f42 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Deletion of /var/lib/nova/instances/750aebda-8c39-4fd7-a1ea-dfe22133ef4b_del complete
2022-02-22 17:12:45.422 7 INFO nova.compute.manager [req-570bbaaa-0776-47e9-ad96-cc7465195f42 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:12:45.488 7 INFO nova.compute.manager [-] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:12:45.688 7 INFO nova.scheduler.client.report [req-570bbaaa-0776-47e9-ad96-cc7465195f42 8c572c8392b64f80a43fe52e4953a670 b8c663940b00432399c190cf84cd5895 - default default] Deleted allocations for instance 750aebda-8c39-4fd7-a1ea-dfe22133ef4b
2022-02-22 17:12:55.845 7 INFO nova.compute.claims [req-f318b0f5-cfcf-4f13-9619-d89ede120ef0 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Claim successful on node rack08-server63
2022-02-22 17:12:56.227 7 INFO nova.virt.libvirt.driver [req-f318b0f5-cfcf-4f13-9619-d89ede120ef0 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Creating image
2022-02-22 17:12:57.517 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] VM Resumed (Lifecycle Event)
2022-02-22 17:12:57.525 7 INFO nova.virt.libvirt.driver [-] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Instance spawned successfully.
2022-02-22 17:12:57.526 7 INFO nova.compute.manager [req-f318b0f5-cfcf-4f13-9619-d89ede120ef0 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-22 17:12:57.612 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] VM Started (Lifecycle Event)
2022-02-22 17:12:57.615 7 INFO nova.compute.manager [req-f318b0f5-cfcf-4f13-9619-d89ede120ef0 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Took 1.81 seconds to build instance.
2022-02-22 17:13:00.334 7 INFO nova.compute.manager [-] [instance: 750aebda-8c39-4fd7-a1ea-dfe22133ef4b] VM Stopped (Lifecycle Event)
2022-02-22 17:13:10.962 7 INFO nova.virt.libvirt.driver [req-e27c6a17-6747-42c3-a4ec-ef4695f920a1 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Ignoring supplied device name: /dev/vdb
2022-02-22 17:13:11.112 7 INFO nova.compute.manager [req-e27c6a17-6747-42c3-a4ec-ef4695f920a1 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Attaching volume 58813207-985e-45be-ab76-2a49e5b5b795 to /dev/vdb
2022-02-22 17:13:11.203 7 WARNING os_brick.initiator.connectors.nvmeof [req-e27c6a17-6747-42c3-a4ec-ef4695f920a1 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:13:12.552 7 INFO os_brick.initiator.connectors.lightos [req-e27c6a17-6747-42c3-a4ec-ef4695f920a1 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: connect_volume called for volume 0687bd08-580e-4ff2-9d38-e8bdd150ef54, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '0687bd08-580e-4ff2-9d38-e8bdd150ef54', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:13:12.556 7 INFO os_brick.initiator.connectors.lightos [req-e27c6a17-6747-42c3-a4ec-ef4695f920a1 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 0687bd08-580e-4ff2-9d38-e8bdd150ef54
2022-02-22 17:13:14.884 7 INFO nova.compute.claims [req-2fdde3f1-5976-4fff-9f58-97c8f0e677bb b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Claim successful on node rack08-server63
2022-02-22 17:13:15.301 7 INFO nova.virt.libvirt.driver [req-2fdde3f1-5976-4fff-9f58-97c8f0e677bb b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Creating image
2022-02-22 17:13:16.458 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] VM Resumed (Lifecycle Event)
2022-02-22 17:13:16.469 7 INFO nova.virt.libvirt.driver [-] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Instance spawned successfully.
2022-02-22 17:13:16.469 7 INFO nova.compute.manager [req-2fdde3f1-5976-4fff-9f58-97c8f0e677bb b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 17:13:16.518 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:13:16.519 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] VM Started (Lifecycle Event)
2022-02-22 17:13:16.557 7 INFO nova.compute.manager [req-2fdde3f1-5976-4fff-9f58-97c8f0e677bb b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Took 1.71 seconds to build instance.
2022-02-22 17:13:20.353 7 INFO nova.compute.manager [req-63195220-4fae-465a-9663-288ba782f679 b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Terminating instance
2022-02-22 17:13:20.696 7 INFO nova.virt.libvirt.driver [-] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Instance destroyed successfully.
2022-02-22 17:13:20.712 7 INFO nova.virt.libvirt.driver [req-63195220-4fae-465a-9663-288ba782f679 b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Deleting instance files /var/lib/nova/instances/5b6532d1-ce48-489a-84e7-5ad2256d7170_del
2022-02-22 17:13:20.713 7 INFO nova.virt.libvirt.driver [req-63195220-4fae-465a-9663-288ba782f679 b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Deletion of /var/lib/nova/instances/5b6532d1-ce48-489a-84e7-5ad2256d7170_del complete
2022-02-22 17:13:20.778 7 INFO nova.compute.manager [req-63195220-4fae-465a-9663-288ba782f679 b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:13:20.841 7 INFO nova.compute.manager [-] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] Took 0.06 seconds to deallocate network for instance.
2022-02-22 17:13:21.035 7 INFO nova.scheduler.client.report [req-63195220-4fae-465a-9663-288ba782f679 b805a7cfc2fd490e8c4bae64aeb55668 1332cb2601274cbba8b8ebc62517b6ae - default default] Deleted allocations for instance 5b6532d1-ce48-489a-84e7-5ad2256d7170
2022-02-22 17:13:24.734 7 INFO nova.compute.manager [req-2e4a2317-8d13-4ad1-b86c-659a07f90944 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Detaching volume 58813207-985e-45be-ab76-2a49e5b5b795
2022-02-22 17:13:24.795 7 INFO nova.virt.block_device [req-2e4a2317-8d13-4ad1-b86c-659a07f90944 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Attempting to driver detach volume 58813207-985e-45be-ab76-2a49e5b5b795 from mountpoint /dev/vdb
2022-02-22 17:13:24.814 7 INFO nova.virt.libvirt.driver [req-2e4a2317-8d13-4ad1-b86c-659a07f90944 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Successfully detached device vdb from instance 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6 from the persistent domain config.
2022-02-22 17:13:24.968 7 INFO nova.virt.libvirt.driver [req-2e4a2317-8d13-4ad1-b86c-659a07f90944 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Successfully detached device vdb from instance 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6 from the live domain config.
2022-02-22 17:13:24.971 7 INFO os_brick.initiator.connectors.lightos [req-2e4a2317-8d13-4ad1-b86c-659a07f90944 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 0687bd08-580e-4ff2-9d38-e8bdd150ef54
2022-02-22 17:13:26.992 7 INFO nova.compute.manager [req-2f2b676b-a55d-488f-9fe8-d91e5f6c6832 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Terminating instance
2022-02-22 17:13:27.341 7 INFO nova.virt.libvirt.driver [-] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Instance destroyed successfully.
2022-02-22 17:13:27.357 7 INFO nova.virt.libvirt.driver [req-2f2b676b-a55d-488f-9fe8-d91e5f6c6832 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Deleting instance files /var/lib/nova/instances/2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6_del
2022-02-22 17:13:27.358 7 INFO nova.virt.libvirt.driver [req-2f2b676b-a55d-488f-9fe8-d91e5f6c6832 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Deletion of /var/lib/nova/instances/2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6_del complete
2022-02-22 17:13:27.426 7 INFO nova.compute.manager [req-2f2b676b-a55d-488f-9fe8-d91e5f6c6832 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:13:27.499 7 INFO nova.compute.manager [-] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:13:27.707 7 INFO nova.scheduler.client.report [req-2f2b676b-a55d-488f-9fe8-d91e5f6c6832 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Deleted allocations for instance 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6
2022-02-22 17:13:35.448 7 INFO nova.compute.claims [req-671cdd88-2a2d-4fea-826b-37754eaa1e14 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Claim successful on node rack08-server63
2022-02-22 17:13:35.693 7 INFO nova.compute.manager [-] [instance: 5b6532d1-ce48-489a-84e7-5ad2256d7170] VM Stopped (Lifecycle Event)
2022-02-22 17:13:35.829 7 INFO nova.virt.libvirt.driver [req-671cdd88-2a2d-4fea-826b-37754eaa1e14 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Creating image
2022-02-22 17:13:36.959 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d50835dd-4284-4546-bec9-249db481cb0b] VM Resumed (Lifecycle Event)
2022-02-22 17:13:36.966 7 INFO nova.virt.libvirt.driver [-] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Instance spawned successfully.
2022-02-22 17:13:36.966 7 INFO nova.compute.manager [req-671cdd88-2a2d-4fea-826b-37754eaa1e14 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 17:13:37.010 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d50835dd-4284-4546-bec9-249db481cb0b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:13:37.011 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: d50835dd-4284-4546-bec9-249db481cb0b] VM Started (Lifecycle Event)
2022-02-22 17:13:37.052 7 INFO nova.compute.manager [req-671cdd88-2a2d-4fea-826b-37754eaa1e14 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Took 1.96 seconds to build instance.
2022-02-22 17:13:38.214 7 INFO nova.virt.libvirt.driver [req-0fabd61e-5900-4a18-8751-4e8ee4850c67 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Ignoring supplied device name: /dev/vdb
2022-02-22 17:13:38.386 7 INFO nova.compute.manager [req-0fabd61e-5900-4a18-8751-4e8ee4850c67 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Attaching volume 00f893ad-4884-4caf-9b9c-448c8a2d40a4 to /dev/vdb
2022-02-22 17:13:38.473 7 WARNING os_brick.initiator.connectors.nvmeof [req-0fabd61e-5900-4a18-8751-4e8ee4850c67 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:13:39.824 7 INFO os_brick.initiator.connectors.lightos [req-0fabd61e-5900-4a18-8751-4e8ee4850c67 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: connect_volume called for volume 75790999-3c6c-4b0f-99e1-c14917f107ac, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '75790999-3c6c-4b0f-99e1-c14917f107ac', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:13:39.828 7 INFO os_brick.initiator.connectors.lightos [req-0fabd61e-5900-4a18-8751-4e8ee4850c67 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 75790999-3c6c-4b0f-99e1-c14917f107ac
2022-02-22 17:13:42.339 7 INFO nova.compute.manager [-] [instance: 2a0f2f7f-c2c1-4e00-ada3-88fdf84919c6] VM Stopped (Lifecycle Event)
2022-02-22 17:13:48.602 7 INFO nova.compute.manager [req-a36714e3-2164-4f10-a281-4d6277ee8f48 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Detaching volume 00f893ad-4884-4caf-9b9c-448c8a2d40a4
2022-02-22 17:13:48.663 7 INFO nova.virt.block_device [req-a36714e3-2164-4f10-a281-4d6277ee8f48 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Attempting to driver detach volume 00f893ad-4884-4caf-9b9c-448c8a2d40a4 from mountpoint /dev/vdb
2022-02-22 17:13:48.682 7 INFO nova.virt.libvirt.driver [req-a36714e3-2164-4f10-a281-4d6277ee8f48 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Successfully detached device vdb from instance d50835dd-4284-4546-bec9-249db481cb0b from the persistent domain config.
2022-02-22 17:13:48.823 7 INFO nova.virt.libvirt.driver [req-a36714e3-2164-4f10-a281-4d6277ee8f48 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Successfully detached device vdb from instance d50835dd-4284-4546-bec9-249db481cb0b from the live domain config.
2022-02-22 17:13:48.826 7 INFO os_brick.initiator.connectors.lightos [req-a36714e3-2164-4f10-a281-4d6277ee8f48 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 75790999-3c6c-4b0f-99e1-c14917f107ac
2022-02-22 17:13:50.855 7 INFO nova.compute.manager [req-eec2904f-cb78-4649-8212-a60552588be4 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Terminating instance
2022-02-22 17:13:51.194 7 INFO nova.virt.libvirt.driver [-] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Instance destroyed successfully.
2022-02-22 17:13:51.210 7 INFO nova.virt.libvirt.driver [req-eec2904f-cb78-4649-8212-a60552588be4 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Deleting instance files /var/lib/nova/instances/d50835dd-4284-4546-bec9-249db481cb0b_del
2022-02-22 17:13:51.211 7 INFO nova.virt.libvirt.driver [req-eec2904f-cb78-4649-8212-a60552588be4 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Deletion of /var/lib/nova/instances/d50835dd-4284-4546-bec9-249db481cb0b_del complete
2022-02-22 17:13:51.276 7 INFO nova.compute.manager [req-eec2904f-cb78-4649-8212-a60552588be4 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 17:13:51.343 7 INFO nova.compute.manager [-] [instance: d50835dd-4284-4546-bec9-249db481cb0b] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:13:51.514 7 INFO nova.scheduler.client.report [req-eec2904f-cb78-4649-8212-a60552588be4 20e02c0a54434b96a9783831f93f0662 09a3ddcb133c40668c32dfe08462e6e6 - default default] Deleted allocations for instance d50835dd-4284-4546-bec9-249db481cb0b
2022-02-22 17:13:55.009 7 INFO nova.compute.claims [req-1ba15795-9196-444e-87f0-7df45825b353 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Claim successful on node rack08-server63
2022-02-22 17:13:55.430 7 INFO nova.virt.libvirt.driver [req-1ba15795-9196-444e-87f0-7df45825b353 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Creating image
2022-02-22 17:13:56.606 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] VM Resumed (Lifecycle Event)
2022-02-22 17:13:56.614 7 INFO nova.virt.libvirt.driver [-] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Instance spawned successfully.
2022-02-22 17:13:56.615 7 INFO nova.compute.manager [req-1ba15795-9196-444e-87f0-7df45825b353 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 17:13:56.667 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 17:13:56.667 7 INFO nova.compute.manager [req-ae0756e4-e0d6-481e-9af9-291c23bc14ed - - - - -] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] VM Started (Lifecycle Event)
2022-02-22 17:13:56.705 7 INFO nova.compute.manager [req-1ba15795-9196-444e-87f0-7df45825b353 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Took 1.74 seconds to build instance.
2022-02-22 17:13:57.142 7 INFO nova.virt.libvirt.driver [req-8086a427-bd48-4cdd-abba-6e291aabd918 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Ignoring supplied device name: /dev/vdb
2022-02-22 17:13:57.309 7 INFO nova.compute.manager [req-8086a427-bd48-4cdd-abba-6e291aabd918 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Attaching volume 5c54b200-3956-4897-9084-2dfb8634f61d to /dev/vdb
2022-02-22 17:13:57.400 7 WARNING os_brick.initiator.connectors.nvmeof [req-8086a427-bd48-4cdd-abba-6e291aabd918 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 17:13:58.738 7 INFO os_brick.initiator.connectors.lightos [req-8086a427-bd48-4cdd-abba-6e291aabd918 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] LIGHTOS: connect_volume called for volume 64ccd39f-d670-478f-9d4e-137db8b0c40c, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '64ccd39f-d670-478f-9d4e-137db8b0c40c', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 17:13:58.742 7 INFO os_brick.initiator.connectors.lightos [req-8086a427-bd48-4cdd-abba-6e291aabd918 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 64ccd39f-d670-478f-9d4e-137db8b0c40c
2022-02-22 17:14:01.003 7 INFO nova.compute.manager [req-2c67521c-60a0-48b1-a4be-2fc200ddb187 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Cinder extended volume 5c54b200-3956-4897-9084-2dfb8634f61d; extending it to detect new size
2022-02-22 17:14:01.083 7 INFO os_brick.initiator.connectors.lightos [req-2c67521c-60a0-48b1-a4be-2fc200ddb187 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 64ccd39f-d670-478f-9d4e-137db8b0c40c
2022-02-22 17:14:01.702 7 INFO nova.compute.manager [req-cfe93654-4053-4500-925b-b34b59ba71e9 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Detaching volume 5c54b200-3956-4897-9084-2dfb8634f61d
2022-02-22 17:14:01.756 7 INFO nova.virt.block_device [req-cfe93654-4053-4500-925b-b34b59ba71e9 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Attempting to driver detach volume 5c54b200-3956-4897-9084-2dfb8634f61d from mountpoint /dev/vdb
2022-02-22 17:14:01.775 7 INFO nova.virt.libvirt.driver [req-cfe93654-4053-4500-925b-b34b59ba71e9 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] Successfully detached device vdb from instance 2015be74-f64c-4de7-895b-113e6d264edb from the persistent domain config.
2022-02-22 17:14:01.929 7 INFO nova.virt.libvirt.driver [req-cfe93654-4053-4500-925b-b34b59ba71e9 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] Successfully detached device vdb from instance 2015be74-f64c-4de7-895b-113e6d264edb from the live domain config.
2022-02-22 17:14:01.932 7 INFO os_brick.initiator.connectors.lightos [req-cfe93654-4053-4500-925b-b34b59ba71e9 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 64ccd39f-d670-478f-9d4e-137db8b0c40c
2022-02-22 17:14:03.948 7 INFO nova.compute.manager [req-7ce50cd3-4b48-4dc8-b6c4-27771b159a16 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Terminating instance
2022-02-22 17:14:04.294 7 INFO nova.virt.libvirt.driver [-] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Instance destroyed successfully.
2022-02-22 17:14:04.310 7 INFO nova.virt.libvirt.driver [req-7ce50cd3-4b48-4dc8-b6c4-27771b159a16 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Deleting instance files /var/lib/nova/instances/2015be74-f64c-4de7-895b-113e6d264edb_del
2022-02-22 17:14:04.311 7 INFO nova.virt.libvirt.driver [req-7ce50cd3-4b48-4dc8-b6c4-27771b159a16 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Deletion of /var/lib/nova/instances/2015be74-f64c-4de7-895b-113e6d264edb_del complete
2022-02-22 17:14:04.379 7 INFO nova.compute.manager [req-7ce50cd3-4b48-4dc8-b6c4-27771b159a16 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 17:14:04.450 7 INFO nova.compute.manager [-] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] Took 0.07 seconds to deallocate network for instance.
2022-02-22 17:14:04.643 7 INFO nova.scheduler.client.report [req-7ce50cd3-4b48-4dc8-b6c4-27771b159a16 2be0ba1ca8174b6c8c94d737c8a0f3ee f759954922874510819904394ea4ec30 - default default] Deleted allocations for instance 2015be74-f64c-4de7-895b-113e6d264edb
2022-02-22 17:14:06.192 7 INFO nova.compute.manager [-] [instance: d50835dd-4284-4546-bec9-249db481cb0b] VM Stopped (Lifecycle Event)
2022-02-22 17:14:19.292 7 INFO nova.compute.manager [-] [instance: 2015be74-f64c-4de7-895b-113e6d264edb] VM Stopped (Lifecycle Event)
