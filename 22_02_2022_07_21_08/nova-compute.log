Build Started 22_02_2022_07_21_08
2022-02-22 09:23:01.581 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 09:23:05.649 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 09:23:06.576 7 INFO nova.virt.driver [req-c1ee3152-e5a0-4fa7-8e0d-732fb58e7b7c - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 09:23:06.965 7 INFO nova.compute.provider_config [req-c1ee3152-e5a0-4fa7-8e0d-732fb58e7b7c - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 09:23:06.984 7 WARNING oslo_config.cfg [req-c1ee3152-e5a0-4fa7-8e0d-732fb58e7b7c - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 09:23:07.006 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 09:23:07.019 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 09:23:07.061 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 09:23:07.172 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 09:23:07.187 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 09:23:07.189 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 09:23:07.594 7 INFO nova.compute.manager [req-728b10eb-3fc4-4f30-9137-aac8d8d2ba9f - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 09:23:09.412 7 INFO nova.virt.libvirt.host [req-728b10eb-3fc4-4f30-9137-aac8d8d2ba9f - - - - -] kernel doesn't support AMD SEV
2022-02-22 09:24:00.206 7 INFO nova.compute.claims [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Claim successful on node rack08-server63
2022-02-22 09:24:00.616 7 INFO nova.virt.libvirt.driver [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Creating image
2022-02-22 09:24:00.622 7 INFO oslo.privsep.daemon [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpc8ntgm6f/privsep.sock']
2022-02-22 09:24:02.263 7 INFO oslo.privsep.daemon [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Spawned new privsep daemon via rootwrap
2022-02-22 09:24:02.113 69 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 09:24:02.119 69 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 09:24:02.124 69 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 09:24:02.125 69 INFO oslo.privsep.daemon [-] privsep daemon running as pid 69
2022-02-22 09:24:03.527 7 INFO nova.compute.manager [-] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] VM Resumed (Lifecycle Event)
2022-02-22 09:24:03.535 7 INFO nova.virt.libvirt.driver [-] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Instance spawned successfully.
2022-02-22 09:24:03.536 7 INFO nova.compute.manager [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Took 2.92 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:03.582 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:03.583 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] VM Started (Lifecycle Event)
2022-02-22 09:24:03.623 7 INFO nova.compute.manager [req-91c76665-b8ed-4249-ac5f-60fd4094a359 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Took 3.46 seconds to build instance.
2022-02-22 09:24:07.053 7 INFO nova.compute.manager [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Attaching volume 8fd3a4ea-081b-4a82-80a6-4fd1048562e5 to /dev/vdb
2022-02-22 09:24:07.136 7 INFO oslo.privsep.daemon [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpqs6iy6c0/privsep.sock']
2022-02-22 09:24:07.801 7 INFO oslo.privsep.daemon [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Spawned new privsep daemon via rootwrap
2022-02-22 09:24:07.720 100 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 09:24:07.728 100 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 09:24:07.733 100 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 09:24:07.733 100 INFO oslo.privsep.daemon [-] privsep daemon running as pid 100
2022-02-22 09:24:08.125 7 WARNING os_brick.initiator.connectors.nvmeof [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:24:09.443 7 INFO os_brick.initiator.connectors.lightos [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: connect_volume called for volume 754d6522-e17f-4971-aff9-059a2ae32e18, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '754d6522-e17f-4971-aff9-059a2ae32e18', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:24:09.479 7 INFO os_brick.initiator.connectors.lightos [req-59766827-fbeb-4bb2-9ece-5473daecaa3f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 754d6522-e17f-4971-aff9-059a2ae32e18
2022-02-22 09:24:11.753 7 INFO nova.compute.claims [req-27be845e-e039-43fd-aa0a-00438d68e2e3 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Claim successful on node rack08-server63
2022-02-22 09:24:12.142 7 INFO nova.virt.libvirt.driver [req-27be845e-e039-43fd-aa0a-00438d68e2e3 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Creating image
2022-02-22 09:24:13.252 7 INFO nova.compute.claims [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Claim successful on node rack08-server63
2022-02-22 09:24:13.337 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] VM Resumed (Lifecycle Event)
2022-02-22 09:24:13.354 7 INFO nova.virt.libvirt.driver [-] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Instance spawned successfully.
2022-02-22 09:24:13.354 7 INFO nova.compute.manager [req-27be845e-e039-43fd-aa0a-00438d68e2e3 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:13.389 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:13.390 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] VM Started (Lifecycle Event)
2022-02-22 09:24:13.436 7 INFO nova.compute.manager [req-27be845e-e039-43fd-aa0a-00438d68e2e3 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Took 1.73 seconds to build instance.
2022-02-22 09:24:13.499 7 INFO nova.virt.libvirt.driver [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 09:24:13.586 7 INFO nova.virt.block_device [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Booting with volume 6bf4ef8e-2710-4230-a2af-743c6871e845 at /dev/vda
2022-02-22 09:24:13.673 7 WARNING os_brick.initiator.connectors.nvmeof [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:24:14.919 7 INFO nova.compute.manager [req-3b6bebbc-79e8-4d6e-8fa2-32a484c45ffe 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Detaching volume 8fd3a4ea-081b-4a82-80a6-4fd1048562e5
2022-02-22 09:24:14.980 7 INFO nova.virt.block_device [req-3b6bebbc-79e8-4d6e-8fa2-32a484c45ffe 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Attempting to driver detach volume 8fd3a4ea-081b-4a82-80a6-4fd1048562e5 from mountpoint /dev/vdb
2022-02-22 09:24:14.999 7 INFO nova.virt.libvirt.driver [req-3b6bebbc-79e8-4d6e-8fa2-32a484c45ffe 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance 3cc71329-f774-4959-bd13-e09e2d6795e8 from the persistent domain config.
2022-02-22 09:24:15.113 7 INFO nova.virt.libvirt.driver [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Creating image
2022-02-22 09:24:15.124 7 INFO os_brick.initiator.connectors.lightos [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: connect_volume called for volume 46496465-7dca-40a9-9099-9b1dfad3bb3d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '46496465-7dca-40a9-9099-9b1dfad3bb3d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:24:15.127 7 INFO os_brick.initiator.connectors.lightos [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 46496465-7dca-40a9-9099-9b1dfad3bb3d
2022-02-22 09:24:15.141 7 INFO nova.virt.libvirt.driver [req-3b6bebbc-79e8-4d6e-8fa2-32a484c45ffe 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance 3cc71329-f774-4959-bd13-e09e2d6795e8 from the live domain config.
2022-02-22 09:24:15.144 7 INFO os_brick.initiator.connectors.lightos [req-3b6bebbc-79e8-4d6e-8fa2-32a484c45ffe 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 754d6522-e17f-4971-aff9-059a2ae32e18
2022-02-22 09:24:16.055 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] VM Resumed (Lifecycle Event)
2022-02-22 09:24:16.063 7 INFO nova.virt.libvirt.driver [-] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Instance spawned successfully.
2022-02-22 09:24:16.064 7 INFO nova.compute.manager [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Took 0.95 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:16.109 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:16.109 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] VM Started (Lifecycle Event)
2022-02-22 09:24:16.151 7 INFO nova.compute.manager [req-256cded6-91b1-422c-a942-ea0677b25e84 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Took 2.94 seconds to build instance.
2022-02-22 09:24:18.454 7 INFO nova.compute.claims [req-e4e80ecf-f1ce-4ebf-868a-a5f1af668553 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Claim successful on node rack08-server63
2022-02-22 09:24:18.508 7 INFO nova.compute.claims [req-5e8b2012-e90f-4889-80d9-76d8e3f1aa1d 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Claim successful on node rack08-server63
2022-02-22 09:24:18.850 7 INFO nova.virt.libvirt.driver [req-e4e80ecf-f1ce-4ebf-868a-a5f1af668553 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Creating image
2022-02-22 09:24:18.881 7 INFO nova.virt.libvirt.driver [req-5e8b2012-e90f-4889-80d9-76d8e3f1aa1d 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Creating image
2022-02-22 09:24:19.099 7 INFO nova.compute.claims [req-540f0121-15ee-4ba7-b0d6-c5f0511a149c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Claim successful on node rack08-server63
2022-02-22 09:24:19.508 7 INFO nova.virt.libvirt.driver [req-540f0121-15ee-4ba7-b0d6-c5f0511a149c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Creating image
2022-02-22 09:24:20.024 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] VM Resumed (Lifecycle Event)
2022-02-22 09:24:20.034 7 INFO nova.virt.libvirt.driver [-] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Instance spawned successfully.
2022-02-22 09:24:20.035 7 INFO nova.compute.manager [req-e4e80ecf-f1ce-4ebf-868a-a5f1af668553 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:20.079 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:20.080 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] VM Started (Lifecycle Event)
2022-02-22 09:24:20.089 7 INFO nova.virt.libvirt.driver [-] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Instance spawned successfully.
2022-02-22 09:24:20.090 7 INFO nova.compute.manager [req-5e8b2012-e90f-4889-80d9-76d8e3f1aa1d 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:20.131 7 INFO nova.compute.manager [req-e4e80ecf-f1ce-4ebf-868a-a5f1af668553 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Took 1.71 seconds to build instance.
2022-02-22 09:24:20.139 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] VM Resumed (Lifecycle Event)
2022-02-22 09:24:20.171 7 INFO nova.compute.manager [req-5e8b2012-e90f-4889-80d9-76d8e3f1aa1d 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Took 1.70 seconds to build instance.
2022-02-22 09:24:20.194 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] VM Started (Lifecycle Event)
2022-02-22 09:24:20.711 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] VM Resumed (Lifecycle Event)
2022-02-22 09:24:20.717 7 INFO nova.virt.libvirt.driver [-] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Instance spawned successfully.
2022-02-22 09:24:20.718 7 INFO nova.compute.manager [req-540f0121-15ee-4ba7-b0d6-c5f0511a149c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:20.768 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:20.769 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] VM Started (Lifecycle Event)
2022-02-22 09:24:20.812 7 INFO nova.compute.manager [req-540f0121-15ee-4ba7-b0d6-c5f0511a149c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Took 1.76 seconds to build instance.
2022-02-22 09:24:23.833 7 INFO nova.compute.manager [req-7b8207b5-834c-4420-8b09-c631067c303b 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Attaching volume eefbf5e3-5216-46db-b6b4-232bce574dc3 to /dev/vdb
2022-02-22 09:24:23.922 7 WARNING os_brick.initiator.connectors.nvmeof [req-7b8207b5-834c-4420-8b09-c631067c303b 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:24:23.980 7 INFO nova.compute.manager [req-78b9a484-e1d4-4ae1-a6dd-f8013aaa6f6b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Attaching volume a5128069-8059-4cd2-9e30-4acd2199e342 to /dev/vdb
2022-02-22 09:24:24.063 7 WARNING os_brick.initiator.connectors.nvmeof [req-78b9a484-e1d4-4ae1-a6dd-f8013aaa6f6b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:24:25.227 7 INFO os_brick.initiator.connectors.lightos [req-7b8207b5-834c-4420-8b09-c631067c303b 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: connect_volume called for volume 0cdd3379-d56c-43ef-8623-7f17518d8749, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '0cdd3379-d56c-43ef-8623-7f17518d8749', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:24:25.231 7 INFO os_brick.initiator.connectors.lightos [req-7b8207b5-834c-4420-8b09-c631067c303b 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 0cdd3379-d56c-43ef-8623-7f17518d8749
2022-02-22 09:24:25.594 7 INFO os_brick.initiator.connectors.lightos [req-78b9a484-e1d4-4ae1-a6dd-f8013aaa6f6b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: connect_volume called for volume 82680499-e9bf-44c2-b71f-9b0883b4ac5b, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '82680499-e9bf-44c2-b71f-9b0883b4ac5b', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:24:25.596 7 INFO os_brick.initiator.connectors.lightos [req-78b9a484-e1d4-4ae1-a6dd-f8013aaa6f6b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 82680499-e9bf-44c2-b71f-9b0883b4ac5b
2022-02-22 09:24:26.308 7 INFO nova.compute.manager [req-9b1f8705-7a95-44b5-949b-e1b518287905 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Attaching volume eefbf5e3-5216-46db-b6b4-232bce574dc3 to /dev/vdb
2022-02-22 09:24:26.404 7 WARNING os_brick.initiator.connectors.nvmeof [req-9b1f8705-7a95-44b5-949b-e1b518287905 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:24:26.574 7 INFO nova.compute.manager [req-c44e74b4-b4be-4af0-9b63-29ae46f5ebaf 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Detaching volume a5128069-8059-4cd2-9e30-4acd2199e342
2022-02-22 09:24:26.641 7 INFO nova.virt.block_device [req-c44e74b4-b4be-4af0-9b63-29ae46f5ebaf 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Attempting to driver detach volume a5128069-8059-4cd2-9e30-4acd2199e342 from mountpoint /dev/vdb
2022-02-22 09:24:26.661 7 INFO nova.virt.libvirt.driver [req-c44e74b4-b4be-4af0-9b63-29ae46f5ebaf 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance eaa6a507-65d1-4ed1-bcee-ba861f0f4707 from the persistent domain config.
2022-02-22 09:24:26.803 7 INFO nova.virt.libvirt.driver [req-c44e74b4-b4be-4af0-9b63-29ae46f5ebaf 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance eaa6a507-65d1-4ed1-bcee-ba861f0f4707 from the live domain config.
2022-02-22 09:24:26.807 7 INFO os_brick.initiator.connectors.lightos [req-c44e74b4-b4be-4af0-9b63-29ae46f5ebaf 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 82680499-e9bf-44c2-b71f-9b0883b4ac5b
2022-02-22 09:24:27.730 7 INFO os_brick.initiator.connectors.lightos [req-9b1f8705-7a95-44b5-949b-e1b518287905 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: connect_volume called for volume 0cdd3379-d56c-43ef-8623-7f17518d8749, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '0cdd3379-d56c-43ef-8623-7f17518d8749', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:24:27.731 7 INFO os_brick.initiator.connectors.lightos [req-9b1f8705-7a95-44b5-949b-e1b518287905 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 0cdd3379-d56c-43ef-8623-7f17518d8749
2022-02-22 09:24:28.869 7 INFO nova.compute.manager [req-87019692-280d-4232-8c7e-1a5ec662d559 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Detaching volume eefbf5e3-5216-46db-b6b4-232bce574dc3
2022-02-22 09:24:28.930 7 INFO nova.virt.block_device [req-87019692-280d-4232-8c7e-1a5ec662d559 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Attempting to driver detach volume eefbf5e3-5216-46db-b6b4-232bce574dc3 from mountpoint /dev/vdb
2022-02-22 09:24:28.949 7 INFO nova.virt.libvirt.driver [req-87019692-280d-4232-8c7e-1a5ec662d559 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Successfully detached device vdb from instance 6ccef52d-b067-4d9f-ae81-d8fb173f9920 from the persistent domain config.
2022-02-22 09:24:29.098 7 INFO nova.virt.libvirt.driver [req-87019692-280d-4232-8c7e-1a5ec662d559 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Successfully detached device vdb from instance 6ccef52d-b067-4d9f-ae81-d8fb173f9920 from the live domain config.
2022-02-22 09:24:29.160 7 INFO nova.virt.libvirt.driver [req-87019692-280d-4232-8c7e-1a5ec662d559 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Detected multiple connections on this host for volume: eefbf5e3-5216-46db-b6b4-232bce574dc3, skipping target disconnect.
2022-02-22 09:24:29.987 7 INFO nova.compute.claims [req-9fce1a06-1a65-45d0-838f-8b16d1f9de1b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Claim successful on node rack08-server63
2022-02-22 09:24:30.395 7 INFO nova.virt.libvirt.driver [req-9fce1a06-1a65-45d0-838f-8b16d1f9de1b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Creating image
2022-02-22 09:24:31.364 7 INFO nova.compute.manager [req-733ed93f-6996-4395-8fa3-4832ba53b90c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Detaching volume eefbf5e3-5216-46db-b6b4-232bce574dc3
2022-02-22 09:24:31.427 7 INFO nova.virt.block_device [req-733ed93f-6996-4395-8fa3-4832ba53b90c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Attempting to driver detach volume eefbf5e3-5216-46db-b6b4-232bce574dc3 from mountpoint /dev/vdb
2022-02-22 09:24:31.444 7 INFO nova.virt.libvirt.driver [req-733ed93f-6996-4395-8fa3-4832ba53b90c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Successfully detached device vdb from instance f6437fd9-0ed2-42b5-8b1c-4176afc59202 from the persistent domain config.
2022-02-22 09:24:31.575 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] VM Resumed (Lifecycle Event)
2022-02-22 09:24:31.583 7 INFO nova.virt.libvirt.driver [-] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Instance spawned successfully.
2022-02-22 09:24:31.583 7 INFO nova.compute.manager [req-9fce1a06-1a65-45d0-838f-8b16d1f9de1b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 09:24:31.637 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:24:31.638 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] VM Started (Lifecycle Event)
2022-02-22 09:24:31.670 7 INFO nova.compute.manager [req-9fce1a06-1a65-45d0-838f-8b16d1f9de1b 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Took 1.72 seconds to build instance.
2022-02-22 09:24:31.703 7 INFO nova.virt.libvirt.driver [req-733ed93f-6996-4395-8fa3-4832ba53b90c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Successfully detached device vdb from instance f6437fd9-0ed2-42b5-8b1c-4176afc59202 from the live domain config.
2022-02-22 09:24:34.546 7 INFO nova.compute.manager [req-e1253368-90a5-4e62-8c25-95c345a1b6ea 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Attaching volume fd7322e6-d602-4d75-9159-036d2ad629e3 to /dev/vdb
2022-02-22 09:24:34.639 7 WARNING os_brick.initiator.connectors.nvmeof [req-e1253368-90a5-4e62-8c25-95c345a1b6ea 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:25:32.199 7 INFO os_brick.initiator.connectors.lightos [req-e1253368-90a5-4e62-8c25-95c345a1b6ea 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: connect_volume called for volume 66f50035-e239-4df5-b2ca-52daed39275f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '66f50035-e239-4df5-b2ca-52daed39275f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:25:32.203 7 INFO os_brick.initiator.connectors.lightos [req-e1253368-90a5-4e62-8c25-95c345a1b6ea 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 66f50035-e239-4df5-b2ca-52daed39275f
2022-02-22 09:25:33.233 7 INFO nova.compute.manager [req-3eebc3de-9b2c-417a-8316-b1258e24227f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Detaching volume fd7322e6-d602-4d75-9159-036d2ad629e3
2022-02-22 09:25:33.293 7 INFO nova.virt.block_device [req-3eebc3de-9b2c-417a-8316-b1258e24227f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Attempting to driver detach volume fd7322e6-d602-4d75-9159-036d2ad629e3 from mountpoint /dev/vdb
2022-02-22 09:25:33.312 7 INFO nova.virt.libvirt.driver [req-3eebc3de-9b2c-417a-8316-b1258e24227f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4 from the persistent domain config.
2022-02-22 09:25:33.452 7 INFO nova.virt.libvirt.driver [req-3eebc3de-9b2c-417a-8316-b1258e24227f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Successfully detached device vdb from instance 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4 from the live domain config.
2022-02-22 09:25:33.456 7 INFO os_brick.initiator.connectors.lightos [req-3eebc3de-9b2c-417a-8316-b1258e24227f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 66f50035-e239-4df5-b2ca-52daed39275f
2022-02-22 09:25:36.675 7 INFO nova.compute.manager [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Terminating instance
2022-02-22 09:25:37.018 7 INFO nova.virt.libvirt.driver [-] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Instance destroyed successfully.
2022-02-22 09:25:37.036 7 INFO nova.virt.libvirt.driver [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Deleting instance files /var/lib/nova/instances/4f0211c3-a24b-4547-93a7-d77ef9dc3ef4_del
2022-02-22 09:25:37.038 7 INFO nova.virt.libvirt.driver [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Deletion of /var/lib/nova/instances/4f0211c3-a24b-4547-93a7-d77ef9dc3ef4_del complete
2022-02-22 09:25:37.111 7 INFO nova.virt.libvirt.host [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] UEFI support detected
2022-02-22 09:25:37.114 7 INFO nova.compute.manager [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 09:25:37.183 7 INFO nova.compute.manager [-] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:25:37.393 7 INFO nova.scheduler.client.report [req-8ae8e22d-a15e-4a52-9947-2534123d4c92 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Deleted allocations for instance 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4
2022-02-22 09:25:39.075 7 INFO nova.compute.manager [req-8a37ea28-88fb-4751-a87a-32e5cdd3888f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Terminating instance
2022-02-22 09:25:39.419 7 INFO nova.virt.libvirt.driver [-] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Instance destroyed successfully.
2022-02-22 09:25:39.434 7 INFO nova.virt.libvirt.driver [req-8a37ea28-88fb-4751-a87a-32e5cdd3888f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Deleting instance files /var/lib/nova/instances/eaa6a507-65d1-4ed1-bcee-ba861f0f4707_del
2022-02-22 09:25:39.436 7 INFO nova.virt.libvirt.driver [req-8a37ea28-88fb-4751-a87a-32e5cdd3888f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Deletion of /var/lib/nova/instances/eaa6a507-65d1-4ed1-bcee-ba861f0f4707_del complete
2022-02-22 09:25:39.505 7 INFO nova.compute.manager [req-8a37ea28-88fb-4751-a87a-32e5cdd3888f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:25:39.577 7 INFO nova.compute.manager [-] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:25:39.778 7 INFO nova.scheduler.client.report [req-8a37ea28-88fb-4751-a87a-32e5cdd3888f 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Deleted allocations for instance eaa6a507-65d1-4ed1-bcee-ba861f0f4707
2022-02-22 09:25:40.318 7 INFO nova.compute.manager [req-b1ab03a8-611b-4e75-936b-7ddbde43c139 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Terminating instance
2022-02-22 09:25:40.683 7 INFO nova.virt.libvirt.driver [-] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Instance destroyed successfully.
2022-02-22 09:25:40.698 7 INFO nova.virt.libvirt.driver [req-b1ab03a8-611b-4e75-936b-7ddbde43c139 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Deleting instance files /var/lib/nova/instances/fc46defd-5968-4606-a8f3-87c9ac8eeff5_del
2022-02-22 09:25:40.700 7 INFO nova.virt.libvirt.driver [req-b1ab03a8-611b-4e75-936b-7ddbde43c139 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Deletion of /var/lib/nova/instances/fc46defd-5968-4606-a8f3-87c9ac8eeff5_del complete
2022-02-22 09:25:40.789 7 INFO nova.compute.manager [req-b1ab03a8-611b-4e75-936b-7ddbde43c139 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Took 0.33 seconds to destroy the instance on the hypervisor.
2022-02-22 09:25:40.853 7 INFO nova.compute.manager [-] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] Took 0.06 seconds to deallocate network for instance.
2022-02-22 09:25:41.052 7 INFO nova.scheduler.client.report [req-b1ab03a8-611b-4e75-936b-7ddbde43c139 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Deleted allocations for instance fc46defd-5968-4606-a8f3-87c9ac8eeff5
2022-02-22 09:25:42.707 7 INFO nova.compute.manager [req-596e7020-e00e-40e4-800e-aecdea8d693a 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Terminating instance
2022-02-22 09:25:43.043 7 INFO nova.virt.libvirt.driver [-] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Instance destroyed successfully.
2022-02-22 09:25:43.057 7 INFO nova.virt.libvirt.driver [req-596e7020-e00e-40e4-800e-aecdea8d693a 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Deleting instance files /var/lib/nova/instances/3cc71329-f774-4959-bd13-e09e2d6795e8_del
2022-02-22 09:25:43.059 7 INFO nova.virt.libvirt.driver [req-596e7020-e00e-40e4-800e-aecdea8d693a 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Deletion of /var/lib/nova/instances/3cc71329-f774-4959-bd13-e09e2d6795e8_del complete
2022-02-22 09:25:43.127 7 INFO nova.compute.manager [req-596e7020-e00e-40e4-800e-aecdea8d693a 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 09:25:43.199 7 INFO nova.compute.manager [-] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:25:43.397 7 INFO nova.scheduler.client.report [req-596e7020-e00e-40e4-800e-aecdea8d693a 1d1837560f9f4457935b33e236b824e2 c2a1aa9036ee4d2fb6eceda533d6be3a - default default] Deleted allocations for instance 3cc71329-f774-4959-bd13-e09e2d6795e8
2022-02-22 09:25:50.606 7 INFO nova.compute.claims [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Claim successful on node rack08-server63
2022-02-22 09:25:50.873 7 INFO nova.virt.libvirt.driver [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 09:25:50.962 7 INFO nova.virt.block_device [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Booting with volume 0432724a-7706-46c9-858d-5eabca53bbb1 at /dev/vda
2022-02-22 09:25:51.054 7 WARNING os_brick.initiator.connectors.nvmeof [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:25:52.017 7 INFO nova.compute.manager [-] [instance: 4f0211c3-a24b-4547-93a7-d77ef9dc3ef4] VM Stopped (Lifecycle Event)
2022-02-22 09:25:52.520 7 INFO nova.virt.libvirt.driver [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Creating image
2022-02-22 09:25:52.531 7 INFO os_brick.initiator.connectors.lightos [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: connect_volume called for volume a382570f-01ba-498d-a06a-c7d4a90a0ced, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a382570f-01ba-498d-a06a-c7d4a90a0ced', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:25:52.534 7 INFO os_brick.initiator.connectors.lightos [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a382570f-01ba-498d-a06a-c7d4a90a0ced
2022-02-22 09:25:53.351 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] VM Resumed (Lifecycle Event)
2022-02-22 09:25:53.358 7 INFO nova.virt.libvirt.driver [-] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Instance spawned successfully.
2022-02-22 09:25:53.359 7 INFO nova.compute.manager [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Took 0.84 seconds to spawn the instance on the hypervisor.
2022-02-22 09:25:53.417 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:25:53.418 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] VM Started (Lifecycle Event)
2022-02-22 09:25:53.450 7 INFO nova.compute.manager [req-bee75906-b96f-4067-8bf9-601b6cf12fc5 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Took 2.88 seconds to build instance.
2022-02-22 09:25:54.417 7 INFO nova.compute.manager [-] [instance: eaa6a507-65d1-4ed1-bcee-ba861f0f4707] VM Stopped (Lifecycle Event)
2022-02-22 09:25:54.724 7 INFO nova.compute.manager [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Terminating instance
2022-02-22 09:25:55.067 7 INFO nova.virt.libvirt.driver [-] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Instance destroyed successfully.
2022-02-22 09:25:55.134 7 INFO os_brick.initiator.connectors.lightos [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a382570f-01ba-498d-a06a-c7d4a90a0ced
2022-02-22 09:25:55.145 7 INFO nova.virt.libvirt.driver [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Deleting instance files /var/lib/nova/instances/255d8c0f-60f0-4991-9c57-bda01d96777f_del
2022-02-22 09:25:55.146 7 INFO nova.virt.libvirt.driver [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Deletion of /var/lib/nova/instances/255d8c0f-60f0-4991-9c57-bda01d96777f_del complete
2022-02-22 09:25:55.216 7 INFO nova.compute.manager [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 09:25:55.281 7 INFO nova.compute.manager [-] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Took 0.06 seconds to deallocate network for instance.
2022-02-22 09:25:55.681 7 INFO nova.compute.manager [-] [instance: fc46defd-5968-4606-a8f3-87c9ac8eeff5] VM Stopped (Lifecycle Event)
2022-02-22 09:25:56.474 7 INFO nova.compute.manager [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] Took 1.19 seconds to detach 1 volumes for instance.
2022-02-22 09:25:56.643 7 INFO nova.scheduler.client.report [req-8f974eec-5776-4086-b3f0-40d028217f93 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Deleted allocations for instance 255d8c0f-60f0-4991-9c57-bda01d96777f
2022-02-22 09:25:58.042 7 INFO nova.compute.manager [-] [instance: 3cc71329-f774-4959-bd13-e09e2d6795e8] VM Stopped (Lifecycle Event)
2022-02-22 09:25:59.633 7 INFO nova.compute.manager [req-012abd64-3b9b-427b-9765-9e8161c1400c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Terminating instance
2022-02-22 09:25:59.975 7 INFO nova.virt.libvirt.driver [-] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Instance destroyed successfully.
2022-02-22 09:25:59.990 7 INFO nova.virt.libvirt.driver [req-012abd64-3b9b-427b-9765-9e8161c1400c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Deleting instance files /var/lib/nova/instances/f6437fd9-0ed2-42b5-8b1c-4176afc59202_del
2022-02-22 09:25:59.991 7 INFO nova.virt.libvirt.driver [req-012abd64-3b9b-427b-9765-9e8161c1400c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Deletion of /var/lib/nova/instances/f6437fd9-0ed2-42b5-8b1c-4176afc59202_del complete
2022-02-22 09:26:00.060 7 INFO nova.compute.manager [req-012abd64-3b9b-427b-9765-9e8161c1400c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:26:00.132 7 INFO nova.compute.manager [-] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:26:00.323 7 INFO nova.scheduler.client.report [req-012abd64-3b9b-427b-9765-9e8161c1400c 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Deleted allocations for instance f6437fd9-0ed2-42b5-8b1c-4176afc59202
2022-02-22 09:26:00.871 7 INFO nova.compute.manager [req-1f9ade29-6cd1-4490-a52e-ccaedc4de09f 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Terminating instance
2022-02-22 09:26:01.210 7 INFO nova.virt.libvirt.driver [-] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Instance destroyed successfully.
2022-02-22 09:26:01.227 7 INFO nova.virt.libvirt.driver [req-1f9ade29-6cd1-4490-a52e-ccaedc4de09f 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Deleting instance files /var/lib/nova/instances/6ccef52d-b067-4d9f-ae81-d8fb173f9920_del
2022-02-22 09:26:01.228 7 INFO nova.virt.libvirt.driver [req-1f9ade29-6cd1-4490-a52e-ccaedc4de09f 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Deletion of /var/lib/nova/instances/6ccef52d-b067-4d9f-ae81-d8fb173f9920_del complete
2022-02-22 09:26:01.297 7 INFO nova.compute.manager [req-1f9ade29-6cd1-4490-a52e-ccaedc4de09f 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:26:01.364 7 INFO nova.compute.manager [-] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:26:01.558 7 INFO nova.scheduler.client.report [req-1f9ade29-6cd1-4490-a52e-ccaedc4de09f 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Deleted allocations for instance 6ccef52d-b067-4d9f-ae81-d8fb173f9920
2022-02-22 09:26:02.114 7 INFO nova.compute.manager [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Terminating instance
2022-02-22 09:26:02.448 7 INFO nova.virt.libvirt.driver [-] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Instance destroyed successfully.
2022-02-22 09:26:02.524 7 INFO os_brick.initiator.connectors.lightos [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 46496465-7dca-40a9-9099-9b1dfad3bb3d
2022-02-22 09:26:02.535 7 INFO nova.virt.libvirt.driver [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Deleting instance files /var/lib/nova/instances/e944ad8c-bb68-4ed6-9468-69273f34b7db_del
2022-02-22 09:26:02.536 7 INFO nova.virt.libvirt.driver [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Deletion of /var/lib/nova/instances/e944ad8c-bb68-4ed6-9468-69273f34b7db_del complete
2022-02-22 09:26:02.599 7 INFO nova.compute.manager [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 09:26:02.668 7 INFO nova.compute.manager [-] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:26:03.867 7 INFO nova.compute.manager [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] Took 1.20 seconds to detach 1 volumes for instance.
2022-02-22 09:26:04.041 7 INFO nova.scheduler.client.report [req-e9378b38-9495-465a-a3cd-53b3c5ce8d31 0305347ac1e94a4097df4267b42b066a 1936bfa1161b4ae29aa122e6d6979c31 - default default] Deleted allocations for instance e944ad8c-bb68-4ed6-9468-69273f34b7db
2022-02-22 09:26:10.065 7 INFO nova.compute.manager [-] [instance: 255d8c0f-60f0-4991-9c57-bda01d96777f] VM Stopped (Lifecycle Event)
2022-02-22 09:26:14.973 7 INFO nova.compute.manager [-] [instance: f6437fd9-0ed2-42b5-8b1c-4176afc59202] VM Stopped (Lifecycle Event)
2022-02-22 09:26:16.207 7 INFO nova.compute.manager [-] [instance: 6ccef52d-b067-4d9f-ae81-d8fb173f9920] VM Stopped (Lifecycle Event)
2022-02-22 09:26:17.446 7 INFO nova.compute.manager [-] [instance: e944ad8c-bb68-4ed6-9468-69273f34b7db] VM Stopped (Lifecycle Event)
2022-02-22 09:26:32.284 7 INFO nova.compute.claims [req-89ec4985-e7ab-4279-9d16-f34262663fee 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Claim successful on node rack08-server63
2022-02-22 09:26:32.669 7 INFO nova.virt.libvirt.driver [req-89ec4985-e7ab-4279-9d16-f34262663fee 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Creating image
2022-02-22 09:26:33.799 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] VM Resumed (Lifecycle Event)
2022-02-22 09:26:33.806 7 INFO nova.virt.libvirt.driver [-] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Instance spawned successfully.
2022-02-22 09:26:33.807 7 INFO nova.compute.manager [req-89ec4985-e7ab-4279-9d16-f34262663fee 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 09:26:33.851 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:26:33.852 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] VM Started (Lifecycle Event)
2022-02-22 09:26:33.894 7 INFO nova.compute.manager [req-89ec4985-e7ab-4279-9d16-f34262663fee 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Took 1.65 seconds to build instance.
2022-02-22 09:26:34.525 7 INFO nova.compute.manager [req-6be82ff9-6006-47e2-9661-be9a23dee289 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Terminating instance
2022-02-22 09:26:34.862 7 INFO nova.virt.libvirt.driver [-] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Instance destroyed successfully.
2022-02-22 09:26:34.878 7 INFO nova.virt.libvirt.driver [req-6be82ff9-6006-47e2-9661-be9a23dee289 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Deleting instance files /var/lib/nova/instances/28007137-21a2-43d7-97d7-8c77bc8c84a1_del
2022-02-22 09:26:34.879 7 INFO nova.virt.libvirt.driver [req-6be82ff9-6006-47e2-9661-be9a23dee289 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Deletion of /var/lib/nova/instances/28007137-21a2-43d7-97d7-8c77bc8c84a1_del complete
2022-02-22 09:26:34.948 7 INFO nova.compute.manager [req-6be82ff9-6006-47e2-9661-be9a23dee289 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:26:35.016 7 INFO nova.compute.manager [-] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:26:35.209 7 INFO nova.scheduler.client.report [req-6be82ff9-6006-47e2-9661-be9a23dee289 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] Deleted allocations for instance 28007137-21a2-43d7-97d7-8c77bc8c84a1
2022-02-22 09:26:36.891 7 INFO nova.compute.claims [req-ae80d5d3-9a27-4caf-bc9b-9a0e47613549 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Claim successful on node rack08-server63
2022-02-22 09:26:37.284 7 INFO nova.virt.libvirt.driver [req-ae80d5d3-9a27-4caf-bc9b-9a0e47613549 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Creating image
2022-02-22 09:26:38.476 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] VM Resumed (Lifecycle Event)
2022-02-22 09:26:38.484 7 INFO nova.virt.libvirt.driver [-] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Instance spawned successfully.
2022-02-22 09:26:38.485 7 INFO nova.compute.manager [req-ae80d5d3-9a27-4caf-bc9b-9a0e47613549 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 09:26:38.530 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:26:38.530 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] VM Started (Lifecycle Event)
2022-02-22 09:26:38.568 7 INFO nova.compute.manager [req-ae80d5d3-9a27-4caf-bc9b-9a0e47613549 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Took 1.71 seconds to build instance.
2022-02-22 09:26:39.216 7 INFO nova.compute.manager [req-f9b24f57-fdef-4e37-b9a7-6215f781c535 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Terminating instance
2022-02-22 09:26:39.560 7 INFO nova.virt.libvirt.driver [-] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Instance destroyed successfully.
2022-02-22 09:26:39.576 7 INFO nova.virt.libvirt.driver [req-f9b24f57-fdef-4e37-b9a7-6215f781c535 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Deleting instance files /var/lib/nova/instances/162d481f-c66f-4857-9207-dff5e5f100c7_del
2022-02-22 09:26:39.577 7 INFO nova.virt.libvirt.driver [req-f9b24f57-fdef-4e37-b9a7-6215f781c535 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Deletion of /var/lib/nova/instances/162d481f-c66f-4857-9207-dff5e5f100c7_del complete
2022-02-22 09:26:39.641 7 INFO nova.compute.manager [req-f9b24f57-fdef-4e37-b9a7-6215f781c535 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 09:26:39.704 7 INFO nova.compute.manager [-] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] Took 0.06 seconds to deallocate network for instance.
2022-02-22 09:26:39.935 7 INFO nova.scheduler.client.report [req-f9b24f57-fdef-4e37-b9a7-6215f781c535 6e3d0200ed4945e9a8af9653be2abb8d 442ea23ad57142cc8a79b8672e4d7891 - default default] Deleted allocations for instance 162d481f-c66f-4857-9207-dff5e5f100c7
2022-02-22 09:26:49.860 7 INFO nova.compute.manager [-] [instance: 28007137-21a2-43d7-97d7-8c77bc8c84a1] VM Stopped (Lifecycle Event)
2022-02-22 09:26:54.557 7 INFO nova.compute.manager [-] [instance: 162d481f-c66f-4857-9207-dff5e5f100c7] VM Stopped (Lifecycle Event)
2022-02-22 09:27:34.482 7 INFO nova.compute.claims [req-12049701-7da7-4c41-9a36-bdc6defe8454 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Claim successful on node rack08-server63
2022-02-22 09:27:34.906 7 INFO nova.virt.libvirt.driver [req-12049701-7da7-4c41-9a36-bdc6defe8454 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Creating image
2022-02-22 09:27:36.122 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 90100b62-0537-4101-9026-6714a6356120] VM Resumed (Lifecycle Event)
2022-02-22 09:27:36.130 7 INFO nova.virt.libvirt.driver [-] [instance: 90100b62-0537-4101-9026-6714a6356120] Instance spawned successfully.
2022-02-22 09:27:36.130 7 INFO nova.compute.manager [req-12049701-7da7-4c41-9a36-bdc6defe8454 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 09:27:36.179 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 90100b62-0537-4101-9026-6714a6356120] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:27:36.180 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 90100b62-0537-4101-9026-6714a6356120] VM Started (Lifecycle Event)
2022-02-22 09:27:36.218 7 INFO nova.compute.manager [req-12049701-7da7-4c41-9a36-bdc6defe8454 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Took 1.77 seconds to build instance.
2022-02-22 09:27:39.837 7 INFO nova.compute.manager [req-ae7d4b8d-5315-4eed-b0c9-c0ee6ce2d50a 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Terminating instance
2022-02-22 09:27:40.189 7 INFO nova.virt.libvirt.driver [-] [instance: 90100b62-0537-4101-9026-6714a6356120] Instance destroyed successfully.
2022-02-22 09:27:40.204 7 INFO nova.virt.libvirt.driver [req-ae7d4b8d-5315-4eed-b0c9-c0ee6ce2d50a 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Deleting instance files /var/lib/nova/instances/90100b62-0537-4101-9026-6714a6356120_del
2022-02-22 09:27:40.205 7 INFO nova.virt.libvirt.driver [req-ae7d4b8d-5315-4eed-b0c9-c0ee6ce2d50a 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Deletion of /var/lib/nova/instances/90100b62-0537-4101-9026-6714a6356120_del complete
2022-02-22 09:27:40.281 7 INFO nova.compute.manager [req-ae7d4b8d-5315-4eed-b0c9-c0ee6ce2d50a 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] [instance: 90100b62-0537-4101-9026-6714a6356120] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:27:40.349 7 INFO nova.compute.manager [-] [instance: 90100b62-0537-4101-9026-6714a6356120] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:27:40.564 7 INFO nova.scheduler.client.report [req-ae7d4b8d-5315-4eed-b0c9-c0ee6ce2d50a 09740f538266425abdf35625ae86eab7 ecaf66d1e7f44c759e0cd52cde885cbc - default default] Deleted allocations for instance 90100b62-0537-4101-9026-6714a6356120
2022-02-22 09:27:49.462 7 INFO nova.compute.claims [req-75c82530-a62c-44a2-bc28-9ebf5aea7ed6 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Claim successful on node rack08-server63
2022-02-22 09:27:49.855 7 INFO nova.virt.libvirt.driver [req-75c82530-a62c-44a2-bc28-9ebf5aea7ed6 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Creating image
2022-02-22 09:27:50.994 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] VM Resumed (Lifecycle Event)
2022-02-22 09:27:51.002 7 INFO nova.virt.libvirt.driver [-] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Instance spawned successfully.
2022-02-22 09:27:51.002 7 INFO nova.compute.manager [req-75c82530-a62c-44a2-bc28-9ebf5aea7ed6 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 09:27:51.049 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:27:51.049 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] VM Started (Lifecycle Event)
2022-02-22 09:27:51.093 7 INFO nova.compute.manager [req-75c82530-a62c-44a2-bc28-9ebf5aea7ed6 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Took 1.67 seconds to build instance.
2022-02-22 09:27:51.440 7 INFO nova.compute.manager [req-fdccc29f-915b-4e1d-af98-f00fcfcb56b7 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Terminating instance
2022-02-22 09:27:51.782 7 INFO nova.virt.libvirt.driver [-] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Instance destroyed successfully.
2022-02-22 09:27:51.798 7 INFO nova.virt.libvirt.driver [req-fdccc29f-915b-4e1d-af98-f00fcfcb56b7 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Deleting instance files /var/lib/nova/instances/94388c8d-f93e-410d-bd8f-999c8656a8f5_del
2022-02-22 09:27:51.800 7 INFO nova.virt.libvirt.driver [req-fdccc29f-915b-4e1d-af98-f00fcfcb56b7 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Deletion of /var/lib/nova/instances/94388c8d-f93e-410d-bd8f-999c8656a8f5_del complete
2022-02-22 09:27:51.863 7 INFO nova.compute.manager [req-fdccc29f-915b-4e1d-af98-f00fcfcb56b7 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 09:27:51.930 7 INFO nova.compute.manager [-] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:27:52.120 7 INFO nova.scheduler.client.report [req-fdccc29f-915b-4e1d-af98-f00fcfcb56b7 9dd80708ac4149099a2794852b4c4b00 9309f1c6e01846538559d74703d1cfef - default default] Deleted allocations for instance 94388c8d-f93e-410d-bd8f-999c8656a8f5
2022-02-22 09:27:55.187 7 INFO nova.compute.manager [-] [instance: 90100b62-0537-4101-9026-6714a6356120] VM Stopped (Lifecycle Event)
2022-02-22 09:28:03.236 7 INFO nova.compute.claims [req-eff4218d-bf58-40e0-b4ce-a6c856ef068d d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Claim successful on node rack08-server63
2022-02-22 09:28:03.634 7 INFO nova.virt.libvirt.driver [req-eff4218d-bf58-40e0-b4ce-a6c856ef068d d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Creating image
2022-02-22 09:28:04.806 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] VM Resumed (Lifecycle Event)
2022-02-22 09:28:04.813 7 INFO nova.virt.libvirt.driver [-] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Instance spawned successfully.
2022-02-22 09:28:04.814 7 INFO nova.compute.manager [req-eff4218d-bf58-40e0-b4ce-a6c856ef068d d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 09:28:04.863 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:28:04.863 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] VM Started (Lifecycle Event)
2022-02-22 09:28:04.900 7 INFO nova.compute.manager [req-eff4218d-bf58-40e0-b4ce-a6c856ef068d d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Took 1.70 seconds to build instance.
2022-02-22 09:28:06.779 7 INFO nova.compute.manager [-] [instance: 94388c8d-f93e-410d-bd8f-999c8656a8f5] VM Stopped (Lifecycle Event)
2022-02-22 09:28:18.327 7 INFO nova.virt.libvirt.driver [req-b4913de2-5cea-448f-9063-7d529e5b5a35 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Ignoring supplied device name: /dev/vdb
2022-02-22 09:28:18.504 7 INFO nova.compute.manager [req-b4913de2-5cea-448f-9063-7d529e5b5a35 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Attaching volume e6a92795-010f-4987-b333-1a5e9298125b to /dev/vdb
2022-02-22 09:28:18.604 7 WARNING os_brick.initiator.connectors.nvmeof [req-b4913de2-5cea-448f-9063-7d529e5b5a35 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:28:19.928 7 INFO os_brick.initiator.connectors.lightos [req-b4913de2-5cea-448f-9063-7d529e5b5a35 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: connect_volume called for volume b35e7a8d-39d2-40f7-a076-75550d55b756, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'b35e7a8d-39d2-40f7-a076-75550d55b756', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:28:19.932 7 INFO os_brick.initiator.connectors.lightos [req-b4913de2-5cea-448f-9063-7d529e5b5a35 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b35e7a8d-39d2-40f7-a076-75550d55b756
2022-02-22 09:28:31.184 7 INFO nova.compute.manager [req-06688aa2-ba40-4b9e-ae52-481cf6b50275 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Detaching volume e6a92795-010f-4987-b333-1a5e9298125b
2022-02-22 09:28:31.250 7 INFO nova.virt.block_device [req-06688aa2-ba40-4b9e-ae52-481cf6b50275 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Attempting to driver detach volume e6a92795-010f-4987-b333-1a5e9298125b from mountpoint /dev/vdb
2022-02-22 09:28:31.268 7 INFO nova.virt.libvirt.driver [req-06688aa2-ba40-4b9e-ae52-481cf6b50275 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Successfully detached device vdb from instance bd044e00-d7c7-4bd8-bf6d-f8075292ce9c from the persistent domain config.
2022-02-22 09:28:31.413 7 INFO nova.virt.libvirt.driver [req-06688aa2-ba40-4b9e-ae52-481cf6b50275 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Successfully detached device vdb from instance bd044e00-d7c7-4bd8-bf6d-f8075292ce9c from the live domain config.
2022-02-22 09:28:31.416 7 INFO os_brick.initiator.connectors.lightos [req-06688aa2-ba40-4b9e-ae52-481cf6b50275 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b35e7a8d-39d2-40f7-a076-75550d55b756
2022-02-22 09:28:33.439 7 INFO nova.compute.manager [req-562ebe0c-8d74-445a-a8bd-f93945431516 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Terminating instance
2022-02-22 09:28:33.782 7 INFO nova.virt.libvirt.driver [-] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Instance destroyed successfully.
2022-02-22 09:28:33.797 7 INFO nova.virt.libvirt.driver [req-562ebe0c-8d74-445a-a8bd-f93945431516 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Deleting instance files /var/lib/nova/instances/bd044e00-d7c7-4bd8-bf6d-f8075292ce9c_del
2022-02-22 09:28:33.798 7 INFO nova.virt.libvirt.driver [req-562ebe0c-8d74-445a-a8bd-f93945431516 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Deletion of /var/lib/nova/instances/bd044e00-d7c7-4bd8-bf6d-f8075292ce9c_del complete
2022-02-22 09:28:33.862 7 INFO nova.compute.manager [req-562ebe0c-8d74-445a-a8bd-f93945431516 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 09:28:33.932 7 INFO nova.compute.manager [-] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:28:34.120 7 INFO nova.scheduler.client.report [req-562ebe0c-8d74-445a-a8bd-f93945431516 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Deleted allocations for instance bd044e00-d7c7-4bd8-bf6d-f8075292ce9c
2022-02-22 09:28:41.564 7 INFO nova.compute.claims [req-93d67765-6087-4c26-8730-78ddda337534 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Claim successful on node rack08-server63
2022-02-22 09:28:41.959 7 INFO nova.virt.libvirt.driver [req-93d67765-6087-4c26-8730-78ddda337534 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Creating image
2022-02-22 09:28:43.119 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: df9db753-0922-46bb-a24d-3f730097c328] VM Resumed (Lifecycle Event)
2022-02-22 09:28:43.126 7 INFO nova.virt.libvirt.driver [-] [instance: df9db753-0922-46bb-a24d-3f730097c328] Instance spawned successfully.
2022-02-22 09:28:43.127 7 INFO nova.compute.manager [req-93d67765-6087-4c26-8730-78ddda337534 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 09:28:43.176 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: df9db753-0922-46bb-a24d-3f730097c328] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:28:43.177 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: df9db753-0922-46bb-a24d-3f730097c328] VM Started (Lifecycle Event)
2022-02-22 09:28:43.212 7 INFO nova.compute.manager [req-93d67765-6087-4c26-8730-78ddda337534 d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Took 1.69 seconds to build instance.
2022-02-22 09:28:43.519 7 INFO nova.virt.libvirt.driver [req-312e9bf3-75af-44dc-9daa-d6ac2d6e174b d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Ignoring supplied device name: /dev/vdb
2022-02-22 09:28:43.672 7 INFO nova.compute.manager [req-312e9bf3-75af-44dc-9daa-d6ac2d6e174b d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Attaching volume 83a5831d-1647-4d13-9b3b-ea2324230be3 to /dev/vdb
2022-02-22 09:28:43.753 7 WARNING os_brick.initiator.connectors.nvmeof [req-312e9bf3-75af-44dc-9daa-d6ac2d6e174b d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:28:45.040 7 INFO os_brick.initiator.connectors.lightos [req-312e9bf3-75af-44dc-9daa-d6ac2d6e174b d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: connect_volume called for volume 721232b2-ca89-4633-bdb0-a72218dc2ad7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '721232b2-ca89-4633-bdb0-a72218dc2ad7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:28:45.044 7 INFO os_brick.initiator.connectors.lightos [req-312e9bf3-75af-44dc-9daa-d6ac2d6e174b d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 721232b2-ca89-4633-bdb0-a72218dc2ad7
2022-02-22 09:28:48.780 7 INFO nova.compute.manager [-] [instance: bd044e00-d7c7-4bd8-bf6d-f8075292ce9c] VM Stopped (Lifecycle Event)
2022-02-22 09:28:49.818 7 INFO nova.compute.claims [req-9a30b690-4d7f-4cad-b81e-6183661a163d 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Claim successful on node rack08-server63
2022-02-22 09:28:50.222 7 INFO nova.virt.libvirt.driver [req-9a30b690-4d7f-4cad-b81e-6183661a163d 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Creating image
2022-02-22 09:28:51.367 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] VM Resumed (Lifecycle Event)
2022-02-22 09:28:51.374 7 INFO nova.virt.libvirt.driver [-] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Instance spawned successfully.
2022-02-22 09:28:51.375 7 INFO nova.compute.manager [req-9a30b690-4d7f-4cad-b81e-6183661a163d 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 09:28:51.422 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 09:28:51.422 7 INFO nova.compute.manager [req-9fc76d0f-3762-4043-aa07-cda20948bf24 - - - - -] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] VM Started (Lifecycle Event)
2022-02-22 09:28:51.463 7 INFO nova.compute.manager [req-9a30b690-4d7f-4cad-b81e-6183661a163d 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Took 1.68 seconds to build instance.
2022-02-22 09:28:51.874 7 INFO nova.virt.libvirt.driver [req-60773607-8a26-4477-b531-d95c5c93fa8a 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Ignoring supplied device name: /dev/vdb
2022-02-22 09:28:52.043 7 INFO nova.compute.manager [req-60773607-8a26-4477-b531-d95c5c93fa8a 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Attaching volume 83f38815-00d5-491e-afe2-b72e3fe9aeee to /dev/vdb
2022-02-22 09:28:52.128 7 WARNING os_brick.initiator.connectors.nvmeof [req-60773607-8a26-4477-b531-d95c5c93fa8a 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 09:28:53.412 7 INFO os_brick.initiator.connectors.lightos [req-60773607-8a26-4477-b531-d95c5c93fa8a 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] LIGHTOS: connect_volume called for volume 6c0e95d8-8a0f-4821-a143-d7abe5016b35, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6c0e95d8-8a0f-4821-a143-d7abe5016b35', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 09:28:53.416 7 INFO os_brick.initiator.connectors.lightos [req-60773607-8a26-4477-b531-d95c5c93fa8a 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6c0e95d8-8a0f-4821-a143-d7abe5016b35
2022-02-22 09:28:53.925 7 INFO nova.compute.manager [req-e56162e4-3ef2-4a9c-ab67-984ff9fda81f d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Detaching volume 83a5831d-1647-4d13-9b3b-ea2324230be3
2022-02-22 09:28:53.982 7 INFO nova.virt.block_device [req-e56162e4-3ef2-4a9c-ab67-984ff9fda81f d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Attempting to driver detach volume 83a5831d-1647-4d13-9b3b-ea2324230be3 from mountpoint /dev/vdb
2022-02-22 09:28:54.000 7 INFO nova.virt.libvirt.driver [req-e56162e4-3ef2-4a9c-ab67-984ff9fda81f d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Successfully detached device vdb from instance df9db753-0922-46bb-a24d-3f730097c328 from the persistent domain config.
2022-02-22 09:28:54.146 7 INFO nova.virt.libvirt.driver [req-e56162e4-3ef2-4a9c-ab67-984ff9fda81f d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Successfully detached device vdb from instance df9db753-0922-46bb-a24d-3f730097c328 from the live domain config.
2022-02-22 09:28:54.150 7 INFO os_brick.initiator.connectors.lightos [req-e56162e4-3ef2-4a9c-ab67-984ff9fda81f d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 721232b2-ca89-4633-bdb0-a72218dc2ad7
2022-02-22 09:28:55.247 7 INFO nova.compute.manager [req-60baf61e-d0d8-4e55-acd6-e233297089e6 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Cinder extended volume 83f38815-00d5-491e-afe2-b72e3fe9aeee; extending it to detect new size
2022-02-22 09:28:55.332 7 INFO os_brick.initiator.connectors.lightos [req-60baf61e-d0d8-4e55-acd6-e233297089e6 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6c0e95d8-8a0f-4821-a143-d7abe5016b35
2022-02-22 09:28:55.937 7 INFO nova.compute.manager [req-7d5f6f4d-f673-47e1-9156-2c0c0d6be2cc 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Detaching volume 83f38815-00d5-491e-afe2-b72e3fe9aeee
2022-02-22 09:28:55.995 7 INFO nova.virt.block_device [req-7d5f6f4d-f673-47e1-9156-2c0c0d6be2cc 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Attempting to driver detach volume 83f38815-00d5-491e-afe2-b72e3fe9aeee from mountpoint /dev/vdb
2022-02-22 09:28:56.014 7 INFO nova.virt.libvirt.driver [req-7d5f6f4d-f673-47e1-9156-2c0c0d6be2cc 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] Successfully detached device vdb from instance 220f26f9-e46d-4c39-900a-5753ce40ce42 from the persistent domain config.
2022-02-22 09:28:56.152 7 INFO nova.compute.manager [req-ff7090ef-29fe-48e8-a624-b76d1cd303cb d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Terminating instance
2022-02-22 09:28:56.158 7 INFO nova.virt.libvirt.driver [req-7d5f6f4d-f673-47e1-9156-2c0c0d6be2cc 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] Successfully detached device vdb from instance 220f26f9-e46d-4c39-900a-5753ce40ce42 from the live domain config.
2022-02-22 09:28:56.160 7 INFO os_brick.initiator.connectors.lightos [req-7d5f6f4d-f673-47e1-9156-2c0c0d6be2cc 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 6c0e95d8-8a0f-4821-a143-d7abe5016b35
2022-02-22 09:28:56.487 7 INFO nova.virt.libvirt.driver [-] [instance: df9db753-0922-46bb-a24d-3f730097c328] Instance destroyed successfully.
2022-02-22 09:28:56.503 7 INFO nova.virt.libvirt.driver [req-ff7090ef-29fe-48e8-a624-b76d1cd303cb d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Deleting instance files /var/lib/nova/instances/df9db753-0922-46bb-a24d-3f730097c328_del
2022-02-22 09:28:56.504 7 INFO nova.virt.libvirt.driver [req-ff7090ef-29fe-48e8-a624-b76d1cd303cb d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Deletion of /var/lib/nova/instances/df9db753-0922-46bb-a24d-3f730097c328_del complete
2022-02-22 09:28:56.573 7 INFO nova.compute.manager [req-ff7090ef-29fe-48e8-a624-b76d1cd303cb d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] [instance: df9db753-0922-46bb-a24d-3f730097c328] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:28:56.641 7 INFO nova.compute.manager [-] [instance: df9db753-0922-46bb-a24d-3f730097c328] Took 0.07 seconds to deallocate network for instance.
2022-02-22 09:28:56.837 7 INFO nova.scheduler.client.report [req-ff7090ef-29fe-48e8-a624-b76d1cd303cb d8820963d56e4faab07cfeb71ae0c28c e4ca3c9cf5144882a494534da773cbed - default default] Deleted allocations for instance df9db753-0922-46bb-a24d-3f730097c328
2022-02-22 09:28:58.185 7 INFO nova.compute.manager [req-b102d77e-c0cb-4ab9-b5a5-3c76040b53b2 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Terminating instance
2022-02-22 09:28:58.521 7 INFO nova.virt.libvirt.driver [-] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Instance destroyed successfully.
2022-02-22 09:28:58.538 7 INFO nova.virt.libvirt.driver [req-b102d77e-c0cb-4ab9-b5a5-3c76040b53b2 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Deleting instance files /var/lib/nova/instances/220f26f9-e46d-4c39-900a-5753ce40ce42_del
2022-02-22 09:28:58.539 7 INFO nova.virt.libvirt.driver [req-b102d77e-c0cb-4ab9-b5a5-3c76040b53b2 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Deletion of /var/lib/nova/instances/220f26f9-e46d-4c39-900a-5753ce40ce42_del complete
2022-02-22 09:28:58.607 7 INFO nova.compute.manager [req-b102d77e-c0cb-4ab9-b5a5-3c76040b53b2 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 09:28:58.673 7 INFO nova.compute.manager [-] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] Took 0.06 seconds to deallocate network for instance.
2022-02-22 09:28:58.869 7 INFO nova.scheduler.client.report [req-b102d77e-c0cb-4ab9-b5a5-3c76040b53b2 5a2c8d9c80494f33aaeffb74f4513726 882232f29bd44e898620237205add71f - default default] Deleted allocations for instance 220f26f9-e46d-4c39-900a-5753ce40ce42
2022-02-22 09:29:11.485 7 INFO nova.compute.manager [-] [instance: df9db753-0922-46bb-a24d-3f730097c328] VM Stopped (Lifecycle Event)
2022-02-22 09:29:13.519 7 INFO nova.compute.manager [-] [instance: 220f26f9-e46d-4c39-900a-5753ce40ce42] VM Stopped (Lifecycle Event)
