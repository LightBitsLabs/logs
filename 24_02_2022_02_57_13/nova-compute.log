Build Started 24_02_2022_02_57_13
2022-02-24 04:59:29.617 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-24 04:59:33.558 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-24 04:59:34.478 7 INFO nova.virt.driver [req-4b07dfcd-8484-4600-bfb2-b3511dff6d02 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-24 04:59:34.874 7 INFO nova.compute.provider_config [req-4b07dfcd-8484-4600-bfb2-b3511dff6d02 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-24 04:59:34.894 7 WARNING oslo_config.cfg [req-4b07dfcd-8484-4600-bfb2-b3511dff6d02 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-24 04:59:34.914 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-24 04:59:34.927 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-24 04:59:34.960 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-24 04:59:35.053 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-24 04:59:35.066 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-24 04:59:35.068 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-24 04:59:35.413 7 INFO nova.compute.manager [req-6acbb53a-179e-4145-8870-a2d2d763656c - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-24 04:59:37.131 7 INFO nova.virt.libvirt.host [req-6acbb53a-179e-4145-8870-a2d2d763656c - - - - -] kernel doesn't support AMD SEV
2022-02-24 05:00:31.848 7 INFO nova.compute.claims [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Claim successful on node rack08-server63
2022-02-24 05:00:32.234 7 INFO nova.virt.libvirt.driver [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Creating image
2022-02-24 05:00:32.238 7 INFO oslo.privsep.daemon [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpaqudv2pq/privsep.sock']
2022-02-24 05:00:33.868 7 INFO oslo.privsep.daemon [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Spawned new privsep daemon via rootwrap
2022-02-24 05:00:33.720 79 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-24 05:00:33.726 79 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-24 05:00:33.731 79 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-24 05:00:33.731 79 INFO oslo.privsep.daemon [-] privsep daemon running as pid 79
2022-02-24 05:00:35.167 7 INFO nova.compute.manager [-] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] VM Resumed (Lifecycle Event)
2022-02-24 05:00:35.178 7 INFO nova.virt.libvirt.driver [-] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Instance spawned successfully.
2022-02-24 05:00:35.243 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:35.244 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] VM Started (Lifecycle Event)
2022-02-24 05:00:35.289 7 INFO nova.compute.manager [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Took 3.06 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:35.300 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:35.374 7 INFO nova.compute.manager [req-eed849c8-2683-40f0-bedf-b02b4652d9cc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Took 3.57 seconds to build instance.
2022-02-24 05:00:40.350 7 INFO nova.compute.manager [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Attaching volume ee4f66b1-3f0d-4a4a-a08e-ab52a6ed2021 to /dev/vdb
2022-02-24 05:00:40.431 7 INFO oslo.privsep.daemon [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp2yx33r_6/privsep.sock']
2022-02-24 05:00:41.101 7 INFO oslo.privsep.daemon [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Spawned new privsep daemon via rootwrap
2022-02-24 05:00:41.019 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-24 05:00:41.026 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-24 05:00:41.031 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-24 05:00:41.032 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-24 05:00:41.429 7 WARNING os_brick.initiator.connectors.nvmeof [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:00:42.775 7 INFO os_brick.initiator.connectors.lightos [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: connect_volume called for volume ad88ed19-ddec-4303-a127-36df1b944eef, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ad88ed19-ddec-4303-a127-36df1b944eef', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:00:42.810 7 INFO os_brick.initiator.connectors.lightos [req-444f4984-15e4-44da-8de7-e97a1f9bba35 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ad88ed19-ddec-4303-a127-36df1b944eef
2022-02-24 05:00:45.413 7 INFO nova.compute.claims [req-11f27781-ecfa-44e8-ab49-ae098678a283 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Claim successful on node rack08-server63
2022-02-24 05:00:45.832 7 INFO nova.virt.libvirt.driver [req-11f27781-ecfa-44e8-ab49-ae098678a283 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Creating image
2022-02-24 05:00:47.036 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] VM Resumed (Lifecycle Event)
2022-02-24 05:00:47.044 7 INFO nova.virt.libvirt.driver [-] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Instance spawned successfully.
2022-02-24 05:00:47.100 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:47.101 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] VM Started (Lifecycle Event)
2022-02-24 05:00:47.145 7 INFO nova.compute.manager [req-11f27781-ecfa-44e8-ab49-ae098678a283 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Took 1.31 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:47.156 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:47.224 7 INFO nova.compute.manager [req-11f27781-ecfa-44e8-ab49-ae098678a283 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Took 1.85 seconds to build instance.
2022-02-24 05:00:47.771 7 INFO nova.compute.claims [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Claim successful on node rack08-server63
2022-02-24 05:00:48.046 7 INFO nova.virt.libvirt.driver [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-24 05:00:48.130 7 INFO nova.virt.block_device [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Booting with volume cde79d2f-5870-48fa-9bde-20a37ea31985 at /dev/vda
2022-02-24 05:00:48.196 7 INFO nova.compute.manager [req-fa26a3f3-c1ba-4368-a127-9115a7038e7d c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Detaching volume ee4f66b1-3f0d-4a4a-a08e-ab52a6ed2021
2022-02-24 05:00:48.218 7 WARNING os_brick.initiator.connectors.nvmeof [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:00:48.257 7 INFO nova.virt.block_device [req-fa26a3f3-c1ba-4368-a127-9115a7038e7d c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Attempting to driver detach volume ee4f66b1-3f0d-4a4a-a08e-ab52a6ed2021 from mountpoint /dev/vdb
2022-02-24 05:00:48.273 7 INFO nova.virt.libvirt.driver [req-fa26a3f3-c1ba-4368-a127-9115a7038e7d c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance a08a70ee-5a6a-4f96-88c0-fde523c58432 from the persistent domain config.
2022-02-24 05:00:48.428 7 INFO nova.virt.libvirt.driver [req-fa26a3f3-c1ba-4368-a127-9115a7038e7d c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance a08a70ee-5a6a-4f96-88c0-fde523c58432 from the live domain config.
2022-02-24 05:00:48.431 7 INFO os_brick.initiator.connectors.lightos [req-fa26a3f3-c1ba-4368-a127-9115a7038e7d c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ad88ed19-ddec-4303-a127-36df1b944eef
2022-02-24 05:00:49.694 7 INFO nova.virt.libvirt.driver [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Creating image
2022-02-24 05:00:49.704 7 INFO os_brick.initiator.connectors.lightos [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: connect_volume called for volume e843712d-bdc7-4b8b-b757-cc564136f17f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'e843712d-bdc7-4b8b-b757-cc564136f17f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:00:49.707 7 INFO os_brick.initiator.connectors.lightos [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid e843712d-bdc7-4b8b-b757-cc564136f17f
2022-02-24 05:00:50.550 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] VM Resumed (Lifecycle Event)
2022-02-24 05:00:50.556 7 INFO nova.virt.libvirt.driver [-] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Instance spawned successfully.
2022-02-24 05:00:50.611 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:50.612 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] VM Started (Lifecycle Event)
2022-02-24 05:00:50.661 7 INFO nova.compute.manager [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Took 0.97 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:50.664 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:50.741 7 INFO nova.compute.manager [req-5e48264d-7264-4b57-83e9-a940de844fc3 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Took 3.01 seconds to build instance.
2022-02-24 05:00:52.063 7 INFO nova.compute.claims [req-0ff3a921-9bec-43fb-82bc-462f21387cbc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Claim successful on node rack08-server63
2022-02-24 05:00:52.432 7 INFO nova.virt.libvirt.driver [req-0ff3a921-9bec-43fb-82bc-462f21387cbc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Creating image
2022-02-24 05:00:52.941 7 INFO nova.compute.claims [req-83fb32e9-1337-459b-9d5b-f9aef0780c81 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Claim successful on node rack08-server63
2022-02-24 05:00:53.075 7 INFO nova.compute.claims [req-58986855-6685-40a9-8d12-1fb7d54fb7e2 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Claim successful on node rack08-server63
2022-02-24 05:00:53.329 7 INFO nova.virt.libvirt.driver [req-83fb32e9-1337-459b-9d5b-f9aef0780c81 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Creating image
2022-02-24 05:00:53.458 7 INFO nova.virt.libvirt.driver [req-58986855-6685-40a9-8d12-1fb7d54fb7e2 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Creating image
2022-02-24 05:00:53.597 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] VM Resumed (Lifecycle Event)
2022-02-24 05:00:53.606 7 INFO nova.virt.libvirt.driver [-] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Instance spawned successfully.
2022-02-24 05:00:53.674 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:53.675 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] VM Started (Lifecycle Event)
2022-02-24 05:00:53.730 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:53.753 7 INFO nova.compute.manager [req-0ff3a921-9bec-43fb-82bc-462f21387cbc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Took 1.32 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:53.837 7 INFO nova.compute.manager [req-0ff3a921-9bec-43fb-82bc-462f21387cbc c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Took 1.81 seconds to build instance.
2022-02-24 05:00:54.493 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c5318a84-1a93-43f2-ac62-723f542569de] VM Resumed (Lifecycle Event)
2022-02-24 05:00:54.500 7 INFO nova.virt.libvirt.driver [-] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Instance spawned successfully.
2022-02-24 05:00:54.558 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c5318a84-1a93-43f2-ac62-723f542569de] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:54.559 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c5318a84-1a93-43f2-ac62-723f542569de] VM Started (Lifecycle Event)
2022-02-24 05:00:54.608 7 INFO nova.compute.manager [req-83fb32e9-1337-459b-9d5b-f9aef0780c81 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:54.619 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c5318a84-1a93-43f2-ac62-723f542569de] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:54.655 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] VM Resumed (Lifecycle Event)
2022-02-24 05:00:54.662 7 INFO nova.virt.libvirt.driver [-] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Instance spawned successfully.
2022-02-24 05:00:54.692 7 INFO nova.compute.manager [req-83fb32e9-1337-459b-9d5b-f9aef0780c81 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Took 1.80 seconds to build instance.
2022-02-24 05:00:54.726 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:54.726 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] VM Started (Lifecycle Event)
2022-02-24 05:00:54.780 7 INFO nova.compute.manager [req-58986855-6685-40a9-8d12-1fb7d54fb7e2 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Took 1.32 seconds to spawn the instance on the hypervisor.
2022-02-24 05:00:54.782 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:00:54.873 7 INFO nova.compute.manager [req-58986855-6685-40a9-8d12-1fb7d54fb7e2 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Took 1.84 seconds to build instance.
2022-02-24 05:00:57.330 7 INFO nova.compute.manager [req-22a37526-4628-47f9-9034-0e8f97df869f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Attaching volume 7a7ecafc-7d70-48d1-b8f7-3ca57c6f0283 to /dev/vdb
2022-02-24 05:00:57.415 7 WARNING os_brick.initiator.connectors.nvmeof [req-22a37526-4628-47f9-9034-0e8f97df869f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:00:57.810 7 INFO nova.compute.manager [req-1dd08b94-560d-462c-af21-e5147257d64f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Attaching volume 1de957f5-21de-4971-ac76-e15940ac84ea to /dev/vdb
2022-02-24 05:00:57.898 7 WARNING os_brick.initiator.connectors.nvmeof [req-1dd08b94-560d-462c-af21-e5147257d64f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:00:58.877 7 INFO os_brick.initiator.connectors.lightos [req-22a37526-4628-47f9-9034-0e8f97df869f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: connect_volume called for volume 99074497-cf2a-405a-91b5-2944980e7fc2, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '99074497-cf2a-405a-91b5-2944980e7fc2', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:00:58.881 7 INFO os_brick.initiator.connectors.lightos [req-22a37526-4628-47f9-9034-0e8f97df869f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 99074497-cf2a-405a-91b5-2944980e7fc2
2022-02-24 05:00:59.192 7 INFO os_brick.initiator.connectors.lightos [req-1dd08b94-560d-462c-af21-e5147257d64f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: connect_volume called for volume eb5e4bad-a9e4-4976-bc40-b477aeb01af6, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'eb5e4bad-a9e4-4976-bc40-b477aeb01af6', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:00:59.194 7 INFO os_brick.initiator.connectors.lightos [req-1dd08b94-560d-462c-af21-e5147257d64f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid eb5e4bad-a9e4-4976-bc40-b477aeb01af6
2022-02-24 05:00:59.942 7 INFO nova.compute.manager [req-5e51a3d6-209a-4d28-aa6e-fc9ef1247b77 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Detaching volume 7a7ecafc-7d70-48d1-b8f7-3ca57c6f0283
2022-02-24 05:01:00.002 7 INFO nova.virt.block_device [req-5e51a3d6-209a-4d28-aa6e-fc9ef1247b77 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Attempting to driver detach volume 7a7ecafc-7d70-48d1-b8f7-3ca57c6f0283 from mountpoint /dev/vdb
2022-02-24 05:01:00.021 7 INFO nova.virt.libvirt.driver [req-5e51a3d6-209a-4d28-aa6e-fc9ef1247b77 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance b9b88761-0b8d-442a-9d1a-6b8e86de7827 from the persistent domain config.
2022-02-24 05:01:00.174 7 INFO nova.virt.libvirt.driver [req-5e51a3d6-209a-4d28-aa6e-fc9ef1247b77 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance b9b88761-0b8d-442a-9d1a-6b8e86de7827 from the live domain config.
2022-02-24 05:01:00.177 7 INFO os_brick.initiator.connectors.lightos [req-5e51a3d6-209a-4d28-aa6e-fc9ef1247b77 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 99074497-cf2a-405a-91b5-2944980e7fc2
2022-02-24 05:01:00.320 7 INFO nova.compute.manager [req-dddcec84-be7f-426d-93d0-8d6157776fdc 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Attaching volume 1de957f5-21de-4971-ac76-e15940ac84ea to /dev/vdb
2022-02-24 05:01:00.412 7 WARNING os_brick.initiator.connectors.nvmeof [req-dddcec84-be7f-426d-93d0-8d6157776fdc 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:01:01.704 7 INFO os_brick.initiator.connectors.lightos [req-dddcec84-be7f-426d-93d0-8d6157776fdc 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: connect_volume called for volume eb5e4bad-a9e4-4976-bc40-b477aeb01af6, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'eb5e4bad-a9e4-4976-bc40-b477aeb01af6', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:01:01.705 7 INFO os_brick.initiator.connectors.lightos [req-dddcec84-be7f-426d-93d0-8d6157776fdc 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid eb5e4bad-a9e4-4976-bc40-b477aeb01af6
2022-02-24 05:01:02.871 7 INFO nova.compute.manager [req-c5448c9e-8532-4732-8965-d85f9e44982b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Detaching volume 1de957f5-21de-4971-ac76-e15940ac84ea
2022-02-24 05:01:02.929 7 INFO nova.virt.block_device [req-c5448c9e-8532-4732-8965-d85f9e44982b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Attempting to driver detach volume 1de957f5-21de-4971-ac76-e15940ac84ea from mountpoint /dev/vdb
2022-02-24 05:01:02.947 7 INFO nova.virt.libvirt.driver [req-c5448c9e-8532-4732-8965-d85f9e44982b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Successfully detached device vdb from instance c5318a84-1a93-43f2-ac62-723f542569de from the persistent domain config.
2022-02-24 05:01:03.101 7 INFO nova.virt.libvirt.driver [req-c5448c9e-8532-4732-8965-d85f9e44982b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Successfully detached device vdb from instance c5318a84-1a93-43f2-ac62-723f542569de from the live domain config.
2022-02-24 05:01:03.183 7 INFO nova.virt.libvirt.driver [req-c5448c9e-8532-4732-8965-d85f9e44982b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Detected multiple connections on this host for volume: 1de957f5-21de-4971-ac76-e15940ac84ea, skipping target disconnect.
2022-02-24 05:01:03.287 7 INFO nova.compute.claims [req-6c089494-e850-490c-b97e-cbb96ff165ca c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Claim successful on node rack08-server63
2022-02-24 05:01:03.679 7 INFO nova.virt.libvirt.driver [req-6c089494-e850-490c-b97e-cbb96ff165ca c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Creating image
2022-02-24 05:01:04.839 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] VM Resumed (Lifecycle Event)
2022-02-24 05:01:04.845 7 INFO nova.virt.libvirt.driver [-] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Instance spawned successfully.
2022-02-24 05:01:04.905 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:01:04.905 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] VM Started (Lifecycle Event)
2022-02-24 05:01:04.954 7 INFO nova.compute.manager [req-6c089494-e850-490c-b97e-cbb96ff165ca c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-24 05:01:04.957 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:01:05.040 7 INFO nova.compute.manager [req-6c089494-e850-490c-b97e-cbb96ff165ca c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Took 1.79 seconds to build instance.
2022-02-24 05:01:05.333 7 INFO nova.compute.manager [req-c1d55c1c-0f11-475f-ad43-20a436eae60f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Detaching volume 1de957f5-21de-4971-ac76-e15940ac84ea
2022-02-24 05:01:05.395 7 INFO nova.virt.block_device [req-c1d55c1c-0f11-475f-ad43-20a436eae60f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Attempting to driver detach volume 1de957f5-21de-4971-ac76-e15940ac84ea from mountpoint /dev/vdb
2022-02-24 05:01:05.411 7 INFO nova.virt.libvirt.driver [req-c1d55c1c-0f11-475f-ad43-20a436eae60f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Successfully detached device vdb from instance c8b5c304-7f8e-4faf-9515-e3b67b0248db from the persistent domain config.
2022-02-24 05:01:05.598 7 INFO nova.virt.libvirt.driver [req-c1d55c1c-0f11-475f-ad43-20a436eae60f 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Successfully detached device vdb from instance c8b5c304-7f8e-4faf-9515-e3b67b0248db from the live domain config.
2022-02-24 05:01:07.863 7 INFO nova.compute.manager [req-6ad4e568-c8a3-4dd6-813f-0bedf56bcf15 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Attaching volume 548ed31d-d945-42d8-b77d-a5f109064574 to /dev/vdb
2022-02-24 05:01:07.952 7 WARNING os_brick.initiator.connectors.nvmeof [req-6ad4e568-c8a3-4dd6-813f-0bedf56bcf15 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:02:05.911 7 INFO os_brick.initiator.connectors.lightos [req-6ad4e568-c8a3-4dd6-813f-0bedf56bcf15 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: connect_volume called for volume cce13c4f-17b5-49ce-add8-5a9258b87147, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'cce13c4f-17b5-49ce-add8-5a9258b87147', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:02:05.915 7 INFO os_brick.initiator.connectors.lightos [req-6ad4e568-c8a3-4dd6-813f-0bedf56bcf15 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid cce13c4f-17b5-49ce-add8-5a9258b87147
2022-02-24 05:02:07.585 7 INFO nova.compute.manager [req-06276eb3-512b-4ca7-acf3-7638cc32c97f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Detaching volume 548ed31d-d945-42d8-b77d-a5f109064574
2022-02-24 05:02:07.646 7 INFO nova.virt.block_device [req-06276eb3-512b-4ca7-acf3-7638cc32c97f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Attempting to driver detach volume 548ed31d-d945-42d8-b77d-a5f109064574 from mountpoint /dev/vdb
2022-02-24 05:02:07.665 7 INFO nova.virt.libvirt.driver [req-06276eb3-512b-4ca7-acf3-7638cc32c97f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance 22c88c47-25e0-4148-892e-3c052f99eb37 from the persistent domain config.
2022-02-24 05:02:07.811 7 INFO nova.virt.libvirt.driver [req-06276eb3-512b-4ca7-acf3-7638cc32c97f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Successfully detached device vdb from instance 22c88c47-25e0-4148-892e-3c052f99eb37 from the live domain config.
2022-02-24 05:02:07.814 7 INFO os_brick.initiator.connectors.lightos [req-06276eb3-512b-4ca7-acf3-7638cc32c97f c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid cce13c4f-17b5-49ce-add8-5a9258b87147
2022-02-24 05:02:11.044 7 INFO nova.compute.manager [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Terminating instance
2022-02-24 05:02:11.389 7 INFO nova.virt.libvirt.driver [-] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Instance destroyed successfully.
2022-02-24 05:02:11.405 7 INFO nova.virt.libvirt.driver [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Deleting instance files /var/lib/nova/instances/22c88c47-25e0-4148-892e-3c052f99eb37_del
2022-02-24 05:02:11.406 7 INFO nova.virt.libvirt.driver [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Deletion of /var/lib/nova/instances/22c88c47-25e0-4148-892e-3c052f99eb37_del complete
2022-02-24 05:02:11.474 7 INFO nova.virt.libvirt.host [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] UEFI support detected
2022-02-24 05:02:11.476 7 INFO nova.compute.manager [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:11.543 7 INFO nova.compute.manager [-] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:02:11.743 7 INFO nova.scheduler.client.report [req-07340d6a-8b4a-4467-9a52-10f69ab173f3 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Deleted allocations for instance 22c88c47-25e0-4148-892e-3c052f99eb37
2022-02-24 05:02:13.450 7 INFO nova.compute.manager [req-47bb6650-89b5-4cee-a91d-89eeb1b31126 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Terminating instance
2022-02-24 05:02:13.806 7 INFO nova.virt.libvirt.driver [-] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Instance destroyed successfully.
2022-02-24 05:02:13.821 7 INFO nova.virt.libvirt.driver [req-47bb6650-89b5-4cee-a91d-89eeb1b31126 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Deleting instance files /var/lib/nova/instances/b9b88761-0b8d-442a-9d1a-6b8e86de7827_del
2022-02-24 05:02:13.823 7 INFO nova.virt.libvirt.driver [req-47bb6650-89b5-4cee-a91d-89eeb1b31126 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Deletion of /var/lib/nova/instances/b9b88761-0b8d-442a-9d1a-6b8e86de7827_del complete
2022-02-24 05:02:13.894 7 INFO nova.compute.manager [req-47bb6650-89b5-4cee-a91d-89eeb1b31126 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:13.959 7 INFO nova.compute.manager [-] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] Took 0.06 seconds to deallocate network for instance.
2022-02-24 05:02:14.165 7 INFO nova.scheduler.client.report [req-47bb6650-89b5-4cee-a91d-89eeb1b31126 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Deleted allocations for instance b9b88761-0b8d-442a-9d1a-6b8e86de7827
2022-02-24 05:02:14.709 7 INFO nova.compute.manager [req-320b2885-2725-4be8-b861-2002f47c18b4 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Terminating instance
2022-02-24 05:02:15.066 7 INFO nova.virt.libvirt.driver [-] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Instance destroyed successfully.
2022-02-24 05:02:15.081 7 INFO nova.virt.libvirt.driver [req-320b2885-2725-4be8-b861-2002f47c18b4 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Deleting instance files /var/lib/nova/instances/4a2bddd6-720f-4eaf-93bb-bc57ef6378a1_del
2022-02-24 05:02:15.083 7 INFO nova.virt.libvirt.driver [req-320b2885-2725-4be8-b861-2002f47c18b4 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Deletion of /var/lib/nova/instances/4a2bddd6-720f-4eaf-93bb-bc57ef6378a1_del complete
2022-02-24 05:02:15.152 7 INFO nova.compute.manager [req-320b2885-2725-4be8-b861-2002f47c18b4 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:15.226 7 INFO nova.compute.manager [-] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:02:15.421 7 INFO nova.scheduler.client.report [req-320b2885-2725-4be8-b861-2002f47c18b4 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Deleted allocations for instance 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1
2022-02-24 05:02:17.117 7 INFO nova.compute.manager [req-ffe2efb1-5c91-464d-8a5f-19d688995d94 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Terminating instance
2022-02-24 05:02:17.473 7 INFO nova.virt.libvirt.driver [-] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Instance destroyed successfully.
2022-02-24 05:02:17.487 7 INFO nova.virt.libvirt.driver [req-ffe2efb1-5c91-464d-8a5f-19d688995d94 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Deleting instance files /var/lib/nova/instances/a08a70ee-5a6a-4f96-88c0-fde523c58432_del
2022-02-24 05:02:17.489 7 INFO nova.virt.libvirt.driver [req-ffe2efb1-5c91-464d-8a5f-19d688995d94 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Deletion of /var/lib/nova/instances/a08a70ee-5a6a-4f96-88c0-fde523c58432_del complete
2022-02-24 05:02:17.558 7 INFO nova.compute.manager [req-ffe2efb1-5c91-464d-8a5f-19d688995d94 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:17.625 7 INFO nova.compute.manager [-] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:02:17.798 7 INFO nova.scheduler.client.report [req-ffe2efb1-5c91-464d-8a5f-19d688995d94 c9dba08a835e493abc870603bed1f0a3 a0a8fe08fe1b486d9e9c1e94ae744f16 - default default] Deleted allocations for instance a08a70ee-5a6a-4f96-88c0-fde523c58432
2022-02-24 05:02:24.624 7 INFO nova.compute.claims [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Claim successful on node rack08-server63
2022-02-24 05:02:24.904 7 INFO nova.virt.libvirt.driver [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-24 05:02:24.991 7 INFO nova.virt.block_device [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Booting with volume b6aa50fa-5de4-4d32-8a60-5e343db7d458 at /dev/vda
2022-02-24 05:02:25.079 7 WARNING os_brick.initiator.connectors.nvmeof [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:02:26.387 7 INFO nova.compute.manager [-] [instance: 22c88c47-25e0-4148-892e-3c052f99eb37] VM Stopped (Lifecycle Event)
2022-02-24 05:02:26.575 7 INFO nova.virt.libvirt.driver [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Creating image
2022-02-24 05:02:26.586 7 INFO os_brick.initiator.connectors.lightos [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: connect_volume called for volume f4baedac-9e27-49f7-8821-2d06489e9cf0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f4baedac-9e27-49f7-8821-2d06489e9cf0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:02:26.591 7 INFO os_brick.initiator.connectors.lightos [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f4baedac-9e27-49f7-8821-2d06489e9cf0
2022-02-24 05:02:27.446 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] VM Resumed (Lifecycle Event)
2022-02-24 05:02:27.453 7 INFO nova.virt.libvirt.driver [-] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Instance spawned successfully.
2022-02-24 05:02:27.506 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:02:27.507 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] VM Started (Lifecycle Event)
2022-02-24 05:02:27.560 7 INFO nova.compute.manager [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Took 0.99 seconds to spawn the instance on the hypervisor.
2022-02-24 05:02:27.564 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:02:27.642 7 INFO nova.compute.manager [req-01618fc7-107b-4082-8618-dfa70f28ac6c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Took 3.05 seconds to build instance.
2022-02-24 05:02:28.804 7 INFO nova.compute.manager [-] [instance: b9b88761-0b8d-442a-9d1a-6b8e86de7827] VM Stopped (Lifecycle Event)
2022-02-24 05:02:29.989 7 INFO nova.compute.manager [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Terminating instance
2022-02-24 05:02:30.063 7 INFO nova.compute.manager [-] [instance: 4a2bddd6-720f-4eaf-93bb-bc57ef6378a1] VM Stopped (Lifecycle Event)
2022-02-24 05:02:30.328 7 INFO nova.virt.libvirt.driver [-] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Instance destroyed successfully.
2022-02-24 05:02:30.400 7 INFO os_brick.initiator.connectors.lightos [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f4baedac-9e27-49f7-8821-2d06489e9cf0
2022-02-24 05:02:30.412 7 INFO nova.virt.libvirt.driver [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Deleting instance files /var/lib/nova/instances/7691a690-657a-49af-84ec-8ef0e9c5bd06_del
2022-02-24 05:02:30.413 7 INFO nova.virt.libvirt.driver [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Deletion of /var/lib/nova/instances/7691a690-657a-49af-84ec-8ef0e9c5bd06_del complete
2022-02-24 05:02:30.484 7 INFO nova.compute.manager [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:30.552 7 INFO nova.compute.manager [-] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:02:31.776 7 INFO nova.compute.manager [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] Took 1.22 seconds to detach 1 volumes for instance.
2022-02-24 05:02:31.951 7 INFO nova.scheduler.client.report [req-1ba3880a-ec55-451e-9d10-5d8eec08d52b 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Deleted allocations for instance 7691a690-657a-49af-84ec-8ef0e9c5bd06
2022-02-24 05:02:32.471 7 INFO nova.compute.manager [-] [instance: a08a70ee-5a6a-4f96-88c0-fde523c58432] VM Stopped (Lifecycle Event)
2022-02-24 05:02:34.887 7 INFO nova.compute.manager [req-525d5c38-60b3-40d3-aab9-d61a30452d0c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Terminating instance
2022-02-24 05:02:35.237 7 INFO nova.virt.libvirt.driver [-] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Instance destroyed successfully.
2022-02-24 05:02:35.252 7 INFO nova.virt.libvirt.driver [req-525d5c38-60b3-40d3-aab9-d61a30452d0c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Deleting instance files /var/lib/nova/instances/c8b5c304-7f8e-4faf-9515-e3b67b0248db_del
2022-02-24 05:02:35.254 7 INFO nova.virt.libvirt.driver [req-525d5c38-60b3-40d3-aab9-d61a30452d0c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Deletion of /var/lib/nova/instances/c8b5c304-7f8e-4faf-9515-e3b67b0248db_del complete
2022-02-24 05:02:35.321 7 INFO nova.compute.manager [req-525d5c38-60b3-40d3-aab9-d61a30452d0c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:35.383 7 INFO nova.compute.manager [-] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] Took 0.06 seconds to deallocate network for instance.
2022-02-24 05:02:35.581 7 INFO nova.scheduler.client.report [req-525d5c38-60b3-40d3-aab9-d61a30452d0c 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Deleted allocations for instance c8b5c304-7f8e-4faf-9515-e3b67b0248db
2022-02-24 05:02:36.145 7 INFO nova.compute.manager [req-16b1635a-77bd-4e3f-bf1f-7170d494e3b6 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Terminating instance
2022-02-24 05:02:36.487 7 INFO nova.virt.libvirt.driver [-] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Instance destroyed successfully.
2022-02-24 05:02:36.503 7 INFO nova.virt.libvirt.driver [req-16b1635a-77bd-4e3f-bf1f-7170d494e3b6 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Deleting instance files /var/lib/nova/instances/c5318a84-1a93-43f2-ac62-723f542569de_del
2022-02-24 05:02:36.505 7 INFO nova.virt.libvirt.driver [req-16b1635a-77bd-4e3f-bf1f-7170d494e3b6 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Deletion of /var/lib/nova/instances/c5318a84-1a93-43f2-ac62-723f542569de_del complete
2022-02-24 05:02:36.574 7 INFO nova.compute.manager [req-16b1635a-77bd-4e3f-bf1f-7170d494e3b6 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:36.639 7 INFO nova.compute.manager [-] [instance: c5318a84-1a93-43f2-ac62-723f542569de] Took 0.06 seconds to deallocate network for instance.
2022-02-24 05:02:36.836 7 INFO nova.scheduler.client.report [req-16b1635a-77bd-4e3f-bf1f-7170d494e3b6 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Deleted allocations for instance c5318a84-1a93-43f2-ac62-723f542569de
2022-02-24 05:02:37.414 7 INFO nova.compute.manager [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Terminating instance
2022-02-24 05:02:37.767 7 INFO nova.virt.libvirt.driver [-] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Instance destroyed successfully.
2022-02-24 05:02:37.842 7 INFO os_brick.initiator.connectors.lightos [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid e843712d-bdc7-4b8b-b757-cc564136f17f
2022-02-24 05:02:37.854 7 INFO nova.virt.libvirt.driver [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Deleting instance files /var/lib/nova/instances/81b3c89a-de96-47a3-be94-46bb4ebcab98_del
2022-02-24 05:02:37.855 7 INFO nova.virt.libvirt.driver [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Deletion of /var/lib/nova/instances/81b3c89a-de96-47a3-be94-46bb4ebcab98_del complete
2022-02-24 05:02:37.923 7 INFO nova.compute.manager [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-24 05:02:38.003 7 INFO nova.compute.manager [-] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Took 0.08 seconds to deallocate network for instance.
2022-02-24 05:02:39.184 7 INFO nova.compute.manager [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] Took 1.18 seconds to detach 1 volumes for instance.
2022-02-24 05:02:39.375 7 INFO nova.scheduler.client.report [req-325f756c-837c-4aa4-9264-98f0b8faec92 11eef7642bc24348a855bfd4cae0b83b 1d5e1845106a401aa1bf5abeafc4677a - default default] Deleted allocations for instance 81b3c89a-de96-47a3-be94-46bb4ebcab98
2022-02-24 05:02:45.325 7 INFO nova.compute.manager [-] [instance: 7691a690-657a-49af-84ec-8ef0e9c5bd06] VM Stopped (Lifecycle Event)
2022-02-24 05:02:50.236 7 INFO nova.compute.manager [-] [instance: c8b5c304-7f8e-4faf-9515-e3b67b0248db] VM Stopped (Lifecycle Event)
2022-02-24 05:02:51.486 7 INFO nova.compute.manager [-] [instance: c5318a84-1a93-43f2-ac62-723f542569de] VM Stopped (Lifecycle Event)
2022-02-24 05:02:52.764 7 INFO nova.compute.manager [-] [instance: 81b3c89a-de96-47a3-be94-46bb4ebcab98] VM Stopped (Lifecycle Event)
2022-02-24 05:03:18.409 7 INFO nova.compute.claims [req-ed8bb68b-4c6f-4161-a185-f2e6d31a0a96 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Claim successful on node rack08-server63
2022-02-24 05:03:18.814 7 INFO nova.virt.libvirt.driver [req-ed8bb68b-4c6f-4161-a185-f2e6d31a0a96 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Creating image
2022-02-24 05:03:20.002 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] VM Resumed (Lifecycle Event)
2022-02-24 05:03:20.009 7 INFO nova.virt.libvirt.driver [-] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Instance spawned successfully.
2022-02-24 05:03:20.069 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:03:20.070 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] VM Started (Lifecycle Event)
2022-02-24 05:03:20.116 7 INFO nova.compute.manager [req-ed8bb68b-4c6f-4161-a185-f2e6d31a0a96 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-24 05:03:20.121 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:03:20.199 7 INFO nova.compute.manager [req-ed8bb68b-4c6f-4161-a185-f2e6d31a0a96 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Took 1.83 seconds to build instance.
2022-02-24 05:03:21.788 7 INFO nova.compute.manager [req-c293fc04-3657-4ab3-912e-cdaa46ded257 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Terminating instance
2022-02-24 05:03:22.143 7 INFO nova.virt.libvirt.driver [-] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Instance destroyed successfully.
2022-02-24 05:03:22.158 7 INFO nova.virt.libvirt.driver [req-c293fc04-3657-4ab3-912e-cdaa46ded257 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Deleting instance files /var/lib/nova/instances/16c21f2a-65f4-444b-a108-2b63915c0f89_del
2022-02-24 05:03:22.159 7 INFO nova.virt.libvirt.driver [req-c293fc04-3657-4ab3-912e-cdaa46ded257 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Deletion of /var/lib/nova/instances/16c21f2a-65f4-444b-a108-2b63915c0f89_del complete
2022-02-24 05:03:22.232 7 INFO nova.compute.manager [req-c293fc04-3657-4ab3-912e-cdaa46ded257 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:03:22.309 7 INFO nova.compute.manager [-] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] Took 0.08 seconds to deallocate network for instance.
2022-02-24 05:03:22.511 7 INFO nova.scheduler.client.report [req-c293fc04-3657-4ab3-912e-cdaa46ded257 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] Deleted allocations for instance 16c21f2a-65f4-444b-a108-2b63915c0f89
2022-02-24 05:03:24.153 7 INFO nova.compute.claims [req-5c86e3b1-8494-4385-8bab-292af49872cc 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Claim successful on node rack08-server63
2022-02-24 05:03:24.559 7 INFO nova.virt.libvirt.driver [req-5c86e3b1-8494-4385-8bab-292af49872cc 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Creating image
2022-02-24 05:03:25.699 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] VM Resumed (Lifecycle Event)
2022-02-24 05:03:25.706 7 INFO nova.virt.libvirt.driver [-] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Instance spawned successfully.
2022-02-24 05:03:25.764 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:03:25.765 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] VM Started (Lifecycle Event)
2022-02-24 05:03:25.812 7 INFO nova.compute.manager [req-5c86e3b1-8494-4385-8bab-292af49872cc 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-24 05:03:25.816 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:03:25.894 7 INFO nova.compute.manager [req-5c86e3b1-8494-4385-8bab-292af49872cc 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Took 1.78 seconds to build instance.
2022-02-24 05:03:26.482 7 INFO nova.compute.manager [req-5093aca9-5a77-4eb9-a434-0d47b80555b3 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Terminating instance
2022-02-24 05:03:26.832 7 INFO nova.virt.libvirt.driver [-] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Instance destroyed successfully.
2022-02-24 05:03:26.847 7 INFO nova.virt.libvirt.driver [req-5093aca9-5a77-4eb9-a434-0d47b80555b3 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Deleting instance files /var/lib/nova/instances/6341cf56-cb0c-4c12-aea0-d247e3fa77ed_del
2022-02-24 05:03:26.848 7 INFO nova.virt.libvirt.driver [req-5093aca9-5a77-4eb9-a434-0d47b80555b3 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Deletion of /var/lib/nova/instances/6341cf56-cb0c-4c12-aea0-d247e3fa77ed_del complete
2022-02-24 05:03:26.916 7 INFO nova.compute.manager [req-5093aca9-5a77-4eb9-a434-0d47b80555b3 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-24 05:03:26.985 7 INFO nova.compute.manager [-] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:03:27.181 7 INFO nova.scheduler.client.report [req-5093aca9-5a77-4eb9-a434-0d47b80555b3 174e5fdf6a2e475f981ddf04c5abcba6 7fde15d078a740899c77faa0ed02e92a - default default] Deleted allocations for instance 6341cf56-cb0c-4c12-aea0-d247e3fa77ed
2022-02-24 05:03:37.140 7 INFO nova.compute.manager [-] [instance: 16c21f2a-65f4-444b-a108-2b63915c0f89] VM Stopped (Lifecycle Event)
2022-02-24 05:03:41.830 7 INFO nova.compute.manager [-] [instance: 6341cf56-cb0c-4c12-aea0-d247e3fa77ed] VM Stopped (Lifecycle Event)
2022-02-24 05:04:27.027 7 INFO nova.compute.claims [req-3dfe2171-a4b6-41df-aea7-d2cca92e20e4 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Claim successful on node rack08-server63
2022-02-24 05:04:27.417 7 INFO nova.virt.libvirt.driver [req-3dfe2171-a4b6-41df-aea7-d2cca92e20e4 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Creating image
2022-02-24 05:04:28.547 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] VM Resumed (Lifecycle Event)
2022-02-24 05:04:28.554 7 INFO nova.virt.libvirt.driver [-] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Instance spawned successfully.
2022-02-24 05:04:28.617 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:04:28.617 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] VM Started (Lifecycle Event)
2022-02-24 05:04:28.664 7 INFO nova.compute.manager [req-3dfe2171-a4b6-41df-aea7-d2cca92e20e4 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-24 05:04:28.675 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:04:28.744 7 INFO nova.compute.manager [req-3dfe2171-a4b6-41df-aea7-d2cca92e20e4 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Took 1.76 seconds to build instance.
2022-02-24 05:04:33.510 7 INFO nova.compute.manager [req-4029e822-4400-474c-a223-1901c8cd92c3 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Terminating instance
2022-02-24 05:04:33.854 7 INFO nova.compute.claims [req-554477be-75f2-4978-927d-c2cd5affa627 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Claim successful on node rack08-server63
2022-02-24 05:04:33.861 7 INFO nova.virt.libvirt.driver [-] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Instance destroyed successfully.
2022-02-24 05:04:33.877 7 INFO nova.virt.libvirt.driver [req-4029e822-4400-474c-a223-1901c8cd92c3 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Deleting instance files /var/lib/nova/instances/91bd9141-b846-474e-bc14-93d6cd2172b7_del
2022-02-24 05:04:33.878 7 INFO nova.virt.libvirt.driver [req-4029e822-4400-474c-a223-1901c8cd92c3 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Deletion of /var/lib/nova/instances/91bd9141-b846-474e-bc14-93d6cd2172b7_del complete
2022-02-24 05:04:33.962 7 INFO nova.compute.manager [req-4029e822-4400-474c-a223-1901c8cd92c3 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Took 0.33 seconds to destroy the instance on the hypervisor.
2022-02-24 05:04:34.027 7 INFO nova.compute.manager [-] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] Took 0.06 seconds to deallocate network for instance.
2022-02-24 05:04:34.194 7 INFO nova.scheduler.client.report [req-4029e822-4400-474c-a223-1901c8cd92c3 d524ded9b062492fbdca1f0f394fb63a 005e5c7a4fd147578e9f8d166657988d - default default] Deleted allocations for instance 91bd9141-b846-474e-bc14-93d6cd2172b7
2022-02-24 05:04:34.230 7 INFO nova.virt.libvirt.driver [req-554477be-75f2-4978-927d-c2cd5affa627 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Creating image
2022-02-24 05:04:35.402 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] VM Resumed (Lifecycle Event)
2022-02-24 05:04:35.409 7 INFO nova.virt.libvirt.driver [-] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Instance spawned successfully.
2022-02-24 05:04:35.469 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:04:35.469 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] VM Started (Lifecycle Event)
2022-02-24 05:04:35.526 7 INFO nova.compute.manager [req-554477be-75f2-4978-927d-c2cd5affa627 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-24 05:04:35.528 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:04:35.610 7 INFO nova.compute.manager [req-554477be-75f2-4978-927d-c2cd5affa627 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Took 1.94 seconds to build instance.
2022-02-24 05:04:48.850 7 INFO nova.compute.manager [-] [instance: 91bd9141-b846-474e-bc14-93d6cd2172b7] VM Stopped (Lifecycle Event)
2022-02-24 05:04:52.044 7 INFO nova.virt.libvirt.driver [req-de00a1ad-b5ed-46dc-9d5e-8ace08b0222a be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Ignoring supplied device name: /dev/vdb
2022-02-24 05:04:52.214 7 INFO nova.compute.manager [req-de00a1ad-b5ed-46dc-9d5e-8ace08b0222a be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Attaching volume d955b6d6-1b1c-495a-8787-b1a490247372 to /dev/vdb
2022-02-24 05:04:52.307 7 WARNING os_brick.initiator.connectors.nvmeof [req-de00a1ad-b5ed-46dc-9d5e-8ace08b0222a be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:04:53.642 7 INFO os_brick.initiator.connectors.lightos [req-de00a1ad-b5ed-46dc-9d5e-8ace08b0222a be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: connect_volume called for volume 8e641f93-39f1-49f6-985d-5ce043f936c9, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8e641f93-39f1-49f6-985d-5ce043f936c9', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:04:53.646 7 INFO os_brick.initiator.connectors.lightos [req-de00a1ad-b5ed-46dc-9d5e-8ace08b0222a be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e641f93-39f1-49f6-985d-5ce043f936c9
2022-02-24 05:05:04.824 7 INFO nova.compute.manager [req-a4f4de77-9fd7-4d44-b77d-e8b5f1eda1eb be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Detaching volume d955b6d6-1b1c-495a-8787-b1a490247372
2022-02-24 05:05:04.891 7 INFO nova.virt.block_device [req-a4f4de77-9fd7-4d44-b77d-e8b5f1eda1eb be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Attempting to driver detach volume d955b6d6-1b1c-495a-8787-b1a490247372 from mountpoint /dev/vdb
2022-02-24 05:05:04.913 7 INFO nova.virt.libvirt.driver [req-a4f4de77-9fd7-4d44-b77d-e8b5f1eda1eb be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Successfully detached device vdb from instance 34cb5db8-99d4-42e6-9736-5cda680cc7c2 from the persistent domain config.
2022-02-24 05:05:05.058 7 INFO nova.virt.libvirt.driver [req-a4f4de77-9fd7-4d44-b77d-e8b5f1eda1eb be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Successfully detached device vdb from instance 34cb5db8-99d4-42e6-9736-5cda680cc7c2 from the live domain config.
2022-02-24 05:05:05.061 7 INFO os_brick.initiator.connectors.lightos [req-a4f4de77-9fd7-4d44-b77d-e8b5f1eda1eb be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e641f93-39f1-49f6-985d-5ce043f936c9
2022-02-24 05:05:07.066 7 INFO nova.compute.manager [req-215b056f-84f0-41fe-85bb-89ac64335cd0 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Terminating instance
2022-02-24 05:05:07.409 7 INFO nova.virt.libvirt.driver [-] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Instance destroyed successfully.
2022-02-24 05:05:07.424 7 INFO nova.virt.libvirt.driver [req-215b056f-84f0-41fe-85bb-89ac64335cd0 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Deleting instance files /var/lib/nova/instances/34cb5db8-99d4-42e6-9736-5cda680cc7c2_del
2022-02-24 05:05:07.425 7 INFO nova.virt.libvirt.driver [req-215b056f-84f0-41fe-85bb-89ac64335cd0 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Deletion of /var/lib/nova/instances/34cb5db8-99d4-42e6-9736-5cda680cc7c2_del complete
2022-02-24 05:05:07.492 7 INFO nova.compute.manager [req-215b056f-84f0-41fe-85bb-89ac64335cd0 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:05:07.562 7 INFO nova.compute.manager [-] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:05:07.758 7 INFO nova.scheduler.client.report [req-215b056f-84f0-41fe-85bb-89ac64335cd0 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Deleted allocations for instance 34cb5db8-99d4-42e6-9736-5cda680cc7c2
2022-02-24 05:05:12.001 7 INFO nova.compute.claims [req-51d91da5-2ca9-4b68-9794-d1a5f0db2bf4 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Claim successful on node rack08-server63
2022-02-24 05:05:12.392 7 INFO nova.virt.libvirt.driver [req-51d91da5-2ca9-4b68-9794-d1a5f0db2bf4 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Creating image
2022-02-24 05:05:13.560 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: ccc9a756-750b-4702-a581-dc9907951b34] VM Resumed (Lifecycle Event)
2022-02-24 05:05:13.567 7 INFO nova.virt.libvirt.driver [-] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Instance spawned successfully.
2022-02-24 05:05:13.621 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: ccc9a756-750b-4702-a581-dc9907951b34] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:13.622 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: ccc9a756-750b-4702-a581-dc9907951b34] VM Started (Lifecycle Event)
2022-02-24 05:05:13.676 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: ccc9a756-750b-4702-a581-dc9907951b34] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:13.684 7 INFO nova.compute.manager [req-51d91da5-2ca9-4b68-9794-d1a5f0db2bf4 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-24 05:05:13.767 7 INFO nova.compute.manager [req-51d91da5-2ca9-4b68-9794-d1a5f0db2bf4 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Took 1.80 seconds to build instance.
2022-02-24 05:05:15.062 7 INFO nova.virt.libvirt.driver [req-68d7ffca-7aa6-4833-a231-e87325fb1e58 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Ignoring supplied device name: /dev/vdb
2022-02-24 05:05:15.213 7 INFO nova.compute.manager [req-68d7ffca-7aa6-4833-a231-e87325fb1e58 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Attaching volume f66196be-fa04-4ecb-a889-2c067266db14 to /dev/vdb
2022-02-24 05:05:15.300 7 WARNING os_brick.initiator.connectors.nvmeof [req-68d7ffca-7aa6-4833-a231-e87325fb1e58 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:05:15.466 7 INFO nova.compute.claims [req-47dd4ea9-e99f-4d0a-9d7c-5848cf48a7ea be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Claim successful on node rack08-server63
2022-02-24 05:05:15.856 7 INFO nova.virt.libvirt.driver [req-47dd4ea9-e99f-4d0a-9d7c-5848cf48a7ea be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Creating image
2022-02-24 05:05:16.587 7 INFO os_brick.initiator.connectors.lightos [req-68d7ffca-7aa6-4833-a231-e87325fb1e58 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] LIGHTOS: connect_volume called for volume e1b8783a-2f30-4b49-b360-28ffd036163e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'e1b8783a-2f30-4b49-b360-28ffd036163e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:05:16.591 7 INFO os_brick.initiator.connectors.lightos [req-68d7ffca-7aa6-4833-a231-e87325fb1e58 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e1b8783a-2f30-4b49-b360-28ffd036163e
2022-02-24 05:05:17.078 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] VM Resumed (Lifecycle Event)
2022-02-24 05:05:17.085 7 INFO nova.virt.libvirt.driver [-] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Instance spawned successfully.
2022-02-24 05:05:17.143 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:17.143 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] VM Started (Lifecycle Event)
2022-02-24 05:05:17.191 7 INFO nova.compute.manager [req-47dd4ea9-e99f-4d0a-9d7c-5848cf48a7ea be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Took 1.34 seconds to spawn the instance on the hypervisor.
2022-02-24 05:05:17.200 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:17.268 7 INFO nova.compute.manager [req-47dd4ea9-e99f-4d0a-9d7c-5848cf48a7ea be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Took 1.84 seconds to build instance.
2022-02-24 05:05:18.385 7 INFO nova.compute.manager [req-45f5bab4-7115-4519-9271-714b3433846d e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Cinder extended volume f66196be-fa04-4ecb-a889-2c067266db14; extending it to detect new size
2022-02-24 05:05:18.461 7 INFO os_brick.initiator.connectors.lightos [req-45f5bab4-7115-4519-9271-714b3433846d e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e1b8783a-2f30-4b49-b360-28ffd036163e
2022-02-24 05:05:18.530 7 INFO nova.virt.libvirt.driver [req-d838bc3c-578e-49a3-b4e9-80804b85c695 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Ignoring supplied device name: /dev/vdb
2022-02-24 05:05:18.692 7 INFO nova.compute.manager [req-d838bc3c-578e-49a3-b4e9-80804b85c695 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Attaching volume 5e8be63a-3f5c-498f-8ac0-0d51516c2fbd to /dev/vdb
2022-02-24 05:05:18.775 7 WARNING os_brick.initiator.connectors.nvmeof [req-d838bc3c-578e-49a3-b4e9-80804b85c695 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 05:05:19.168 7 INFO nova.compute.manager [req-af30a29d-a5f3-4587-a295-112a1c8228dd a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Detaching volume f66196be-fa04-4ecb-a889-2c067266db14
2022-02-24 05:05:19.235 7 INFO nova.virt.block_device [req-af30a29d-a5f3-4587-a295-112a1c8228dd a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Attempting to driver detach volume f66196be-fa04-4ecb-a889-2c067266db14 from mountpoint /dev/vdb
2022-02-24 05:05:19.254 7 INFO nova.virt.libvirt.driver [req-af30a29d-a5f3-4587-a295-112a1c8228dd a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] Successfully detached device vdb from instance ccc9a756-750b-4702-a581-dc9907951b34 from the persistent domain config.
2022-02-24 05:05:19.406 7 INFO nova.virt.libvirt.driver [req-af30a29d-a5f3-4587-a295-112a1c8228dd a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] Successfully detached device vdb from instance ccc9a756-750b-4702-a581-dc9907951b34 from the live domain config.
2022-02-24 05:05:19.409 7 INFO os_brick.initiator.connectors.lightos [req-af30a29d-a5f3-4587-a295-112a1c8228dd a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid e1b8783a-2f30-4b49-b360-28ffd036163e
2022-02-24 05:05:20.056 7 INFO os_brick.initiator.connectors.lightos [req-d838bc3c-578e-49a3-b4e9-80804b85c695 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: connect_volume called for volume ba88b691-4cc8-48e1-b711-b8e782357c2f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ba88b691-4cc8-48e1-b711-b8e782357c2f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 05:05:20.060 7 INFO os_brick.initiator.connectors.lightos [req-d838bc3c-578e-49a3-b4e9-80804b85c695 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ba88b691-4cc8-48e1-b711-b8e782357c2f
2022-02-24 05:05:21.451 7 INFO nova.compute.manager [req-7a4ffe13-989f-4c62-9ca0-1d451d141ca3 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Terminating instance
2022-02-24 05:05:21.795 7 INFO nova.virt.libvirt.driver [-] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Instance destroyed successfully.
2022-02-24 05:05:21.810 7 INFO nova.virt.libvirt.driver [req-7a4ffe13-989f-4c62-9ca0-1d451d141ca3 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Deleting instance files /var/lib/nova/instances/ccc9a756-750b-4702-a581-dc9907951b34_del
2022-02-24 05:05:21.811 7 INFO nova.virt.libvirt.driver [req-7a4ffe13-989f-4c62-9ca0-1d451d141ca3 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Deletion of /var/lib/nova/instances/ccc9a756-750b-4702-a581-dc9907951b34_del complete
2022-02-24 05:05:21.882 7 INFO nova.compute.manager [req-7a4ffe13-989f-4c62-9ca0-1d451d141ca3 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:05:21.949 7 INFO nova.compute.manager [-] [instance: ccc9a756-750b-4702-a581-dc9907951b34] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:05:22.148 7 INFO nova.scheduler.client.report [req-7a4ffe13-989f-4c62-9ca0-1d451d141ca3 a4947d59a9514453a3ee97d89fc037c4 b852a1477e544b10bcd802d921cb8169 - default default] Deleted allocations for instance ccc9a756-750b-4702-a581-dc9907951b34
2022-02-24 05:05:22.406 7 INFO nova.compute.manager [-] [instance: 34cb5db8-99d4-42e6-9736-5cda680cc7c2] VM Stopped (Lifecycle Event)
2022-02-24 05:05:28.979 7 INFO nova.compute.manager [req-879e4771-c9ba-4c22-99a2-833d0dd87703 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Detaching volume 5e8be63a-3f5c-498f-8ac0-0d51516c2fbd
2022-02-24 05:05:29.045 7 INFO nova.virt.block_device [req-879e4771-c9ba-4c22-99a2-833d0dd87703 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Attempting to driver detach volume 5e8be63a-3f5c-498f-8ac0-0d51516c2fbd from mountpoint /dev/vdb
2022-02-24 05:05:29.065 7 INFO nova.virt.libvirt.driver [req-879e4771-c9ba-4c22-99a2-833d0dd87703 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Successfully detached device vdb from instance e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d from the persistent domain config.
2022-02-24 05:05:29.204 7 INFO nova.virt.libvirt.driver [req-879e4771-c9ba-4c22-99a2-833d0dd87703 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Successfully detached device vdb from instance e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d from the live domain config.
2022-02-24 05:05:29.208 7 INFO os_brick.initiator.connectors.lightos [req-879e4771-c9ba-4c22-99a2-833d0dd87703 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ba88b691-4cc8-48e1-b711-b8e782357c2f
2022-02-24 05:05:31.228 7 INFO nova.compute.manager [req-a2a49532-9e82-4495-8c95-f0fadba186c8 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Terminating instance
2022-02-24 05:05:31.272 7 INFO nova.compute.claims [req-d0d311e0-4786-43b1-8aa4-ffce3929ed7d ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Claim successful on node rack08-server63
2022-02-24 05:05:31.625 7 INFO nova.virt.libvirt.driver [-] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Instance destroyed successfully.
2022-02-24 05:05:31.643 7 INFO nova.virt.libvirt.driver [req-a2a49532-9e82-4495-8c95-f0fadba186c8 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Deleting instance files /var/lib/nova/instances/e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d_del
2022-02-24 05:05:31.644 7 INFO nova.virt.libvirt.driver [req-a2a49532-9e82-4495-8c95-f0fadba186c8 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Deletion of /var/lib/nova/instances/e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d_del complete
2022-02-24 05:05:31.717 7 INFO nova.compute.manager [req-a2a49532-9e82-4495-8c95-f0fadba186c8 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:05:31.781 7 INFO nova.compute.manager [-] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] Took 0.06 seconds to deallocate network for instance.
2022-02-24 05:05:31.881 7 INFO nova.virt.libvirt.driver [req-d0d311e0-4786-43b1-8aa4-ffce3929ed7d ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Creating image
2022-02-24 05:05:31.986 7 INFO nova.scheduler.client.report [req-a2a49532-9e82-4495-8c95-f0fadba186c8 be77cc9fe88340039cd4411971b90147 7e5cc7d5e1de484183c34a182ac1421a - default default] Deleted allocations for instance e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d
2022-02-24 05:05:33.043 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] VM Resumed (Lifecycle Event)
2022-02-24 05:05:33.053 7 INFO nova.virt.libvirt.driver [-] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Instance spawned successfully.
2022-02-24 05:05:33.111 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:33.112 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] VM Started (Lifecycle Event)
2022-02-24 05:05:33.160 7 INFO nova.compute.manager [req-d0d311e0-4786-43b1-8aa4-ffce3929ed7d ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-24 05:05:33.170 7 INFO nova.compute.manager [req-8f3510dd-488e-448f-b1c6-ac0ca0bb1384 - - - - -] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 05:05:33.246 7 INFO nova.compute.manager [req-d0d311e0-4786-43b1-8aa4-ffce3929ed7d ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Took 2.01 seconds to build instance.
2022-02-24 05:05:33.902 7 INFO nova.compute.manager [req-feb22955-8720-4b5d-8b26-7c8d4da72bed ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Terminating instance
2022-02-24 05:05:34.252 7 INFO nova.virt.libvirt.driver [-] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Instance destroyed successfully.
2022-02-24 05:05:34.268 7 INFO nova.virt.libvirt.driver [req-feb22955-8720-4b5d-8b26-7c8d4da72bed ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Deleting instance files /var/lib/nova/instances/0c13e6f6-43b5-4bb4-87f7-cd43c849dc18_del
2022-02-24 05:05:34.269 7 INFO nova.virt.libvirt.driver [req-feb22955-8720-4b5d-8b26-7c8d4da72bed ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Deletion of /var/lib/nova/instances/0c13e6f6-43b5-4bb4-87f7-cd43c849dc18_del complete
2022-02-24 05:05:34.337 7 INFO nova.compute.manager [req-feb22955-8720-4b5d-8b26-7c8d4da72bed ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 05:05:34.404 7 INFO nova.compute.manager [-] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] Took 0.07 seconds to deallocate network for instance.
2022-02-24 05:05:34.605 7 INFO nova.scheduler.client.report [req-feb22955-8720-4b5d-8b26-7c8d4da72bed ef5308b5ca754b15bfd54b92e5db456d 1f72f372a4314fddb78fc5b29057306d - default default] Deleted allocations for instance 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18
2022-02-24 05:05:36.792 7 INFO nova.compute.manager [-] [instance: ccc9a756-750b-4702-a581-dc9907951b34] VM Stopped (Lifecycle Event)
2022-02-24 05:05:46.624 7 INFO nova.compute.manager [-] [instance: e7cae6e8-95d8-4fb8-869a-d5306b0f7a8d] VM Stopped (Lifecycle Event)
2022-02-24 05:05:49.250 7 INFO nova.compute.manager [-] [instance: 0c13e6f6-43b5-4bb4-87f7-cd43c849dc18] VM Stopped (Lifecycle Event)
