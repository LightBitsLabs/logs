Build Started 22_02_2022_13_42_24
2022-02-22 15:46:10.870 8 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 15:46:14.900 8 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 15:46:15.846 8 INFO nova.virt.driver [req-abfd8ba1-97eb-4dfc-9bac-5c83e6ce6b29 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 15:46:16.227 8 INFO nova.compute.provider_config [req-abfd8ba1-97eb-4dfc-9bac-5c83e6ce6b29 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 15:46:16.246 8 WARNING oslo_config.cfg [req-abfd8ba1-97eb-4dfc-9bac-5c83e6ce6b29 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 15:46:16.266 8 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 15:46:16.283 8 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 15:46:16.316 8 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 15:46:16.429 8 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 15:46:16.445 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 15:46:16.448 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 15:46:16.855 8 INFO nova.compute.manager [req-8dd67fe0-ad23-4c88-88f3-541082a3d819 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 15:46:16.989 8 INFO nova.service [req-8dd67fe0-ad23-4c88-88f3-541082a3d819 - - - - -] Updating service version for nova-compute on rack08-server63 from 60 to 61
2022-02-22 15:46:18.708 8 INFO nova.virt.libvirt.host [req-8dd67fe0-ad23-4c88-88f3-541082a3d819 - - - - -] kernel doesn't support AMD SEV
2022-02-22 15:47:09.492 8 INFO nova.compute.claims [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Claim successful on node rack08-server63
2022-02-22 15:47:09.891 8 INFO nova.virt.libvirt.driver [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Creating image
2022-02-22 15:47:09.905 8 INFO oslo.privsep.daemon [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp94qo8lsk/privsep.sock']
2022-02-22 15:47:11.538 8 INFO oslo.privsep.daemon [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Spawned new privsep daemon via rootwrap
2022-02-22 15:47:11.389 71 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 15:47:11.394 71 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 15:47:11.400 71 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 15:47:11.400 71 INFO oslo.privsep.daemon [-] privsep daemon running as pid 71
2022-02-22 15:47:12.815 8 INFO nova.compute.manager [-] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] VM Resumed (Lifecycle Event)
2022-02-22 15:47:12.823 8 INFO nova.virt.libvirt.driver [-] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Instance spawned successfully.
2022-02-22 15:47:12.823 8 INFO nova.compute.manager [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Took 2.93 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:12.870 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:12.871 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] VM Started (Lifecycle Event)
2022-02-22 15:47:12.912 8 INFO nova.compute.manager [req-3ee495aa-7e32-48df-89a5-16388ac41cbe dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Took 3.46 seconds to build instance.
2022-02-22 15:47:16.504 8 INFO nova.compute.manager [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Attaching volume 65173ee1-6436-4943-b97f-8244ca9c1c19 to /dev/vdb
2022-02-22 15:47:16.593 8 INFO oslo.privsep.daemon [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmptd7ra6ib/privsep.sock']
2022-02-22 15:47:17.568 8 INFO oslo.privsep.daemon [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Spawned new privsep daemon via rootwrap
2022-02-22 15:47:17.167 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 15:47:17.174 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 15:47:17.178 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 15:47:17.178 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-22 15:47:17.898 8 WARNING os_brick.initiator.connectors.nvmeof [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:47:19.223 8 INFO os_brick.initiator.connectors.lightos [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: connect_volume called for volume 5dbaaa5f-a3e1-483e-9cb3-c1db9104481f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5dbaaa5f-a3e1-483e-9cb3-c1db9104481f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:47:19.257 8 INFO os_brick.initiator.connectors.lightos [req-c1962b56-cb7d-44e5-a596-29ccc4bf6322 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5dbaaa5f-a3e1-483e-9cb3-c1db9104481f
2022-02-22 15:47:21.107 8 INFO nova.compute.claims [req-4ac903a5-6fe7-4039-bb2b-00a5982f0fe2 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Claim successful on node rack08-server63
2022-02-22 15:47:21.500 8 INFO nova.virt.libvirt.driver [req-4ac903a5-6fe7-4039-bb2b-00a5982f0fe2 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Creating image
2022-02-22 15:47:22.313 8 INFO nova.compute.claims [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Claim successful on node rack08-server63
2022-02-22 15:47:22.562 8 INFO nova.virt.libvirt.driver [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 15:47:22.648 8 INFO nova.virt.block_device [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Booting with volume 180a3734-5582-44dd-9ddb-e2f4493f44fc at /dev/vda
2022-02-22 15:47:22.680 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] VM Resumed (Lifecycle Event)
2022-02-22 15:47:22.688 8 INFO nova.virt.libvirt.driver [-] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Instance spawned successfully.
2022-02-22 15:47:22.689 8 INFO nova.compute.manager [req-4ac903a5-6fe7-4039-bb2b-00a5982f0fe2 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:22.735 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:22.736 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] VM Started (Lifecycle Event)
2022-02-22 15:47:22.751 8 WARNING os_brick.initiator.connectors.nvmeof [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:47:22.805 8 INFO nova.compute.manager [req-4ac903a5-6fe7-4039-bb2b-00a5982f0fe2 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Took 1.74 seconds to build instance.
2022-02-22 15:47:24.229 8 INFO nova.virt.libvirt.driver [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Creating image
2022-02-22 15:47:24.238 8 INFO os_brick.initiator.connectors.lightos [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: connect_volume called for volume a9178c89-d7f9-45ae-8523-4f186d9fdeaf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a9178c89-d7f9-45ae-8523-4f186d9fdeaf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:47:24.241 8 INFO os_brick.initiator.connectors.lightos [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a9178c89-d7f9-45ae-8523-4f186d9fdeaf
2022-02-22 15:47:24.284 8 INFO nova.compute.manager [req-03cb3483-c047-46a0-9070-03efe53f0179 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Detaching volume 65173ee1-6436-4943-b97f-8244ca9c1c19
2022-02-22 15:47:24.343 8 INFO nova.virt.block_device [req-03cb3483-c047-46a0-9070-03efe53f0179 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Attempting to driver detach volume 65173ee1-6436-4943-b97f-8244ca9c1c19 from mountpoint /dev/vdb
2022-02-22 15:47:24.370 8 INFO nova.virt.libvirt.driver [req-03cb3483-c047-46a0-9070-03efe53f0179 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719 from the persistent domain config.
2022-02-22 15:47:24.512 8 INFO nova.virt.libvirt.driver [req-03cb3483-c047-46a0-9070-03efe53f0179 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719 from the live domain config.
2022-02-22 15:47:24.514 8 INFO os_brick.initiator.connectors.lightos [req-03cb3483-c047-46a0-9070-03efe53f0179 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5dbaaa5f-a3e1-483e-9cb3-c1db9104481f
2022-02-22 15:47:25.028 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] VM Resumed (Lifecycle Event)
2022-02-22 15:47:25.036 8 INFO nova.virt.libvirt.driver [-] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Instance spawned successfully.
2022-02-22 15:47:25.037 8 INFO nova.compute.manager [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Took 0.81 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:25.082 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:25.083 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] VM Started (Lifecycle Event)
2022-02-22 15:47:25.121 8 INFO nova.compute.manager [req-73d2227f-abf8-430c-b196-a74013744423 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Took 2.85 seconds to build instance.
2022-02-22 15:47:27.520 8 INFO nova.compute.claims [req-f4622f8d-ae6b-4d55-9b13-9dbe45c64e3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Claim successful on node rack08-server63
2022-02-22 15:47:27.708 8 INFO nova.compute.claims [req-b072e944-3b71-4a8a-81ec-6e7cd7e8ea4a dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Claim successful on node rack08-server63
2022-02-22 15:47:27.906 8 INFO nova.virt.libvirt.driver [req-f4622f8d-ae6b-4d55-9b13-9dbe45c64e3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Creating image
2022-02-22 15:47:28.010 8 INFO nova.compute.claims [req-43a5db85-07a7-48ae-b8fa-312df6a2c4fa 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Claim successful on node rack08-server63
2022-02-22 15:47:28.093 8 INFO nova.virt.libvirt.driver [req-b072e944-3b71-4a8a-81ec-6e7cd7e8ea4a dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Creating image
2022-02-22 15:47:28.456 8 INFO nova.virt.libvirt.driver [req-43a5db85-07a7-48ae-b8fa-312df6a2c4fa 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Creating image
2022-02-22 15:47:29.210 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] VM Resumed (Lifecycle Event)
2022-02-22 15:47:29.216 8 INFO nova.virt.libvirt.driver [-] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Instance spawned successfully.
2022-02-22 15:47:29.217 8 INFO nova.compute.manager [req-f4622f8d-ae6b-4d55-9b13-9dbe45c64e3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Took 1.31 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:29.277 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:29.277 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] VM Started (Lifecycle Event)
2022-02-22 15:47:29.300 8 INFO nova.compute.manager [req-f4622f8d-ae6b-4d55-9b13-9dbe45c64e3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Took 1.81 seconds to build instance.
2022-02-22 15:47:29.331 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] VM Resumed (Lifecycle Event)
2022-02-22 15:47:29.338 8 INFO nova.virt.libvirt.driver [-] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Instance spawned successfully.
2022-02-22 15:47:29.339 8 INFO nova.compute.manager [req-b072e944-3b71-4a8a-81ec-6e7cd7e8ea4a dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:29.388 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:29.388 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] VM Started (Lifecycle Event)
2022-02-22 15:47:29.422 8 INFO nova.compute.manager [req-b072e944-3b71-4a8a-81ec-6e7cd7e8ea4a dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Took 1.76 seconds to build instance.
2022-02-22 15:47:29.637 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: d567e892-2268-4f96-83db-b28c8f780a11] VM Resumed (Lifecycle Event)
2022-02-22 15:47:29.643 8 INFO nova.virt.libvirt.driver [-] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Instance spawned successfully.
2022-02-22 15:47:29.644 8 INFO nova.compute.manager [req-43a5db85-07a7-48ae-b8fa-312df6a2c4fa 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:29.690 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: d567e892-2268-4f96-83db-b28c8f780a11] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:29.691 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: d567e892-2268-4f96-83db-b28c8f780a11] VM Started (Lifecycle Event)
2022-02-22 15:47:29.725 8 INFO nova.compute.manager [req-43a5db85-07a7-48ae-b8fa-312df6a2c4fa 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Took 1.76 seconds to build instance.
2022-02-22 15:47:32.724 8 INFO nova.compute.manager [req-ed0bc7a7-043a-416d-8153-c1c985653938 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Attaching volume 82db09f6-de31-4640-97b9-8cca91869b74 to /dev/vdb
2022-02-22 15:47:32.811 8 WARNING os_brick.initiator.connectors.nvmeof [req-ed0bc7a7-043a-416d-8153-c1c985653938 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:47:33.616 8 INFO nova.compute.manager [req-5f14a6ab-263d-4122-861b-46a4bd6eb69f dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Attaching volume 0258ba45-f9b6-4c29-85f9-e77140866a41 to /dev/vdb
2022-02-22 15:47:33.712 8 WARNING os_brick.initiator.connectors.nvmeof [req-5f14a6ab-263d-4122-861b-46a4bd6eb69f dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:47:34.115 8 INFO os_brick.initiator.connectors.lightos [req-ed0bc7a7-043a-416d-8153-c1c985653938 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: connect_volume called for volume 2211604e-d95b-4923-b90a-fcb5f20be3de, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2211604e-d95b-4923-b90a-fcb5f20be3de', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:47:34.119 8 INFO os_brick.initiator.connectors.lightos [req-ed0bc7a7-043a-416d-8153-c1c985653938 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2211604e-d95b-4923-b90a-fcb5f20be3de
2022-02-22 15:47:35.050 8 INFO os_brick.initiator.connectors.lightos [req-5f14a6ab-263d-4122-861b-46a4bd6eb69f dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: connect_volume called for volume 273d1615-8514-4a99-aae7-deed57b43d9f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '273d1615-8514-4a99-aae7-deed57b43d9f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:47:35.057 8 INFO os_brick.initiator.connectors.lightos [req-5f14a6ab-263d-4122-861b-46a4bd6eb69f dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 273d1615-8514-4a99-aae7-deed57b43d9f
2022-02-22 15:47:35.207 8 INFO nova.compute.manager [req-d71ca480-aafd-4a28-93b1-c4c069845a3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Attaching volume 82db09f6-de31-4640-97b9-8cca91869b74 to /dev/vdb
2022-02-22 15:47:35.302 8 WARNING os_brick.initiator.connectors.nvmeof [req-d71ca480-aafd-4a28-93b1-c4c069845a3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:47:36.221 8 INFO nova.compute.manager [req-b920ebee-4ea5-4aa3-9218-963d839433ea dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Detaching volume 0258ba45-f9b6-4c29-85f9-e77140866a41
2022-02-22 15:47:36.295 8 INFO nova.virt.block_device [req-b920ebee-4ea5-4aa3-9218-963d839433ea dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Attempting to driver detach volume 0258ba45-f9b6-4c29-85f9-e77140866a41 from mountpoint /dev/vdb
2022-02-22 15:47:36.316 8 INFO nova.virt.libvirt.driver [req-b920ebee-4ea5-4aa3-9218-963d839433ea dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 579091fd-24f5-4a14-aff5-08d0332b3440 from the persistent domain config.
2022-02-22 15:47:36.459 8 INFO nova.virt.libvirt.driver [req-b920ebee-4ea5-4aa3-9218-963d839433ea dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 579091fd-24f5-4a14-aff5-08d0332b3440 from the live domain config.
2022-02-22 15:47:36.462 8 INFO os_brick.initiator.connectors.lightos [req-b920ebee-4ea5-4aa3-9218-963d839433ea dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 273d1615-8514-4a99-aae7-deed57b43d9f
2022-02-22 15:47:36.613 8 INFO os_brick.initiator.connectors.lightos [req-d71ca480-aafd-4a28-93b1-c4c069845a3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: connect_volume called for volume 2211604e-d95b-4923-b90a-fcb5f20be3de, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2211604e-d95b-4923-b90a-fcb5f20be3de', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:47:36.614 8 INFO os_brick.initiator.connectors.lightos [req-d71ca480-aafd-4a28-93b1-c4c069845a3e 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2211604e-d95b-4923-b90a-fcb5f20be3de
2022-02-22 15:47:37.796 8 INFO nova.compute.manager [req-b0b5daad-b59b-4336-9bdb-3421d5504755 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Detaching volume 82db09f6-de31-4640-97b9-8cca91869b74
2022-02-22 15:47:37.860 8 INFO nova.virt.block_device [req-b0b5daad-b59b-4336-9bdb-3421d5504755 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Attempting to driver detach volume 82db09f6-de31-4640-97b9-8cca91869b74 from mountpoint /dev/vdb
2022-02-22 15:47:37.880 8 INFO nova.virt.libvirt.driver [req-b0b5daad-b59b-4336-9bdb-3421d5504755 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Successfully detached device vdb from instance dcc4dc38-8e10-4dc2-b864-3dfd17927b86 from the persistent domain config.
2022-02-22 15:47:38.026 8 INFO nova.virt.libvirt.driver [req-b0b5daad-b59b-4336-9bdb-3421d5504755 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Successfully detached device vdb from instance dcc4dc38-8e10-4dc2-b864-3dfd17927b86 from the live domain config.
2022-02-22 15:47:38.106 8 INFO nova.virt.libvirt.driver [req-b0b5daad-b59b-4336-9bdb-3421d5504755 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Detected multiple connections on this host for volume: 82db09f6-de31-4640-97b9-8cca91869b74, skipping target disconnect.
2022-02-22 15:47:39.612 8 INFO nova.compute.claims [req-92dd17b5-348e-41c1-aca3-85e08f4fcd1c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Claim successful on node rack08-server63
2022-02-22 15:47:39.995 8 INFO nova.virt.libvirt.driver [req-92dd17b5-348e-41c1-aca3-85e08f4fcd1c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Creating image
2022-02-22 15:47:40.281 8 INFO nova.compute.manager [req-d8897303-3fc0-4833-94c0-f6eee14cfd11 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Detaching volume 82db09f6-de31-4640-97b9-8cca91869b74
2022-02-22 15:47:40.339 8 INFO nova.virt.block_device [req-d8897303-3fc0-4833-94c0-f6eee14cfd11 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Attempting to driver detach volume 82db09f6-de31-4640-97b9-8cca91869b74 from mountpoint /dev/vdb
2022-02-22 15:47:40.365 8 INFO nova.virt.libvirt.driver [req-d8897303-3fc0-4833-94c0-f6eee14cfd11 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Successfully detached device vdb from instance d567e892-2268-4f96-83db-b28c8f780a11 from the persistent domain config.
2022-02-22 15:47:40.531 8 INFO nova.virt.libvirt.driver [req-d8897303-3fc0-4833-94c0-f6eee14cfd11 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Successfully detached device vdb from instance d567e892-2268-4f96-83db-b28c8f780a11 from the live domain config.
2022-02-22 15:47:41.143 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] VM Resumed (Lifecycle Event)
2022-02-22 15:47:41.152 8 INFO nova.virt.libvirt.driver [-] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Instance spawned successfully.
2022-02-22 15:47:41.152 8 INFO nova.compute.manager [req-92dd17b5-348e-41c1-aca3-85e08f4fcd1c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 15:47:41.204 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:47:41.204 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] VM Started (Lifecycle Event)
2022-02-22 15:47:41.239 8 INFO nova.compute.manager [req-92dd17b5-348e-41c1-aca3-85e08f4fcd1c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Took 1.67 seconds to build instance.
2022-02-22 15:47:44.201 8 INFO nova.compute.manager [req-52431714-a107-4115-a1d8-04312289194c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Attaching volume 8b642abd-a431-42bf-9b23-a5ca1771af69 to /dev/vdb
2022-02-22 15:47:44.291 8 WARNING os_brick.initiator.connectors.nvmeof [req-52431714-a107-4115-a1d8-04312289194c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:48:41.228 8 INFO os_brick.initiator.connectors.lightos [req-52431714-a107-4115-a1d8-04312289194c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: connect_volume called for volume c8e07d55-f1f0-44b5-afe1-3b029596a9b5, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c8e07d55-f1f0-44b5-afe1-3b029596a9b5', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:48:41.232 8 INFO os_brick.initiator.connectors.lightos [req-52431714-a107-4115-a1d8-04312289194c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c8e07d55-f1f0-44b5-afe1-3b029596a9b5
2022-02-22 15:48:41.900 8 INFO nova.compute.manager [req-643b796f-5f50-4121-b0af-2e0efdbcb005 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Detaching volume 8b642abd-a431-42bf-9b23-a5ca1771af69
2022-02-22 15:48:41.959 8 INFO nova.virt.block_device [req-643b796f-5f50-4121-b0af-2e0efdbcb005 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Attempting to driver detach volume 8b642abd-a431-42bf-9b23-a5ca1771af69 from mountpoint /dev/vdb
2022-02-22 15:48:41.982 8 INFO nova.virt.libvirt.driver [req-643b796f-5f50-4121-b0af-2e0efdbcb005 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 1b64db66-f2a2-4a35-bf27-0041b7f6c310 from the persistent domain config.
2022-02-22 15:48:42.123 8 INFO nova.virt.libvirt.driver [req-643b796f-5f50-4121-b0af-2e0efdbcb005 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Successfully detached device vdb from instance 1b64db66-f2a2-4a35-bf27-0041b7f6c310 from the live domain config.
2022-02-22 15:48:42.126 8 INFO os_brick.initiator.connectors.lightos [req-643b796f-5f50-4121-b0af-2e0efdbcb005 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c8e07d55-f1f0-44b5-afe1-3b029596a9b5
2022-02-22 15:48:45.330 8 INFO nova.compute.manager [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Terminating instance
2022-02-22 15:48:45.674 8 INFO nova.virt.libvirt.driver [-] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Instance destroyed successfully.
2022-02-22 15:48:45.689 8 INFO nova.virt.libvirt.driver [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Deleting instance files /var/lib/nova/instances/1b64db66-f2a2-4a35-bf27-0041b7f6c310_del
2022-02-22 15:48:45.691 8 INFO nova.virt.libvirt.driver [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Deletion of /var/lib/nova/instances/1b64db66-f2a2-4a35-bf27-0041b7f6c310_del complete
2022-02-22 15:48:45.761 8 INFO nova.virt.libvirt.host [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] UEFI support detected
2022-02-22 15:48:45.764 8 INFO nova.compute.manager [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:48:45.835 8 INFO nova.compute.manager [-] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:48:46.024 8 INFO nova.scheduler.client.report [req-b87bc6ab-387e-4aa1-bcc5-2d7039352ec8 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Deleted allocations for instance 1b64db66-f2a2-4a35-bf27-0041b7f6c310
2022-02-22 15:48:47.722 8 INFO nova.compute.manager [req-68bbb763-ada3-4668-ace1-61a14d6724f1 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Terminating instance
2022-02-22 15:48:48.064 8 INFO nova.virt.libvirt.driver [-] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Instance destroyed successfully.
2022-02-22 15:48:48.080 8 INFO nova.virt.libvirt.driver [req-68bbb763-ada3-4668-ace1-61a14d6724f1 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Deleting instance files /var/lib/nova/instances/579091fd-24f5-4a14-aff5-08d0332b3440_del
2022-02-22 15:48:48.082 8 INFO nova.virt.libvirt.driver [req-68bbb763-ada3-4668-ace1-61a14d6724f1 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Deletion of /var/lib/nova/instances/579091fd-24f5-4a14-aff5-08d0332b3440_del complete
2022-02-22 15:48:48.152 8 INFO nova.compute.manager [req-68bbb763-ada3-4668-ace1-61a14d6724f1 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:48:48.219 8 INFO nova.compute.manager [-] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:48:48.401 8 INFO nova.scheduler.client.report [req-68bbb763-ada3-4668-ace1-61a14d6724f1 dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Deleted allocations for instance 579091fd-24f5-4a14-aff5-08d0332b3440
2022-02-22 15:48:48.959 8 INFO nova.compute.manager [req-b6f88942-504d-4875-bd49-3cda1676276d dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Terminating instance
2022-02-22 15:48:49.297 8 INFO nova.virt.libvirt.driver [-] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Instance destroyed successfully.
2022-02-22 15:48:49.314 8 INFO nova.virt.libvirt.driver [req-b6f88942-504d-4875-bd49-3cda1676276d dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Deleting instance files /var/lib/nova/instances/f902d069-5362-427b-9cd9-82bdec99fdd1_del
2022-02-22 15:48:49.316 8 INFO nova.virt.libvirt.driver [req-b6f88942-504d-4875-bd49-3cda1676276d dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Deletion of /var/lib/nova/instances/f902d069-5362-427b-9cd9-82bdec99fdd1_del complete
2022-02-22 15:48:49.435 8 INFO nova.compute.manager [req-b6f88942-504d-4875-bd49-3cda1676276d dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-22 15:48:49.500 8 INFO nova.compute.manager [-] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:48:49.721 8 INFO nova.scheduler.client.report [req-b6f88942-504d-4875-bd49-3cda1676276d dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Deleted allocations for instance f902d069-5362-427b-9cd9-82bdec99fdd1
2022-02-22 15:48:51.351 8 INFO nova.compute.manager [req-2b2f3fbd-698c-475b-afe5-d1964017727c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Terminating instance
2022-02-22 15:48:51.689 8 INFO nova.virt.libvirt.driver [-] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Instance destroyed successfully.
2022-02-22 15:48:51.705 8 INFO nova.virt.libvirt.driver [req-2b2f3fbd-698c-475b-afe5-d1964017727c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Deleting instance files /var/lib/nova/instances/4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719_del
2022-02-22 15:48:51.707 8 INFO nova.virt.libvirt.driver [req-2b2f3fbd-698c-475b-afe5-d1964017727c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Deletion of /var/lib/nova/instances/4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719_del complete
2022-02-22 15:48:51.783 8 INFO nova.compute.manager [req-2b2f3fbd-698c-475b-afe5-d1964017727c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 15:48:51.846 8 INFO nova.compute.manager [-] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:48:52.059 8 INFO nova.scheduler.client.report [req-2b2f3fbd-698c-475b-afe5-d1964017727c dd88d2ba929545c0bfe5ab7be169dae1 09c92d54140c4fc58c07d92fb670cc8c - default default] Deleted allocations for instance 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719
2022-02-22 15:48:59.422 8 INFO nova.compute.claims [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Claim successful on node rack08-server63
2022-02-22 15:48:59.691 8 INFO nova.virt.libvirt.driver [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 15:48:59.775 8 INFO nova.virt.block_device [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Booting with volume b5966920-55f2-4e7c-b775-a3b02341abe8 at /dev/vda
2022-02-22 15:48:59.883 8 WARNING os_brick.initiator.connectors.nvmeof [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:49:00.672 8 INFO nova.compute.manager [-] [instance: 1b64db66-f2a2-4a35-bf27-0041b7f6c310] VM Stopped (Lifecycle Event)
2022-02-22 15:49:01.365 8 INFO nova.virt.libvirt.driver [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Creating image
2022-02-22 15:49:01.377 8 INFO os_brick.initiator.connectors.lightos [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: connect_volume called for volume d4945e1e-a588-42c8-8e95-297517a95adf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd4945e1e-a588-42c8-8e95-297517a95adf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:49:01.380 8 INFO os_brick.initiator.connectors.lightos [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d4945e1e-a588-42c8-8e95-297517a95adf
2022-02-22 15:49:02.230 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] VM Resumed (Lifecycle Event)
2022-02-22 15:49:02.238 8 INFO nova.virt.libvirt.driver [-] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Instance spawned successfully.
2022-02-22 15:49:02.238 8 INFO nova.compute.manager [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Took 0.87 seconds to spawn the instance on the hypervisor.
2022-02-22 15:49:02.284 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:49:02.285 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] VM Started (Lifecycle Event)
2022-02-22 15:49:02.322 8 INFO nova.compute.manager [req-ed151f7b-7eb0-4fd5-97d7-4832097f5eb3 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Took 2.94 seconds to build instance.
2022-02-22 15:49:03.062 8 INFO nova.compute.manager [-] [instance: 579091fd-24f5-4a14-aff5-08d0332b3440] VM Stopped (Lifecycle Event)
2022-02-22 15:49:04.295 8 INFO nova.compute.manager [-] [instance: f902d069-5362-427b-9cd9-82bdec99fdd1] VM Stopped (Lifecycle Event)
2022-02-22 15:49:04.708 8 INFO nova.compute.manager [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Terminating instance
2022-02-22 15:49:05.046 8 INFO nova.virt.libvirt.driver [-] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Instance destroyed successfully.
2022-02-22 15:49:05.117 8 INFO os_brick.initiator.connectors.lightos [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d4945e1e-a588-42c8-8e95-297517a95adf
2022-02-22 15:49:05.128 8 INFO nova.virt.libvirt.driver [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Deleting instance files /var/lib/nova/instances/57b0768e-65be-447e-b608-6f89ad643c15_del
2022-02-22 15:49:05.129 8 INFO nova.virt.libvirt.driver [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Deletion of /var/lib/nova/instances/57b0768e-65be-447e-b608-6f89ad643c15_del complete
2022-02-22 15:49:05.198 8 INFO nova.compute.manager [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 15:49:05.265 8 INFO nova.compute.manager [-] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:49:06.490 8 INFO nova.compute.manager [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] Took 1.22 seconds to detach 1 volumes for instance.
2022-02-22 15:49:06.680 8 INFO nova.scheduler.client.report [req-3a8aff94-b6d2-4563-a710-f4a86a798ef1 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Deleted allocations for instance 57b0768e-65be-447e-b608-6f89ad643c15
2022-02-22 15:49:06.686 8 INFO nova.compute.manager [-] [instance: 4dad7bf7-6d7b-4ead-b2f2-ac7c6e544719] VM Stopped (Lifecycle Event)
2022-02-22 15:49:09.610 8 INFO nova.compute.manager [req-af1a0f06-4a8d-4e3e-8866-749645260f57 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Terminating instance
2022-02-22 15:49:09.950 8 INFO nova.virt.libvirt.driver [-] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Instance destroyed successfully.
2022-02-22 15:49:09.967 8 INFO nova.virt.libvirt.driver [req-af1a0f06-4a8d-4e3e-8866-749645260f57 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Deleting instance files /var/lib/nova/instances/d567e892-2268-4f96-83db-b28c8f780a11_del
2022-02-22 15:49:09.969 8 INFO nova.virt.libvirt.driver [req-af1a0f06-4a8d-4e3e-8866-749645260f57 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Deletion of /var/lib/nova/instances/d567e892-2268-4f96-83db-b28c8f780a11_del complete
2022-02-22 15:49:10.038 8 INFO nova.compute.manager [req-af1a0f06-4a8d-4e3e-8866-749645260f57 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:49:10.102 8 INFO nova.compute.manager [-] [instance: d567e892-2268-4f96-83db-b28c8f780a11] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:49:10.294 8 INFO nova.scheduler.client.report [req-af1a0f06-4a8d-4e3e-8866-749645260f57 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Deleted allocations for instance d567e892-2268-4f96-83db-b28c8f780a11
2022-02-22 15:49:10.852 8 INFO nova.compute.manager [req-56f45cd1-2cff-4628-8c05-73dd72675258 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Terminating instance
2022-02-22 15:49:11.190 8 INFO nova.virt.libvirt.driver [-] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Instance destroyed successfully.
2022-02-22 15:49:11.204 8 INFO nova.virt.libvirt.driver [req-56f45cd1-2cff-4628-8c05-73dd72675258 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Deleting instance files /var/lib/nova/instances/dcc4dc38-8e10-4dc2-b864-3dfd17927b86_del
2022-02-22 15:49:11.205 8 INFO nova.virt.libvirt.driver [req-56f45cd1-2cff-4628-8c05-73dd72675258 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Deletion of /var/lib/nova/instances/dcc4dc38-8e10-4dc2-b864-3dfd17927b86_del complete
2022-02-22 15:49:11.273 8 INFO nova.compute.manager [req-56f45cd1-2cff-4628-8c05-73dd72675258 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:49:11.343 8 INFO nova.compute.manager [-] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:49:11.542 8 INFO nova.scheduler.client.report [req-56f45cd1-2cff-4628-8c05-73dd72675258 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Deleted allocations for instance dcc4dc38-8e10-4dc2-b864-3dfd17927b86
2022-02-22 15:49:12.085 8 INFO nova.compute.manager [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Terminating instance
2022-02-22 15:49:12.426 8 INFO nova.virt.libvirt.driver [-] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Instance destroyed successfully.
2022-02-22 15:49:12.516 8 INFO os_brick.initiator.connectors.lightos [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a9178c89-d7f9-45ae-8523-4f186d9fdeaf
2022-02-22 15:49:12.528 8 INFO nova.virt.libvirt.driver [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Deleting instance files /var/lib/nova/instances/a6741f70-96b4-49fe-a044-519e2a00b037_del
2022-02-22 15:49:12.529 8 INFO nova.virt.libvirt.driver [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Deletion of /var/lib/nova/instances/a6741f70-96b4-49fe-a044-519e2a00b037_del complete
2022-02-22 15:49:12.610 8 INFO nova.compute.manager [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Took 0.40 seconds to destroy the instance on the hypervisor.
2022-02-22 15:49:12.675 8 INFO nova.compute.manager [-] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:49:13.870 8 INFO nova.compute.manager [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] Took 1.19 seconds to detach 1 volumes for instance.
2022-02-22 15:49:14.060 8 INFO nova.scheduler.client.report [req-9355f12d-cdbc-41e5-9e52-3f376673594b 18c844cebea54fc6a204fae70f12ce34 72ea26be20714d48960ce061d6cad836 - default default] Deleted allocations for instance a6741f70-96b4-49fe-a044-519e2a00b037
2022-02-22 15:49:20.044 8 INFO nova.compute.manager [-] [instance: 57b0768e-65be-447e-b608-6f89ad643c15] VM Stopped (Lifecycle Event)
2022-02-22 15:49:24.947 8 INFO nova.compute.manager [-] [instance: d567e892-2268-4f96-83db-b28c8f780a11] VM Stopped (Lifecycle Event)
2022-02-22 15:49:26.187 8 INFO nova.compute.manager [-] [instance: dcc4dc38-8e10-4dc2-b864-3dfd17927b86] VM Stopped (Lifecycle Event)
2022-02-22 15:49:27.424 8 INFO nova.compute.manager [-] [instance: a6741f70-96b4-49fe-a044-519e2a00b037] VM Stopped (Lifecycle Event)
2022-02-22 15:50:01.476 8 INFO nova.compute.claims [req-753f65cd-7375-4564-bcb4-99eeab5994f4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Claim successful on node rack08-server63
2022-02-22 15:50:01.876 8 INFO nova.virt.libvirt.driver [req-753f65cd-7375-4564-bcb4-99eeab5994f4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Creating image
2022-02-22 15:50:03.078 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] VM Resumed (Lifecycle Event)
2022-02-22 15:50:03.086 8 INFO nova.virt.libvirt.driver [-] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Instance spawned successfully.
2022-02-22 15:50:03.087 8 INFO nova.compute.manager [req-753f65cd-7375-4564-bcb4-99eeab5994f4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 15:50:03.134 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:50:03.134 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] VM Started (Lifecycle Event)
2022-02-22 15:50:03.175 8 INFO nova.compute.manager [req-753f65cd-7375-4564-bcb4-99eeab5994f4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Took 1.74 seconds to build instance.
2022-02-22 15:50:03.732 8 INFO nova.compute.manager [req-e0f17a5c-88f3-4642-aac8-54691820f309 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Terminating instance
2022-02-22 15:50:04.081 8 INFO nova.virt.libvirt.driver [-] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Instance destroyed successfully.
2022-02-22 15:50:04.096 8 INFO nova.virt.libvirt.driver [req-e0f17a5c-88f3-4642-aac8-54691820f309 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Deleting instance files /var/lib/nova/instances/64e02cf7-e681-4885-9576-f3c1ef879dc7_del
2022-02-22 15:50:04.097 8 INFO nova.virt.libvirt.driver [req-e0f17a5c-88f3-4642-aac8-54691820f309 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Deletion of /var/lib/nova/instances/64e02cf7-e681-4885-9576-f3c1ef879dc7_del complete
2022-02-22 15:50:04.167 8 INFO nova.compute.manager [req-e0f17a5c-88f3-4642-aac8-54691820f309 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:50:04.235 8 INFO nova.compute.manager [-] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:50:04.435 8 INFO nova.scheduler.client.report [req-e0f17a5c-88f3-4642-aac8-54691820f309 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] Deleted allocations for instance 64e02cf7-e681-4885-9576-f3c1ef879dc7
2022-02-22 15:50:06.036 8 INFO nova.compute.claims [req-5742d4aa-fc42-4022-bb1d-0c59e7432dc4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Claim successful on node rack08-server63
2022-02-22 15:50:06.427 8 INFO nova.virt.libvirt.driver [req-5742d4aa-fc42-4022-bb1d-0c59e7432dc4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Creating image
2022-02-22 15:50:07.594 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] VM Resumed (Lifecycle Event)
2022-02-22 15:50:07.601 8 INFO nova.virt.libvirt.driver [-] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Instance spawned successfully.
2022-02-22 15:50:07.602 8 INFO nova.compute.manager [req-5742d4aa-fc42-4022-bb1d-0c59e7432dc4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 15:50:07.649 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:50:07.649 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] VM Started (Lifecycle Event)
2022-02-22 15:50:07.686 8 INFO nova.compute.manager [req-5742d4aa-fc42-4022-bb1d-0c59e7432dc4 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Took 1.69 seconds to build instance.
2022-02-22 15:50:08.384 8 INFO nova.compute.manager [req-a9c293a9-1e46-4bd3-bf95-4b8b27c70994 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Terminating instance
2022-02-22 15:50:08.730 8 INFO nova.virt.libvirt.driver [-] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Instance destroyed successfully.
2022-02-22 15:50:08.745 8 INFO nova.virt.libvirt.driver [req-a9c293a9-1e46-4bd3-bf95-4b8b27c70994 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Deleting instance files /var/lib/nova/instances/05db81dc-19ed-4b7c-9890-fb6a4fe84366_del
2022-02-22 15:50:08.746 8 INFO nova.virt.libvirt.driver [req-a9c293a9-1e46-4bd3-bf95-4b8b27c70994 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Deletion of /var/lib/nova/instances/05db81dc-19ed-4b7c-9890-fb6a4fe84366_del complete
2022-02-22 15:50:08.814 8 INFO nova.compute.manager [req-a9c293a9-1e46-4bd3-bf95-4b8b27c70994 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:50:08.883 8 INFO nova.compute.manager [-] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:50:09.073 8 INFO nova.scheduler.client.report [req-a9c293a9-1e46-4bd3-bf95-4b8b27c70994 65cea4438a484f02b5fa3db61361133b dbf5efeb82ec4049a5b306538dacf9c0 - default default] Deleted allocations for instance 05db81dc-19ed-4b7c-9890-fb6a4fe84366
2022-02-22 15:50:19.078 8 INFO nova.compute.manager [-] [instance: 64e02cf7-e681-4885-9576-f3c1ef879dc7] VM Stopped (Lifecycle Event)
2022-02-22 15:50:19.122 8 INFO nova.compute.claims [req-bd56c7db-f0c7-44e7-89d9-d48790307da3 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Claim successful on node rack08-server63
2022-02-22 15:50:19.531 8 INFO nova.virt.libvirt.driver [req-bd56c7db-f0c7-44e7-89d9-d48790307da3 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Creating image
2022-02-22 15:50:20.678 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] VM Resumed (Lifecycle Event)
2022-02-22 15:50:20.685 8 INFO nova.virt.libvirt.driver [-] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Instance spawned successfully.
2022-02-22 15:50:20.686 8 INFO nova.compute.manager [req-bd56c7db-f0c7-44e7-89d9-d48790307da3 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 15:50:20.732 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:50:20.733 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] VM Started (Lifecycle Event)
2022-02-22 15:50:20.771 8 INFO nova.compute.manager [req-bd56c7db-f0c7-44e7-89d9-d48790307da3 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Took 1.69 seconds to build instance.
2022-02-22 15:50:23.726 8 INFO nova.compute.manager [-] [instance: 05db81dc-19ed-4b7c-9890-fb6a4fe84366] VM Stopped (Lifecycle Event)
2022-02-22 15:50:28.581 8 INFO nova.compute.manager [req-0a632fe5-ae98-4d9a-8185-4f4c23ea2285 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Terminating instance
2022-02-22 15:50:28.925 8 INFO nova.virt.libvirt.driver [-] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Instance destroyed successfully.
2022-02-22 15:50:28.938 8 INFO nova.virt.libvirt.driver [req-0a632fe5-ae98-4d9a-8185-4f4c23ea2285 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Deleting instance files /var/lib/nova/instances/088419b0-b461-4adb-9585-844d3836f0d3_del
2022-02-22 15:50:28.939 8 INFO nova.virt.libvirt.driver [req-0a632fe5-ae98-4d9a-8185-4f4c23ea2285 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Deletion of /var/lib/nova/instances/088419b0-b461-4adb-9585-844d3836f0d3_del complete
2022-02-22 15:50:29.004 8 INFO nova.compute.manager [req-0a632fe5-ae98-4d9a-8185-4f4c23ea2285 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:50:29.074 8 INFO nova.compute.manager [-] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:50:29.269 8 INFO nova.scheduler.client.report [req-0a632fe5-ae98-4d9a-8185-4f4c23ea2285 41656e7fa85741888bf22326ea20aa7f 77e984db3863415886323c21f39cac8c - default default] Deleted allocations for instance 088419b0-b461-4adb-9585-844d3836f0d3
2022-02-22 15:50:43.923 8 INFO nova.compute.manager [-] [instance: 088419b0-b461-4adb-9585-844d3836f0d3] VM Stopped (Lifecycle Event)
2022-02-22 15:51:18.121 8 INFO nova.compute.claims [req-6dbc3f9a-c680-4cc3-b18e-772a2fc93887 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Claim successful on node rack08-server63
2022-02-22 15:51:18.536 8 INFO nova.virt.libvirt.driver [req-6dbc3f9a-c680-4cc3-b18e-772a2fc93887 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Creating image
2022-02-22 15:51:19.720 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] VM Resumed (Lifecycle Event)
2022-02-22 15:51:19.727 8 INFO nova.virt.libvirt.driver [-] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Instance spawned successfully.
2022-02-22 15:51:19.728 8 INFO nova.compute.manager [req-6dbc3f9a-c680-4cc3-b18e-772a2fc93887 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 15:51:19.775 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:51:19.776 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] VM Started (Lifecycle Event)
2022-02-22 15:51:19.815 8 INFO nova.compute.manager [req-6dbc3f9a-c680-4cc3-b18e-772a2fc93887 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Took 1.89 seconds to build instance.
2022-02-22 15:51:36.338 8 INFO nova.virt.libvirt.driver [req-f7465d4c-5e3e-43cc-9b85-d30d43bdd8e2 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Ignoring supplied device name: /dev/vdb
2022-02-22 15:51:36.502 8 INFO nova.compute.manager [req-f7465d4c-5e3e-43cc-9b85-d30d43bdd8e2 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Attaching volume c25fd0e3-1a4a-404e-8153-13bdcb6d291b to /dev/vdb
2022-02-22 15:51:36.607 8 WARNING os_brick.initiator.connectors.nvmeof [req-f7465d4c-5e3e-43cc-9b85-d30d43bdd8e2 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:51:37.885 8 INFO os_brick.initiator.connectors.lightos [req-f7465d4c-5e3e-43cc-9b85-d30d43bdd8e2 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: connect_volume called for volume 89fd8381-d390-4e44-a016-762b4e92ab8e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '89fd8381-d390-4e44-a016-762b4e92ab8e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:51:37.889 8 INFO os_brick.initiator.connectors.lightos [req-f7465d4c-5e3e-43cc-9b85-d30d43bdd8e2 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 89fd8381-d390-4e44-a016-762b4e92ab8e
2022-02-22 15:51:42.500 8 INFO nova.compute.claims [req-ffc832a3-78b5-4aa0-9c8a-544e7211bef6 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Claim successful on node rack08-server63
2022-02-22 15:51:42.889 8 INFO nova.virt.libvirt.driver [req-ffc832a3-78b5-4aa0-9c8a-544e7211bef6 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Creating image
2022-02-22 15:51:44.062 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] VM Resumed (Lifecycle Event)
2022-02-22 15:51:44.069 8 INFO nova.virt.libvirt.driver [-] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Instance spawned successfully.
2022-02-22 15:51:44.070 8 INFO nova.compute.manager [req-ffc832a3-78b5-4aa0-9c8a-544e7211bef6 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 15:51:44.126 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:51:44.127 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] VM Started (Lifecycle Event)
2022-02-22 15:51:44.155 8 INFO nova.compute.manager [req-ffc832a3-78b5-4aa0-9c8a-544e7211bef6 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Took 1.70 seconds to build instance.
2022-02-22 15:51:44.443 8 INFO nova.virt.libvirt.driver [req-311f6733-583e-4714-8ad1-801cf7f70256 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Ignoring supplied device name: /dev/vdb
2022-02-22 15:51:44.606 8 INFO nova.compute.manager [req-311f6733-583e-4714-8ad1-801cf7f70256 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Attaching volume d29d8c31-f7ea-4057-906c-37bcf2c3c1f5 to /dev/vdb
2022-02-22 15:51:44.695 8 WARNING os_brick.initiator.connectors.nvmeof [req-311f6733-583e-4714-8ad1-801cf7f70256 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:51:45.980 8 INFO os_brick.initiator.connectors.lightos [req-311f6733-583e-4714-8ad1-801cf7f70256 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] LIGHTOS: connect_volume called for volume 35646dea-a55d-4b9e-aa4c-f32600adb023, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '35646dea-a55d-4b9e-aa4c-f32600adb023', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:51:45.985 8 INFO os_brick.initiator.connectors.lightos [req-311f6733-583e-4714-8ad1-801cf7f70256 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 35646dea-a55d-4b9e-aa4c-f32600adb023
2022-02-22 15:51:47.852 8 INFO nova.compute.manager [req-0dd9b1f1-0e71-46e8-abd5-0cac9670799a e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Cinder extended volume d29d8c31-f7ea-4057-906c-37bcf2c3c1f5; extending it to detect new size
2022-02-22 15:51:47.928 8 INFO os_brick.initiator.connectors.lightos [req-0dd9b1f1-0e71-46e8-abd5-0cac9670799a e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 35646dea-a55d-4b9e-aa4c-f32600adb023
2022-02-22 15:51:48.596 8 INFO nova.compute.manager [req-c6a2f684-1ffb-4238-ae4e-74a419773967 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Detaching volume d29d8c31-f7ea-4057-906c-37bcf2c3c1f5
2022-02-22 15:51:48.658 8 INFO nova.virt.block_device [req-c6a2f684-1ffb-4238-ae4e-74a419773967 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Attempting to driver detach volume d29d8c31-f7ea-4057-906c-37bcf2c3c1f5 from mountpoint /dev/vdb
2022-02-22 15:51:48.908 8 INFO nova.virt.libvirt.driver [req-c6a2f684-1ffb-4238-ae4e-74a419773967 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] Successfully detached device vdb from instance 7c64564d-4c51-4050-8a98-d52acc391fcc from the persistent domain config.
2022-02-22 15:51:49.048 8 INFO nova.virt.libvirt.driver [req-c6a2f684-1ffb-4238-ae4e-74a419773967 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] Successfully detached device vdb from instance 7c64564d-4c51-4050-8a98-d52acc391fcc from the live domain config.
2022-02-22 15:51:49.051 8 INFO os_brick.initiator.connectors.lightos [req-c6a2f684-1ffb-4238-ae4e-74a419773967 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 35646dea-a55d-4b9e-aa4c-f32600adb023
2022-02-22 15:51:49.113 8 INFO nova.compute.manager [req-9d8cdd9f-b9f4-4121-af42-0b4b4ee5487e 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Detaching volume c25fd0e3-1a4a-404e-8153-13bdcb6d291b
2022-02-22 15:51:49.175 8 INFO nova.virt.block_device [req-9d8cdd9f-b9f4-4121-af42-0b4b4ee5487e 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Attempting to driver detach volume c25fd0e3-1a4a-404e-8153-13bdcb6d291b from mountpoint /dev/vdb
2022-02-22 15:51:49.193 8 INFO nova.virt.libvirt.driver [req-9d8cdd9f-b9f4-4121-af42-0b4b4ee5487e 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Successfully detached device vdb from instance 3e94a7a6-9cc0-471d-b28a-18efb5684174 from the persistent domain config.
2022-02-22 15:51:49.337 8 INFO nova.virt.libvirt.driver [req-9d8cdd9f-b9f4-4121-af42-0b4b4ee5487e 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Successfully detached device vdb from instance 3e94a7a6-9cc0-471d-b28a-18efb5684174 from the live domain config.
2022-02-22 15:51:49.341 8 INFO os_brick.initiator.connectors.lightos [req-9d8cdd9f-b9f4-4121-af42-0b4b4ee5487e 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 89fd8381-d390-4e44-a016-762b4e92ab8e
2022-02-22 15:51:50.840 8 INFO nova.compute.manager [req-c00cd638-4279-4ac0-941a-856c3e019e95 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Terminating instance
2022-02-22 15:51:51.188 8 INFO nova.virt.libvirt.driver [-] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Instance destroyed successfully.
2022-02-22 15:51:51.203 8 INFO nova.virt.libvirt.driver [req-c00cd638-4279-4ac0-941a-856c3e019e95 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Deleting instance files /var/lib/nova/instances/7c64564d-4c51-4050-8a98-d52acc391fcc_del
2022-02-22 15:51:51.203 8 INFO nova.virt.libvirt.driver [req-c00cd638-4279-4ac0-941a-856c3e019e95 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Deletion of /var/lib/nova/instances/7c64564d-4c51-4050-8a98-d52acc391fcc_del complete
2022-02-22 15:51:51.277 8 INFO nova.compute.manager [req-c00cd638-4279-4ac0-941a-856c3e019e95 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:51:51.342 8 INFO nova.compute.manager [-] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:51:51.373 8 INFO nova.compute.manager [req-472f6a1a-42d9-4af2-90f7-7c6abb83ad64 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Terminating instance
2022-02-22 15:51:51.539 8 INFO nova.scheduler.client.report [req-c00cd638-4279-4ac0-941a-856c3e019e95 172f23a24ddd40a19441955742c2886d 75d624cc401c4a9a9a934e7b7cef0d18 - default default] Deleted allocations for instance 7c64564d-4c51-4050-8a98-d52acc391fcc
2022-02-22 15:51:51.711 8 INFO nova.virt.libvirt.driver [-] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Instance destroyed successfully.
2022-02-22 15:51:51.727 8 INFO nova.virt.libvirt.driver [req-472f6a1a-42d9-4af2-90f7-7c6abb83ad64 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Deleting instance files /var/lib/nova/instances/3e94a7a6-9cc0-471d-b28a-18efb5684174_del
2022-02-22 15:51:51.728 8 INFO nova.virt.libvirt.driver [req-472f6a1a-42d9-4af2-90f7-7c6abb83ad64 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Deletion of /var/lib/nova/instances/3e94a7a6-9cc0-471d-b28a-18efb5684174_del complete
2022-02-22 15:51:51.795 8 INFO nova.compute.manager [req-472f6a1a-42d9-4af2-90f7-7c6abb83ad64 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:51:51.863 8 INFO nova.compute.manager [-] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:51:52.040 8 INFO nova.scheduler.client.report [req-472f6a1a-42d9-4af2-90f7-7c6abb83ad64 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Deleted allocations for instance 3e94a7a6-9cc0-471d-b28a-18efb5684174
2022-02-22 15:51:59.655 8 INFO nova.compute.claims [req-89e27fb9-a775-4c86-83fa-5cb1f94bbb23 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Claim successful on node rack08-server63
2022-02-22 15:52:00.048 8 INFO nova.virt.libvirt.driver [req-89e27fb9-a775-4c86-83fa-5cb1f94bbb23 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Creating image
2022-02-22 15:52:01.263 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] VM Resumed (Lifecycle Event)
2022-02-22 15:52:01.271 8 INFO nova.virt.libvirt.driver [-] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Instance spawned successfully.
2022-02-22 15:52:01.272 8 INFO nova.compute.manager [req-89e27fb9-a775-4c86-83fa-5cb1f94bbb23 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 15:52:01.318 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:52:01.319 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] VM Started (Lifecycle Event)
2022-02-22 15:52:01.352 8 INFO nova.compute.manager [req-89e27fb9-a775-4c86-83fa-5cb1f94bbb23 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Took 1.74 seconds to build instance.
2022-02-22 15:52:01.658 8 INFO nova.virt.libvirt.driver [req-ba88bf0d-3616-4162-af33-ecb402463636 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Ignoring supplied device name: /dev/vdb
2022-02-22 15:52:01.826 8 INFO nova.compute.manager [req-ba88bf0d-3616-4162-af33-ecb402463636 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Attaching volume 882668be-907b-45d0-87c5-2fcd09cb147a to /dev/vdb
2022-02-22 15:52:01.919 8 WARNING os_brick.initiator.connectors.nvmeof [req-ba88bf0d-3616-4162-af33-ecb402463636 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:52:03.209 8 INFO os_brick.initiator.connectors.lightos [req-ba88bf0d-3616-4162-af33-ecb402463636 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: connect_volume called for volume b9455bb3-f88d-4c8e-bf7b-f2a8166cded8, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'b9455bb3-f88d-4c8e-bf7b-f2a8166cded8', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:52:03.213 8 INFO os_brick.initiator.connectors.lightos [req-ba88bf0d-3616-4162-af33-ecb402463636 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b9455bb3-f88d-4c8e-bf7b-f2a8166cded8
2022-02-22 15:52:06.183 8 INFO nova.compute.manager [-] [instance: 7c64564d-4c51-4050-8a98-d52acc391fcc] VM Stopped (Lifecycle Event)
2022-02-22 15:52:06.707 8 INFO nova.compute.manager [-] [instance: 3e94a7a6-9cc0-471d-b28a-18efb5684174] VM Stopped (Lifecycle Event)
2022-02-22 15:52:12.274 8 INFO nova.compute.manager [req-fd1c258c-60ff-441c-920f-444294fe1f3a 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Detaching volume 882668be-907b-45d0-87c5-2fcd09cb147a
2022-02-22 15:52:12.343 8 INFO nova.virt.block_device [req-fd1c258c-60ff-441c-920f-444294fe1f3a 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Attempting to driver detach volume 882668be-907b-45d0-87c5-2fcd09cb147a from mountpoint /dev/vdb
2022-02-22 15:52:12.364 8 INFO nova.virt.libvirt.driver [req-fd1c258c-60ff-441c-920f-444294fe1f3a 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Successfully detached device vdb from instance 3f62d0ae-e403-40da-b463-4a66e727274b from the persistent domain config.
2022-02-22 15:52:12.508 8 INFO nova.virt.libvirt.driver [req-fd1c258c-60ff-441c-920f-444294fe1f3a 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Successfully detached device vdb from instance 3f62d0ae-e403-40da-b463-4a66e727274b from the live domain config.
2022-02-22 15:52:12.511 8 INFO os_brick.initiator.connectors.lightos [req-fd1c258c-60ff-441c-920f-444294fe1f3a 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid b9455bb3-f88d-4c8e-bf7b-f2a8166cded8
2022-02-22 15:52:14.516 8 INFO nova.compute.manager [req-3b5f4ee9-cc8a-42c8-a44a-479e28091cc5 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Terminating instance
2022-02-22 15:52:14.862 8 INFO nova.virt.libvirt.driver [-] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Instance destroyed successfully.
2022-02-22 15:52:14.878 8 INFO nova.virt.libvirt.driver [req-3b5f4ee9-cc8a-42c8-a44a-479e28091cc5 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Deleting instance files /var/lib/nova/instances/3f62d0ae-e403-40da-b463-4a66e727274b_del
2022-02-22 15:52:14.879 8 INFO nova.virt.libvirt.driver [req-3b5f4ee9-cc8a-42c8-a44a-479e28091cc5 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Deletion of /var/lib/nova/instances/3f62d0ae-e403-40da-b463-4a66e727274b_del complete
2022-02-22 15:52:14.946 8 INFO nova.compute.manager [req-3b5f4ee9-cc8a-42c8-a44a-479e28091cc5 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:52:15.013 8 INFO nova.compute.manager [-] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:52:15.208 8 INFO nova.scheduler.client.report [req-3b5f4ee9-cc8a-42c8-a44a-479e28091cc5 0b78b0defd174ebaa80e3db6c861d4fc 0ce3df0f0b3c4e3b923606f6d9369067 - default default] Deleted allocations for instance 3f62d0ae-e403-40da-b463-4a66e727274b
2022-02-22 15:52:29.860 8 INFO nova.compute.manager [-] [instance: 3f62d0ae-e403-40da-b463-4a66e727274b] VM Stopped (Lifecycle Event)
2022-02-22 15:52:37.910 8 INFO nova.compute.claims [req-cd8896e2-828b-4b15-89bb-08c15f5dec62 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Claim successful on node rack08-server63
2022-02-22 15:52:38.311 8 INFO nova.virt.libvirt.driver [req-cd8896e2-828b-4b15-89bb-08c15f5dec62 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Creating image
2022-02-22 15:52:39.503 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] VM Resumed (Lifecycle Event)
2022-02-22 15:52:39.511 8 INFO nova.virt.libvirt.driver [-] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Instance spawned successfully.
2022-02-22 15:52:39.512 8 INFO nova.compute.manager [req-cd8896e2-828b-4b15-89bb-08c15f5dec62 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 15:52:39.564 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:52:39.564 8 INFO nova.compute.manager [req-031da59c-7359-4721-b7a5-1f1eb6da1003 - - - - -] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] VM Started (Lifecycle Event)
2022-02-22 15:52:39.600 8 INFO nova.compute.manager [req-cd8896e2-828b-4b15-89bb-08c15f5dec62 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Took 1.73 seconds to build instance.
2022-02-22 15:52:40.045 8 INFO nova.compute.manager [req-526b8147-9738-4cf3-a653-deb886e5eb28 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Terminating instance
2022-02-22 15:52:40.389 8 INFO nova.virt.libvirt.driver [-] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Instance destroyed successfully.
2022-02-22 15:52:40.404 8 INFO nova.virt.libvirt.driver [req-526b8147-9738-4cf3-a653-deb886e5eb28 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Deleting instance files /var/lib/nova/instances/5efddad7-db6f-48af-ab14-7d34f730a651_del
2022-02-22 15:52:40.406 8 INFO nova.virt.libvirt.driver [req-526b8147-9738-4cf3-a653-deb886e5eb28 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Deletion of /var/lib/nova/instances/5efddad7-db6f-48af-ab14-7d34f730a651_del complete
2022-02-22 15:52:40.473 8 INFO nova.compute.manager [req-526b8147-9738-4cf3-a653-deb886e5eb28 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:52:40.543 8 INFO nova.compute.manager [-] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:52:40.749 8 INFO nova.scheduler.client.report [req-526b8147-9738-4cf3-a653-deb886e5eb28 0d114a477c154557b00a2dd55a8b2296 ad8775eb236d4cae94814942c2a42e58 - default default] Deleted allocations for instance 5efddad7-db6f-48af-ab14-7d34f730a651
2022-02-22 15:52:55.387 8 INFO nova.compute.manager [-] [instance: 5efddad7-db6f-48af-ab14-7d34f730a651] VM Stopped (Lifecycle Event)
