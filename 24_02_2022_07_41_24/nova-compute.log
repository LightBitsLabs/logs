Build Started 24_02_2022_07_41_24
2022-02-24 09:43:36.335 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-24 09:43:40.338 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-24 09:43:41.257 7 INFO nova.virt.driver [req-462b68f3-2108-4b5a-94a8-27524d869687 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-24 09:43:41.643 7 INFO nova.compute.provider_config [req-462b68f3-2108-4b5a-94a8-27524d869687 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-24 09:43:41.662 7 WARNING oslo_config.cfg [req-462b68f3-2108-4b5a-94a8-27524d869687 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-24 09:43:41.683 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-24 09:43:41.696 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-24 09:43:41.732 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-24 09:43:41.826 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-24 09:43:41.840 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-24 09:43:41.843 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-24 09:43:42.170 7 INFO nova.compute.manager [req-070cf37e-3673-4df2-b270-108f876bee3e - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-24 09:43:43.964 7 INFO nova.virt.libvirt.host [req-070cf37e-3673-4df2-b270-108f876bee3e - - - - -] kernel doesn't support AMD SEV
2022-02-24 09:44:34.861 7 INFO nova.compute.claims [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Claim successful on node rack08-server63
2022-02-24 09:44:35.261 7 INFO nova.virt.libvirt.driver [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Creating image
2022-02-24 09:44:35.265 7 INFO oslo.privsep.daemon [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp84nlwh74/privsep.sock']
2022-02-24 09:44:36.894 7 INFO oslo.privsep.daemon [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Spawned new privsep daemon via rootwrap
2022-02-24 09:44:36.749 71 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-24 09:44:36.755 71 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-24 09:44:36.761 71 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-24 09:44:36.761 71 INFO oslo.privsep.daemon [-] privsep daemon running as pid 71
2022-02-24 09:44:38.268 7 INFO nova.compute.manager [-] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] VM Resumed (Lifecycle Event)
2022-02-24 09:44:38.275 7 INFO nova.virt.libvirt.driver [-] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Instance spawned successfully.
2022-02-24 09:44:38.334 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:38.335 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] VM Started (Lifecycle Event)
2022-02-24 09:44:38.386 7 INFO nova.compute.manager [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Took 3.13 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:38.398 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:38.475 7 INFO nova.compute.manager [req-02462b89-c07a-4eb6-b695-f92958ddb62f 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Took 3.66 seconds to build instance.
2022-02-24 09:44:42.050 7 INFO nova.compute.manager [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Attaching volume a129511f-0c2c-422c-995d-48ba7ac5e44c to /dev/vdb
2022-02-24 09:44:42.131 7 INFO oslo.privsep.daemon [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmph58ahghb/privsep.sock']
2022-02-24 09:44:43.009 7 INFO oslo.privsep.daemon [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Spawned new privsep daemon via rootwrap
2022-02-24 09:44:42.719 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-24 09:44:42.726 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-24 09:44:42.730 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-24 09:44:42.730 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-24 09:44:43.338 7 WARNING os_brick.initiator.connectors.nvmeof [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:44:44.718 7 INFO os_brick.initiator.connectors.lightos [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: connect_volume called for volume f9cf3812-eceb-4dbc-a660-50ac0da8e153, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f9cf3812-eceb-4dbc-a660-50ac0da8e153', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:44:44.752 7 INFO os_brick.initiator.connectors.lightos [req-461f2d8d-ace8-42c7-8c1e-779d83e72f5d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f9cf3812-eceb-4dbc-a660-50ac0da8e153
2022-02-24 09:44:46.690 7 INFO nova.compute.claims [req-e288dc1a-bda7-40cd-9a2e-2def3bfa8c87 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Claim successful on node rack08-server63
2022-02-24 09:44:47.091 7 INFO nova.virt.libvirt.driver [req-e288dc1a-bda7-40cd-9a2e-2def3bfa8c87 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Creating image
2022-02-24 09:44:48.288 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] VM Resumed (Lifecycle Event)
2022-02-24 09:44:48.296 7 INFO nova.virt.libvirt.driver [-] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Instance spawned successfully.
2022-02-24 09:44:48.349 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:48.350 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] VM Started (Lifecycle Event)
2022-02-24 09:44:48.404 7 INFO nova.compute.manager [req-e288dc1a-bda7-40cd-9a2e-2def3bfa8c87 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Took 1.31 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:48.405 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:48.487 7 INFO nova.compute.manager [req-e288dc1a-bda7-40cd-9a2e-2def3bfa8c87 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Took 1.85 seconds to build instance.
2022-02-24 09:44:49.868 7 INFO nova.compute.manager [req-3248f8f1-95ac-4c8d-b112-a2bd15ea2987 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Detaching volume a129511f-0c2c-422c-995d-48ba7ac5e44c
2022-02-24 09:44:49.927 7 INFO nova.virt.block_device [req-3248f8f1-95ac-4c8d-b112-a2bd15ea2987 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Attempting to driver detach volume a129511f-0c2c-422c-995d-48ba7ac5e44c from mountpoint /dev/vdb
2022-02-24 09:44:49.944 7 INFO nova.virt.libvirt.driver [req-3248f8f1-95ac-4c8d-b112-a2bd15ea2987 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance fefd2dd7-ec49-407e-a70a-0e349ead8a7a from the persistent domain config.
2022-02-24 09:44:50.086 7 INFO nova.virt.libvirt.driver [req-3248f8f1-95ac-4c8d-b112-a2bd15ea2987 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance fefd2dd7-ec49-407e-a70a-0e349ead8a7a from the live domain config.
2022-02-24 09:44:50.089 7 INFO os_brick.initiator.connectors.lightos [req-3248f8f1-95ac-4c8d-b112-a2bd15ea2987 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f9cf3812-eceb-4dbc-a660-50ac0da8e153
2022-02-24 09:44:51.182 7 INFO nova.compute.claims [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Claim successful on node rack08-server63
2022-02-24 09:44:51.446 7 INFO nova.virt.libvirt.driver [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-24 09:44:51.533 7 INFO nova.virt.block_device [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Booting with volume 69c640cf-cc39-4d44-aa3e-67087af643f6 at /dev/vda
2022-02-24 09:44:51.624 7 WARNING os_brick.initiator.connectors.nvmeof [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:44:53.163 7 INFO nova.virt.libvirt.driver [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Creating image
2022-02-24 09:44:53.175 7 INFO os_brick.initiator.connectors.lightos [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: connect_volume called for volume ac016491-053d-4f10-b8a4-95c7a8f79b23, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ac016491-053d-4f10-b8a4-95c7a8f79b23', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:44:53.178 7 INFO os_brick.initiator.connectors.lightos [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ac016491-053d-4f10-b8a4-95c7a8f79b23
2022-02-24 09:44:53.384 7 INFO nova.compute.claims [req-c77e4af9-fb6a-4e72-9253-c7ef9763f80d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Claim successful on node rack08-server63
2022-02-24 09:44:53.776 7 INFO nova.virt.libvirt.driver [req-c77e4af9-fb6a-4e72-9253-c7ef9763f80d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Creating image
2022-02-24 09:44:54.019 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] VM Resumed (Lifecycle Event)
2022-02-24 09:44:54.031 7 INFO nova.virt.libvirt.driver [-] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Instance spawned successfully.
2022-02-24 09:44:54.100 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:54.101 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] VM Started (Lifecycle Event)
2022-02-24 09:44:54.156 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:54.161 7 INFO nova.compute.manager [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Took 1.00 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:54.237 7 INFO nova.compute.manager [req-0cc7dbf5-6122-46f2-b33d-095b4759869e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Took 3.09 seconds to build instance.
2022-02-24 09:44:54.965 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] VM Resumed (Lifecycle Event)
2022-02-24 09:44:54.972 7 INFO nova.virt.libvirt.driver [-] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Instance spawned successfully.
2022-02-24 09:44:55.024 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:55.024 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] VM Started (Lifecycle Event)
2022-02-24 09:44:55.076 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:55.094 7 INFO nova.compute.manager [req-c77e4af9-fb6a-4e72-9253-c7ef9763f80d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Took 1.32 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:55.185 7 INFO nova.compute.manager [req-c77e4af9-fb6a-4e72-9253-c7ef9763f80d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Took 1.84 seconds to build instance.
2022-02-24 09:44:56.420 7 INFO nova.compute.claims [req-6424c407-c807-4693-a1aa-746dfcefa50e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Claim successful on node rack08-server63
2022-02-24 09:44:56.834 7 INFO nova.virt.libvirt.driver [req-6424c407-c807-4693-a1aa-746dfcefa50e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Creating image
2022-02-24 09:44:56.954 7 INFO nova.compute.claims [req-5281fddf-1994-4e07-bbbd-2192b4ea2193 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Claim successful on node rack08-server63
2022-02-24 09:44:57.353 7 INFO nova.virt.libvirt.driver [req-5281fddf-1994-4e07-bbbd-2192b4ea2193 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Creating image
2022-02-24 09:44:57.913 7 INFO nova.compute.manager [req-a40388df-2202-45ff-b644-d8eb081544ee 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Attaching volume 9feba784-615d-479d-8bc2-67fb57388366 to /dev/vdb
2022-02-24 09:44:58.005 7 WARNING os_brick.initiator.connectors.nvmeof [req-a40388df-2202-45ff-b644-d8eb081544ee 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:44:58.055 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] VM Resumed (Lifecycle Event)
2022-02-24 09:44:58.063 7 INFO nova.virt.libvirt.driver [-] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Instance spawned successfully.
2022-02-24 09:44:58.114 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:58.115 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] VM Started (Lifecycle Event)
2022-02-24 09:44:58.167 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:58.174 7 INFO nova.compute.manager [req-6424c407-c807-4693-a1aa-746dfcefa50e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Took 1.34 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:58.257 7 INFO nova.compute.manager [req-6424c407-c807-4693-a1aa-746dfcefa50e 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Took 1.88 seconds to build instance.
2022-02-24 09:44:58.509 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] VM Resumed (Lifecycle Event)
2022-02-24 09:44:58.516 7 INFO nova.virt.libvirt.driver [-] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Instance spawned successfully.
2022-02-24 09:44:58.576 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:58.577 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] VM Started (Lifecycle Event)
2022-02-24 09:44:58.621 7 INFO nova.compute.manager [req-5281fddf-1994-4e07-bbbd-2192b4ea2193 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-24 09:44:58.780 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:44:58.851 7 INFO nova.compute.manager [req-5281fddf-1994-4e07-bbbd-2192b4ea2193 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Took 1.95 seconds to build instance.
2022-02-24 09:44:59.350 7 INFO os_brick.initiator.connectors.lightos [req-a40388df-2202-45ff-b644-d8eb081544ee 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: connect_volume called for volume 90f11bb0-e325-4253-aa13-dd1f0248e869, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '90f11bb0-e325-4253-aa13-dd1f0248e869', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:44:59.354 7 INFO os_brick.initiator.connectors.lightos [req-a40388df-2202-45ff-b644-d8eb081544ee 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 90f11bb0-e325-4253-aa13-dd1f0248e869
2022-02-24 09:45:00.514 7 INFO nova.compute.manager [req-577e32d3-a4b1-4ee5-910e-af128ccbe327 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Detaching volume 9feba784-615d-479d-8bc2-67fb57388366
2022-02-24 09:45:00.573 7 INFO nova.virt.block_device [req-577e32d3-a4b1-4ee5-910e-af128ccbe327 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Attempting to driver detach volume 9feba784-615d-479d-8bc2-67fb57388366 from mountpoint /dev/vdb
2022-02-24 09:45:00.597 7 INFO nova.virt.libvirt.driver [req-577e32d3-a4b1-4ee5-910e-af128ccbe327 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance 4b46006f-5c72-40c4-86a8-5c5759178161 from the persistent domain config.
2022-02-24 09:45:00.741 7 INFO nova.virt.libvirt.driver [req-577e32d3-a4b1-4ee5-910e-af128ccbe327 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance 4b46006f-5c72-40c4-86a8-5c5759178161 from the live domain config.
2022-02-24 09:45:00.745 7 INFO os_brick.initiator.connectors.lightos [req-577e32d3-a4b1-4ee5-910e-af128ccbe327 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 90f11bb0-e325-4253-aa13-dd1f0248e869
2022-02-24 09:45:02.853 7 INFO nova.compute.manager [req-1b8f53d6-1d93-4e23-9979-07c48e76eb6a 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Attaching volume ffe47274-6f05-4025-951f-cbde6f92adbb to /dev/vdb
2022-02-24 09:45:02.940 7 WARNING os_brick.initiator.connectors.nvmeof [req-1b8f53d6-1d93-4e23-9979-07c48e76eb6a 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:45:03.894 7 INFO nova.compute.claims [req-c70bbfb8-1b67-4cef-938e-1df5c462fee8 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Claim successful on node rack08-server63
2022-02-24 09:45:04.293 7 INFO nova.virt.libvirt.driver [req-c70bbfb8-1b67-4cef-938e-1df5c462fee8 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Creating image
2022-02-24 09:45:04.318 7 INFO os_brick.initiator.connectors.lightos [req-1b8f53d6-1d93-4e23-9979-07c48e76eb6a 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: connect_volume called for volume 43bf3dba-cd01-4767-aa72-57673da5e8a2, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '43bf3dba-cd01-4767-aa72-57673da5e8a2', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:45:04.322 7 INFO os_brick.initiator.connectors.lightos [req-1b8f53d6-1d93-4e23-9979-07c48e76eb6a 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 43bf3dba-cd01-4767-aa72-57673da5e8a2
2022-02-24 09:45:05.332 7 INFO nova.compute.manager [req-edb6f64f-25e2-450d-9ff2-0becd489f68d 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Attaching volume ffe47274-6f05-4025-951f-cbde6f92adbb to /dev/vdb
2022-02-24 09:45:05.423 7 WARNING os_brick.initiator.connectors.nvmeof [req-edb6f64f-25e2-450d-9ff2-0becd489f68d 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:45:05.464 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] VM Resumed (Lifecycle Event)
2022-02-24 09:45:05.472 7 INFO nova.virt.libvirt.driver [-] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Instance spawned successfully.
2022-02-24 09:45:05.531 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:45:05.532 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] VM Started (Lifecycle Event)
2022-02-24 09:45:05.582 7 INFO nova.compute.manager [req-c70bbfb8-1b67-4cef-938e-1df5c462fee8 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-24 09:45:05.596 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:45:05.671 7 INFO nova.compute.manager [req-c70bbfb8-1b67-4cef-938e-1df5c462fee8 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Took 1.81 seconds to build instance.
2022-02-24 09:45:06.783 7 INFO os_brick.initiator.connectors.lightos [req-edb6f64f-25e2-450d-9ff2-0becd489f68d 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: connect_volume called for volume 43bf3dba-cd01-4767-aa72-57673da5e8a2, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '43bf3dba-cd01-4767-aa72-57673da5e8a2', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:45:06.784 7 INFO os_brick.initiator.connectors.lightos [req-edb6f64f-25e2-450d-9ff2-0becd489f68d 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 43bf3dba-cd01-4767-aa72-57673da5e8a2
2022-02-24 09:45:07.923 7 INFO nova.compute.manager [req-f01d2104-97dd-476e-a146-5c72c745845c 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Detaching volume ffe47274-6f05-4025-951f-cbde6f92adbb
2022-02-24 09:45:07.986 7 INFO nova.virt.block_device [req-f01d2104-97dd-476e-a146-5c72c745845c 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Attempting to driver detach volume ffe47274-6f05-4025-951f-cbde6f92adbb from mountpoint /dev/vdb
2022-02-24 09:45:08.009 7 INFO nova.virt.libvirt.driver [req-f01d2104-97dd-476e-a146-5c72c745845c 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Successfully detached device vdb from instance 94318096-c9aa-4d80-a494-bce1c4280f3e from the persistent domain config.
2022-02-24 09:45:08.156 7 INFO nova.virt.libvirt.driver [req-f01d2104-97dd-476e-a146-5c72c745845c 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Successfully detached device vdb from instance 94318096-c9aa-4d80-a494-bce1c4280f3e from the live domain config.
2022-02-24 09:45:08.230 7 INFO nova.virt.libvirt.driver [req-f01d2104-97dd-476e-a146-5c72c745845c 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Detected multiple connections on this host for volume: ffe47274-6f05-4025-951f-cbde6f92adbb, skipping target disconnect.
2022-02-24 09:45:08.544 7 INFO nova.compute.manager [req-6b5e582e-4faa-4b03-8844-48eeeaf919d6 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Attaching volume 2dc5fa11-87fb-4a1c-83f1-d03b293a0404 to /dev/vdb
2022-02-24 09:45:08.630 7 WARNING os_brick.initiator.connectors.nvmeof [req-6b5e582e-4faa-4b03-8844-48eeeaf919d6 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:45:09.984 7 INFO os_brick.initiator.connectors.lightos [req-6b5e582e-4faa-4b03-8844-48eeeaf919d6 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: connect_volume called for volume 7d74cedf-d6d0-42da-a532-e37d4ab5f1a4, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '7d74cedf-d6d0-42da-a532-e37d4ab5f1a4', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:45:09.988 7 INFO os_brick.initiator.connectors.lightos [req-6b5e582e-4faa-4b03-8844-48eeeaf919d6 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 7d74cedf-d6d0-42da-a532-e37d4ab5f1a4
2022-02-24 09:45:10.402 7 INFO nova.compute.manager [req-eb00f8ba-dc1b-4e3c-85bd-47736cbb8c70 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Detaching volume ffe47274-6f05-4025-951f-cbde6f92adbb
2022-02-24 09:45:10.462 7 INFO nova.virt.block_device [req-eb00f8ba-dc1b-4e3c-85bd-47736cbb8c70 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Attempting to driver detach volume ffe47274-6f05-4025-951f-cbde6f92adbb from mountpoint /dev/vdb
2022-02-24 09:45:10.480 7 INFO nova.virt.libvirt.driver [req-eb00f8ba-dc1b-4e3c-85bd-47736cbb8c70 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Successfully detached device vdb from instance 0b3078ae-e02c-4d7b-85d9-9749a6c5189d from the persistent domain config.
2022-02-24 09:45:10.658 7 INFO nova.virt.libvirt.driver [req-eb00f8ba-dc1b-4e3c-85bd-47736cbb8c70 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Successfully detached device vdb from instance 0b3078ae-e02c-4d7b-85d9-9749a6c5189d from the live domain config.
2022-02-24 09:45:11.066 7 INFO nova.compute.manager [req-d2e71e8f-816f-43ff-bc7e-b9b5a95ae91a 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Detaching volume 2dc5fa11-87fb-4a1c-83f1-d03b293a0404
2022-02-24 09:45:11.146 7 INFO nova.virt.block_device [req-d2e71e8f-816f-43ff-bc7e-b9b5a95ae91a 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Attempting to driver detach volume 2dc5fa11-87fb-4a1c-83f1-d03b293a0404 from mountpoint /dev/vdb
2022-02-24 09:45:11.165 7 INFO nova.virt.libvirt.driver [req-d2e71e8f-816f-43ff-bc7e-b9b5a95ae91a 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance 5c475641-1f3f-472e-87c4-2bffc78bfc5d from the persistent domain config.
2022-02-24 09:45:11.310 7 INFO nova.virt.libvirt.driver [req-d2e71e8f-816f-43ff-bc7e-b9b5a95ae91a 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Successfully detached device vdb from instance 5c475641-1f3f-472e-87c4-2bffc78bfc5d from the live domain config.
2022-02-24 09:46:10.910 7 INFO os_brick.initiator.connectors.lightos [req-d2e71e8f-816f-43ff-bc7e-b9b5a95ae91a 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 7d74cedf-d6d0-42da-a532-e37d4ab5f1a4
2022-02-24 09:46:14.555 7 INFO nova.compute.manager [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Terminating instance
2022-02-24 09:46:14.895 7 INFO nova.virt.libvirt.driver [-] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Instance destroyed successfully.
2022-02-24 09:46:14.911 7 INFO nova.virt.libvirt.driver [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Deleting instance files /var/lib/nova/instances/5c475641-1f3f-472e-87c4-2bffc78bfc5d_del
2022-02-24 09:46:14.913 7 INFO nova.virt.libvirt.driver [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Deletion of /var/lib/nova/instances/5c475641-1f3f-472e-87c4-2bffc78bfc5d_del complete
2022-02-24 09:46:14.982 7 INFO nova.virt.libvirt.host [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] UEFI support detected
2022-02-24 09:46:14.984 7 INFO nova.compute.manager [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:15.054 7 INFO nova.compute.manager [-] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:15.248 7 INFO nova.scheduler.client.report [req-d7e76f0b-8846-419d-b9aa-d2c8bda64c29 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Deleted allocations for instance 5c475641-1f3f-472e-87c4-2bffc78bfc5d
2022-02-24 09:46:16.938 7 INFO nova.compute.manager [req-24e9c18a-4e3b-4e77-b482-a0b8e1ecb165 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Terminating instance
2022-02-24 09:46:17.293 7 INFO nova.virt.libvirt.driver [-] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Instance destroyed successfully.
2022-02-24 09:46:17.308 7 INFO nova.virt.libvirt.driver [req-24e9c18a-4e3b-4e77-b482-a0b8e1ecb165 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Deleting instance files /var/lib/nova/instances/4b46006f-5c72-40c4-86a8-5c5759178161_del
2022-02-24 09:46:17.310 7 INFO nova.virt.libvirt.driver [req-24e9c18a-4e3b-4e77-b482-a0b8e1ecb165 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Deletion of /var/lib/nova/instances/4b46006f-5c72-40c4-86a8-5c5759178161_del complete
2022-02-24 09:46:17.377 7 INFO nova.compute.manager [req-24e9c18a-4e3b-4e77-b482-a0b8e1ecb165 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:17.445 7 INFO nova.compute.manager [-] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:17.639 7 INFO nova.scheduler.client.report [req-24e9c18a-4e3b-4e77-b482-a0b8e1ecb165 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Deleted allocations for instance 4b46006f-5c72-40c4-86a8-5c5759178161
2022-02-24 09:46:18.205 7 INFO nova.compute.manager [req-8f7100b1-79a5-47fe-abf3-30015e2552f0 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Terminating instance
2022-02-24 09:46:18.575 7 INFO nova.virt.libvirt.driver [-] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Instance destroyed successfully.
2022-02-24 09:46:18.590 7 INFO nova.virt.libvirt.driver [req-8f7100b1-79a5-47fe-abf3-30015e2552f0 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Deleting instance files /var/lib/nova/instances/5231775e-a878-4ee8-b124-9bb16d1de60b_del
2022-02-24 09:46:18.592 7 INFO nova.virt.libvirt.driver [req-8f7100b1-79a5-47fe-abf3-30015e2552f0 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Deletion of /var/lib/nova/instances/5231775e-a878-4ee8-b124-9bb16d1de60b_del complete
2022-02-24 09:46:18.662 7 INFO nova.compute.manager [req-8f7100b1-79a5-47fe-abf3-30015e2552f0 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:18.726 7 INFO nova.compute.manager [-] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] Took 0.06 seconds to deallocate network for instance.
2022-02-24 09:46:18.930 7 INFO nova.scheduler.client.report [req-8f7100b1-79a5-47fe-abf3-30015e2552f0 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Deleted allocations for instance 5231775e-a878-4ee8-b124-9bb16d1de60b
2022-02-24 09:46:20.592 7 INFO nova.compute.manager [req-50200296-2829-44e5-b769-9fe0509a157d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Terminating instance
2022-02-24 09:46:20.950 7 INFO nova.virt.libvirt.driver [-] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Instance destroyed successfully.
2022-02-24 09:46:20.965 7 INFO nova.virt.libvirt.driver [req-50200296-2829-44e5-b769-9fe0509a157d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Deleting instance files /var/lib/nova/instances/fefd2dd7-ec49-407e-a70a-0e349ead8a7a_del
2022-02-24 09:46:20.967 7 INFO nova.virt.libvirt.driver [req-50200296-2829-44e5-b769-9fe0509a157d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Deletion of /var/lib/nova/instances/fefd2dd7-ec49-407e-a70a-0e349ead8a7a_del complete
2022-02-24 09:46:21.034 7 INFO nova.compute.manager [req-50200296-2829-44e5-b769-9fe0509a157d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:21.102 7 INFO nova.compute.manager [-] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:21.302 7 INFO nova.scheduler.client.report [req-50200296-2829-44e5-b769-9fe0509a157d 9cddb8924e7b47898f7417ff95fa1f23 734672246ef14b1f90f90d34cfd8f383 - default default] Deleted allocations for instance fefd2dd7-ec49-407e-a70a-0e349ead8a7a
2022-02-24 09:46:27.510 7 INFO nova.compute.claims [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Claim successful on node rack08-server63
2022-02-24 09:46:27.786 7 INFO nova.virt.libvirt.driver [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-24 09:46:27.874 7 INFO nova.virt.block_device [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Booting with volume cae43bff-c243-459b-be87-b3f6c87825b3 at /dev/vda
2022-02-24 09:46:27.971 7 WARNING os_brick.initiator.connectors.nvmeof [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:46:29.485 7 INFO nova.virt.libvirt.driver [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Creating image
2022-02-24 09:46:29.495 7 INFO os_brick.initiator.connectors.lightos [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: connect_volume called for volume 7a04704f-7a26-457a-b196-fe3d6dd791ac, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '7a04704f-7a26-457a-b196-fe3d6dd791ac', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:46:29.498 7 INFO os_brick.initiator.connectors.lightos [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 7a04704f-7a26-457a-b196-fe3d6dd791ac
2022-02-24 09:46:29.892 7 INFO nova.compute.manager [-] [instance: 5c475641-1f3f-472e-87c4-2bffc78bfc5d] VM Stopped (Lifecycle Event)
2022-02-24 09:46:30.348 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] VM Resumed (Lifecycle Event)
2022-02-24 09:46:30.353 7 INFO nova.virt.libvirt.driver [-] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Instance spawned successfully.
2022-02-24 09:46:30.411 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:46:30.411 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] VM Started (Lifecycle Event)
2022-02-24 09:46:30.457 7 INFO nova.compute.manager [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Took 0.97 seconds to spawn the instance on the hypervisor.
2022-02-24 09:46:30.468 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:46:30.533 7 INFO nova.compute.manager [req-70562f0d-e23d-4f10-a37f-aacff397fb4b 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Took 3.06 seconds to build instance.
2022-02-24 09:46:31.901 7 INFO nova.compute.claims [req-15b73551-656c-4b83-840b-0b33d5a5516c 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Claim successful on node rack08-server63
2022-02-24 09:46:32.291 7 INFO nova.compute.manager [-] [instance: 4b46006f-5c72-40c4-86a8-5c5759178161] VM Stopped (Lifecycle Event)
2022-02-24 09:46:32.308 7 INFO nova.virt.libvirt.driver [req-15b73551-656c-4b83-840b-0b33d5a5516c 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Creating image
2022-02-24 09:46:32.957 7 INFO nova.compute.manager [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Terminating instance
2022-02-24 09:46:33.316 7 INFO nova.virt.libvirt.driver [-] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Instance destroyed successfully.
2022-02-24 09:46:33.391 7 INFO os_brick.initiator.connectors.lightos [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 7a04704f-7a26-457a-b196-fe3d6dd791ac
2022-02-24 09:46:33.403 7 INFO nova.virt.libvirt.driver [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Deleting instance files /var/lib/nova/instances/afa5d417-5caa-4785-96a3-e441e4917c7b_del
2022-02-24 09:46:33.404 7 INFO nova.virt.libvirt.driver [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Deletion of /var/lib/nova/instances/afa5d417-5caa-4785-96a3-e441e4917c7b_del complete
2022-02-24 09:46:33.477 7 INFO nova.compute.manager [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:33.540 7 INFO nova.compute.manager [-] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Took 0.06 seconds to deallocate network for instance.
2022-02-24 09:46:33.573 7 INFO nova.compute.manager [-] [instance: 5231775e-a878-4ee8-b124-9bb16d1de60b] VM Stopped (Lifecycle Event)
2022-02-24 09:46:33.777 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] VM Resumed (Lifecycle Event)
2022-02-24 09:46:33.783 7 INFO nova.virt.libvirt.driver [-] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Instance spawned successfully.
2022-02-24 09:46:33.835 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:46:33.836 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] VM Started (Lifecycle Event)
2022-02-24 09:46:33.895 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:46:33.900 7 INFO nova.compute.manager [req-15b73551-656c-4b83-840b-0b33d5a5516c 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Took 1.59 seconds to spawn the instance on the hypervisor.
2022-02-24 09:46:33.977 7 INFO nova.compute.manager [req-15b73551-656c-4b83-840b-0b33d5a5516c 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Took 2.12 seconds to build instance.
2022-02-24 09:46:34.779 7 INFO nova.compute.manager [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-24 09:46:34.988 7 INFO nova.scheduler.client.report [req-25522a1e-93cc-433c-9115-16b7d511e714 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Deleted allocations for instance afa5d417-5caa-4785-96a3-e441e4917c7b
2022-02-24 09:46:35.947 7 INFO nova.compute.manager [-] [instance: fefd2dd7-ec49-407e-a70a-0e349ead8a7a] VM Stopped (Lifecycle Event)
2022-02-24 09:46:37.869 7 INFO nova.compute.manager [req-64011431-67ec-458b-9328-713134412c19 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Terminating instance
2022-02-24 09:46:38.221 7 INFO nova.virt.libvirt.driver [-] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Instance destroyed successfully.
2022-02-24 09:46:38.235 7 INFO nova.virt.libvirt.driver [req-64011431-67ec-458b-9328-713134412c19 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Deleting instance files /var/lib/nova/instances/0b3078ae-e02c-4d7b-85d9-9749a6c5189d_del
2022-02-24 09:46:38.237 7 INFO nova.virt.libvirt.driver [req-64011431-67ec-458b-9328-713134412c19 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Deletion of /var/lib/nova/instances/0b3078ae-e02c-4d7b-85d9-9749a6c5189d_del complete
2022-02-24 09:46:38.314 7 INFO nova.compute.manager [req-64011431-67ec-458b-9328-713134412c19 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:38.390 7 INFO nova.compute.manager [-] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:38.570 7 INFO nova.scheduler.client.report [req-64011431-67ec-458b-9328-713134412c19 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Deleted allocations for instance 0b3078ae-e02c-4d7b-85d9-9749a6c5189d
2022-02-24 09:46:39.146 7 INFO nova.compute.manager [req-fc8a3d7f-c7d1-48f0-a382-08b3db47f281 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Terminating instance
2022-02-24 09:46:39.416 7 INFO nova.compute.manager [req-c045b29a-446d-4307-aa4d-a626c52df5fb 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Terminating instance
2022-02-24 09:46:39.496 7 INFO nova.virt.libvirt.driver [-] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Instance destroyed successfully.
2022-02-24 09:46:39.510 7 INFO nova.virt.libvirt.driver [req-fc8a3d7f-c7d1-48f0-a382-08b3db47f281 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Deleting instance files /var/lib/nova/instances/94318096-c9aa-4d80-a494-bce1c4280f3e_del
2022-02-24 09:46:39.512 7 INFO nova.virt.libvirt.driver [req-fc8a3d7f-c7d1-48f0-a382-08b3db47f281 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Deletion of /var/lib/nova/instances/94318096-c9aa-4d80-a494-bce1c4280f3e_del complete
2022-02-24 09:46:39.755 7 INFO nova.compute.manager [req-fc8a3d7f-c7d1-48f0-a382-08b3db47f281 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Took 0.49 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:39.762 7 INFO nova.virt.libvirt.driver [-] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Instance destroyed successfully.
2022-02-24 09:46:39.776 7 INFO nova.virt.libvirt.driver [req-c045b29a-446d-4307-aa4d-a626c52df5fb 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Deleting instance files /var/lib/nova/instances/f50d5934-a03c-42ff-9d6c-7a60dc594de1_del
2022-02-24 09:46:39.777 7 INFO nova.virt.libvirt.driver [req-c045b29a-446d-4307-aa4d-a626c52df5fb 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Deletion of /var/lib/nova/instances/f50d5934-a03c-42ff-9d6c-7a60dc594de1_del complete
2022-02-24 09:46:39.824 7 INFO nova.compute.manager [-] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:39.840 7 INFO nova.compute.manager [req-c045b29a-446d-4307-aa4d-a626c52df5fb 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:39.912 7 INFO nova.compute.manager [-] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:46:40.029 7 INFO nova.scheduler.client.report [req-fc8a3d7f-c7d1-48f0-a382-08b3db47f281 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Deleted allocations for instance 94318096-c9aa-4d80-a494-bce1c4280f3e
2022-02-24 09:46:40.082 7 INFO nova.scheduler.client.report [req-c045b29a-446d-4307-aa4d-a626c52df5fb 1a8bdf7cf112486f82bf3d874885055b dc904ca7a9e54e7096c04e9fca58310b - default default] Deleted allocations for instance f50d5934-a03c-42ff-9d6c-7a60dc594de1
2022-02-24 09:46:40.398 7 INFO nova.compute.manager [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Terminating instance
2022-02-24 09:46:40.741 7 INFO nova.virt.libvirt.driver [-] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Instance destroyed successfully.
2022-02-24 09:46:40.807 7 INFO os_brick.initiator.connectors.lightos [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ac016491-053d-4f10-b8a4-95c7a8f79b23
2022-02-24 09:46:40.819 7 INFO nova.virt.libvirt.driver [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Deleting instance files /var/lib/nova/instances/57ef6e72-4abd-44e7-8475-a5432ba015e5_del
2022-02-24 09:46:40.820 7 INFO nova.virt.libvirt.driver [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Deletion of /var/lib/nova/instances/57ef6e72-4abd-44e7-8475-a5432ba015e5_del complete
2022-02-24 09:46:40.885 7 INFO nova.compute.manager [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-24 09:46:40.949 7 INFO nova.compute.manager [-] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Took 0.06 seconds to deallocate network for instance.
2022-02-24 09:46:42.205 7 INFO nova.compute.manager [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] Took 1.26 seconds to detach 1 volumes for instance.
2022-02-24 09:46:42.394 7 INFO nova.scheduler.client.report [req-4fabd3bb-f6cf-40e2-946a-a52c4a670ec3 64e40b911acf4ad996f591af94c96c4a 03ceb0e1cb7e4ae3afd61391717bddf3 - default default] Deleted allocations for instance 57ef6e72-4abd-44e7-8475-a5432ba015e5
2022-02-24 09:46:48.313 7 INFO nova.compute.manager [-] [instance: afa5d417-5caa-4785-96a3-e441e4917c7b] VM Stopped (Lifecycle Event)
2022-02-24 09:46:53.219 7 INFO nova.compute.manager [-] [instance: 0b3078ae-e02c-4d7b-85d9-9749a6c5189d] VM Stopped (Lifecycle Event)
2022-02-24 09:46:54.487 7 INFO nova.compute.manager [-] [instance: 94318096-c9aa-4d80-a494-bce1c4280f3e] VM Stopped (Lifecycle Event)
2022-02-24 09:46:54.754 7 INFO nova.compute.manager [-] [instance: f50d5934-a03c-42ff-9d6c-7a60dc594de1] VM Stopped (Lifecycle Event)
2022-02-24 09:46:55.739 7 INFO nova.compute.manager [-] [instance: 57ef6e72-4abd-44e7-8475-a5432ba015e5] VM Stopped (Lifecycle Event)
2022-02-24 09:48:07.285 7 INFO nova.compute.claims [req-874f315c-88ec-4f22-84b8-6ac55cae08d7 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Claim successful on node rack08-server63
2022-02-24 09:48:07.690 7 INFO nova.virt.libvirt.driver [req-874f315c-88ec-4f22-84b8-6ac55cae08d7 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Creating image
2022-02-24 09:48:08.855 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] VM Resumed (Lifecycle Event)
2022-02-24 09:48:08.866 7 INFO nova.virt.libvirt.driver [-] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Instance spawned successfully.
2022-02-24 09:48:08.919 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:08.920 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] VM Started (Lifecycle Event)
2022-02-24 09:48:08.971 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:08.975 7 INFO nova.compute.manager [req-874f315c-88ec-4f22-84b8-6ac55cae08d7 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-24 09:48:09.064 7 INFO nova.compute.manager [req-874f315c-88ec-4f22-84b8-6ac55cae08d7 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Took 1.82 seconds to build instance.
2022-02-24 09:48:10.356 7 INFO nova.compute.manager [req-094ea83f-160d-4cfd-a6a7-28bd117ab773 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Terminating instance
2022-02-24 09:48:10.696 7 INFO nova.virt.libvirt.driver [-] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Instance destroyed successfully.
2022-02-24 09:48:10.712 7 INFO nova.virt.libvirt.driver [req-094ea83f-160d-4cfd-a6a7-28bd117ab773 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Deleting instance files /var/lib/nova/instances/fdb61f6a-0137-49d1-a574-05dd2b02d9a9_del
2022-02-24 09:48:10.713 7 INFO nova.virt.libvirt.driver [req-094ea83f-160d-4cfd-a6a7-28bd117ab773 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Deletion of /var/lib/nova/instances/fdb61f6a-0137-49d1-a574-05dd2b02d9a9_del complete
2022-02-24 09:48:10.781 7 INFO nova.compute.manager [req-094ea83f-160d-4cfd-a6a7-28bd117ab773 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:48:10.849 7 INFO nova.compute.manager [-] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:48:11.046 7 INFO nova.scheduler.client.report [req-094ea83f-160d-4cfd-a6a7-28bd117ab773 0fb9a7ac63194086a0520992049f16d4 270d5848930f4d4caeb00355dcdd5938 - default default] Deleted allocations for instance fdb61f6a-0137-49d1-a574-05dd2b02d9a9
2022-02-24 09:48:21.129 7 INFO nova.compute.claims [req-82b5c9bf-2f41-450a-bcf9-978c9922711d 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Claim successful on node rack08-server63
2022-02-24 09:48:21.546 7 INFO nova.virt.libvirt.driver [req-82b5c9bf-2f41-450a-bcf9-978c9922711d 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Creating image
2022-02-24 09:48:22.659 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] VM Resumed (Lifecycle Event)
2022-02-24 09:48:22.666 7 INFO nova.virt.libvirt.driver [-] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Instance spawned successfully.
2022-02-24 09:48:22.727 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:22.728 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] VM Started (Lifecycle Event)
2022-02-24 09:48:22.773 7 INFO nova.compute.manager [req-82b5c9bf-2f41-450a-bcf9-978c9922711d 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-24 09:48:22.782 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:22.852 7 INFO nova.compute.manager [req-82b5c9bf-2f41-450a-bcf9-978c9922711d 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Took 1.76 seconds to build instance.
2022-02-24 09:48:25.695 7 INFO nova.compute.manager [-] [instance: fdb61f6a-0137-49d1-a574-05dd2b02d9a9] VM Stopped (Lifecycle Event)
2022-02-24 09:48:36.205 7 INFO nova.virt.libvirt.driver [req-a8e538d7-78c5-4c9a-8085-77f2d91abac7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Ignoring supplied device name: /dev/vdb
2022-02-24 09:48:36.358 7 INFO nova.compute.manager [req-a8e538d7-78c5-4c9a-8085-77f2d91abac7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Attaching volume 4a3366eb-b985-428e-9939-740dc1326cf8 to /dev/vdb
2022-02-24 09:48:36.453 7 WARNING os_brick.initiator.connectors.nvmeof [req-a8e538d7-78c5-4c9a-8085-77f2d91abac7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:48:37.829 7 INFO os_brick.initiator.connectors.lightos [req-a8e538d7-78c5-4c9a-8085-77f2d91abac7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: connect_volume called for volume d9f8bb40-e881-4514-9f24-7466fe2581cd, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd9f8bb40-e881-4514-9f24-7466fe2581cd', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:48:37.833 7 INFO os_brick.initiator.connectors.lightos [req-a8e538d7-78c5-4c9a-8085-77f2d91abac7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d9f8bb40-e881-4514-9f24-7466fe2581cd
2022-02-24 09:48:48.950 7 INFO nova.compute.manager [req-78f7e05f-9543-4529-9b65-f9e0d829f6f7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Detaching volume 4a3366eb-b985-428e-9939-740dc1326cf8
2022-02-24 09:48:49.012 7 INFO nova.virt.block_device [req-78f7e05f-9543-4529-9b65-f9e0d829f6f7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Attempting to driver detach volume 4a3366eb-b985-428e-9939-740dc1326cf8 from mountpoint /dev/vdb
2022-02-24 09:48:49.030 7 INFO nova.virt.libvirt.driver [req-78f7e05f-9543-4529-9b65-f9e0d829f6f7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Successfully detached device vdb from instance f57e47ed-9cf9-491f-b565-5817b4ecc1fb from the persistent domain config.
2022-02-24 09:48:49.170 7 INFO nova.virt.libvirt.driver [req-78f7e05f-9543-4529-9b65-f9e0d829f6f7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Successfully detached device vdb from instance f57e47ed-9cf9-491f-b565-5817b4ecc1fb from the live domain config.
2022-02-24 09:48:49.173 7 INFO os_brick.initiator.connectors.lightos [req-78f7e05f-9543-4529-9b65-f9e0d829f6f7 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d9f8bb40-e881-4514-9f24-7466fe2581cd
2022-02-24 09:48:51.199 7 INFO nova.compute.manager [req-d50ea174-7fda-4eb7-82f3-901f642f3a47 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Terminating instance
2022-02-24 09:48:51.539 7 INFO nova.virt.libvirt.driver [-] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Instance destroyed successfully.
2022-02-24 09:48:51.554 7 INFO nova.virt.libvirt.driver [req-d50ea174-7fda-4eb7-82f3-901f642f3a47 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Deleting instance files /var/lib/nova/instances/f57e47ed-9cf9-491f-b565-5817b4ecc1fb_del
2022-02-24 09:48:51.555 7 INFO nova.virt.libvirt.driver [req-d50ea174-7fda-4eb7-82f3-901f642f3a47 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Deletion of /var/lib/nova/instances/f57e47ed-9cf9-491f-b565-5817b4ecc1fb_del complete
2022-02-24 09:48:51.624 7 INFO nova.compute.manager [req-d50ea174-7fda-4eb7-82f3-901f642f3a47 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:48:51.691 7 INFO nova.compute.manager [-] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:48:51.884 7 INFO nova.scheduler.client.report [req-d50ea174-7fda-4eb7-82f3-901f642f3a47 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Deleted allocations for instance f57e47ed-9cf9-491f-b565-5817b4ecc1fb
2022-02-24 09:48:54.509 7 INFO nova.compute.claims [req-50eac427-f7cc-46e7-bb0e-4fbcab1c2ad6 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Claim successful on node rack08-server63
2022-02-24 09:48:54.896 7 INFO nova.virt.libvirt.driver [req-50eac427-f7cc-46e7-bb0e-4fbcab1c2ad6 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Creating image
2022-02-24 09:48:56.034 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] VM Resumed (Lifecycle Event)
2022-02-24 09:48:56.041 7 INFO nova.virt.libvirt.driver [-] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Instance spawned successfully.
2022-02-24 09:48:56.099 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:56.100 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] VM Started (Lifecycle Event)
2022-02-24 09:48:56.146 7 INFO nova.compute.manager [req-50eac427-f7cc-46e7-bb0e-4fbcab1c2ad6 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-24 09:48:56.157 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:48:56.233 7 INFO nova.compute.manager [req-50eac427-f7cc-46e7-bb0e-4fbcab1c2ad6 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Took 1.76 seconds to build instance.
2022-02-24 09:48:56.779 7 INFO nova.compute.manager [req-39359ff7-e7c7-4ff4-8f03-7ce258f45771 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Terminating instance
2022-02-24 09:48:57.135 7 INFO nova.virt.libvirt.driver [-] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Instance destroyed successfully.
2022-02-24 09:48:57.150 7 INFO nova.virt.libvirt.driver [req-39359ff7-e7c7-4ff4-8f03-7ce258f45771 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Deleting instance files /var/lib/nova/instances/d8a819b7-ff32-4b08-8b45-db71fd6be650_del
2022-02-24 09:48:57.152 7 INFO nova.virt.libvirt.driver [req-39359ff7-e7c7-4ff4-8f03-7ce258f45771 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Deletion of /var/lib/nova/instances/d8a819b7-ff32-4b08-8b45-db71fd6be650_del complete
2022-02-24 09:48:57.220 7 INFO nova.compute.manager [req-39359ff7-e7c7-4ff4-8f03-7ce258f45771 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:48:57.288 7 INFO nova.compute.manager [-] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:48:57.485 7 INFO nova.scheduler.client.report [req-39359ff7-e7c7-4ff4-8f03-7ce258f45771 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] Deleted allocations for instance d8a819b7-ff32-4b08-8b45-db71fd6be650
2022-02-24 09:48:59.157 7 INFO nova.compute.claims [req-6dacfe5a-21d9-4a9b-8181-8209a6b24ccd 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Claim successful on node rack08-server63
2022-02-24 09:48:59.496 7 INFO nova.compute.claims [req-c3f84d4f-a805-4178-afdb-35a2ccb36216 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Claim successful on node rack08-server63
2022-02-24 09:48:59.539 7 INFO nova.virt.libvirt.driver [req-6dacfe5a-21d9-4a9b-8181-8209a6b24ccd 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Creating image
2022-02-24 09:48:59.920 7 INFO nova.virt.libvirt.driver [req-c3f84d4f-a805-4178-afdb-35a2ccb36216 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Creating image
2022-02-24 09:49:00.852 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] VM Resumed (Lifecycle Event)
2022-02-24 09:49:00.860 7 INFO nova.virt.libvirt.driver [-] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Instance spawned successfully.
2022-02-24 09:49:00.909 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:00.910 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] VM Started (Lifecycle Event)
2022-02-24 09:49:00.965 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:00.970 7 INFO nova.compute.manager [req-6dacfe5a-21d9-4a9b-8181-8209a6b24ccd 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Took 1.43 seconds to spawn the instance on the hypervisor.
2022-02-24 09:49:01.050 7 INFO nova.compute.manager [req-6dacfe5a-21d9-4a9b-8181-8209a6b24ccd 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Took 1.93 seconds to build instance.
2022-02-24 09:49:01.121 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] VM Resumed (Lifecycle Event)
2022-02-24 09:49:01.128 7 INFO nova.virt.libvirt.driver [-] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Instance spawned successfully.
2022-02-24 09:49:01.182 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:01.182 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] VM Started (Lifecycle Event)
2022-02-24 09:49:01.233 7 INFO nova.compute.manager [req-c3f84d4f-a805-4178-afdb-35a2ccb36216 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Took 1.31 seconds to spawn the instance on the hypervisor.
2022-02-24 09:49:01.235 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:01.313 7 INFO nova.compute.manager [req-c3f84d4f-a805-4178-afdb-35a2ccb36216 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Took 1.85 seconds to build instance.
2022-02-24 09:49:02.491 7 INFO nova.virt.libvirt.driver [req-9e1aaee7-8818-4aa8-8a38-0e4e3f15d08b 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Ignoring supplied device name: /dev/vdb
2022-02-24 09:49:02.560 7 INFO nova.compute.manager [req-89518eed-dcd4-40a7-b5b3-4b305066db56 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Terminating instance
2022-02-24 09:49:02.650 7 INFO nova.compute.manager [req-9e1aaee7-8818-4aa8-8a38-0e4e3f15d08b 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Attaching volume 4a71c5b4-46f7-4422-93fe-45350c7794a8 to /dev/vdb
2022-02-24 09:49:02.748 7 WARNING os_brick.initiator.connectors.nvmeof [req-9e1aaee7-8818-4aa8-8a38-0e4e3f15d08b 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:49:02.925 7 INFO nova.virt.libvirt.driver [-] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Instance destroyed successfully.
2022-02-24 09:49:02.941 7 INFO nova.virt.libvirt.driver [req-89518eed-dcd4-40a7-b5b3-4b305066db56 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Deleting instance files /var/lib/nova/instances/f1cfdde8-0d14-4879-88fe-70d60ae59927_del
2022-02-24 09:49:02.942 7 INFO nova.virt.libvirt.driver [req-89518eed-dcd4-40a7-b5b3-4b305066db56 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Deletion of /var/lib/nova/instances/f1cfdde8-0d14-4879-88fe-70d60ae59927_del complete
2022-02-24 09:49:03.006 7 INFO nova.compute.manager [req-89518eed-dcd4-40a7-b5b3-4b305066db56 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-24 09:49:03.076 7 INFO nova.compute.manager [-] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:49:03.265 7 INFO nova.scheduler.client.report [req-89518eed-dcd4-40a7-b5b3-4b305066db56 72661369c9ba415eb35e17089ed1c1d4 bb8776bc013a4bf59b5a85a0e6d33101 - default default] Deleted allocations for instance f1cfdde8-0d14-4879-88fe-70d60ae59927
2022-02-24 09:49:04.089 7 INFO os_brick.initiator.connectors.lightos [req-9e1aaee7-8818-4aa8-8a38-0e4e3f15d08b 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: connect_volume called for volume f0ebbb0c-f702-48e9-9f81-5845d920b67d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f0ebbb0c-f702-48e9-9f81-5845d920b67d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:49:04.093 7 INFO os_brick.initiator.connectors.lightos [req-9e1aaee7-8818-4aa8-8a38-0e4e3f15d08b 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f0ebbb0c-f702-48e9-9f81-5845d920b67d
2022-02-24 09:49:06.536 7 INFO nova.compute.manager [-] [instance: f57e47ed-9cf9-491f-b565-5817b4ecc1fb] VM Stopped (Lifecycle Event)
2022-02-24 09:49:12.133 7 INFO nova.compute.manager [-] [instance: d8a819b7-ff32-4b08-8b45-db71fd6be650] VM Stopped (Lifecycle Event)
2022-02-24 09:49:12.877 7 INFO nova.compute.manager [req-661a2bef-af3c-4d14-875f-51dc9b3ea71e 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Detaching volume 4a71c5b4-46f7-4422-93fe-45350c7794a8
2022-02-24 09:49:12.933 7 INFO nova.virt.block_device [req-661a2bef-af3c-4d14-875f-51dc9b3ea71e 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Attempting to driver detach volume 4a71c5b4-46f7-4422-93fe-45350c7794a8 from mountpoint /dev/vdb
2022-02-24 09:49:12.955 7 INFO nova.virt.libvirt.driver [req-661a2bef-af3c-4d14-875f-51dc9b3ea71e 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Successfully detached device vdb from instance ae6407b4-1bda-4188-a32a-03ad981ae5fa from the persistent domain config.
2022-02-24 09:49:13.094 7 INFO nova.virt.libvirt.driver [req-661a2bef-af3c-4d14-875f-51dc9b3ea71e 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Successfully detached device vdb from instance ae6407b4-1bda-4188-a32a-03ad981ae5fa from the live domain config.
2022-02-24 09:49:13.097 7 INFO os_brick.initiator.connectors.lightos [req-661a2bef-af3c-4d14-875f-51dc9b3ea71e 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f0ebbb0c-f702-48e9-9f81-5845d920b67d
2022-02-24 09:49:16.130 7 INFO nova.compute.manager [req-b4e00f52-8fae-4bb9-a7ac-7109f31d32b0 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Terminating instance
2022-02-24 09:49:16.495 7 INFO nova.virt.libvirt.driver [-] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Instance destroyed successfully.
2022-02-24 09:49:16.511 7 INFO nova.virt.libvirt.driver [req-b4e00f52-8fae-4bb9-a7ac-7109f31d32b0 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Deleting instance files /var/lib/nova/instances/ae6407b4-1bda-4188-a32a-03ad981ae5fa_del
2022-02-24 09:49:16.512 7 INFO nova.virt.libvirt.driver [req-b4e00f52-8fae-4bb9-a7ac-7109f31d32b0 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Deletion of /var/lib/nova/instances/ae6407b4-1bda-4188-a32a-03ad981ae5fa_del complete
2022-02-24 09:49:17.084 7 INFO nova.compute.manager [req-b4e00f52-8fae-4bb9-a7ac-7109f31d32b0 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Took 0.81 seconds to destroy the instance on the hypervisor.
2022-02-24 09:49:17.147 7 INFO nova.compute.manager [-] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] Took 0.06 seconds to deallocate network for instance.
2022-02-24 09:49:17.922 7 INFO nova.compute.manager [-] [instance: f1cfdde8-0d14-4879-88fe-70d60ae59927] VM Stopped (Lifecycle Event)
2022-02-24 09:49:18.517 7 INFO nova.scheduler.client.report [req-b4e00f52-8fae-4bb9-a7ac-7109f31d32b0 1cec3a98aa6943ab8fea01ac0c3e51ae c955c2f988f849bcb7b7b5599caeab71 - default default] Deleted allocations for instance ae6407b4-1bda-4188-a32a-03ad981ae5fa
2022-02-24 09:49:30.583 7 INFO nova.compute.claims [req-bee3ab58-5f3e-4a30-8201-dc2064c9d21c de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Claim successful on node rack08-server63
2022-02-24 09:49:30.970 7 INFO nova.virt.libvirt.driver [req-bee3ab58-5f3e-4a30-8201-dc2064c9d21c de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Creating image
2022-02-24 09:49:31.493 7 INFO nova.compute.manager [-] [instance: ae6407b4-1bda-4188-a32a-03ad981ae5fa] VM Stopped (Lifecycle Event)
2022-02-24 09:49:32.134 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] VM Resumed (Lifecycle Event)
2022-02-24 09:49:32.141 7 INFO nova.virt.libvirt.driver [-] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Instance spawned successfully.
2022-02-24 09:49:32.194 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:32.195 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] VM Started (Lifecycle Event)
2022-02-24 09:49:32.250 7 INFO nova.compute.manager [req-bee3ab58-5f3e-4a30-8201-dc2064c9d21c de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-24 09:49:32.251 7 INFO nova.compute.manager [req-38cbcd0c-3c28-47da-bd62-6a2778663056 - - - - -] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-24 09:49:32.326 7 INFO nova.compute.manager [req-bee3ab58-5f3e-4a30-8201-dc2064c9d21c de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Took 1.78 seconds to build instance.
2022-02-24 09:49:32.562 7 INFO nova.virt.libvirt.driver [req-d8c37b07-b0bb-46a8-861f-ff9e2dac9188 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Ignoring supplied device name: /dev/vdb
2022-02-24 09:49:32.741 7 INFO nova.compute.manager [req-d8c37b07-b0bb-46a8-861f-ff9e2dac9188 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Attaching volume f11b0a61-8d16-4aaa-a417-bfeebd2294a2 to /dev/vdb
2022-02-24 09:49:32.827 7 WARNING os_brick.initiator.connectors.nvmeof [req-d8c37b07-b0bb-46a8-861f-ff9e2dac9188 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-24 09:49:34.182 7 INFO os_brick.initiator.connectors.lightos [req-d8c37b07-b0bb-46a8-861f-ff9e2dac9188 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] LIGHTOS: connect_volume called for volume a4057d07-9c9a-4234-b607-b8d6f58835c7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a4057d07-9c9a-4234-b607-b8d6f58835c7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-24 09:49:34.186 7 INFO os_brick.initiator.connectors.lightos [req-d8c37b07-b0bb-46a8-861f-ff9e2dac9188 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a4057d07-9c9a-4234-b607-b8d6f58835c7
2022-02-24 09:49:35.987 7 INFO nova.compute.manager [req-3b782dfa-3871-4c46-9f8f-4777af6dd6a2 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Cinder extended volume f11b0a61-8d16-4aaa-a417-bfeebd2294a2; extending it to detect new size
2022-02-24 09:49:36.055 7 INFO os_brick.initiator.connectors.lightos [req-3b782dfa-3871-4c46-9f8f-4777af6dd6a2 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a4057d07-9c9a-4234-b607-b8d6f58835c7
2022-02-24 09:49:36.726 7 INFO nova.compute.manager [req-4ad83a39-fb82-4895-9bee-b18e3a06a621 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Detaching volume f11b0a61-8d16-4aaa-a417-bfeebd2294a2
2022-02-24 09:49:36.794 7 INFO nova.virt.block_device [req-4ad83a39-fb82-4895-9bee-b18e3a06a621 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Attempting to driver detach volume f11b0a61-8d16-4aaa-a417-bfeebd2294a2 from mountpoint /dev/vdb
2022-02-24 09:49:36.813 7 INFO nova.virt.libvirt.driver [req-4ad83a39-fb82-4895-9bee-b18e3a06a621 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] Successfully detached device vdb from instance 0ca42d27-7b3c-4b4b-9856-633e67500e0b from the persistent domain config.
2022-02-24 09:49:36.946 7 INFO nova.virt.libvirt.driver [req-4ad83a39-fb82-4895-9bee-b18e3a06a621 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] Successfully detached device vdb from instance 0ca42d27-7b3c-4b4b-9856-633e67500e0b from the live domain config.
2022-02-24 09:49:36.949 7 INFO os_brick.initiator.connectors.lightos [req-4ad83a39-fb82-4895-9bee-b18e3a06a621 de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a4057d07-9c9a-4234-b607-b8d6f58835c7
2022-02-24 09:49:38.984 7 INFO nova.compute.manager [req-d13da0e6-306c-4033-9384-68aff626ffde de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Terminating instance
2022-02-24 09:49:39.332 7 INFO nova.virt.libvirt.driver [-] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Instance destroyed successfully.
2022-02-24 09:49:39.347 7 INFO nova.virt.libvirt.driver [req-d13da0e6-306c-4033-9384-68aff626ffde de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Deleting instance files /var/lib/nova/instances/0ca42d27-7b3c-4b4b-9856-633e67500e0b_del
2022-02-24 09:49:39.348 7 INFO nova.virt.libvirt.driver [req-d13da0e6-306c-4033-9384-68aff626ffde de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Deletion of /var/lib/nova/instances/0ca42d27-7b3c-4b4b-9856-633e67500e0b_del complete
2022-02-24 09:49:39.418 7 INFO nova.compute.manager [req-d13da0e6-306c-4033-9384-68aff626ffde de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-24 09:49:39.486 7 INFO nova.compute.manager [-] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] Took 0.07 seconds to deallocate network for instance.
2022-02-24 09:49:39.691 7 INFO nova.scheduler.client.report [req-d13da0e6-306c-4033-9384-68aff626ffde de1e58b7c96a4d76834cae956fef40c7 1e6f1568c540487790c1af54fbc9ad17 - default default] Deleted allocations for instance 0ca42d27-7b3c-4b4b-9856-633e67500e0b
2022-02-24 09:49:54.330 7 INFO nova.compute.manager [-] [instance: 0ca42d27-7b3c-4b4b-9856-633e67500e0b] VM Stopped (Lifecycle Event)
