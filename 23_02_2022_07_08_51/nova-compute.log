Build Started 23_02_2022_07_08_51
2022-02-23 09:10:59.400 8 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-23 09:11:03.418 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-23 09:11:04.324 7 INFO nova.virt.driver [req-4bf96cb9-3862-49db-84c8-40c538b747eb - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-23 09:11:04.711 7 INFO nova.compute.provider_config [req-4bf96cb9-3862-49db-84c8-40c538b747eb - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-23 09:11:04.730 7 WARNING oslo_config.cfg [req-4bf96cb9-3862-49db-84c8-40c538b747eb - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-23 09:11:04.751 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-23 09:11:04.764 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-23 09:11:04.801 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-23 09:11:04.910 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-23 09:11:04.925 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-23 09:11:04.927 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-23 09:11:05.259 7 INFO nova.compute.manager [req-4420030b-3ea0-41ab-9d94-8504d3521edb - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-23 09:11:07.112 7 INFO nova.virt.libvirt.host [req-4420030b-3ea0-41ab-9d94-8504d3521edb - - - - -] kernel doesn't support AMD SEV
2022-02-23 09:11:58.079 7 INFO nova.compute.claims [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Claim successful on node rack08-server63
2022-02-23 09:11:58.461 7 INFO nova.virt.libvirt.driver [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Creating image
2022-02-23 09:11:58.467 7 INFO oslo.privsep.daemon [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpkgcbv5iu/privsep.sock']
2022-02-23 09:12:00.108 7 INFO oslo.privsep.daemon [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Spawned new privsep daemon via rootwrap
2022-02-23 09:11:59.955 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 09:11:59.960 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 09:11:59.965 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-23 09:11:59.966 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-23 09:12:01.367 7 INFO nova.compute.manager [-] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] VM Resumed (Lifecycle Event)
2022-02-23 09:12:01.375 7 INFO nova.virt.libvirt.driver [-] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Instance spawned successfully.
2022-02-23 09:12:01.426 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:01.427 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] VM Started (Lifecycle Event)
2022-02-23 09:12:01.479 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:01.486 7 INFO nova.compute.manager [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Took 3.03 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:01.571 7 INFO nova.compute.manager [req-96277ebe-6b28-4153-aa77-8041d7ab3cde d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Took 3.53 seconds to build instance.
2022-02-23 09:12:04.733 7 INFO nova.compute.manager [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Attaching volume 3cc6bd83-1f66-4321-b69d-4d3ffad080d2 to /dev/vdb
2022-02-23 09:12:04.816 7 INFO oslo.privsep.daemon [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmp0sdi87ts/privsep.sock']
2022-02-23 09:12:06.109 7 INFO oslo.privsep.daemon [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Spawned new privsep daemon via rootwrap
2022-02-23 09:12:05.412 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 09:12:05.419 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 09:12:05.424 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-23 09:12:05.425 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-23 09:12:06.438 7 WARNING os_brick.initiator.connectors.nvmeof [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:12:07.781 7 INFO os_brick.initiator.connectors.lightos [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: connect_volume called for volume f2c6d650-a850-4254-bc4b-92ea685c9ac9, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f2c6d650-a850-4254-bc4b-92ea685c9ac9', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:12:07.815 7 INFO os_brick.initiator.connectors.lightos [req-7fc48894-c075-4960-95e2-9fe231cd916c d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f2c6d650-a850-4254-bc4b-92ea685c9ac9
2022-02-23 09:12:10.401 7 INFO nova.compute.claims [req-fc85b80c-d701-4d62-9ae3-50cf67352314 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Claim successful on node rack08-server63
2022-02-23 09:12:10.802 7 INFO nova.virt.libvirt.driver [req-fc85b80c-d701-4d62-9ae3-50cf67352314 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Creating image
2022-02-23 09:12:11.991 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] VM Resumed (Lifecycle Event)
2022-02-23 09:12:11.999 7 INFO nova.virt.libvirt.driver [-] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Instance spawned successfully.
2022-02-23 09:12:12.054 7 INFO nova.compute.claims [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Claim successful on node rack08-server63
2022-02-23 09:12:12.059 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:12.059 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] VM Started (Lifecycle Event)
2022-02-23 09:12:12.103 7 INFO nova.compute.manager [req-fc85b80c-d701-4d62-9ae3-50cf67352314 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:12.113 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:12.186 7 INFO nova.compute.manager [req-fc85b80c-d701-4d62-9ae3-50cf67352314 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Took 1.84 seconds to build instance.
2022-02-23 09:12:12.298 7 INFO nova.virt.libvirt.driver [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 09:12:12.384 7 INFO nova.virt.block_device [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Booting with volume 5527e120-6882-4381-bc1c-1f20c62c1b17 at /dev/vda
2022-02-23 09:12:12.472 7 WARNING os_brick.initiator.connectors.nvmeof [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:12:13.573 7 INFO nova.compute.manager [req-27a345bb-d698-45d1-8c53-3961dfba53b6 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Detaching volume 3cc6bd83-1f66-4321-b69d-4d3ffad080d2
2022-02-23 09:12:13.633 7 INFO nova.virt.block_device [req-27a345bb-d698-45d1-8c53-3961dfba53b6 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Attempting to driver detach volume 3cc6bd83-1f66-4321-b69d-4d3ffad080d2 from mountpoint /dev/vdb
2022-02-23 09:12:13.652 7 INFO nova.virt.libvirt.driver [req-27a345bb-d698-45d1-8c53-3961dfba53b6 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance a7a70a7c-4806-4016-ba3c-9f61bd0911f5 from the persistent domain config.
2022-02-23 09:12:13.794 7 INFO nova.virt.libvirt.driver [req-27a345bb-d698-45d1-8c53-3961dfba53b6 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance a7a70a7c-4806-4016-ba3c-9f61bd0911f5 from the live domain config.
2022-02-23 09:12:13.797 7 INFO os_brick.initiator.connectors.lightos [req-27a345bb-d698-45d1-8c53-3961dfba53b6 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid f2c6d650-a850-4254-bc4b-92ea685c9ac9
2022-02-23 09:12:13.935 7 INFO nova.virt.libvirt.driver [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Creating image
2022-02-23 09:12:13.945 7 INFO os_brick.initiator.connectors.lightos [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: connect_volume called for volume c5d882fd-4263-4ef9-9802-3a3e7d14604d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c5d882fd-4263-4ef9-9802-3a3e7d14604d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:12:13.947 7 INFO os_brick.initiator.connectors.lightos [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid c5d882fd-4263-4ef9-9802-3a3e7d14604d
2022-02-23 09:12:14.750 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] VM Resumed (Lifecycle Event)
2022-02-23 09:12:14.757 7 INFO nova.virt.libvirt.driver [-] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Instance spawned successfully.
2022-02-23 09:12:14.810 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:14.811 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] VM Started (Lifecycle Event)
2022-02-23 09:12:14.866 7 INFO nova.compute.manager [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Took 0.93 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:14.868 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:14.953 7 INFO nova.compute.manager [req-089124ee-a062-4ff7-bbdf-cd77ae4443f0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Took 2.94 seconds to build instance.
2022-02-23 09:12:17.057 7 INFO nova.compute.claims [req-60327d17-b0ae-4d5b-abbd-6f2cc02a6843 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Claim successful on node rack08-server63
2022-02-23 09:12:17.246 7 INFO nova.compute.claims [req-b40d1c17-3dd1-4900-b5b1-13783c321d0d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Claim successful on node rack08-server63
2022-02-23 09:12:17.437 7 INFO nova.virt.libvirt.driver [req-60327d17-b0ae-4d5b-abbd-6f2cc02a6843 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Creating image
2022-02-23 09:12:17.629 7 INFO nova.virt.libvirt.driver [req-b40d1c17-3dd1-4900-b5b1-13783c321d0d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Creating image
2022-02-23 09:12:17.835 7 INFO nova.compute.claims [req-a634832d-c4c7-4fa2-844b-61759ff74cf0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Claim successful on node rack08-server63
2022-02-23 09:12:18.231 7 INFO nova.virt.libvirt.driver [req-a634832d-c4c7-4fa2-844b-61759ff74cf0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Creating image
2022-02-23 09:12:18.639 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] VM Resumed (Lifecycle Event)
2022-02-23 09:12:18.651 7 INFO nova.virt.libvirt.driver [-] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Instance spawned successfully.
2022-02-23 09:12:18.698 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:18.698 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] VM Started (Lifecycle Event)
2022-02-23 09:12:18.744 7 INFO nova.virt.libvirt.driver [-] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Instance spawned successfully.
2022-02-23 09:12:18.756 7 INFO nova.compute.manager [req-60327d17-b0ae-4d5b-abbd-6f2cc02a6843 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Took 1.32 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:18.758 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:18.759 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] VM Resumed (Lifecycle Event)
2022-02-23 09:12:18.810 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:18.811 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] VM Started (Lifecycle Event)
2022-02-23 09:12:18.845 7 INFO nova.compute.manager [req-60327d17-b0ae-4d5b-abbd-6f2cc02a6843 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Took 1.82 seconds to build instance.
2022-02-23 09:12:18.857 7 INFO nova.compute.manager [req-b40d1c17-3dd1-4900-b5b1-13783c321d0d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:18.878 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:18.940 7 INFO nova.compute.manager [req-b40d1c17-3dd1-4900-b5b1-13783c321d0d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Took 1.73 seconds to build instance.
2022-02-23 09:12:19.361 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] VM Resumed (Lifecycle Event)
2022-02-23 09:12:19.370 7 INFO nova.virt.libvirt.driver [-] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Instance spawned successfully.
2022-02-23 09:12:19.433 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:19.433 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] VM Started (Lifecycle Event)
2022-02-23 09:12:19.473 7 INFO nova.compute.manager [req-a634832d-c4c7-4fa2-844b-61759ff74cf0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:19.490 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:19.556 7 INFO nova.compute.manager [req-a634832d-c4c7-4fa2-844b-61759ff74cf0 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Took 1.79 seconds to build instance.
2022-02-23 09:12:22.623 7 INFO nova.compute.manager [req-f4c89df5-36f0-4f11-b511-56ea77a415ed d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Attaching volume 5f2ad408-12ea-4347-853c-bd6c45b0ce03 to /dev/vdb
2022-02-23 09:12:22.629 7 INFO nova.compute.manager [req-831e7cbd-1184-4d00-aab9-5450975799e7 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Attaching volume e3e7ec8f-bd83-423f-8367-32ec0abb7935 to /dev/vdb
2022-02-23 09:12:22.718 7 WARNING os_brick.initiator.connectors.nvmeof [req-831e7cbd-1184-4d00-aab9-5450975799e7 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:12:22.725 7 WARNING os_brick.initiator.connectors.nvmeof [req-f4c89df5-36f0-4f11-b511-56ea77a415ed d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:12:24.083 7 INFO os_brick.initiator.connectors.lightos [req-f4c89df5-36f0-4f11-b511-56ea77a415ed d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: connect_volume called for volume 8e57b307-c36c-482b-8e47-7e8e94c4809b, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8e57b307-c36c-482b-8e47-7e8e94c4809b', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:12:24.087 7 INFO os_brick.initiator.connectors.lightos [req-f4c89df5-36f0-4f11-b511-56ea77a415ed d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e57b307-c36c-482b-8e47-7e8e94c4809b
2022-02-23 09:12:24.090 7 INFO os_brick.initiator.connectors.lightos [req-831e7cbd-1184-4d00-aab9-5450975799e7 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: connect_volume called for volume ed4e80a6-120e-4a23-bdb7-6b174d64ed30, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ed4e80a6-120e-4a23-bdb7-6b174d64ed30', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:12:24.093 7 INFO os_brick.initiator.connectors.lightos [req-831e7cbd-1184-4d00-aab9-5450975799e7 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid ed4e80a6-120e-4a23-bdb7-6b174d64ed30
2022-02-23 09:12:25.117 7 INFO nova.compute.manager [req-be26db0a-512b-4d6d-a448-752c7b00ce4c d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Attaching volume e3e7ec8f-bd83-423f-8367-32ec0abb7935 to /dev/vdb
2022-02-23 09:12:25.213 7 WARNING os_brick.initiator.connectors.nvmeof [req-be26db0a-512b-4d6d-a448-752c7b00ce4c d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:12:25.244 7 INFO nova.compute.manager [req-9c65e3a5-db37-46bf-96ca-b35ac3fecd8a d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Detaching volume 5f2ad408-12ea-4347-853c-bd6c45b0ce03
2022-02-23 09:12:25.589 7 INFO nova.virt.block_device [req-9c65e3a5-db37-46bf-96ca-b35ac3fecd8a d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Attempting to driver detach volume 5f2ad408-12ea-4347-853c-bd6c45b0ce03 from mountpoint /dev/vdb
2022-02-23 09:12:25.608 7 INFO nova.virt.libvirt.driver [req-9c65e3a5-db37-46bf-96ca-b35ac3fecd8a d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance 40ee0705-040f-471e-9983-02974f98f6c3 from the persistent domain config.
2022-02-23 09:12:25.749 7 INFO nova.virt.libvirt.driver [req-9c65e3a5-db37-46bf-96ca-b35ac3fecd8a d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance 40ee0705-040f-471e-9983-02974f98f6c3 from the live domain config.
2022-02-23 09:12:25.753 7 INFO os_brick.initiator.connectors.lightos [req-9c65e3a5-db37-46bf-96ca-b35ac3fecd8a d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8e57b307-c36c-482b-8e47-7e8e94c4809b
2022-02-23 09:12:26.521 7 INFO os_brick.initiator.connectors.lightos [req-be26db0a-512b-4d6d-a448-752c7b00ce4c d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: connect_volume called for volume ed4e80a6-120e-4a23-bdb7-6b174d64ed30, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ed4e80a6-120e-4a23-bdb7-6b174d64ed30', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:12:26.522 7 INFO os_brick.initiator.connectors.lightos [req-be26db0a-512b-4d6d-a448-752c7b00ce4c d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid ed4e80a6-120e-4a23-bdb7-6b174d64ed30
2022-02-23 09:12:27.677 7 INFO nova.compute.manager [req-6d2a7a31-1fb0-428f-bab3-cd9576d3ac2d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Detaching volume e3e7ec8f-bd83-423f-8367-32ec0abb7935
2022-02-23 09:12:27.740 7 INFO nova.virt.block_device [req-6d2a7a31-1fb0-428f-bab3-cd9576d3ac2d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Attempting to driver detach volume e3e7ec8f-bd83-423f-8367-32ec0abb7935 from mountpoint /dev/vdb
2022-02-23 09:12:27.758 7 INFO nova.virt.libvirt.driver [req-6d2a7a31-1fb0-428f-bab3-cd9576d3ac2d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Successfully detached device vdb from instance fbba98af-9f01-4de5-923d-a0cc4aa51490 from the persistent domain config.
2022-02-23 09:12:27.899 7 INFO nova.virt.libvirt.driver [req-6d2a7a31-1fb0-428f-bab3-cd9576d3ac2d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Successfully detached device vdb from instance fbba98af-9f01-4de5-923d-a0cc4aa51490 from the live domain config.
2022-02-23 09:12:27.971 7 INFO nova.virt.libvirt.driver [req-6d2a7a31-1fb0-428f-bab3-cd9576d3ac2d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Detected multiple connections on this host for volume: e3e7ec8f-bd83-423f-8367-32ec0abb7935, skipping target disconnect.
2022-02-23 09:12:28.625 7 INFO nova.compute.claims [req-c82c5516-3f2a-4e3d-b685-2c750d79446f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Claim successful on node rack08-server63
2022-02-23 09:12:29.004 7 INFO nova.virt.libvirt.driver [req-c82c5516-3f2a-4e3d-b685-2c750d79446f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Creating image
2022-02-23 09:12:30.160 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] VM Resumed (Lifecycle Event)
2022-02-23 09:12:30.168 7 INFO nova.virt.libvirt.driver [-] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Instance spawned successfully.
2022-02-23 09:12:30.174 7 INFO nova.compute.manager [req-531ddb4e-94f6-4912-a6bf-fb6c86f31cb2 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Detaching volume e3e7ec8f-bd83-423f-8367-32ec0abb7935
2022-02-23 09:12:30.230 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:30.230 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] VM Started (Lifecycle Event)
2022-02-23 09:12:30.234 7 INFO nova.virt.block_device [req-531ddb4e-94f6-4912-a6bf-fb6c86f31cb2 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Attempting to driver detach volume e3e7ec8f-bd83-423f-8367-32ec0abb7935 from mountpoint /dev/vdb
2022-02-23 09:12:30.254 7 INFO nova.virt.libvirt.driver [req-531ddb4e-94f6-4912-a6bf-fb6c86f31cb2 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Successfully detached device vdb from instance 69c066ff-2eed-410b-aa49-606ebf7589cb from the persistent domain config.
2022-02-23 09:12:30.278 7 INFO nova.compute.manager [req-c82c5516-3f2a-4e3d-b685-2c750d79446f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-23 09:12:30.283 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:12:30.361 7 INFO nova.compute.manager [req-c82c5516-3f2a-4e3d-b685-2c750d79446f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Took 1.78 seconds to build instance.
2022-02-23 09:12:30.448 7 INFO nova.virt.libvirt.driver [req-531ddb4e-94f6-4912-a6bf-fb6c86f31cb2 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Successfully detached device vdb from instance 69c066ff-2eed-410b-aa49-606ebf7589cb from the live domain config.
2022-02-23 09:12:33.184 7 INFO nova.compute.manager [req-f93d9f41-0e4b-41f2-aee1-6e110406be30 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Attaching volume 7c0e6c90-797f-43a6-9611-20298269fb3d to /dev/vdb
2022-02-23 09:12:33.275 7 WARNING os_brick.initiator.connectors.nvmeof [req-f93d9f41-0e4b-41f2-aee1-6e110406be30 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:13:30.945 7 INFO os_brick.initiator.connectors.lightos [req-f93d9f41-0e4b-41f2-aee1-6e110406be30 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: connect_volume called for volume 05bf12bc-545f-4b3a-9546-531ff70ae192, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '05bf12bc-545f-4b3a-9546-531ff70ae192', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:13:30.949 7 INFO os_brick.initiator.connectors.lightos [req-f93d9f41-0e4b-41f2-aee1-6e110406be30 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 05bf12bc-545f-4b3a-9546-531ff70ae192
2022-02-23 09:13:32.002 7 INFO nova.compute.manager [req-0de48bdf-9f8a-4483-8d2a-4eaabc720e96 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Detaching volume 7c0e6c90-797f-43a6-9611-20298269fb3d
2022-02-23 09:13:32.061 7 INFO nova.virt.block_device [req-0de48bdf-9f8a-4483-8d2a-4eaabc720e96 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Attempting to driver detach volume 7c0e6c90-797f-43a6-9611-20298269fb3d from mountpoint /dev/vdb
2022-02-23 09:13:32.079 7 INFO nova.virt.libvirt.driver [req-0de48bdf-9f8a-4483-8d2a-4eaabc720e96 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance 6ea77cb0-4370-4eab-959b-6125ed27f1ae from the persistent domain config.
2022-02-23 09:13:32.222 7 INFO nova.virt.libvirt.driver [req-0de48bdf-9f8a-4483-8d2a-4eaabc720e96 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Successfully detached device vdb from instance 6ea77cb0-4370-4eab-959b-6125ed27f1ae from the live domain config.
2022-02-23 09:13:32.227 7 INFO os_brick.initiator.connectors.lightos [req-0de48bdf-9f8a-4483-8d2a-4eaabc720e96 d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 05bf12bc-545f-4b3a-9546-531ff70ae192
2022-02-23 09:13:35.458 7 INFO nova.compute.manager [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Terminating instance
2022-02-23 09:13:35.817 7 INFO nova.virt.libvirt.driver [-] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Instance destroyed successfully.
2022-02-23 09:13:35.832 7 INFO nova.virt.libvirt.driver [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Deleting instance files /var/lib/nova/instances/6ea77cb0-4370-4eab-959b-6125ed27f1ae_del
2022-02-23 09:13:35.834 7 INFO nova.virt.libvirt.driver [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Deletion of /var/lib/nova/instances/6ea77cb0-4370-4eab-959b-6125ed27f1ae_del complete
2022-02-23 09:13:35.906 7 INFO nova.virt.libvirt.host [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] UEFI support detected
2022-02-23 09:13:35.909 7 INFO nova.compute.manager [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:35.979 7 INFO nova.compute.manager [-] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:13:36.180 7 INFO nova.scheduler.client.report [req-10f7f826-fa97-4c76-aa4a-7d6cb001790d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Deleted allocations for instance 6ea77cb0-4370-4eab-959b-6125ed27f1ae
2022-02-23 09:13:37.867 7 INFO nova.compute.manager [req-c5256ce4-5ae0-4dd3-b0d0-0de657ecbbdd d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Terminating instance
2022-02-23 09:13:38.210 7 INFO nova.virt.libvirt.driver [-] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Instance destroyed successfully.
2022-02-23 09:13:38.225 7 INFO nova.virt.libvirt.driver [req-c5256ce4-5ae0-4dd3-b0d0-0de657ecbbdd d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Deleting instance files /var/lib/nova/instances/40ee0705-040f-471e-9983-02974f98f6c3_del
2022-02-23 09:13:38.227 7 INFO nova.virt.libvirt.driver [req-c5256ce4-5ae0-4dd3-b0d0-0de657ecbbdd d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Deletion of /var/lib/nova/instances/40ee0705-040f-471e-9983-02974f98f6c3_del complete
2022-02-23 09:13:38.296 7 INFO nova.compute.manager [req-c5256ce4-5ae0-4dd3-b0d0-0de657ecbbdd d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:38.364 7 INFO nova.compute.manager [-] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:13:38.562 7 INFO nova.scheduler.client.report [req-c5256ce4-5ae0-4dd3-b0d0-0de657ecbbdd d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Deleted allocations for instance 40ee0705-040f-471e-9983-02974f98f6c3
2022-02-23 09:13:39.125 7 INFO nova.compute.manager [req-4cc13a5e-a84c-40ad-91a3-4048700d8d0f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Terminating instance
2022-02-23 09:13:39.471 7 INFO nova.virt.libvirt.driver [-] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Instance destroyed successfully.
2022-02-23 09:13:39.487 7 INFO nova.virt.libvirt.driver [req-4cc13a5e-a84c-40ad-91a3-4048700d8d0f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Deleting instance files /var/lib/nova/instances/efae4567-f596-4bb6-92a0-1c612a12a5a1_del
2022-02-23 09:13:39.489 7 INFO nova.virt.libvirt.driver [req-4cc13a5e-a84c-40ad-91a3-4048700d8d0f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Deletion of /var/lib/nova/instances/efae4567-f596-4bb6-92a0-1c612a12a5a1_del complete
2022-02-23 09:13:39.557 7 INFO nova.compute.manager [req-4cc13a5e-a84c-40ad-91a3-4048700d8d0f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:39.624 7 INFO nova.compute.manager [-] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:13:39.830 7 INFO nova.scheduler.client.report [req-4cc13a5e-a84c-40ad-91a3-4048700d8d0f d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Deleted allocations for instance efae4567-f596-4bb6-92a0-1c612a12a5a1
2022-02-23 09:13:41.535 7 INFO nova.compute.manager [req-2ad7b50c-9a00-4273-ba32-02afe6e4265d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Terminating instance
2022-02-23 09:13:41.891 7 INFO nova.virt.libvirt.driver [-] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Instance destroyed successfully.
2022-02-23 09:13:41.907 7 INFO nova.virt.libvirt.driver [req-2ad7b50c-9a00-4273-ba32-02afe6e4265d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Deleting instance files /var/lib/nova/instances/a7a70a7c-4806-4016-ba3c-9f61bd0911f5_del
2022-02-23 09:13:41.908 7 INFO nova.virt.libvirt.driver [req-2ad7b50c-9a00-4273-ba32-02afe6e4265d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Deletion of /var/lib/nova/instances/a7a70a7c-4806-4016-ba3c-9f61bd0911f5_del complete
2022-02-23 09:13:41.986 7 INFO nova.compute.manager [req-2ad7b50c-9a00-4273-ba32-02afe6e4265d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:42.060 7 INFO nova.compute.manager [-] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:13:42.257 7 INFO nova.scheduler.client.report [req-2ad7b50c-9a00-4273-ba32-02afe6e4265d d98380344b3e4590b246468890e13251 61c3a54345cc46b8bbc1458c88371a4e - default default] Deleted allocations for instance a7a70a7c-4806-4016-ba3c-9f61bd0911f5
2022-02-23 09:13:49.570 7 INFO nova.compute.claims [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Claim successful on node rack08-server63
2022-02-23 09:13:49.833 7 INFO nova.virt.libvirt.driver [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 09:13:49.920 7 INFO nova.virt.block_device [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Booting with volume 675109a9-03ba-4e0e-ab17-12b3165ad0f8 at /dev/vda
2022-02-23 09:13:50.007 7 WARNING os_brick.initiator.connectors.nvmeof [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:13:50.814 7 INFO nova.compute.manager [-] [instance: 6ea77cb0-4370-4eab-959b-6125ed27f1ae] VM Stopped (Lifecycle Event)
2022-02-23 09:13:51.446 7 INFO nova.virt.libvirt.driver [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Creating image
2022-02-23 09:13:51.459 7 INFO os_brick.initiator.connectors.lightos [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: connect_volume called for volume 5c4ebd3b-4f2a-4e9e-8432-9495fffc316f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5c4ebd3b-4f2a-4e9e-8432-9495fffc316f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:13:51.462 7 INFO os_brick.initiator.connectors.lightos [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5c4ebd3b-4f2a-4e9e-8432-9495fffc316f
2022-02-23 09:13:52.270 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] VM Resumed (Lifecycle Event)
2022-02-23 09:13:52.277 7 INFO nova.virt.libvirt.driver [-] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Instance spawned successfully.
2022-02-23 09:13:52.333 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:13:52.334 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] VM Started (Lifecycle Event)
2022-02-23 09:13:52.380 7 INFO nova.compute.manager [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Took 0.94 seconds to spawn the instance on the hypervisor.
2022-02-23 09:13:52.385 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:13:52.459 7 INFO nova.compute.manager [req-e01bbebd-5b61-4622-8442-b585c2342b1e d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Took 2.93 seconds to build instance.
2022-02-23 09:13:53.207 7 INFO nova.compute.manager [-] [instance: 40ee0705-040f-471e-9983-02974f98f6c3] VM Stopped (Lifecycle Event)
2022-02-23 09:13:53.785 7 INFO nova.compute.manager [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Terminating instance
2022-02-23 09:13:54.120 7 INFO nova.virt.libvirt.driver [-] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Instance destroyed successfully.
2022-02-23 09:13:54.187 7 INFO os_brick.initiator.connectors.lightos [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5c4ebd3b-4f2a-4e9e-8432-9495fffc316f
2022-02-23 09:13:54.199 7 INFO nova.virt.libvirt.driver [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Deleting instance files /var/lib/nova/instances/d0a95f8f-2ad2-4f72-9896-d062963407ee_del
2022-02-23 09:13:54.200 7 INFO nova.virt.libvirt.driver [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Deletion of /var/lib/nova/instances/d0a95f8f-2ad2-4f72-9896-d062963407ee_del complete
2022-02-23 09:13:54.266 7 INFO nova.compute.manager [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:54.325 7 INFO nova.compute.manager [-] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Took 0.06 seconds to deallocate network for instance.
2022-02-23 09:13:54.468 7 INFO nova.compute.manager [-] [instance: efae4567-f596-4bb6-92a0-1c612a12a5a1] VM Stopped (Lifecycle Event)
2022-02-23 09:13:55.520 7 INFO nova.compute.manager [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] Took 1.19 seconds to detach 1 volumes for instance.
2022-02-23 09:13:55.722 7 INFO nova.scheduler.client.report [req-3a7b4dfe-fc70-4a98-ada7-503e3127f230 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Deleted allocations for instance d0a95f8f-2ad2-4f72-9896-d062963407ee
2022-02-23 09:13:56.888 7 INFO nova.compute.manager [-] [instance: a7a70a7c-4806-4016-ba3c-9f61bd0911f5] VM Stopped (Lifecycle Event)
2022-02-23 09:13:58.770 7 INFO nova.compute.manager [req-1d833f97-9eb6-4f4f-a26e-f219ec49e14a d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Terminating instance
2022-02-23 09:13:59.122 7 INFO nova.virt.libvirt.driver [-] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Instance destroyed successfully.
2022-02-23 09:13:59.142 7 INFO nova.virt.libvirt.driver [req-1d833f97-9eb6-4f4f-a26e-f219ec49e14a d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Deleting instance files /var/lib/nova/instances/69c066ff-2eed-410b-aa49-606ebf7589cb_del
2022-02-23 09:13:59.144 7 INFO nova.virt.libvirt.driver [req-1d833f97-9eb6-4f4f-a26e-f219ec49e14a d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Deletion of /var/lib/nova/instances/69c066ff-2eed-410b-aa49-606ebf7589cb_del complete
2022-02-23 09:13:59.215 7 INFO nova.compute.manager [req-1d833f97-9eb6-4f4f-a26e-f219ec49e14a d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:13:59.281 7 INFO nova.compute.manager [-] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:13:59.446 7 INFO nova.scheduler.client.report [req-1d833f97-9eb6-4f4f-a26e-f219ec49e14a d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Deleted allocations for instance 69c066ff-2eed-410b-aa49-606ebf7589cb
2022-02-23 09:14:00.027 7 INFO nova.compute.manager [req-094c363f-1ff0-4b13-b093-ff989aaaeb9d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Terminating instance
2022-02-23 09:14:00.367 7 INFO nova.virt.libvirt.driver [-] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Instance destroyed successfully.
2022-02-23 09:14:00.382 7 INFO nova.virt.libvirt.driver [req-094c363f-1ff0-4b13-b093-ff989aaaeb9d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Deleting instance files /var/lib/nova/instances/fbba98af-9f01-4de5-923d-a0cc4aa51490_del
2022-02-23 09:14:00.384 7 INFO nova.virt.libvirt.driver [req-094c363f-1ff0-4b13-b093-ff989aaaeb9d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Deletion of /var/lib/nova/instances/fbba98af-9f01-4de5-923d-a0cc4aa51490_del complete
2022-02-23 09:14:00.451 7 INFO nova.compute.manager [req-094c363f-1ff0-4b13-b093-ff989aaaeb9d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:14:00.521 7 INFO nova.compute.manager [-] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:14:00.710 7 INFO nova.scheduler.client.report [req-094c363f-1ff0-4b13-b093-ff989aaaeb9d d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Deleted allocations for instance fbba98af-9f01-4de5-923d-a0cc4aa51490
2022-02-23 09:14:01.279 7 INFO nova.compute.manager [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Terminating instance
2022-02-23 09:14:01.614 7 INFO nova.virt.libvirt.driver [-] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Instance destroyed successfully.
2022-02-23 09:14:01.684 7 INFO os_brick.initiator.connectors.lightos [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid c5d882fd-4263-4ef9-9802-3a3e7d14604d
2022-02-23 09:14:01.696 7 INFO nova.virt.libvirt.driver [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Deleting instance files /var/lib/nova/instances/27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9_del
2022-02-23 09:14:01.697 7 INFO nova.virt.libvirt.driver [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Deletion of /var/lib/nova/instances/27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9_del complete
2022-02-23 09:14:01.775 7 INFO nova.compute.manager [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-23 09:14:01.845 7 INFO nova.compute.manager [-] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:14:03.027 7 INFO nova.compute.manager [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] Took 1.18 seconds to detach 1 volumes for instance.
2022-02-23 09:14:03.208 7 INFO nova.scheduler.client.report [req-7f85a5da-2e09-4b1c-acf1-849b5c40c184 d29bc4339b3b4615b70bcf065dc40cab 85608b3161054a19a69dd39876180f2f - default default] Deleted allocations for instance 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9
2022-02-23 09:14:09.118 7 INFO nova.compute.manager [-] [instance: d0a95f8f-2ad2-4f72-9896-d062963407ee] VM Stopped (Lifecycle Event)
2022-02-23 09:14:14.120 7 INFO nova.compute.manager [-] [instance: 69c066ff-2eed-410b-aa49-606ebf7589cb] VM Stopped (Lifecycle Event)
2022-02-23 09:14:15.364 7 INFO nova.compute.manager [-] [instance: fbba98af-9f01-4de5-923d-a0cc4aa51490] VM Stopped (Lifecycle Event)
2022-02-23 09:14:16.612 7 INFO nova.compute.manager [-] [instance: 27dbe1d3-68fb-44cd-ad8f-950e23cfa1b9] VM Stopped (Lifecycle Event)
2022-02-23 09:14:34.498 7 INFO nova.compute.claims [req-b06c7e7e-8e69-42c3-8870-2c33246487cb c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Claim successful on node rack08-server63
2022-02-23 09:14:34.890 7 INFO nova.virt.libvirt.driver [req-b06c7e7e-8e69-42c3-8870-2c33246487cb c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Creating image
2022-02-23 09:14:36.103 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] VM Resumed (Lifecycle Event)
2022-02-23 09:14:36.112 7 INFO nova.virt.libvirt.driver [-] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Instance spawned successfully.
2022-02-23 09:14:36.162 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:14:36.163 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] VM Started (Lifecycle Event)
2022-02-23 09:14:36.213 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:14:36.224 7 INFO nova.compute.manager [req-b06c7e7e-8e69-42c3-8870-2c33246487cb c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Took 1.33 seconds to spawn the instance on the hypervisor.
2022-02-23 09:14:36.311 7 INFO nova.compute.manager [req-b06c7e7e-8e69-42c3-8870-2c33246487cb c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Took 1.85 seconds to build instance.
2022-02-23 09:14:37.868 7 INFO nova.compute.manager [req-d72bfd6c-e85d-4e6b-bcc4-cbc7ad47cb30 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Terminating instance
2022-02-23 09:14:38.209 7 INFO nova.virt.libvirt.driver [-] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Instance destroyed successfully.
2022-02-23 09:14:38.227 7 INFO nova.virt.libvirt.driver [req-d72bfd6c-e85d-4e6b-bcc4-cbc7ad47cb30 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Deleting instance files /var/lib/nova/instances/39f5e86a-eee3-4177-a952-330d7cdae9b0_del
2022-02-23 09:14:38.228 7 INFO nova.virt.libvirt.driver [req-d72bfd6c-e85d-4e6b-bcc4-cbc7ad47cb30 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Deletion of /var/lib/nova/instances/39f5e86a-eee3-4177-a952-330d7cdae9b0_del complete
2022-02-23 09:14:38.298 7 INFO nova.compute.manager [req-d72bfd6c-e85d-4e6b-bcc4-cbc7ad47cb30 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:14:38.363 7 INFO nova.compute.manager [-] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] Took 0.06 seconds to deallocate network for instance.
2022-02-23 09:14:38.564 7 INFO nova.scheduler.client.report [req-d72bfd6c-e85d-4e6b-bcc4-cbc7ad47cb30 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] Deleted allocations for instance 39f5e86a-eee3-4177-a952-330d7cdae9b0
2022-02-23 09:14:40.173 7 INFO nova.compute.claims [req-fd95cee1-876a-4df4-9315-29053f912802 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Claim successful on node rack08-server63
2022-02-23 09:14:40.561 7 INFO nova.virt.libvirt.driver [req-fd95cee1-876a-4df4-9315-29053f912802 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Creating image
2022-02-23 09:14:41.698 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] VM Resumed (Lifecycle Event)
2022-02-23 09:14:41.706 7 INFO nova.virt.libvirt.driver [-] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Instance spawned successfully.
2022-02-23 09:14:41.757 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:14:41.758 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] VM Started (Lifecycle Event)
2022-02-23 09:14:41.806 7 INFO nova.compute.manager [req-fd95cee1-876a-4df4-9315-29053f912802 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-23 09:14:41.817 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:14:41.887 7 INFO nova.compute.manager [req-fd95cee1-876a-4df4-9315-29053f912802 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Took 1.75 seconds to build instance.
2022-02-23 09:14:42.501 7 INFO nova.compute.manager [req-2cdf2467-68e0-49ca-92c7-8098584d3bc6 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Terminating instance
2022-02-23 09:14:42.844 7 INFO nova.virt.libvirt.driver [-] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Instance destroyed successfully.
2022-02-23 09:14:42.860 7 INFO nova.virt.libvirt.driver [req-2cdf2467-68e0-49ca-92c7-8098584d3bc6 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Deleting instance files /var/lib/nova/instances/9d5118ed-00e0-4c4a-ac95-e6954785ec2f_del
2022-02-23 09:14:42.861 7 INFO nova.virt.libvirt.driver [req-2cdf2467-68e0-49ca-92c7-8098584d3bc6 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Deletion of /var/lib/nova/instances/9d5118ed-00e0-4c4a-ac95-e6954785ec2f_del complete
2022-02-23 09:14:42.928 7 INFO nova.compute.manager [req-2cdf2467-68e0-49ca-92c7-8098584d3bc6 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:14:43.005 7 INFO nova.compute.manager [-] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] Took 0.08 seconds to deallocate network for instance.
2022-02-23 09:14:43.197 7 INFO nova.scheduler.client.report [req-2cdf2467-68e0-49ca-92c7-8098584d3bc6 c8abd086c79b4bca87a8084ef2a7bd47 e847c2f8292e4e4db8f7bfbe64d4ff5a - default default] Deleted allocations for instance 9d5118ed-00e0-4c4a-ac95-e6954785ec2f
2022-02-23 09:14:53.208 7 INFO nova.compute.manager [-] [instance: 39f5e86a-eee3-4177-a952-330d7cdae9b0] VM Stopped (Lifecycle Event)
2022-02-23 09:14:57.842 7 INFO nova.compute.manager [-] [instance: 9d5118ed-00e0-4c4a-ac95-e6954785ec2f] VM Stopped (Lifecycle Event)
2022-02-23 09:15:31.321 7 INFO nova.compute.claims [req-2b512462-7b83-4d9e-9edf-7bf86cae3884 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Claim successful on node rack08-server63
2022-02-23 09:15:31.752 7 INFO nova.virt.libvirt.driver [req-2b512462-7b83-4d9e-9edf-7bf86cae3884 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Creating image
2022-02-23 09:15:33.032 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] VM Resumed (Lifecycle Event)
2022-02-23 09:15:33.040 7 INFO nova.virt.libvirt.driver [-] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Instance spawned successfully.
2022-02-23 09:15:33.096 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:15:33.097 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] VM Started (Lifecycle Event)
2022-02-23 09:15:33.149 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:15:33.153 7 INFO nova.compute.manager [req-2b512462-7b83-4d9e-9edf-7bf86cae3884 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Took 1.40 seconds to spawn the instance on the hypervisor.
2022-02-23 09:15:33.235 7 INFO nova.compute.manager [req-2b512462-7b83-4d9e-9edf-7bf86cae3884 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Took 1.96 seconds to build instance.
2022-02-23 09:15:38.765 7 INFO nova.compute.manager [req-6252496d-48a4-4d97-900f-15cc4ba887ae 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Terminating instance
2022-02-23 09:15:39.114 7 INFO nova.virt.libvirt.driver [-] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Instance destroyed successfully.
2022-02-23 09:15:39.128 7 INFO nova.virt.libvirt.driver [req-6252496d-48a4-4d97-900f-15cc4ba887ae 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Deleting instance files /var/lib/nova/instances/178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4_del
2022-02-23 09:15:39.130 7 INFO nova.virt.libvirt.driver [req-6252496d-48a4-4d97-900f-15cc4ba887ae 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Deletion of /var/lib/nova/instances/178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4_del complete
2022-02-23 09:15:39.205 7 INFO nova.compute.manager [req-6252496d-48a4-4d97-900f-15cc4ba887ae 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:15:39.282 7 INFO nova.compute.manager [-] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] Took 0.08 seconds to deallocate network for instance.
2022-02-23 09:15:39.486 7 INFO nova.scheduler.client.report [req-6252496d-48a4-4d97-900f-15cc4ba887ae 772f608ee87145acb65975329c965aff 868f9cc9fc024264b21f062d29a5e181 - default default] Deleted allocations for instance 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4
2022-02-23 09:15:51.741 7 INFO nova.compute.claims [req-e16a4c9d-4633-46a8-826b-1e129d7df7d8 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Claim successful on node rack08-server63
2022-02-23 09:15:52.145 7 INFO nova.virt.libvirt.driver [req-e16a4c9d-4633-46a8-826b-1e129d7df7d8 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Creating image
2022-02-23 09:15:53.364 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] VM Resumed (Lifecycle Event)
2022-02-23 09:15:53.372 7 INFO nova.virt.libvirt.driver [-] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Instance spawned successfully.
2022-02-23 09:15:53.422 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:15:53.422 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] VM Started (Lifecycle Event)
2022-02-23 09:15:53.476 7 INFO nova.compute.manager [req-e16a4c9d-4633-46a8-826b-1e129d7df7d8 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Took 1.33 seconds to spawn the instance on the hypervisor.
2022-02-23 09:15:53.478 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:15:53.561 7 INFO nova.compute.manager [req-e16a4c9d-4633-46a8-826b-1e129d7df7d8 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Took 1.86 seconds to build instance.
2022-02-23 09:15:54.111 7 INFO nova.compute.manager [-] [instance: 178a0c5a-5daf-46f3-a7cb-d7d6c50ec7e4] VM Stopped (Lifecycle Event)
2022-02-23 09:16:10.515 7 INFO nova.virt.libvirt.driver [req-3606c6cd-1ca6-4423-b7f7-40308f379d44 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Ignoring supplied device name: /dev/vdb
2022-02-23 09:16:10.674 7 INFO nova.compute.manager [req-3606c6cd-1ca6-4423-b7f7-40308f379d44 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Attaching volume 32d2c231-dbab-4a8e-9d6a-b20a6024de90 to /dev/vdb
2022-02-23 09:16:10.772 7 WARNING os_brick.initiator.connectors.nvmeof [req-3606c6cd-1ca6-4423-b7f7-40308f379d44 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:16:12.067 7 INFO os_brick.initiator.connectors.lightos [req-3606c6cd-1ca6-4423-b7f7-40308f379d44 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: connect_volume called for volume cc56f8ee-c895-4645-80d1-0e1613064923, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'cc56f8ee-c895-4645-80d1-0e1613064923', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:16:12.071 7 INFO os_brick.initiator.connectors.lightos [req-3606c6cd-1ca6-4423-b7f7-40308f379d44 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid cc56f8ee-c895-4645-80d1-0e1613064923
2022-02-23 09:16:23.625 7 INFO nova.compute.manager [req-84233043-9240-4483-84c9-3d35f64bd0f0 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Detaching volume 32d2c231-dbab-4a8e-9d6a-b20a6024de90
2022-02-23 09:16:23.683 7 INFO nova.virt.block_device [req-84233043-9240-4483-84c9-3d35f64bd0f0 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Attempting to driver detach volume 32d2c231-dbab-4a8e-9d6a-b20a6024de90 from mountpoint /dev/vdb
2022-02-23 09:16:23.705 7 INFO nova.virt.libvirt.driver [req-84233043-9240-4483-84c9-3d35f64bd0f0 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Successfully detached device vdb from instance bf065cd9-eeab-4598-b7ab-5de08a4ce4df from the persistent domain config.
2022-02-23 09:16:23.857 7 INFO nova.virt.libvirt.driver [req-84233043-9240-4483-84c9-3d35f64bd0f0 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Successfully detached device vdb from instance bf065cd9-eeab-4598-b7ab-5de08a4ce4df from the live domain config.
2022-02-23 09:16:23.860 7 INFO os_brick.initiator.connectors.lightos [req-84233043-9240-4483-84c9-3d35f64bd0f0 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid cc56f8ee-c895-4645-80d1-0e1613064923
2022-02-23 09:16:25.898 7 INFO nova.compute.manager [req-be80385c-f470-4514-9634-c8773f1916d7 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Terminating instance
2022-02-23 09:16:26.253 7 INFO nova.virt.libvirt.driver [-] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Instance destroyed successfully.
2022-02-23 09:16:26.268 7 INFO nova.virt.libvirt.driver [req-be80385c-f470-4514-9634-c8773f1916d7 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Deleting instance files /var/lib/nova/instances/bf065cd9-eeab-4598-b7ab-5de08a4ce4df_del
2022-02-23 09:16:26.269 7 INFO nova.virt.libvirt.driver [req-be80385c-f470-4514-9634-c8773f1916d7 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Deletion of /var/lib/nova/instances/bf065cd9-eeab-4598-b7ab-5de08a4ce4df_del complete
2022-02-23 09:16:26.336 7 INFO nova.compute.manager [req-be80385c-f470-4514-9634-c8773f1916d7 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 09:16:26.404 7 INFO nova.compute.manager [-] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:16:26.600 7 INFO nova.scheduler.client.report [req-be80385c-f470-4514-9634-c8773f1916d7 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Deleted allocations for instance bf065cd9-eeab-4598-b7ab-5de08a4ce4df
2022-02-23 09:16:34.035 7 INFO nova.compute.claims [req-85d3798f-511a-45c5-ac18-62b63211f5f6 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Claim successful on node rack08-server63
2022-02-23 09:16:34.471 7 INFO nova.virt.libvirt.driver [req-85d3798f-511a-45c5-ac18-62b63211f5f6 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Creating image
2022-02-23 09:16:35.626 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] VM Resumed (Lifecycle Event)
2022-02-23 09:16:35.634 7 INFO nova.virt.libvirt.driver [-] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Instance spawned successfully.
2022-02-23 09:16:35.694 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:16:35.695 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] VM Started (Lifecycle Event)
2022-02-23 09:16:35.740 7 INFO nova.compute.manager [req-85d3798f-511a-45c5-ac18-62b63211f5f6 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-23 09:16:35.751 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:16:35.826 7 INFO nova.compute.manager [req-85d3798f-511a-45c5-ac18-62b63211f5f6 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Took 1.83 seconds to build instance.
2022-02-23 09:16:37.112 7 INFO nova.virt.libvirt.driver [req-d5cd284f-debe-4401-a73f-0db5bb53b03f 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Ignoring supplied device name: /dev/vdb
2022-02-23 09:16:37.262 7 INFO nova.compute.manager [req-d5cd284f-debe-4401-a73f-0db5bb53b03f 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Attaching volume 2f351094-bef5-429e-99eb-d2b4c3d93b91 to /dev/vdb
2022-02-23 09:16:37.344 7 WARNING os_brick.initiator.connectors.nvmeof [req-d5cd284f-debe-4401-a73f-0db5bb53b03f 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:16:38.632 7 INFO os_brick.initiator.connectors.lightos [req-d5cd284f-debe-4401-a73f-0db5bb53b03f 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: connect_volume called for volume 6e7ada37-a892-49c6-97b3-0b79fb6dbfbb, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6e7ada37-a892-49c6-97b3-0b79fb6dbfbb', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:16:38.636 7 INFO os_brick.initiator.connectors.lightos [req-d5cd284f-debe-4401-a73f-0db5bb53b03f 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6e7ada37-a892-49c6-97b3-0b79fb6dbfbb
2022-02-23 09:16:41.251 7 INFO nova.compute.manager [-] [instance: bf065cd9-eeab-4598-b7ab-5de08a4ce4df] VM Stopped (Lifecycle Event)
2022-02-23 09:16:47.554 7 INFO nova.compute.manager [req-f98d86e6-9f6c-4b45-ae89-d1c7eea90e04 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Detaching volume 2f351094-bef5-429e-99eb-d2b4c3d93b91
2022-02-23 09:16:47.620 7 INFO nova.virt.block_device [req-f98d86e6-9f6c-4b45-ae89-d1c7eea90e04 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Attempting to driver detach volume 2f351094-bef5-429e-99eb-d2b4c3d93b91 from mountpoint /dev/vdb
2022-02-23 09:16:47.639 7 INFO nova.virt.libvirt.driver [req-f98d86e6-9f6c-4b45-ae89-d1c7eea90e04 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Successfully detached device vdb from instance 21252e29-d796-438c-b37a-0a0f1f9389ea from the persistent domain config.
2022-02-23 09:16:47.784 7 INFO nova.virt.libvirt.driver [req-f98d86e6-9f6c-4b45-ae89-d1c7eea90e04 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Successfully detached device vdb from instance 21252e29-d796-438c-b37a-0a0f1f9389ea from the live domain config.
2022-02-23 09:16:47.787 7 INFO os_brick.initiator.connectors.lightos [req-f98d86e6-9f6c-4b45-ae89-d1c7eea90e04 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6e7ada37-a892-49c6-97b3-0b79fb6dbfbb
2022-02-23 09:16:49.353 7 INFO nova.compute.claims [req-bf9d0b6f-af62-4fa5-bc4f-a215892efd54 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Claim successful on node rack08-server63
2022-02-23 09:16:49.746 7 INFO nova.virt.libvirt.driver [req-bf9d0b6f-af62-4fa5-bc4f-a215892efd54 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Creating image
2022-02-23 09:16:49.813 7 INFO nova.compute.manager [req-51c50791-0b7b-4345-88b9-0ad488fbeba9 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Terminating instance
2022-02-23 09:16:50.180 7 INFO nova.virt.libvirt.driver [-] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Instance destroyed successfully.
2022-02-23 09:16:50.197 7 INFO nova.virt.libvirt.driver [req-51c50791-0b7b-4345-88b9-0ad488fbeba9 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Deleting instance files /var/lib/nova/instances/21252e29-d796-438c-b37a-0a0f1f9389ea_del
2022-02-23 09:16:50.198 7 INFO nova.virt.libvirt.driver [req-51c50791-0b7b-4345-88b9-0ad488fbeba9 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Deletion of /var/lib/nova/instances/21252e29-d796-438c-b37a-0a0f1f9389ea_del complete
2022-02-23 09:16:50.273 7 INFO nova.compute.manager [req-51c50791-0b7b-4345-88b9-0ad488fbeba9 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-23 09:16:50.345 7 INFO nova.compute.manager [-] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:16:50.526 7 INFO nova.scheduler.client.report [req-51c50791-0b7b-4345-88b9-0ad488fbeba9 1952cdcb6f8a461f8e313682b00953d5 85f8627203394049ac4ceabb5b6d5840 - default default] Deleted allocations for instance 21252e29-d796-438c-b37a-0a0f1f9389ea
2022-02-23 09:16:50.980 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] VM Resumed (Lifecycle Event)
2022-02-23 09:16:50.987 7 INFO nova.virt.libvirt.driver [-] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Instance spawned successfully.
2022-02-23 09:16:51.047 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:16:51.048 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] VM Started (Lifecycle Event)
2022-02-23 09:16:51.090 7 INFO nova.compute.manager [req-bf9d0b6f-af62-4fa5-bc4f-a215892efd54 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Took 1.35 seconds to spawn the instance on the hypervisor.
2022-02-23 09:16:51.101 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:16:51.170 7 INFO nova.compute.manager [req-bf9d0b6f-af62-4fa5-bc4f-a215892efd54 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Took 1.86 seconds to build instance.
2022-02-23 09:16:52.425 7 INFO nova.virt.libvirt.driver [req-1cfd58a3-3ebc-4a6f-b32b-1b594dc1da4b 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Ignoring supplied device name: /dev/vdb
2022-02-23 09:16:52.596 7 INFO nova.compute.manager [req-1cfd58a3-3ebc-4a6f-b32b-1b594dc1da4b 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Attaching volume b3b47801-9d8d-4ba7-9f75-66ac5a985cd6 to /dev/vdb
2022-02-23 09:16:52.693 7 WARNING os_brick.initiator.connectors.nvmeof [req-1cfd58a3-3ebc-4a6f-b32b-1b594dc1da4b 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 09:16:53.995 7 INFO os_brick.initiator.connectors.lightos [req-1cfd58a3-3ebc-4a6f-b32b-1b594dc1da4b 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] LIGHTOS: connect_volume called for volume ebc7df66-55d5-4666-9f62-53ae2bdec7be, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ebc7df66-55d5-4666-9f62-53ae2bdec7be', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 09:16:54.000 7 INFO os_brick.initiator.connectors.lightos [req-1cfd58a3-3ebc-4a6f-b32b-1b594dc1da4b 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ebc7df66-55d5-4666-9f62-53ae2bdec7be
2022-02-23 09:16:55.841 7 INFO nova.compute.manager [req-a0021fa6-5b31-4338-96d4-fe77544a0b91 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Cinder extended volume b3b47801-9d8d-4ba7-9f75-66ac5a985cd6; extending it to detect new size
2022-02-23 09:16:55.914 7 INFO os_brick.initiator.connectors.lightos [req-a0021fa6-5b31-4338-96d4-fe77544a0b91 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ebc7df66-55d5-4666-9f62-53ae2bdec7be
2022-02-23 09:16:56.640 7 INFO nova.compute.manager [req-f062db8e-fe22-44f4-b6c7-78e406e8f171 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Detaching volume b3b47801-9d8d-4ba7-9f75-66ac5a985cd6
2022-02-23 09:16:56.696 7 INFO nova.virt.block_device [req-f062db8e-fe22-44f4-b6c7-78e406e8f171 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Attempting to driver detach volume b3b47801-9d8d-4ba7-9f75-66ac5a985cd6 from mountpoint /dev/vdb
2022-02-23 09:16:56.721 7 INFO nova.virt.libvirt.driver [req-f062db8e-fe22-44f4-b6c7-78e406e8f171 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] Successfully detached device vdb from instance 29231730-16de-4d06-9b3e-eeb1456a7d5d from the persistent domain config.
2022-02-23 09:16:56.861 7 INFO nova.virt.libvirt.driver [req-f062db8e-fe22-44f4-b6c7-78e406e8f171 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] Successfully detached device vdb from instance 29231730-16de-4d06-9b3e-eeb1456a7d5d from the live domain config.
2022-02-23 09:16:56.864 7 INFO os_brick.initiator.connectors.lightos [req-f062db8e-fe22-44f4-b6c7-78e406e8f171 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ebc7df66-55d5-4666-9f62-53ae2bdec7be
2022-02-23 09:16:58.890 7 INFO nova.compute.manager [req-2ee90391-1d8b-42ce-a74e-44c26a8981c1 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Terminating instance
2022-02-23 09:16:59.229 7 INFO nova.virt.libvirt.driver [-] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Instance destroyed successfully.
2022-02-23 09:16:59.245 7 INFO nova.virt.libvirt.driver [req-2ee90391-1d8b-42ce-a74e-44c26a8981c1 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Deleting instance files /var/lib/nova/instances/29231730-16de-4d06-9b3e-eeb1456a7d5d_del
2022-02-23 09:16:59.246 7 INFO nova.virt.libvirt.driver [req-2ee90391-1d8b-42ce-a74e-44c26a8981c1 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Deletion of /var/lib/nova/instances/29231730-16de-4d06-9b3e-eeb1456a7d5d_del complete
2022-02-23 09:16:59.314 7 INFO nova.compute.manager [req-2ee90391-1d8b-42ce-a74e-44c26a8981c1 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:16:59.377 7 INFO nova.compute.manager [-] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] Took 0.06 seconds to deallocate network for instance.
2022-02-23 09:16:59.551 7 INFO nova.scheduler.client.report [req-2ee90391-1d8b-42ce-a74e-44c26a8981c1 182579b98f554edba52b273e5dad55f7 df05bcb0c44149f58c39be96863d9c19 - default default] Deleted allocations for instance 29231730-16de-4d06-9b3e-eeb1456a7d5d
2022-02-23 09:17:05.177 7 INFO nova.compute.manager [-] [instance: 21252e29-d796-438c-b37a-0a0f1f9389ea] VM Stopped (Lifecycle Event)
2022-02-23 09:17:14.228 7 INFO nova.compute.manager [-] [instance: 29231730-16de-4d06-9b3e-eeb1456a7d5d] VM Stopped (Lifecycle Event)
2022-02-23 09:17:16.290 7 INFO nova.compute.claims [req-6772b5f7-c299-44a3-8662-0ae8e13334b9 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Claim successful on node rack08-server63
2022-02-23 09:17:16.694 7 INFO nova.virt.libvirt.driver [req-6772b5f7-c299-44a3-8662-0ae8e13334b9 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Creating image
2022-02-23 09:17:17.838 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] VM Resumed (Lifecycle Event)
2022-02-23 09:17:17.846 7 INFO nova.virt.libvirt.driver [-] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Instance spawned successfully.
2022-02-23 09:17:17.902 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:17:17.903 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] VM Started (Lifecycle Event)
2022-02-23 09:17:17.954 7 INFO nova.compute.manager [req-72a934d9-264c-4be5-870d-bbe3fbdc40b9 - - - - -] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 09:17:17.960 7 INFO nova.compute.manager [req-6772b5f7-c299-44a3-8662-0ae8e13334b9 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-23 09:17:18.043 7 INFO nova.compute.manager [req-6772b5f7-c299-44a3-8662-0ae8e13334b9 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Took 1.80 seconds to build instance.
2022-02-23 09:17:18.542 7 INFO nova.compute.manager [req-e235e0a6-0990-40e4-b13b-19a99ebfd20e 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Terminating instance
2022-02-23 09:17:18.886 7 INFO nova.virt.libvirt.driver [-] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Instance destroyed successfully.
2022-02-23 09:17:18.903 7 INFO nova.virt.libvirt.driver [req-e235e0a6-0990-40e4-b13b-19a99ebfd20e 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Deleting instance files /var/lib/nova/instances/d09873b3-f87e-4ecc-b2c1-ffc27415017a_del
2022-02-23 09:17:18.904 7 INFO nova.virt.libvirt.driver [req-e235e0a6-0990-40e4-b13b-19a99ebfd20e 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Deletion of /var/lib/nova/instances/d09873b3-f87e-4ecc-b2c1-ffc27415017a_del complete
2022-02-23 09:17:18.976 7 INFO nova.compute.manager [req-e235e0a6-0990-40e4-b13b-19a99ebfd20e 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 09:17:19.046 7 INFO nova.compute.manager [-] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] Took 0.07 seconds to deallocate network for instance.
2022-02-23 09:17:19.249 7 INFO nova.scheduler.client.report [req-e235e0a6-0990-40e4-b13b-19a99ebfd20e 92fc1f6bdc444f029d0d077558c6fdaf c382e9e7df1a40faa369e691451b370e - default default] Deleted allocations for instance d09873b3-f87e-4ecc-b2c1-ffc27415017a
2022-02-23 09:17:33.884 7 INFO nova.compute.manager [-] [instance: d09873b3-f87e-4ecc-b2c1-ffc27415017a] VM Stopped (Lifecycle Event)
