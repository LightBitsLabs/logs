Build Started 22_02_2022_20_53_30
2022-02-22 22:56:07.685 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 22:56:11.663 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 22:56:12.589 7 INFO nova.virt.driver [req-ebdbb499-2559-47b7-822e-85e925732fda - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 22:56:12.979 7 INFO nova.compute.provider_config [req-ebdbb499-2559-47b7-822e-85e925732fda - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 22:56:12.998 7 WARNING oslo_config.cfg [req-ebdbb499-2559-47b7-822e-85e925732fda - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 22:56:13.019 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 22:56:13.032 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 22:56:13.069 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 22:56:13.169 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 22:56:13.185 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 22:56:13.187 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 22:56:13.594 7 INFO nova.compute.manager [req-411d729c-2d9b-4c3a-8efd-1f1e23d635c1 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 22:56:15.400 7 INFO nova.virt.libvirt.host [req-411d729c-2d9b-4c3a-8efd-1f1e23d635c1 - - - - -] kernel doesn't support AMD SEV
2022-02-22 22:57:06.297 7 INFO nova.compute.claims [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Claim successful on node rack08-server63
2022-02-22 22:57:06.699 7 INFO nova.virt.libvirt.driver [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Creating image
2022-02-22 22:57:06.703 7 INFO oslo.privsep.daemon [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpmqtr_k8t/privsep.sock']
2022-02-22 22:57:08.352 7 INFO oslo.privsep.daemon [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Spawned new privsep daemon via rootwrap
2022-02-22 22:57:08.202 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 22:57:08.208 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 22:57:08.213 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 22:57:08.213 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-22 22:57:09.655 7 INFO nova.compute.manager [-] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] VM Resumed (Lifecycle Event)
2022-02-22 22:57:09.663 7 INFO nova.virt.libvirt.driver [-] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Instance spawned successfully.
2022-02-22 22:57:09.664 7 INFO nova.compute.manager [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Took 2.97 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:09.713 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:09.714 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] VM Started (Lifecycle Event)
2022-02-22 22:57:09.749 7 INFO nova.compute.manager [req-763d3755-b976-45fc-bca8-dba159f0d45b fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Took 3.49 seconds to build instance.
2022-02-22 22:57:12.912 7 INFO nova.compute.manager [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Attaching volume 1b1dd0d9-f82e-4e8c-b524-8659b2161229 to /dev/vdb
2022-02-22 22:57:12.989 7 INFO oslo.privsep.daemon [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpicjuwc_j/privsep.sock']
2022-02-22 22:57:13.647 7 INFO oslo.privsep.daemon [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Spawned new privsep daemon via rootwrap
2022-02-22 22:57:13.569 105 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 22:57:13.576 105 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 22:57:13.581 105 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 22:57:13.581 105 INFO oslo.privsep.daemon [-] privsep daemon running as pid 105
2022-02-22 22:57:14.658 7 WARNING os_brick.initiator.connectors.nvmeof [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:15.985 7 INFO os_brick.initiator.connectors.lightos [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: connect_volume called for volume 2b60224e-1bbc-4bca-9a5c-aeb8c459b024, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2b60224e-1bbc-4bca-9a5c-aeb8c459b024', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:57:16.018 7 INFO os_brick.initiator.connectors.lightos [req-446a81f6-6c6b-43b6-a7f1-1a320b2ce39e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2b60224e-1bbc-4bca-9a5c-aeb8c459b024
2022-02-22 22:57:18.618 7 INFO nova.compute.claims [req-4a47750f-3688-4b6f-ab2f-992ee1723ce9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Claim successful on node rack08-server63
2022-02-22 22:57:19.034 7 INFO nova.virt.libvirt.driver [req-4a47750f-3688-4b6f-ab2f-992ee1723ce9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Creating image
2022-02-22 22:57:20.254 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] VM Resumed (Lifecycle Event)
2022-02-22 22:57:20.264 7 INFO nova.virt.libvirt.driver [-] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Instance spawned successfully.
2022-02-22 22:57:20.265 7 INFO nova.compute.manager [req-4a47750f-3688-4b6f-ab2f-992ee1723ce9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:20.308 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:20.309 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] VM Started (Lifecycle Event)
2022-02-22 22:57:20.352 7 INFO nova.compute.manager [req-4a47750f-3688-4b6f-ab2f-992ee1723ce9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Took 1.77 seconds to build instance.
2022-02-22 22:57:20.822 7 INFO nova.compute.manager [req-81bf014f-dc3f-4e61-865a-4542c5a736b3 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Detaching volume 1b1dd0d9-f82e-4e8c-b524-8659b2161229
2022-02-22 22:57:20.881 7 INFO nova.virt.block_device [req-81bf014f-dc3f-4e61-865a-4542c5a736b3 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Attempting to driver detach volume 1b1dd0d9-f82e-4e8c-b524-8659b2161229 from mountpoint /dev/vdb
2022-02-22 22:57:20.901 7 INFO nova.virt.libvirt.driver [req-81bf014f-dc3f-4e61-865a-4542c5a736b3 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8 from the persistent domain config.
2022-02-22 22:57:21.042 7 INFO nova.virt.libvirt.driver [req-81bf014f-dc3f-4e61-865a-4542c5a736b3 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8 from the live domain config.
2022-02-22 22:57:21.045 7 INFO os_brick.initiator.connectors.lightos [req-81bf014f-dc3f-4e61-865a-4542c5a736b3 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2b60224e-1bbc-4bca-9a5c-aeb8c459b024
2022-02-22 22:57:22.518 7 INFO nova.compute.claims [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Claim successful on node rack08-server63
2022-02-22 22:57:22.781 7 INFO nova.virt.libvirt.driver [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 22:57:22.872 7 INFO nova.virt.block_device [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Booting with volume 30e27b70-c841-4145-b6a4-e2b35bb1a8ce at /dev/vda
2022-02-22 22:57:22.961 7 WARNING os_brick.initiator.connectors.nvmeof [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:24.217 7 INFO nova.compute.claims [req-464ef102-d1cb-4dc2-8f90-5c5b5e4b4d0a fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Claim successful on node rack08-server63
2022-02-22 22:57:24.404 7 INFO nova.virt.libvirt.driver [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Creating image
2022-02-22 22:57:24.413 7 INFO os_brick.initiator.connectors.lightos [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: connect_volume called for volume 377f64e7-aebc-4647-af4c-2aa7572481b1, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '377f64e7-aebc-4647-af4c-2aa7572481b1', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:57:24.417 7 INFO os_brick.initiator.connectors.lightos [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 377f64e7-aebc-4647-af4c-2aa7572481b1
2022-02-22 22:57:24.589 7 INFO nova.virt.libvirt.driver [req-464ef102-d1cb-4dc2-8f90-5c5b5e4b4d0a fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Creating image
2022-02-22 22:57:25.285 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] VM Resumed (Lifecycle Event)
2022-02-22 22:57:25.293 7 INFO nova.virt.libvirt.driver [-] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Instance spawned successfully.
2022-02-22 22:57:25.293 7 INFO nova.compute.manager [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Took 0.89 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:25.342 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:25.342 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] VM Started (Lifecycle Event)
2022-02-22 22:57:25.379 7 INFO nova.compute.manager [req-a17b7c58-8f07-4269-98a1-4d08f1d1492a b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Took 2.90 seconds to build instance.
2022-02-22 22:57:25.748 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] VM Resumed (Lifecycle Event)
2022-02-22 22:57:25.754 7 INFO nova.virt.libvirt.driver [-] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Instance spawned successfully.
2022-02-22 22:57:25.754 7 INFO nova.compute.manager [req-464ef102-d1cb-4dc2-8f90-5c5b5e4b4d0a fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:25.800 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:25.800 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] VM Started (Lifecycle Event)
2022-02-22 22:57:25.835 7 INFO nova.compute.manager [req-464ef102-d1cb-4dc2-8f90-5c5b5e4b4d0a fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Took 1.65 seconds to build instance.
2022-02-22 22:57:27.692 7 INFO nova.compute.claims [req-79a544f1-e318-4b17-a0df-dda68ebd865d b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Claim successful on node rack08-server63
2022-02-22 22:57:28.103 7 INFO nova.virt.libvirt.driver [req-79a544f1-e318-4b17-a0df-dda68ebd865d b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Creating image
2022-02-22 22:57:28.215 7 INFO nova.compute.claims [req-7e13286a-0fed-4299-8cac-2cb21cf93943 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Claim successful on node rack08-server63
2022-02-22 22:57:28.589 7 INFO nova.virt.libvirt.driver [req-7e13286a-0fed-4299-8cac-2cb21cf93943 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Creating image
2022-02-22 22:57:28.726 7 INFO nova.compute.manager [req-65557946-0725-48e9-9d47-e859a8c252b6 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Attaching volume 5e99f29a-8864-4331-98b9-b2ea62462c97 to /dev/vdb
2022-02-22 22:57:28.829 7 WARNING os_brick.initiator.connectors.nvmeof [req-65557946-0725-48e9-9d47-e859a8c252b6 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:29.286 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] VM Resumed (Lifecycle Event)
2022-02-22 22:57:29.293 7 INFO nova.virt.libvirt.driver [-] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Instance spawned successfully.
2022-02-22 22:57:29.294 7 INFO nova.compute.manager [req-79a544f1-e318-4b17-a0df-dda68ebd865d b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:29.351 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:29.352 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] VM Started (Lifecycle Event)
2022-02-22 22:57:29.385 7 INFO nova.compute.manager [req-79a544f1-e318-4b17-a0df-dda68ebd865d b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Took 1.73 seconds to build instance.
2022-02-22 22:57:29.762 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] VM Resumed (Lifecycle Event)
2022-02-22 22:57:29.768 7 INFO nova.virt.libvirt.driver [-] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Instance spawned successfully.
2022-02-22 22:57:29.769 7 INFO nova.compute.manager [req-7e13286a-0fed-4299-8cac-2cb21cf93943 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:29.857 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] VM Started (Lifecycle Event)
2022-02-22 22:57:29.861 7 INFO nova.compute.manager [req-7e13286a-0fed-4299-8cac-2cb21cf93943 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Took 1.69 seconds to build instance.
2022-02-22 22:57:30.129 7 INFO os_brick.initiator.connectors.lightos [req-65557946-0725-48e9-9d47-e859a8c252b6 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: connect_volume called for volume f337358a-0de0-4745-93aa-c64dc41f06a5, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'f337358a-0de0-4745-93aa-c64dc41f06a5', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:57:30.132 7 INFO os_brick.initiator.connectors.lightos [req-65557946-0725-48e9-9d47-e859a8c252b6 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid f337358a-0de0-4745-93aa-c64dc41f06a5
2022-02-22 22:57:31.312 7 INFO nova.compute.manager [req-2a23c493-5815-437a-812c-7d3bc0fe92c9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Detaching volume 5e99f29a-8864-4331-98b9-b2ea62462c97
2022-02-22 22:57:31.373 7 INFO nova.virt.block_device [req-2a23c493-5815-437a-812c-7d3bc0fe92c9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Attempting to driver detach volume 5e99f29a-8864-4331-98b9-b2ea62462c97 from mountpoint /dev/vdb
2022-02-22 22:57:31.392 7 INFO nova.virt.libvirt.driver [req-2a23c493-5815-437a-812c-7d3bc0fe92c9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 7ba8072b-d0dc-4033-936f-29533ca5712c from the persistent domain config.
2022-02-22 22:57:31.542 7 INFO nova.virt.libvirt.driver [req-2a23c493-5815-437a-812c-7d3bc0fe92c9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 7ba8072b-d0dc-4033-936f-29533ca5712c from the live domain config.
2022-02-22 22:57:31.545 7 INFO os_brick.initiator.connectors.lightos [req-2a23c493-5815-437a-812c-7d3bc0fe92c9 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid f337358a-0de0-4745-93aa-c64dc41f06a5
2022-02-22 22:57:32.960 7 INFO nova.compute.manager [req-ff4e1146-dab8-4553-9288-80c4fa06aa9e b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Attaching volume 01132030-c58b-4a61-b547-03b3a0ea9fdc to /dev/vdb
2022-02-22 22:57:33.048 7 WARNING os_brick.initiator.connectors.nvmeof [req-ff4e1146-dab8-4553-9288-80c4fa06aa9e b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:34.365 7 INFO os_brick.initiator.connectors.lightos [req-ff4e1146-dab8-4553-9288-80c4fa06aa9e b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: connect_volume called for volume 63b39ffb-55c3-4f15-b683-7c37352b498a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '63b39ffb-55c3-4f15-b683-7c37352b498a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:57:34.369 7 INFO os_brick.initiator.connectors.lightos [req-ff4e1146-dab8-4553-9288-80c4fa06aa9e b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 63b39ffb-55c3-4f15-b683-7c37352b498a
2022-02-22 22:57:34.763 7 INFO nova.compute.claims [req-352802a0-6366-4be8-8586-f836df3bb3bd fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Claim successful on node rack08-server63
2022-02-22 22:57:35.140 7 INFO nova.virt.libvirt.driver [req-352802a0-6366-4be8-8586-f836df3bb3bd fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Creating image
2022-02-22 22:57:35.490 7 INFO nova.compute.manager [req-15ab2a8c-8549-40a1-9767-66b2c8c23f70 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Attaching volume 01132030-c58b-4a61-b547-03b3a0ea9fdc to /dev/vdb
2022-02-22 22:57:35.582 7 WARNING os_brick.initiator.connectors.nvmeof [req-15ab2a8c-8549-40a1-9767-66b2c8c23f70 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:36.402 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] VM Resumed (Lifecycle Event)
2022-02-22 22:57:36.412 7 INFO nova.virt.libvirt.driver [-] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Instance spawned successfully.
2022-02-22 22:57:36.413 7 INFO nova.compute.manager [req-352802a0-6366-4be8-8586-f836df3bb3bd fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-22 22:57:36.465 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:57:36.466 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] VM Started (Lifecycle Event)
2022-02-22 22:57:36.506 7 INFO nova.compute.manager [req-352802a0-6366-4be8-8586-f836df3bb3bd fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Took 1.78 seconds to build instance.
2022-02-22 22:57:36.872 7 INFO os_brick.initiator.connectors.lightos [req-15ab2a8c-8549-40a1-9767-66b2c8c23f70 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: connect_volume called for volume 63b39ffb-55c3-4f15-b683-7c37352b498a, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '63b39ffb-55c3-4f15-b683-7c37352b498a', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:57:36.873 7 INFO os_brick.initiator.connectors.lightos [req-15ab2a8c-8549-40a1-9767-66b2c8c23f70 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 63b39ffb-55c3-4f15-b683-7c37352b498a
2022-02-22 22:57:38.045 7 INFO nova.compute.manager [req-22add33a-ea07-4112-b7b6-b21cf57d948c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Detaching volume 01132030-c58b-4a61-b547-03b3a0ea9fdc
2022-02-22 22:57:38.106 7 INFO nova.virt.block_device [req-22add33a-ea07-4112-b7b6-b21cf57d948c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Attempting to driver detach volume 01132030-c58b-4a61-b547-03b3a0ea9fdc from mountpoint /dev/vdb
2022-02-22 22:57:38.124 7 INFO nova.virt.libvirt.driver [req-22add33a-ea07-4112-b7b6-b21cf57d948c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Successfully detached device vdb from instance da5e61ef-65c3-40bc-8f2e-2fdab89a0307 from the persistent domain config.
2022-02-22 22:57:38.265 7 INFO nova.virt.libvirt.driver [req-22add33a-ea07-4112-b7b6-b21cf57d948c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Successfully detached device vdb from instance da5e61ef-65c3-40bc-8f2e-2fdab89a0307 from the live domain config.
2022-02-22 22:57:38.335 7 INFO nova.virt.libvirt.driver [req-22add33a-ea07-4112-b7b6-b21cf57d948c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Detected multiple connections on this host for volume: 01132030-c58b-4a61-b547-03b3a0ea9fdc, skipping target disconnect.
2022-02-22 22:57:40.351 7 INFO nova.compute.manager [req-ef558bfb-a18c-4c7e-9659-4a2b1580e985 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Attaching volume 127bdd2f-1ae0-4fb0-9e1f-1899961691cf to /dev/vdb
2022-02-22 22:57:40.437 7 WARNING os_brick.initiator.connectors.nvmeof [req-ef558bfb-a18c-4c7e-9659-4a2b1580e985 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:57:40.515 7 INFO nova.compute.manager [req-4157ac86-5b7f-4361-b489-31abb757995b b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Detaching volume 01132030-c58b-4a61-b547-03b3a0ea9fdc
2022-02-22 22:57:40.576 7 INFO nova.virt.block_device [req-4157ac86-5b7f-4361-b489-31abb757995b b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Attempting to driver detach volume 01132030-c58b-4a61-b547-03b3a0ea9fdc from mountpoint /dev/vdb
2022-02-22 22:57:40.597 7 INFO nova.virt.libvirt.driver [req-4157ac86-5b7f-4361-b489-31abb757995b b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Successfully detached device vdb from instance 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6 from the persistent domain config.
2022-02-22 22:57:40.779 7 INFO nova.virt.libvirt.driver [req-4157ac86-5b7f-4361-b489-31abb757995b b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Successfully detached device vdb from instance 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6 from the live domain config.
2022-02-22 22:58:41.607 7 INFO os_brick.initiator.connectors.lightos [req-ef558bfb-a18c-4c7e-9659-4a2b1580e985 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: connect_volume called for volume a080830e-a85c-470e-b5c2-281ad75f900e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a080830e-a85c-470e-b5c2-281ad75f900e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:58:41.610 7 INFO os_brick.initiator.connectors.lightos [req-ef558bfb-a18c-4c7e-9659-4a2b1580e985 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid a080830e-a85c-470e-b5c2-281ad75f900e
2022-02-22 22:58:43.239 7 INFO nova.compute.manager [req-6fe1f411-0dfa-409a-9218-4160e44c9706 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Detaching volume 127bdd2f-1ae0-4fb0-9e1f-1899961691cf
2022-02-22 22:58:43.297 7 INFO nova.virt.block_device [req-6fe1f411-0dfa-409a-9218-4160e44c9706 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Attempting to driver detach volume 127bdd2f-1ae0-4fb0-9e1f-1899961691cf from mountpoint /dev/vdb
2022-02-22 22:58:43.317 7 INFO nova.virt.libvirt.driver [req-6fe1f411-0dfa-409a-9218-4160e44c9706 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63 from the persistent domain config.
2022-02-22 22:58:43.457 7 INFO nova.virt.libvirt.driver [req-6fe1f411-0dfa-409a-9218-4160e44c9706 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Successfully detached device vdb from instance 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63 from the live domain config.
2022-02-22 22:58:43.461 7 INFO os_brick.initiator.connectors.lightos [req-6fe1f411-0dfa-409a-9218-4160e44c9706 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid a080830e-a85c-470e-b5c2-281ad75f900e
2022-02-22 22:58:46.712 7 INFO nova.compute.manager [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Terminating instance
2022-02-22 22:58:47.066 7 INFO nova.virt.libvirt.driver [-] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Instance destroyed successfully.
2022-02-22 22:58:47.082 7 INFO nova.virt.libvirt.driver [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Deleting instance files /var/lib/nova/instances/6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63_del
2022-02-22 22:58:47.084 7 INFO nova.virt.libvirt.driver [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Deletion of /var/lib/nova/instances/6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63_del complete
2022-02-22 22:58:47.153 7 INFO nova.virt.libvirt.host [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] UEFI support detected
2022-02-22 22:58:47.156 7 INFO nova.compute.manager [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 22:58:47.225 7 INFO nova.compute.manager [-] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:58:47.431 7 INFO nova.scheduler.client.report [req-31b648d5-bd0b-4bd1-ae74-be2cb3e5edf7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Deleted allocations for instance 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63
2022-02-22 22:58:49.088 7 INFO nova.compute.manager [req-19fae3ea-94d5-4d81-a063-fd28aa193926 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Terminating instance
2022-02-22 22:58:49.439 7 INFO nova.virt.libvirt.driver [-] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Instance destroyed successfully.
2022-02-22 22:58:49.456 7 INFO nova.virt.libvirt.driver [req-19fae3ea-94d5-4d81-a063-fd28aa193926 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Deleting instance files /var/lib/nova/instances/7ba8072b-d0dc-4033-936f-29533ca5712c_del
2022-02-22 22:58:49.457 7 INFO nova.virt.libvirt.driver [req-19fae3ea-94d5-4d81-a063-fd28aa193926 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Deletion of /var/lib/nova/instances/7ba8072b-d0dc-4033-936f-29533ca5712c_del complete
2022-02-22 22:58:49.529 7 INFO nova.compute.manager [req-19fae3ea-94d5-4d81-a063-fd28aa193926 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 22:58:49.598 7 INFO nova.compute.manager [-] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:58:49.797 7 INFO nova.scheduler.client.report [req-19fae3ea-94d5-4d81-a063-fd28aa193926 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Deleted allocations for instance 7ba8072b-d0dc-4033-936f-29533ca5712c
2022-02-22 22:58:50.338 7 INFO nova.compute.manager [req-ef2b5a68-f55b-44c0-8849-0a40e3fd57a7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Terminating instance
2022-02-22 22:58:50.679 7 INFO nova.virt.libvirt.driver [-] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Instance destroyed successfully.
2022-02-22 22:58:50.695 7 INFO nova.virt.libvirt.driver [req-ef2b5a68-f55b-44c0-8849-0a40e3fd57a7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Deleting instance files /var/lib/nova/instances/f0154655-fc6e-4733-b60f-95feac0d9293_del
2022-02-22 22:58:50.697 7 INFO nova.virt.libvirt.driver [req-ef2b5a68-f55b-44c0-8849-0a40e3fd57a7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Deletion of /var/lib/nova/instances/f0154655-fc6e-4733-b60f-95feac0d9293_del complete
2022-02-22 22:58:50.764 7 INFO nova.compute.manager [req-ef2b5a68-f55b-44c0-8849-0a40e3fd57a7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 22:58:50.835 7 INFO nova.compute.manager [-] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:58:51.039 7 INFO nova.scheduler.client.report [req-ef2b5a68-f55b-44c0-8849-0a40e3fd57a7 fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Deleted allocations for instance f0154655-fc6e-4733-b60f-95feac0d9293
2022-02-22 22:58:52.748 7 INFO nova.compute.manager [req-a8aa0adb-4d63-45f7-bd1b-31873dbc408e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Terminating instance
2022-02-22 22:58:53.092 7 INFO nova.virt.libvirt.driver [-] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Instance destroyed successfully.
2022-02-22 22:58:53.105 7 INFO nova.virt.libvirt.driver [req-a8aa0adb-4d63-45f7-bd1b-31873dbc408e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Deleting instance files /var/lib/nova/instances/0a2061b3-91ab-4c49-8c68-b0fcdefa08d8_del
2022-02-22 22:58:53.107 7 INFO nova.virt.libvirt.driver [req-a8aa0adb-4d63-45f7-bd1b-31873dbc408e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Deletion of /var/lib/nova/instances/0a2061b3-91ab-4c49-8c68-b0fcdefa08d8_del complete
2022-02-22 22:58:53.176 7 INFO nova.compute.manager [req-a8aa0adb-4d63-45f7-bd1b-31873dbc408e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 22:58:53.239 7 INFO nova.compute.manager [-] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] Took 0.06 seconds to deallocate network for instance.
2022-02-22 22:58:53.457 7 INFO nova.scheduler.client.report [req-a8aa0adb-4d63-45f7-bd1b-31873dbc408e fc468134edd14d42aeeeefcb20e26302 155d86ae7261404888042acfd20180cc - default default] Deleted allocations for instance 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8
2022-02-22 22:58:56.469 7 INFO nova.compute.claims [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Claim successful on node rack08-server63
2022-02-22 22:58:56.738 7 INFO nova.virt.libvirt.driver [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 22:58:56.824 7 INFO nova.virt.block_device [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Booting with volume 92447a33-e309-4299-8d7d-b58d04f873c2 at /dev/vda
2022-02-22 22:58:56.919 7 WARNING os_brick.initiator.connectors.nvmeof [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 22:58:58.372 7 INFO nova.virt.libvirt.driver [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Creating image
2022-02-22 22:58:58.385 7 INFO os_brick.initiator.connectors.lightos [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: connect_volume called for volume 34936d5c-0b63-4137-b1b6-a7f8158f5b47, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '34936d5c-0b63-4137-b1b6-a7f8158f5b47', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 22:58:58.388 7 INFO os_brick.initiator.connectors.lightos [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 34936d5c-0b63-4137-b1b6-a7f8158f5b47
2022-02-22 22:58:59.235 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] VM Resumed (Lifecycle Event)
2022-02-22 22:58:59.242 7 INFO nova.virt.libvirt.driver [-] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Instance spawned successfully.
2022-02-22 22:58:59.242 7 INFO nova.compute.manager [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Took 0.87 seconds to spawn the instance on the hypervisor.
2022-02-22 22:58:59.291 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:58:59.291 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] VM Started (Lifecycle Event)
2022-02-22 22:58:59.332 7 INFO nova.compute.manager [req-0e588731-db05-4610-8fab-dedcc4581324 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Took 2.90 seconds to build instance.
2022-02-22 22:59:00.625 7 INFO nova.compute.manager [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Terminating instance
2022-02-22 22:59:00.985 7 INFO nova.virt.libvirt.driver [-] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Instance destroyed successfully.
2022-02-22 22:59:01.059 7 INFO os_brick.initiator.connectors.lightos [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 34936d5c-0b63-4137-b1b6-a7f8158f5b47
2022-02-22 22:59:01.070 7 INFO nova.virt.libvirt.driver [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Deleting instance files /var/lib/nova/instances/a8de3b45-b785-4443-9467-4aa9788608c0_del
2022-02-22 22:59:01.071 7 INFO nova.virt.libvirt.driver [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Deletion of /var/lib/nova/instances/a8de3b45-b785-4443-9467-4aa9788608c0_del complete
2022-02-22 22:59:01.135 7 INFO nova.compute.manager [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:01.202 7 INFO nova.compute.manager [-] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:59:02.064 7 INFO nova.compute.manager [-] [instance: 6fa38aa0-5d9f-48b2-9b2a-3e46058f1f63] VM Stopped (Lifecycle Event)
2022-02-22 22:59:02.394 7 INFO nova.compute.manager [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] Took 1.19 seconds to detach 1 volumes for instance.
2022-02-22 22:59:02.590 7 INFO nova.scheduler.client.report [req-603d16fc-b328-4002-8e84-ab761797d025 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Deleted allocations for instance a8de3b45-b785-4443-9467-4aa9788608c0
2022-02-22 22:59:04.434 7 INFO nova.compute.manager [-] [instance: 7ba8072b-d0dc-4033-936f-29533ca5712c] VM Stopped (Lifecycle Event)
2022-02-22 22:59:05.541 7 INFO nova.compute.manager [req-ee2b7e36-22aa-4bac-8caf-abc8088b8d82 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Terminating instance
2022-02-22 22:59:05.677 7 INFO nova.compute.manager [-] [instance: f0154655-fc6e-4733-b60f-95feac0d9293] VM Stopped (Lifecycle Event)
2022-02-22 22:59:05.888 7 INFO nova.virt.libvirt.driver [-] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Instance destroyed successfully.
2022-02-22 22:59:05.904 7 INFO nova.virt.libvirt.driver [req-ee2b7e36-22aa-4bac-8caf-abc8088b8d82 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Deleting instance files /var/lib/nova/instances/2f1d6016-9fb6-46e8-8e62-c9103dfb62e6_del
2022-02-22 22:59:05.905 7 INFO nova.virt.libvirt.driver [req-ee2b7e36-22aa-4bac-8caf-abc8088b8d82 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Deletion of /var/lib/nova/instances/2f1d6016-9fb6-46e8-8e62-c9103dfb62e6_del complete
2022-02-22 22:59:05.979 7 INFO nova.compute.manager [req-ee2b7e36-22aa-4bac-8caf-abc8088b8d82 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:06.046 7 INFO nova.compute.manager [-] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:59:06.244 7 INFO nova.scheduler.client.report [req-ee2b7e36-22aa-4bac-8caf-abc8088b8d82 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Deleted allocations for instance 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6
2022-02-22 22:59:06.786 7 INFO nova.compute.manager [req-11121a8b-e736-476e-8e31-48a5740adbf0 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Terminating instance
2022-02-22 22:59:07.128 7 INFO nova.virt.libvirt.driver [-] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Instance destroyed successfully.
2022-02-22 22:59:07.144 7 INFO nova.virt.libvirt.driver [req-11121a8b-e736-476e-8e31-48a5740adbf0 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Deleting instance files /var/lib/nova/instances/da5e61ef-65c3-40bc-8f2e-2fdab89a0307_del
2022-02-22 22:59:07.145 7 INFO nova.virt.libvirt.driver [req-11121a8b-e736-476e-8e31-48a5740adbf0 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Deletion of /var/lib/nova/instances/da5e61ef-65c3-40bc-8f2e-2fdab89a0307_del complete
2022-02-22 22:59:07.213 7 INFO nova.compute.manager [req-11121a8b-e736-476e-8e31-48a5740adbf0 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:07.289 7 INFO nova.compute.manager [-] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] Took 0.08 seconds to deallocate network for instance.
2022-02-22 22:59:07.474 7 INFO nova.scheduler.client.report [req-11121a8b-e736-476e-8e31-48a5740adbf0 b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Deleted allocations for instance da5e61ef-65c3-40bc-8f2e-2fdab89a0307
2022-02-22 22:59:08.055 7 INFO nova.compute.manager [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Terminating instance
2022-02-22 22:59:08.088 7 INFO nova.compute.manager [-] [instance: 0a2061b3-91ab-4c49-8c68-b0fcdefa08d8] VM Stopped (Lifecycle Event)
2022-02-22 22:59:08.391 7 INFO nova.virt.libvirt.driver [-] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Instance destroyed successfully.
2022-02-22 22:59:08.460 7 INFO os_brick.initiator.connectors.lightos [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 377f64e7-aebc-4647-af4c-2aa7572481b1
2022-02-22 22:59:08.471 7 INFO nova.virt.libvirt.driver [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Deleting instance files /var/lib/nova/instances/02002caf-1b3f-4673-99c8-cf462b0a46ad_del
2022-02-22 22:59:08.472 7 INFO nova.virt.libvirt.driver [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Deletion of /var/lib/nova/instances/02002caf-1b3f-4673-99c8-cf462b0a46ad_del complete
2022-02-22 22:59:08.565 7 INFO nova.compute.manager [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Took 0.39 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:08.629 7 INFO nova.compute.manager [-] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Took 0.06 seconds to deallocate network for instance.
2022-02-22 22:59:09.826 7 INFO nova.compute.manager [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] Took 1.20 seconds to detach 1 volumes for instance.
2022-02-22 22:59:09.995 7 INFO nova.scheduler.client.report [req-24309af3-9aea-45bf-9172-1f05882b667c b598f9cca8ea4e19a81377613cd5cbfa 86ee36c1d3cc4ace8c02c365bb41167e - default default] Deleted allocations for instance 02002caf-1b3f-4673-99c8-cf462b0a46ad
2022-02-22 22:59:15.983 7 INFO nova.compute.manager [-] [instance: a8de3b45-b785-4443-9467-4aa9788608c0] VM Stopped (Lifecycle Event)
2022-02-22 22:59:20.886 7 INFO nova.compute.manager [-] [instance: 2f1d6016-9fb6-46e8-8e62-c9103dfb62e6] VM Stopped (Lifecycle Event)
2022-02-22 22:59:22.126 7 INFO nova.compute.manager [-] [instance: da5e61ef-65c3-40bc-8f2e-2fdab89a0307] VM Stopped (Lifecycle Event)
2022-02-22 22:59:23.388 7 INFO nova.compute.manager [-] [instance: 02002caf-1b3f-4673-99c8-cf462b0a46ad] VM Stopped (Lifecycle Event)
2022-02-22 22:59:28.259 7 INFO nova.compute.claims [req-b28b5a8e-188b-4c97-b98f-1ce74d37cd70 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Claim successful on node rack08-server63
2022-02-22 22:59:28.677 7 INFO nova.virt.libvirt.driver [req-b28b5a8e-188b-4c97-b98f-1ce74d37cd70 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Creating image
2022-02-22 22:59:29.792 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] VM Resumed (Lifecycle Event)
2022-02-22 22:59:29.799 7 INFO nova.virt.libvirt.driver [-] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Instance spawned successfully.
2022-02-22 22:59:29.799 7 INFO nova.compute.manager [req-b28b5a8e-188b-4c97-b98f-1ce74d37cd70 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Took 1.12 seconds to spawn the instance on the hypervisor.
2022-02-22 22:59:29.847 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:59:29.848 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] VM Started (Lifecycle Event)
2022-02-22 22:59:29.882 7 INFO nova.compute.manager [req-b28b5a8e-188b-4c97-b98f-1ce74d37cd70 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Took 1.66 seconds to build instance.
2022-02-22 22:59:30.555 7 INFO nova.compute.manager [req-285c5116-17be-40fc-a6a6-dd276d74792e cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Terminating instance
2022-02-22 22:59:30.893 7 INFO nova.virt.libvirt.driver [-] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Instance destroyed successfully.
2022-02-22 22:59:30.907 7 INFO nova.virt.libvirt.driver [req-285c5116-17be-40fc-a6a6-dd276d74792e cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Deleting instance files /var/lib/nova/instances/ac35bba0-102a-4321-ae80-b1ce7a00cb31_del
2022-02-22 22:59:30.908 7 INFO nova.virt.libvirt.driver [req-285c5116-17be-40fc-a6a6-dd276d74792e cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Deletion of /var/lib/nova/instances/ac35bba0-102a-4321-ae80-b1ce7a00cb31_del complete
2022-02-22 22:59:30.972 7 INFO nova.compute.manager [req-285c5116-17be-40fc-a6a6-dd276d74792e cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:31.044 7 INFO nova.compute.manager [-] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] Took 0.07 seconds to deallocate network for instance.
2022-02-22 22:59:31.217 7 INFO nova.scheduler.client.report [req-285c5116-17be-40fc-a6a6-dd276d74792e cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] Deleted allocations for instance ac35bba0-102a-4321-ae80-b1ce7a00cb31
2022-02-22 22:59:32.855 7 INFO nova.compute.claims [req-cee19181-b7a5-46db-a862-4ed1f9aa8758 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Claim successful on node rack08-server63
2022-02-22 22:59:33.241 7 INFO nova.virt.libvirt.driver [req-cee19181-b7a5-46db-a862-4ed1f9aa8758 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Creating image
2022-02-22 22:59:34.456 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] VM Resumed (Lifecycle Event)
2022-02-22 22:59:34.463 7 INFO nova.virt.libvirt.driver [-] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Instance spawned successfully.
2022-02-22 22:59:34.464 7 INFO nova.compute.manager [req-cee19181-b7a5-46db-a862-4ed1f9aa8758 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 22:59:34.508 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 22:59:34.508 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] VM Started (Lifecycle Event)
2022-02-22 22:59:34.543 7 INFO nova.compute.manager [req-cee19181-b7a5-46db-a862-4ed1f9aa8758 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Took 1.72 seconds to build instance.
2022-02-22 22:59:35.191 7 INFO nova.compute.manager [req-acf0099a-e05e-47a0-afad-c9100966a588 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Terminating instance
2022-02-22 22:59:35.528 7 INFO nova.virt.libvirt.driver [-] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Instance destroyed successfully.
2022-02-22 22:59:35.543 7 INFO nova.virt.libvirt.driver [req-acf0099a-e05e-47a0-afad-c9100966a588 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Deleting instance files /var/lib/nova/instances/170e86c5-6b74-47fc-8e37-8edfa66e6ac0_del
2022-02-22 22:59:35.544 7 INFO nova.virt.libvirt.driver [req-acf0099a-e05e-47a0-afad-c9100966a588 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Deletion of /var/lib/nova/instances/170e86c5-6b74-47fc-8e37-8edfa66e6ac0_del complete
2022-02-22 22:59:35.618 7 INFO nova.compute.manager [req-acf0099a-e05e-47a0-afad-c9100966a588 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 22:59:35.679 7 INFO nova.compute.manager [-] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] Took 0.06 seconds to deallocate network for instance.
2022-02-22 22:59:35.871 7 INFO nova.scheduler.client.report [req-acf0099a-e05e-47a0-afad-c9100966a588 cd5ca53a9fd64b5f994e3dffdc7a13de ea09f5da1f8348e2b423a3f6d2a6fbcc - default default] Deleted allocations for instance 170e86c5-6b74-47fc-8e37-8edfa66e6ac0
2022-02-22 22:59:45.891 7 INFO nova.compute.manager [-] [instance: ac35bba0-102a-4321-ae80-b1ce7a00cb31] VM Stopped (Lifecycle Event)
2022-02-22 22:59:50.525 7 INFO nova.compute.manager [-] [instance: 170e86c5-6b74-47fc-8e37-8edfa66e6ac0] VM Stopped (Lifecycle Event)
2022-02-22 23:00:01.044 7 INFO nova.compute.claims [req-594fb514-7d7d-41f2-a361-6d8ac585ebfb 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Claim successful on node rack08-server63
2022-02-22 23:00:01.441 7 INFO nova.virt.libvirt.driver [req-594fb514-7d7d-41f2-a361-6d8ac585ebfb 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Creating image
2022-02-22 23:00:02.611 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] VM Resumed (Lifecycle Event)
2022-02-22 23:00:02.619 7 INFO nova.virt.libvirt.driver [-] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Instance spawned successfully.
2022-02-22 23:00:02.620 7 INFO nova.compute.manager [req-594fb514-7d7d-41f2-a361-6d8ac585ebfb 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 23:00:02.672 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 23:00:02.673 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] VM Started (Lifecycle Event)
2022-02-22 23:00:02.705 7 INFO nova.compute.manager [req-594fb514-7d7d-41f2-a361-6d8ac585ebfb 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Took 1.71 seconds to build instance.
2022-02-22 23:00:03.017 7 INFO nova.virt.libvirt.driver [req-36c69bed-0f89-4130-847b-cc9bcc80fcd7 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Ignoring supplied device name: /dev/vdb
2022-02-22 23:00:03.206 7 INFO nova.compute.manager [req-36c69bed-0f89-4130-847b-cc9bcc80fcd7 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Attaching volume 49885a08-0718-4d26-ba72-2e3ab4ed0308 to /dev/vdb
2022-02-22 23:00:03.293 7 WARNING os_brick.initiator.connectors.nvmeof [req-36c69bed-0f89-4130-847b-cc9bcc80fcd7 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 23:00:04.581 7 INFO os_brick.initiator.connectors.lightos [req-36c69bed-0f89-4130-847b-cc9bcc80fcd7 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] LIGHTOS: connect_volume called for volume 79f33572-4ee9-4e50-9db0-073af94cfca7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '79f33572-4ee9-4e50-9db0-073af94cfca7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 23:00:04.586 7 INFO os_brick.initiator.connectors.lightos [req-36c69bed-0f89-4130-847b-cc9bcc80fcd7 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 79f33572-4ee9-4e50-9db0-073af94cfca7
2022-02-22 23:00:06.417 7 INFO nova.compute.manager [req-e3e2fb14-ca0d-4938-bf95-71969772f709 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Cinder extended volume 49885a08-0718-4d26-ba72-2e3ab4ed0308; extending it to detect new size
2022-02-22 23:00:06.508 7 INFO os_brick.initiator.connectors.lightos [req-e3e2fb14-ca0d-4938-bf95-71969772f709 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 79f33572-4ee9-4e50-9db0-073af94cfca7
2022-02-22 23:00:07.133 7 INFO nova.compute.manager [req-15bb063a-7671-4708-95af-ba152a83b7c9 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Detaching volume 49885a08-0718-4d26-ba72-2e3ab4ed0308
2022-02-22 23:00:07.188 7 INFO nova.virt.block_device [req-15bb063a-7671-4708-95af-ba152a83b7c9 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Attempting to driver detach volume 49885a08-0718-4d26-ba72-2e3ab4ed0308 from mountpoint /dev/vdb
2022-02-22 23:00:07.207 7 INFO nova.virt.libvirt.driver [req-15bb063a-7671-4708-95af-ba152a83b7c9 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] Successfully detached device vdb from instance 76a6ddda-62de-474e-9a04-31b692d186f5 from the persistent domain config.
2022-02-22 23:00:07.345 7 INFO nova.virt.libvirt.driver [req-15bb063a-7671-4708-95af-ba152a83b7c9 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] Successfully detached device vdb from instance 76a6ddda-62de-474e-9a04-31b692d186f5 from the live domain config.
2022-02-22 23:00:07.348 7 INFO os_brick.initiator.connectors.lightos [req-15bb063a-7671-4708-95af-ba152a83b7c9 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 79f33572-4ee9-4e50-9db0-073af94cfca7
2022-02-22 23:00:09.392 7 INFO nova.compute.manager [req-cc00fb24-ea99-4cfa-98f9-52195cc4c9cd 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Terminating instance
2022-02-22 23:00:09.732 7 INFO nova.virt.libvirt.driver [-] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Instance destroyed successfully.
2022-02-22 23:00:09.748 7 INFO nova.virt.libvirt.driver [req-cc00fb24-ea99-4cfa-98f9-52195cc4c9cd 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Deleting instance files /var/lib/nova/instances/76a6ddda-62de-474e-9a04-31b692d186f5_del
2022-02-22 23:00:09.749 7 INFO nova.virt.libvirt.driver [req-cc00fb24-ea99-4cfa-98f9-52195cc4c9cd 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Deletion of /var/lib/nova/instances/76a6ddda-62de-474e-9a04-31b692d186f5_del complete
2022-02-22 23:00:09.816 7 INFO nova.compute.manager [req-cc00fb24-ea99-4cfa-98f9-52195cc4c9cd 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 23:00:09.883 7 INFO nova.compute.manager [-] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] Took 0.07 seconds to deallocate network for instance.
2022-02-22 23:00:10.058 7 INFO nova.scheduler.client.report [req-cc00fb24-ea99-4cfa-98f9-52195cc4c9cd 3195f6fa2e1e4fe3a8d5a1167e7ae08e ca551bad94d748f298c1b53e302f6d9d - default default] Deleted allocations for instance 76a6ddda-62de-474e-9a04-31b692d186f5
2022-02-22 23:00:24.731 7 INFO nova.compute.manager [-] [instance: 76a6ddda-62de-474e-9a04-31b692d186f5] VM Stopped (Lifecycle Event)
2022-02-22 23:01:03.077 7 INFO nova.compute.claims [req-f97ce730-738c-4ae5-b7a2-58731fa4def2 b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Claim successful on node rack08-server63
2022-02-22 23:01:03.530 7 INFO nova.virt.libvirt.driver [req-f97ce730-738c-4ae5-b7a2-58731fa4def2 b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Creating image
2022-02-22 23:01:04.636 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 043f4189-024e-411d-b046-52829519e155] VM Resumed (Lifecycle Event)
2022-02-22 23:01:04.644 7 INFO nova.virt.libvirt.driver [-] [instance: 043f4189-024e-411d-b046-52829519e155] Instance spawned successfully.
2022-02-22 23:01:04.644 7 INFO nova.compute.manager [req-f97ce730-738c-4ae5-b7a2-58731fa4def2 b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Took 1.11 seconds to spawn the instance on the hypervisor.
2022-02-22 23:01:04.698 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 043f4189-024e-411d-b046-52829519e155] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 23:01:04.698 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 043f4189-024e-411d-b046-52829519e155] VM Started (Lifecycle Event)
2022-02-22 23:01:04.738 7 INFO nova.compute.manager [req-f97ce730-738c-4ae5-b7a2-58731fa4def2 b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Took 1.70 seconds to build instance.
2022-02-22 23:01:05.231 7 INFO nova.compute.manager [req-8aa26b56-90fc-4ade-8843-51df2b30f1cf b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Terminating instance
2022-02-22 23:01:05.564 7 INFO nova.virt.libvirt.driver [-] [instance: 043f4189-024e-411d-b046-52829519e155] Instance destroyed successfully.
2022-02-22 23:01:05.578 7 INFO nova.virt.libvirt.driver [req-8aa26b56-90fc-4ade-8843-51df2b30f1cf b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Deleting instance files /var/lib/nova/instances/043f4189-024e-411d-b046-52829519e155_del
2022-02-22 23:01:05.579 7 INFO nova.virt.libvirt.driver [req-8aa26b56-90fc-4ade-8843-51df2b30f1cf b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Deletion of /var/lib/nova/instances/043f4189-024e-411d-b046-52829519e155_del complete
2022-02-22 23:01:05.648 7 INFO nova.compute.manager [req-8aa26b56-90fc-4ade-8843-51df2b30f1cf b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] [instance: 043f4189-024e-411d-b046-52829519e155] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 23:01:05.713 7 INFO nova.compute.manager [-] [instance: 043f4189-024e-411d-b046-52829519e155] Took 0.06 seconds to deallocate network for instance.
2022-02-22 23:01:05.883 7 INFO nova.scheduler.client.report [req-8aa26b56-90fc-4ade-8843-51df2b30f1cf b550c006f6ac42fa82e25cc928f02a6b 2d7959f5cbdc48209dd8082b2340b7a9 - default default] Deleted allocations for instance 043f4189-024e-411d-b046-52829519e155
2022-02-22 23:01:16.732 7 INFO nova.compute.claims [req-6b168b9b-d985-48ec-8926-375e1270103b ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Claim successful on node rack08-server63
2022-02-22 23:01:17.726 7 INFO nova.compute.claims [req-4eea43a2-c130-4b57-a915-51fc78e638d3 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Claim successful on node rack08-server63
2022-02-22 23:01:18.047 7 INFO nova.virt.libvirt.driver [req-6b168b9b-d985-48ec-8926-375e1270103b ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Creating image
2022-02-22 23:01:18.117 7 INFO nova.virt.libvirt.driver [req-4eea43a2-c130-4b57-a915-51fc78e638d3 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Creating image
2022-02-22 23:01:19.251 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] VM Resumed (Lifecycle Event)
2022-02-22 23:01:19.259 7 INFO nova.virt.libvirt.driver [-] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Instance spawned successfully.
2022-02-22 23:01:19.259 7 INFO nova.compute.manager [req-6b168b9b-d985-48ec-8926-375e1270103b ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 23:01:19.304 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 23:01:19.305 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] VM Started (Lifecycle Event)
2022-02-22 23:01:19.346 7 INFO nova.compute.manager [req-6b168b9b-d985-48ec-8926-375e1270103b ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Took 2.81 seconds to build instance.
2022-02-22 23:01:19.350 7 INFO nova.virt.libvirt.driver [-] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Instance spawned successfully.
2022-02-22 23:01:19.351 7 INFO nova.compute.manager [req-4eea43a2-c130-4b57-a915-51fc78e638d3 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-22 23:01:19.364 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] VM Resumed (Lifecycle Event)
2022-02-22 23:01:19.417 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 23:01:19.418 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] VM Started (Lifecycle Event)
2022-02-22 23:01:19.430 7 INFO nova.compute.manager [req-4eea43a2-c130-4b57-a915-51fc78e638d3 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Took 1.74 seconds to build instance.
2022-02-22 23:01:20.562 7 INFO nova.compute.manager [-] [instance: 043f4189-024e-411d-b046-52829519e155] VM Stopped (Lifecycle Event)
2022-02-22 23:01:24.813 7 INFO nova.compute.manager [req-d4a9cac0-c3a7-49ae-8540-6c9f6db89103 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Terminating instance
2022-02-22 23:01:25.157 7 INFO nova.virt.libvirt.driver [-] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Instance destroyed successfully.
2022-02-22 23:01:25.173 7 INFO nova.virt.libvirt.driver [req-d4a9cac0-c3a7-49ae-8540-6c9f6db89103 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Deleting instance files /var/lib/nova/instances/cb88c356-c198-48fe-b912-14d9f3a932ed_del
2022-02-22 23:01:25.174 7 INFO nova.virt.libvirt.driver [req-d4a9cac0-c3a7-49ae-8540-6c9f6db89103 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Deletion of /var/lib/nova/instances/cb88c356-c198-48fe-b912-14d9f3a932ed_del complete
2022-02-22 23:01:25.243 7 INFO nova.compute.manager [req-d4a9cac0-c3a7-49ae-8540-6c9f6db89103 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 23:01:25.318 7 INFO nova.compute.manager [-] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] Took 0.07 seconds to deallocate network for instance.
2022-02-22 23:01:25.513 7 INFO nova.scheduler.client.report [req-d4a9cac0-c3a7-49ae-8540-6c9f6db89103 1262e3576cb04b938ac9f4420c8a3b2d b158d4ac506f4a8f97a542e09429d52c - default default] Deleted allocations for instance cb88c356-c198-48fe-b912-14d9f3a932ed
2022-02-22 23:01:31.774 7 INFO nova.virt.libvirt.driver [req-14d7bb8b-274c-423f-879f-fa94397be5f7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Ignoring supplied device name: /dev/vdb
2022-02-22 23:01:31.937 7 INFO nova.compute.manager [req-14d7bb8b-274c-423f-879f-fa94397be5f7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Attaching volume 8d9dfb02-4eed-44cf-a253-0569c031dd74 to /dev/vdb
2022-02-22 23:01:32.026 7 WARNING os_brick.initiator.connectors.nvmeof [req-14d7bb8b-274c-423f-879f-fa94397be5f7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 23:01:33.310 7 INFO os_brick.initiator.connectors.lightos [req-14d7bb8b-274c-423f-879f-fa94397be5f7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: connect_volume called for volume 2a6f9bdb-61a9-49bb-8d08-b9d3c5aeb114, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2a6f9bdb-61a9-49bb-8d08-b9d3c5aeb114', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 23:01:33.314 7 INFO os_brick.initiator.connectors.lightos [req-14d7bb8b-274c-423f-879f-fa94397be5f7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2a6f9bdb-61a9-49bb-8d08-b9d3c5aeb114
2022-02-22 23:01:40.155 7 INFO nova.compute.manager [-] [instance: cb88c356-c198-48fe-b912-14d9f3a932ed] VM Stopped (Lifecycle Event)
2022-02-22 23:01:44.587 7 INFO nova.compute.manager [req-446ed375-e64f-4b17-adf1-624d79d09877 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Detaching volume 8d9dfb02-4eed-44cf-a253-0569c031dd74
2022-02-22 23:01:44.652 7 INFO nova.virt.block_device [req-446ed375-e64f-4b17-adf1-624d79d09877 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Attempting to driver detach volume 8d9dfb02-4eed-44cf-a253-0569c031dd74 from mountpoint /dev/vdb
2022-02-22 23:01:44.671 7 INFO nova.virt.libvirt.driver [req-446ed375-e64f-4b17-adf1-624d79d09877 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Successfully detached device vdb from instance 7530b0b4-45d6-4884-8551-3d2c8fd34491 from the persistent domain config.
2022-02-22 23:01:44.824 7 INFO nova.virt.libvirt.driver [req-446ed375-e64f-4b17-adf1-624d79d09877 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Successfully detached device vdb from instance 7530b0b4-45d6-4884-8551-3d2c8fd34491 from the live domain config.
2022-02-22 23:01:44.827 7 INFO os_brick.initiator.connectors.lightos [req-446ed375-e64f-4b17-adf1-624d79d09877 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 2a6f9bdb-61a9-49bb-8d08-b9d3c5aeb114
2022-02-22 23:01:46.832 7 INFO nova.compute.manager [req-38dd59a2-bca5-4a9c-94d7-cf8273a312fb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Terminating instance
2022-02-22 23:01:47.173 7 INFO nova.virt.libvirt.driver [-] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Instance destroyed successfully.
2022-02-22 23:01:47.191 7 INFO nova.virt.libvirt.driver [req-38dd59a2-bca5-4a9c-94d7-cf8273a312fb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Deleting instance files /var/lib/nova/instances/7530b0b4-45d6-4884-8551-3d2c8fd34491_del
2022-02-22 23:01:47.192 7 INFO nova.virt.libvirt.driver [req-38dd59a2-bca5-4a9c-94d7-cf8273a312fb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Deletion of /var/lib/nova/instances/7530b0b4-45d6-4884-8551-3d2c8fd34491_del complete
2022-02-22 23:01:47.265 7 INFO nova.compute.manager [req-38dd59a2-bca5-4a9c-94d7-cf8273a312fb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 23:01:47.326 7 INFO nova.compute.manager [-] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] Took 0.06 seconds to deallocate network for instance.
2022-02-22 23:01:47.517 7 INFO nova.scheduler.client.report [req-38dd59a2-bca5-4a9c-94d7-cf8273a312fb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Deleted allocations for instance 7530b0b4-45d6-4884-8551-3d2c8fd34491
2022-02-22 23:01:55.051 7 INFO nova.compute.claims [req-9e482539-4f3d-4527-aaaf-ac9e49d59dc7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Claim successful on node rack08-server63
2022-02-22 23:01:55.464 7 INFO nova.virt.libvirt.driver [req-9e482539-4f3d-4527-aaaf-ac9e49d59dc7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Creating image
2022-02-22 23:01:56.659 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] VM Resumed (Lifecycle Event)
2022-02-22 23:01:56.667 7 INFO nova.virt.libvirt.driver [-] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Instance spawned successfully.
2022-02-22 23:01:56.667 7 INFO nova.compute.manager [req-9e482539-4f3d-4527-aaaf-ac9e49d59dc7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 23:01:56.713 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 23:01:56.714 7 INFO nova.compute.manager [req-7f028734-912b-4e1a-afa9-f11bfc27dde1 - - - - -] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] VM Started (Lifecycle Event)
2022-02-22 23:01:56.764 7 INFO nova.compute.manager [req-9e482539-4f3d-4527-aaaf-ac9e49d59dc7 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Took 1.76 seconds to build instance.
2022-02-22 23:01:57.019 7 INFO nova.virt.libvirt.driver [req-e69e44fd-242e-49b7-b337-6466568d53cb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Ignoring supplied device name: /dev/vdb
2022-02-22 23:01:57.174 7 INFO nova.compute.manager [req-e69e44fd-242e-49b7-b337-6466568d53cb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Attaching volume a17a3efd-b6f4-4ca9-8966-aa54418af231 to /dev/vdb
2022-02-22 23:01:57.260 7 WARNING os_brick.initiator.connectors.nvmeof [req-e69e44fd-242e-49b7-b337-6466568d53cb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 23:01:58.563 7 INFO os_brick.initiator.connectors.lightos [req-e69e44fd-242e-49b7-b337-6466568d53cb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: connect_volume called for volume 9c196b38-11cd-4e99-be06-82945712da6d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9c196b38-11cd-4e99-be06-82945712da6d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 23:01:58.567 7 INFO os_brick.initiator.connectors.lightos [req-e69e44fd-242e-49b7-b337-6466568d53cb ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9c196b38-11cd-4e99-be06-82945712da6d
2022-02-22 23:02:02.172 7 INFO nova.compute.manager [-] [instance: 7530b0b4-45d6-4884-8551-3d2c8fd34491] VM Stopped (Lifecycle Event)
2022-02-22 23:02:07.477 7 INFO nova.compute.manager [req-d773d7ec-35a0-411e-92e5-9a252ea25ec9 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Detaching volume a17a3efd-b6f4-4ca9-8966-aa54418af231
2022-02-22 23:02:07.533 7 INFO nova.virt.block_device [req-d773d7ec-35a0-411e-92e5-9a252ea25ec9 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Attempting to driver detach volume a17a3efd-b6f4-4ca9-8966-aa54418af231 from mountpoint /dev/vdb
2022-02-22 23:02:07.553 7 INFO nova.virt.libvirt.driver [req-d773d7ec-35a0-411e-92e5-9a252ea25ec9 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Successfully detached device vdb from instance c9584f78-d987-4e70-b0d6-1d2618ac2cda from the persistent domain config.
2022-02-22 23:02:07.696 7 INFO nova.virt.libvirt.driver [req-d773d7ec-35a0-411e-92e5-9a252ea25ec9 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Successfully detached device vdb from instance c9584f78-d987-4e70-b0d6-1d2618ac2cda from the live domain config.
2022-02-22 23:02:07.699 7 INFO os_brick.initiator.connectors.lightos [req-d773d7ec-35a0-411e-92e5-9a252ea25ec9 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9c196b38-11cd-4e99-be06-82945712da6d
2022-02-22 23:02:09.723 7 INFO nova.compute.manager [req-1f880350-fa6e-4fc8-9328-980b7fd51766 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Terminating instance
2022-02-22 23:02:10.068 7 INFO nova.virt.libvirt.driver [-] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Instance destroyed successfully.
2022-02-22 23:02:10.083 7 INFO nova.virt.libvirt.driver [req-1f880350-fa6e-4fc8-9328-980b7fd51766 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Deleting instance files /var/lib/nova/instances/c9584f78-d987-4e70-b0d6-1d2618ac2cda_del
2022-02-22 23:02:10.085 7 INFO nova.virt.libvirt.driver [req-1f880350-fa6e-4fc8-9328-980b7fd51766 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Deletion of /var/lib/nova/instances/c9584f78-d987-4e70-b0d6-1d2618ac2cda_del complete
2022-02-22 23:02:10.149 7 INFO nova.compute.manager [req-1f880350-fa6e-4fc8-9328-980b7fd51766 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 23:02:10.215 7 INFO nova.compute.manager [-] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] Took 0.06 seconds to deallocate network for instance.
2022-02-22 23:02:10.424 7 INFO nova.scheduler.client.report [req-1f880350-fa6e-4fc8-9328-980b7fd51766 ec338a93042b481dbbf6cc61cbcf11c3 982542c82c2f4ce0bfc592a7aaca7e6a - default default] Deleted allocations for instance c9584f78-d987-4e70-b0d6-1d2618ac2cda
2022-02-22 23:02:25.066 7 INFO nova.compute.manager [-] [instance: c9584f78-d987-4e70-b0d6-1d2618ac2cda] VM Stopped (Lifecycle Event)
