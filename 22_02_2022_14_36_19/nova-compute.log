Build Started 22_02_2022_14_36_19
2022-02-22 16:39:14.613 8 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 16:39:18.576 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 16:39:19.493 7 INFO nova.virt.driver [req-3020ca85-264b-4a61-8d66-c6334b3fc446 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 16:39:19.882 7 INFO nova.compute.provider_config [req-3020ca85-264b-4a61-8d66-c6334b3fc446 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 16:39:19.902 7 WARNING oslo_config.cfg [req-3020ca85-264b-4a61-8d66-c6334b3fc446 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 16:39:19.923 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 16:39:19.935 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 16:39:19.968 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 16:39:20.067 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 16:39:20.081 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 16:39:20.083 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 16:39:20.485 7 INFO nova.compute.manager [req-d3732662-3262-4595-92b2-dee76ef5b417 - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 16:39:22.316 7 INFO nova.virt.libvirt.host [req-d3732662-3262-4595-92b2-dee76ef5b417 - - - - -] kernel doesn't support AMD SEV
2022-02-22 16:40:13.451 7 INFO nova.compute.claims [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Claim successful on node rack08-server63
2022-02-22 16:40:13.857 7 INFO nova.virt.libvirt.driver [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Creating image
2022-02-22 16:40:13.862 7 INFO oslo.privsep.daemon [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpw0qnmfna/privsep.sock']
2022-02-22 16:40:15.490 7 INFO oslo.privsep.daemon [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Spawned new privsep daemon via rootwrap
2022-02-22 16:40:15.340 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 16:40:15.346 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 16:40:15.351 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 16:40:15.352 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-22 16:40:16.741 7 INFO nova.compute.manager [-] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] VM Resumed (Lifecycle Event)
2022-02-22 16:40:16.748 7 INFO nova.virt.libvirt.driver [-] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Instance spawned successfully.
2022-02-22 16:40:16.749 7 INFO nova.compute.manager [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Took 2.89 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:16.798 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:16.798 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] VM Started (Lifecycle Event)
2022-02-22 16:40:16.840 7 INFO nova.compute.manager [req-8151f011-1cf4-43bf-9869-3b743ca0c5d0 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Took 3.43 seconds to build instance.
2022-02-22 16:40:20.285 7 INFO nova.compute.manager [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Attaching volume 13869347-4835-4164-a646-8f4983de9b73 to /dev/vdb
2022-02-22 16:40:20.362 7 INFO oslo.privsep.daemon [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpece3iliu/privsep.sock']
2022-02-22 16:40:21.176 7 INFO oslo.privsep.daemon [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Spawned new privsep daemon via rootwrap
2022-02-22 16:40:20.945 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 16:40:20.953 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 16:40:20.956 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 16:40:20.956 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-22 16:40:21.501 7 WARNING os_brick.initiator.connectors.nvmeof [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:40:22.884 7 INFO os_brick.initiator.connectors.lightos [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: connect_volume called for volume 9a9e201b-4b5e-42c5-aa8b-ac4d332f054c, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9a9e201b-4b5e-42c5-aa8b-ac4d332f054c', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:40:22.917 7 INFO os_brick.initiator.connectors.lightos [req-3007456c-6896-4d90-8e10-f626cb871169 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9a9e201b-4b5e-42c5-aa8b-ac4d332f054c
2022-02-22 16:40:25.003 7 INFO nova.compute.claims [req-d458493f-9f40-4d53-8d81-4804e122a020 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Claim successful on node rack08-server63
2022-02-22 16:40:25.456 7 INFO nova.virt.libvirt.driver [req-d458493f-9f40-4d53-8d81-4804e122a020 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Creating image
2022-02-22 16:40:26.638 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] VM Resumed (Lifecycle Event)
2022-02-22 16:40:26.645 7 INFO nova.virt.libvirt.driver [-] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Instance spawned successfully.
2022-02-22 16:40:26.646 7 INFO nova.compute.manager [req-d458493f-9f40-4d53-8d81-4804e122a020 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:26.693 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:26.694 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] VM Started (Lifecycle Event)
2022-02-22 16:40:26.751 7 INFO nova.compute.manager [req-d458493f-9f40-4d53-8d81-4804e122a020 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Took 1.79 seconds to build instance.
2022-02-22 16:40:27.411 7 INFO nova.compute.claims [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Claim successful on node rack08-server63
2022-02-22 16:40:27.666 7 INFO nova.virt.libvirt.driver [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 16:40:27.747 7 INFO nova.virt.block_device [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Booting with volume fca4204d-5f38-4d70-863c-20663ffaebf7 at /dev/vda
2022-02-22 16:40:27.827 7 WARNING os_brick.initiator.connectors.nvmeof [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:40:28.099 7 INFO nova.compute.manager [req-bce8bf92-4ec4-444a-87e4-5683b7439ba2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Detaching volume 13869347-4835-4164-a646-8f4983de9b73
2022-02-22 16:40:28.155 7 INFO nova.virt.block_device [req-bce8bf92-4ec4-444a-87e4-5683b7439ba2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Attempting to driver detach volume 13869347-4835-4164-a646-8f4983de9b73 from mountpoint /dev/vdb
2022-02-22 16:40:28.174 7 INFO nova.virt.libvirt.driver [req-bce8bf92-4ec4-444a-87e4-5683b7439ba2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance bf49219a-5b9d-4879-b370-cbca7a8e8c60 from the persistent domain config.
2022-02-22 16:40:28.315 7 INFO nova.virt.libvirt.driver [req-bce8bf92-4ec4-444a-87e4-5683b7439ba2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance bf49219a-5b9d-4879-b370-cbca7a8e8c60 from the live domain config.
2022-02-22 16:40:28.318 7 INFO os_brick.initiator.connectors.lightos [req-bce8bf92-4ec4-444a-87e4-5683b7439ba2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9a9e201b-4b5e-42c5-aa8b-ac4d332f054c
2022-02-22 16:40:29.368 7 INFO nova.virt.libvirt.driver [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Creating image
2022-02-22 16:40:29.379 7 INFO os_brick.initiator.connectors.lightos [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: connect_volume called for volume 2a01e4a2-16ac-4f80-b1da-b4369b5fad92, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '2a01e4a2-16ac-4f80-b1da-b4369b5fad92', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:40:29.382 7 INFO os_brick.initiator.connectors.lightos [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 2a01e4a2-16ac-4f80-b1da-b4369b5fad92
2022-02-22 16:40:30.218 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] VM Resumed (Lifecycle Event)
2022-02-22 16:40:30.225 7 INFO nova.virt.libvirt.driver [-] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Instance spawned successfully.
2022-02-22 16:40:30.226 7 INFO nova.compute.manager [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Took 0.86 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:30.271 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:30.272 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] VM Started (Lifecycle Event)
2022-02-22 16:40:30.311 7 INFO nova.compute.manager [req-ea5e7a5a-6dec-4d29-a7db-173732135a7a 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Took 2.94 seconds to build instance.
2022-02-22 16:40:31.614 7 INFO nova.compute.claims [req-619539ce-1d9c-41a6-a581-0c1b23022530 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Claim successful on node rack08-server63
2022-02-22 16:40:32.000 7 INFO nova.virt.libvirt.driver [req-619539ce-1d9c-41a6-a581-0c1b23022530 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Creating image
2022-02-22 16:40:32.726 7 INFO nova.compute.claims [req-4b543685-3dd7-4457-88c5-91a834743ae7 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Claim successful on node rack08-server63
2022-02-22 16:40:33.095 7 INFO nova.virt.libvirt.driver [req-4b543685-3dd7-4457-88c5-91a834743ae7 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Creating image
2022-02-22 16:40:33.161 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] VM Resumed (Lifecycle Event)
2022-02-22 16:40:33.168 7 INFO nova.virt.libvirt.driver [-] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Instance spawned successfully.
2022-02-22 16:40:33.169 7 INFO nova.compute.manager [req-619539ce-1d9c-41a6-a581-0c1b23022530 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:33.177 7 INFO nova.compute.claims [req-bf7b2420-1ec9-4748-91b8-6db646673363 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Claim successful on node rack08-server63
2022-02-22 16:40:33.232 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:33.233 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] VM Started (Lifecycle Event)
2022-02-22 16:40:33.279 7 INFO nova.compute.manager [req-619539ce-1d9c-41a6-a581-0c1b23022530 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Took 1.70 seconds to build instance.
2022-02-22 16:40:33.574 7 INFO nova.virt.libvirt.driver [req-bf7b2420-1ec9-4748-91b8-6db646673363 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Creating image
2022-02-22 16:40:34.291 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] VM Resumed (Lifecycle Event)
2022-02-22 16:40:34.298 7 INFO nova.virt.libvirt.driver [-] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Instance spawned successfully.
2022-02-22 16:40:34.299 7 INFO nova.compute.manager [req-4b543685-3dd7-4457-88c5-91a834743ae7 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:34.343 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:34.344 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] VM Started (Lifecycle Event)
2022-02-22 16:40:34.378 7 INFO nova.compute.manager [req-4b543685-3dd7-4457-88c5-91a834743ae7 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Took 1.69 seconds to build instance.
2022-02-22 16:40:34.742 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] VM Resumed (Lifecycle Event)
2022-02-22 16:40:34.750 7 INFO nova.virt.libvirt.driver [-] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Instance spawned successfully.
2022-02-22 16:40:34.751 7 INFO nova.compute.manager [req-bf7b2420-1ec9-4748-91b8-6db646673363 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:34.794 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:34.794 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] VM Started (Lifecycle Event)
2022-02-22 16:40:34.831 7 INFO nova.compute.manager [req-bf7b2420-1ec9-4748-91b8-6db646673363 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Took 1.69 seconds to build instance.
2022-02-22 16:40:36.977 7 INFO nova.compute.manager [req-f68417ef-1774-4402-af46-ba6dd4f10377 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Attaching volume 9138376a-6444-4425-b5ed-e8b7483ea4c2 to /dev/vdb
2022-02-22 16:40:37.069 7 WARNING os_brick.initiator.connectors.nvmeof [req-f68417ef-1774-4402-af46-ba6dd4f10377 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:40:37.102 7 INFO nova.compute.manager [req-1fbe749e-0825-411f-8049-6b7aa21c12e5 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Attaching volume 7f038cc6-9eae-473e-ae63-0b0bedc0280f to /dev/vdb
2022-02-22 16:40:37.203 7 WARNING os_brick.initiator.connectors.nvmeof [req-1fbe749e-0825-411f-8049-6b7aa21c12e5 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:40:38.435 7 INFO os_brick.initiator.connectors.lightos [req-f68417ef-1774-4402-af46-ba6dd4f10377 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: connect_volume called for volume 64e32865-83e8-48bc-aed7-5a27ba9ccf61, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '64e32865-83e8-48bc-aed7-5a27ba9ccf61', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:40:38.439 7 INFO os_brick.initiator.connectors.lightos [req-f68417ef-1774-4402-af46-ba6dd4f10377 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 64e32865-83e8-48bc-aed7-5a27ba9ccf61
2022-02-22 16:40:38.667 7 INFO os_brick.initiator.connectors.lightos [req-1fbe749e-0825-411f-8049-6b7aa21c12e5 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: connect_volume called for volume 12239699-af19-4c0b-8f19-78193973f2c7, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '12239699-af19-4c0b-8f19-78193973f2c7', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:40:38.670 7 INFO os_brick.initiator.connectors.lightos [req-1fbe749e-0825-411f-8049-6b7aa21c12e5 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 12239699-af19-4c0b-8f19-78193973f2c7
2022-02-22 16:40:39.467 7 INFO nova.compute.manager [req-1942c2b7-3605-4af6-b2ff-1f00a97eba1f 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Attaching volume 9138376a-6444-4425-b5ed-e8b7483ea4c2 to /dev/vdb
2022-02-22 16:40:39.554 7 WARNING os_brick.initiator.connectors.nvmeof [req-1942c2b7-3605-4af6-b2ff-1f00a97eba1f 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:40:39.704 7 INFO nova.compute.manager [req-59c2d968-ef56-46bb-b994-af76aa0f36fb 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Detaching volume 7f038cc6-9eae-473e-ae63-0b0bedc0280f
2022-02-22 16:40:39.760 7 INFO nova.virt.block_device [req-59c2d968-ef56-46bb-b994-af76aa0f36fb 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Attempting to driver detach volume 7f038cc6-9eae-473e-ae63-0b0bedc0280f from mountpoint /dev/vdb
2022-02-22 16:40:39.780 7 INFO nova.virt.libvirt.driver [req-59c2d968-ef56-46bb-b994-af76aa0f36fb 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance acaf0463-e2b9-4dc0-9a82-d82a1e967b8a from the persistent domain config.
2022-02-22 16:40:39.921 7 INFO nova.virt.libvirt.driver [req-59c2d968-ef56-46bb-b994-af76aa0f36fb 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance acaf0463-e2b9-4dc0-9a82-d82a1e967b8a from the live domain config.
2022-02-22 16:40:39.924 7 INFO os_brick.initiator.connectors.lightos [req-59c2d968-ef56-46bb-b994-af76aa0f36fb 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 12239699-af19-4c0b-8f19-78193973f2c7
2022-02-22 16:40:40.909 7 INFO os_brick.initiator.connectors.lightos [req-1942c2b7-3605-4af6-b2ff-1f00a97eba1f 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: connect_volume called for volume 64e32865-83e8-48bc-aed7-5a27ba9ccf61, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '64e32865-83e8-48bc-aed7-5a27ba9ccf61', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:40:40.910 7 INFO os_brick.initiator.connectors.lightos [req-1942c2b7-3605-4af6-b2ff-1f00a97eba1f 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 64e32865-83e8-48bc-aed7-5a27ba9ccf61
2022-02-22 16:40:42.020 7 INFO nova.compute.manager [req-daad85cc-95b9-4201-b296-82207c2a0fdb 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Detaching volume 9138376a-6444-4425-b5ed-e8b7483ea4c2
2022-02-22 16:40:42.080 7 INFO nova.virt.block_device [req-daad85cc-95b9-4201-b296-82207c2a0fdb 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Attempting to driver detach volume 9138376a-6444-4425-b5ed-e8b7483ea4c2 from mountpoint /dev/vdb
2022-02-22 16:40:42.099 7 INFO nova.virt.libvirt.driver [req-daad85cc-95b9-4201-b296-82207c2a0fdb 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Successfully detached device vdb from instance 5a7f0ae2-09c7-49c1-b219-1db474e6edaf from the persistent domain config.
2022-02-22 16:40:42.238 7 INFO nova.virt.libvirt.driver [req-daad85cc-95b9-4201-b296-82207c2a0fdb 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Successfully detached device vdb from instance 5a7f0ae2-09c7-49c1-b219-1db474e6edaf from the live domain config.
2022-02-22 16:40:42.307 7 INFO nova.virt.libvirt.driver [req-daad85cc-95b9-4201-b296-82207c2a0fdb 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Detected multiple connections on this host for volume: 9138376a-6444-4425-b5ed-e8b7483ea4c2, skipping target disconnect.
2022-02-22 16:40:43.182 7 INFO nova.compute.claims [req-0d798a0b-56aa-4c3a-94f6-61aa947fd11e 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Claim successful on node rack08-server63
2022-02-22 16:40:43.568 7 INFO nova.virt.libvirt.driver [req-0d798a0b-56aa-4c3a-94f6-61aa947fd11e 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Creating image
2022-02-22 16:40:44.480 7 INFO nova.compute.manager [req-105cc618-2356-46c3-8a57-90b9a92d358c 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Detaching volume 9138376a-6444-4425-b5ed-e8b7483ea4c2
2022-02-22 16:40:44.543 7 INFO nova.virt.block_device [req-105cc618-2356-46c3-8a57-90b9a92d358c 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Attempting to driver detach volume 9138376a-6444-4425-b5ed-e8b7483ea4c2 from mountpoint /dev/vdb
2022-02-22 16:40:44.561 7 INFO nova.virt.libvirt.driver [req-105cc618-2356-46c3-8a57-90b9a92d358c 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Successfully detached device vdb from instance 7769286a-4f2e-4c4a-9a9f-6b21ca895a86 from the persistent domain config.
2022-02-22 16:40:44.726 7 INFO nova.virt.libvirt.driver [req-105cc618-2356-46c3-8a57-90b9a92d358c 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Successfully detached device vdb from instance 7769286a-4f2e-4c4a-9a9f-6b21ca895a86 from the live domain config.
2022-02-22 16:40:44.776 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] VM Resumed (Lifecycle Event)
2022-02-22 16:40:44.783 7 INFO nova.virt.libvirt.driver [-] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Instance spawned successfully.
2022-02-22 16:40:44.783 7 INFO nova.compute.manager [req-0d798a0b-56aa-4c3a-94f6-61aa947fd11e 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 16:40:44.838 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:40:44.839 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] VM Started (Lifecycle Event)
2022-02-22 16:40:44.872 7 INFO nova.compute.manager [req-0d798a0b-56aa-4c3a-94f6-61aa947fd11e 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Took 1.73 seconds to build instance.
2022-02-22 16:40:48.737 7 INFO nova.compute.manager [req-6cfeac21-e875-4d06-bb98-126e8855092b 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Attaching volume 8adde113-e666-405b-9739-79903b0e6375 to /dev/vdb
2022-02-22 16:40:48.839 7 WARNING os_brick.initiator.connectors.nvmeof [req-6cfeac21-e875-4d06-bb98-126e8855092b 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:41:10.945 7 INFO nova.compute.claims [req-fa8a60ed-8e28-4cd3-b50b-6d2985adcf22 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Claim successful on node rack08-server63
2022-02-22 16:41:11.356 7 INFO nova.virt.libvirt.driver [req-fa8a60ed-8e28-4cd3-b50b-6d2985adcf22 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Creating image
2022-02-22 16:41:12.551 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 62488c2f-531f-485a-90fc-22d35936633b] VM Resumed (Lifecycle Event)
2022-02-22 16:41:12.559 7 INFO nova.virt.libvirt.driver [-] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Instance spawned successfully.
2022-02-22 16:41:12.560 7 INFO nova.compute.manager [req-fa8a60ed-8e28-4cd3-b50b-6d2985adcf22 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 16:41:12.608 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 62488c2f-531f-485a-90fc-22d35936633b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:41:12.609 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 62488c2f-531f-485a-90fc-22d35936633b] VM Started (Lifecycle Event)
2022-02-22 16:41:12.643 7 INFO nova.compute.manager [req-fa8a60ed-8e28-4cd3-b50b-6d2985adcf22 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Took 1.74 seconds to build instance.
2022-02-22 16:41:16.347 7 INFO nova.compute.manager [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Terminating instance
2022-02-22 16:41:16.708 7 INFO nova.virt.libvirt.driver [-] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Instance destroyed successfully.
2022-02-22 16:41:16.728 7 INFO nova.virt.libvirt.driver [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Deleting instance files /var/lib/nova/instances/62488c2f-531f-485a-90fc-22d35936633b_del
2022-02-22 16:41:16.729 7 INFO nova.virt.libvirt.driver [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Deletion of /var/lib/nova/instances/62488c2f-531f-485a-90fc-22d35936633b_del complete
2022-02-22 16:41:16.799 7 INFO nova.virt.libvirt.host [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] UEFI support detected
2022-02-22 16:41:16.801 7 INFO nova.compute.manager [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:41:16.867 7 INFO nova.compute.manager [-] [instance: 62488c2f-531f-485a-90fc-22d35936633b] Took 0.06 seconds to deallocate network for instance.
2022-02-22 16:41:17.063 7 INFO nova.scheduler.client.report [req-c324a5c8-0404-4ce5-b1db-a40fbb5326d2 59ec3ebd4a0b458ebec638bc35402b41 d86af25bafc7490c9c6196c964acdedf - default default] Deleted allocations for instance 62488c2f-531f-485a-90fc-22d35936633b
2022-02-22 16:41:31.706 7 INFO nova.compute.manager [-] [instance: 62488c2f-531f-485a-90fc-22d35936633b] VM Stopped (Lifecycle Event)
2022-02-22 16:41:44.994 7 INFO os_brick.initiator.connectors.lightos [req-6cfeac21-e875-4d06-bb98-126e8855092b 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: connect_volume called for volume 1cf473dd-3ae9-4a0b-b93e-b51f7a0c474b, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1cf473dd-3ae9-4a0b-b93e-b51f7a0c474b', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:41:44.997 7 INFO os_brick.initiator.connectors.lightos [req-6cfeac21-e875-4d06-bb98-126e8855092b 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1cf473dd-3ae9-4a0b-b93e-b51f7a0c474b
2022-02-22 16:41:46.361 7 INFO nova.compute.manager [req-32be24a3-ce42-47be-ae81-3ec4818ed3c9 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Detaching volume 8adde113-e666-405b-9739-79903b0e6375
2022-02-22 16:41:46.417 7 INFO nova.virt.block_device [req-32be24a3-ce42-47be-ae81-3ec4818ed3c9 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Attempting to driver detach volume 8adde113-e666-405b-9739-79903b0e6375 from mountpoint /dev/vdb
2022-02-22 16:41:46.439 7 INFO nova.virt.libvirt.driver [req-32be24a3-ce42-47be-ae81-3ec4818ed3c9 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance 5ccfd949-8031-4667-a076-f29509d07f76 from the persistent domain config.
2022-02-22 16:41:46.582 7 INFO nova.virt.libvirt.driver [req-32be24a3-ce42-47be-ae81-3ec4818ed3c9 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Successfully detached device vdb from instance 5ccfd949-8031-4667-a076-f29509d07f76 from the live domain config.
2022-02-22 16:41:46.585 7 INFO os_brick.initiator.connectors.lightos [req-32be24a3-ce42-47be-ae81-3ec4818ed3c9 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1cf473dd-3ae9-4a0b-b93e-b51f7a0c474b
2022-02-22 16:41:49.817 7 INFO nova.compute.manager [req-0b5d2103-1e1d-42ee-bfa1-881f85726cce 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Terminating instance
2022-02-22 16:41:50.171 7 INFO nova.virt.libvirt.driver [-] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Instance destroyed successfully.
2022-02-22 16:41:50.188 7 INFO nova.virt.libvirt.driver [req-0b5d2103-1e1d-42ee-bfa1-881f85726cce 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Deleting instance files /var/lib/nova/instances/5ccfd949-8031-4667-a076-f29509d07f76_del
2022-02-22 16:41:50.189 7 INFO nova.virt.libvirt.driver [req-0b5d2103-1e1d-42ee-bfa1-881f85726cce 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Deletion of /var/lib/nova/instances/5ccfd949-8031-4667-a076-f29509d07f76_del complete
2022-02-22 16:41:50.260 7 INFO nova.compute.manager [req-0b5d2103-1e1d-42ee-bfa1-881f85726cce 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:41:50.330 7 INFO nova.compute.manager [-] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:41:50.529 7 INFO nova.scheduler.client.report [req-0b5d2103-1e1d-42ee-bfa1-881f85726cce 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Deleted allocations for instance 5ccfd949-8031-4667-a076-f29509d07f76
2022-02-22 16:41:52.224 7 INFO nova.compute.manager [req-8ca72593-36e1-47cc-8ea5-989ab6a380c2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Terminating instance
2022-02-22 16:41:52.565 7 INFO nova.virt.libvirt.driver [-] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Instance destroyed successfully.
2022-02-22 16:41:52.580 7 INFO nova.virt.libvirt.driver [req-8ca72593-36e1-47cc-8ea5-989ab6a380c2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Deleting instance files /var/lib/nova/instances/acaf0463-e2b9-4dc0-9a82-d82a1e967b8a_del
2022-02-22 16:41:52.582 7 INFO nova.virt.libvirt.driver [req-8ca72593-36e1-47cc-8ea5-989ab6a380c2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Deletion of /var/lib/nova/instances/acaf0463-e2b9-4dc0-9a82-d82a1e967b8a_del complete
2022-02-22 16:41:52.651 7 INFO nova.compute.manager [req-8ca72593-36e1-47cc-8ea5-989ab6a380c2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:41:52.722 7 INFO nova.compute.manager [-] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:41:52.919 7 INFO nova.scheduler.client.report [req-8ca72593-36e1-47cc-8ea5-989ab6a380c2 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Deleted allocations for instance acaf0463-e2b9-4dc0-9a82-d82a1e967b8a
2022-02-22 16:41:53.471 7 INFO nova.compute.manager [req-6a9c052a-9c8e-4ece-b806-3bf24481c8c4 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Terminating instance
2022-02-22 16:41:53.826 7 INFO nova.virt.libvirt.driver [-] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Instance destroyed successfully.
2022-02-22 16:41:53.843 7 INFO nova.virt.libvirt.driver [req-6a9c052a-9c8e-4ece-b806-3bf24481c8c4 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Deleting instance files /var/lib/nova/instances/51668ecd-91b8-4fd5-ac7c-1162f00071a0_del
2022-02-22 16:41:53.845 7 INFO nova.virt.libvirt.driver [req-6a9c052a-9c8e-4ece-b806-3bf24481c8c4 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Deletion of /var/lib/nova/instances/51668ecd-91b8-4fd5-ac7c-1162f00071a0_del complete
2022-02-22 16:41:53.912 7 INFO nova.compute.manager [req-6a9c052a-9c8e-4ece-b806-3bf24481c8c4 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:41:54.071 7 INFO nova.compute.manager [-] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] Took 0.16 seconds to deallocate network for instance.
2022-02-22 16:41:54.267 7 INFO nova.scheduler.client.report [req-6a9c052a-9c8e-4ece-b806-3bf24481c8c4 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Deleted allocations for instance 51668ecd-91b8-4fd5-ac7c-1162f00071a0
2022-02-22 16:41:55.874 7 INFO nova.compute.manager [req-e2dc85f6-345c-4f71-af18-ec191a1f3b9a 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Terminating instance
2022-02-22 16:41:56.207 7 INFO nova.virt.libvirt.driver [-] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Instance destroyed successfully.
2022-02-22 16:41:56.223 7 INFO nova.virt.libvirt.driver [req-e2dc85f6-345c-4f71-af18-ec191a1f3b9a 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Deleting instance files /var/lib/nova/instances/bf49219a-5b9d-4879-b370-cbca7a8e8c60_del
2022-02-22 16:41:56.225 7 INFO nova.virt.libvirt.driver [req-e2dc85f6-345c-4f71-af18-ec191a1f3b9a 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Deletion of /var/lib/nova/instances/bf49219a-5b9d-4879-b370-cbca7a8e8c60_del complete
2022-02-22 16:41:56.293 7 INFO nova.compute.manager [req-e2dc85f6-345c-4f71-af18-ec191a1f3b9a 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:41:56.359 7 INFO nova.compute.manager [-] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:41:56.550 7 INFO nova.scheduler.client.report [req-e2dc85f6-345c-4f71-af18-ec191a1f3b9a 1875d138cd07497a9c04dbaadb2c33b2 9b5886e31be24939a05f8649249b6ddb - default default] Deleted allocations for instance bf49219a-5b9d-4879-b370-cbca7a8e8c60
2022-02-22 16:42:03.722 7 INFO nova.compute.claims [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Claim successful on node rack08-server63
2022-02-22 16:42:03.985 7 INFO nova.virt.libvirt.driver [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 16:42:04.071 7 INFO nova.virt.block_device [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Booting with volume d7e88890-2642-44b1-9e05-d19f232e056a at /dev/vda
2022-02-22 16:42:04.159 7 WARNING os_brick.initiator.connectors.nvmeof [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:42:05.169 7 INFO nova.compute.manager [-] [instance: 5ccfd949-8031-4667-a076-f29509d07f76] VM Stopped (Lifecycle Event)
2022-02-22 16:42:05.669 7 INFO nova.virt.libvirt.driver [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Creating image
2022-02-22 16:42:05.679 7 INFO os_brick.initiator.connectors.lightos [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: connect_volume called for volume c4d77742-77e9-489e-8cc8-6f10bc7c7ba0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c4d77742-77e9-489e-8cc8-6f10bc7c7ba0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:42:05.682 7 INFO os_brick.initiator.connectors.lightos [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c4d77742-77e9-489e-8cc8-6f10bc7c7ba0
2022-02-22 16:42:06.530 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] VM Resumed (Lifecycle Event)
2022-02-22 16:42:06.537 7 INFO nova.virt.libvirt.driver [-] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Instance spawned successfully.
2022-02-22 16:42:06.537 7 INFO nova.compute.manager [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Took 0.87 seconds to spawn the instance on the hypervisor.
2022-02-22 16:42:06.586 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:42:06.586 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] VM Started (Lifecycle Event)
2022-02-22 16:42:06.624 7 INFO nova.compute.manager [req-8a321bec-30dd-45d8-aa9b-7cdd8087a86b 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Took 2.94 seconds to build instance.
2022-02-22 16:42:07.562 7 INFO nova.compute.manager [-] [instance: acaf0463-e2b9-4dc0-9a82-d82a1e967b8a] VM Stopped (Lifecycle Event)
2022-02-22 16:42:07.849 7 INFO nova.compute.manager [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Terminating instance
2022-02-22 16:42:08.206 7 INFO nova.virt.libvirt.driver [-] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Instance destroyed successfully.
2022-02-22 16:42:08.273 7 INFO os_brick.initiator.connectors.lightos [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c4d77742-77e9-489e-8cc8-6f10bc7c7ba0
2022-02-22 16:42:08.285 7 INFO nova.virt.libvirt.driver [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Deleting instance files /var/lib/nova/instances/220410a7-538f-40ce-a07d-dff0313181cd_del
2022-02-22 16:42:08.285 7 INFO nova.virt.libvirt.driver [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Deletion of /var/lib/nova/instances/220410a7-538f-40ce-a07d-dff0313181cd_del complete
2022-02-22 16:42:08.358 7 INFO nova.compute.manager [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 16:42:08.430 7 INFO nova.compute.manager [-] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:42:08.823 7 INFO nova.compute.manager [-] [instance: 51668ecd-91b8-4fd5-ac7c-1162f00071a0] VM Stopped (Lifecycle Event)
2022-02-22 16:42:09.677 7 INFO nova.compute.manager [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-22 16:42:09.868 7 INFO nova.scheduler.client.report [req-1f08ec6f-9695-48c4-9880-2a8d90a7341d 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Deleted allocations for instance 220410a7-538f-40ce-a07d-dff0313181cd
2022-02-22 16:42:11.205 7 INFO nova.compute.manager [-] [instance: bf49219a-5b9d-4879-b370-cbca7a8e8c60] VM Stopped (Lifecycle Event)
2022-02-22 16:42:12.755 7 INFO nova.compute.manager [req-43da3092-349f-41e8-b77e-0bbffc33b8af 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Terminating instance
2022-02-22 16:42:13.091 7 INFO nova.virt.libvirt.driver [-] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Instance destroyed successfully.
2022-02-22 16:42:13.106 7 INFO nova.virt.libvirt.driver [req-43da3092-349f-41e8-b77e-0bbffc33b8af 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Deleting instance files /var/lib/nova/instances/7769286a-4f2e-4c4a-9a9f-6b21ca895a86_del
2022-02-22 16:42:13.107 7 INFO nova.virt.libvirt.driver [req-43da3092-349f-41e8-b77e-0bbffc33b8af 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Deletion of /var/lib/nova/instances/7769286a-4f2e-4c4a-9a9f-6b21ca895a86_del complete
2022-02-22 16:42:13.173 7 INFO nova.compute.manager [req-43da3092-349f-41e8-b77e-0bbffc33b8af 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 16:42:13.238 7 INFO nova.compute.manager [-] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] Took 0.06 seconds to deallocate network for instance.
2022-02-22 16:42:13.438 7 INFO nova.scheduler.client.report [req-43da3092-349f-41e8-b77e-0bbffc33b8af 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Deleted allocations for instance 7769286a-4f2e-4c4a-9a9f-6b21ca895a86
2022-02-22 16:42:13.984 7 INFO nova.compute.manager [req-29513276-6f31-44dc-9d60-e2d1765cff61 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Terminating instance
2022-02-22 16:42:14.326 7 INFO nova.virt.libvirt.driver [-] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Instance destroyed successfully.
2022-02-22 16:42:14.345 7 INFO nova.virt.libvirt.driver [req-29513276-6f31-44dc-9d60-e2d1765cff61 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Deleting instance files /var/lib/nova/instances/5a7f0ae2-09c7-49c1-b219-1db474e6edaf_del
2022-02-22 16:42:14.346 7 INFO nova.virt.libvirt.driver [req-29513276-6f31-44dc-9d60-e2d1765cff61 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Deletion of /var/lib/nova/instances/5a7f0ae2-09c7-49c1-b219-1db474e6edaf_del complete
2022-02-22 16:42:14.416 7 INFO nova.compute.manager [req-29513276-6f31-44dc-9d60-e2d1765cff61 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:42:14.486 7 INFO nova.compute.manager [-] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:42:14.652 7 INFO nova.scheduler.client.report [req-29513276-6f31-44dc-9d60-e2d1765cff61 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Deleted allocations for instance 5a7f0ae2-09c7-49c1-b219-1db474e6edaf
2022-02-22 16:42:15.222 7 INFO nova.compute.manager [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Terminating instance
2022-02-22 16:42:15.567 7 INFO nova.virt.libvirt.driver [-] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Instance destroyed successfully.
2022-02-22 16:42:15.634 7 INFO os_brick.initiator.connectors.lightos [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 2a01e4a2-16ac-4f80-b1da-b4369b5fad92
2022-02-22 16:42:15.645 7 INFO nova.virt.libvirt.driver [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Deleting instance files /var/lib/nova/instances/3f1bcfc2-d74d-4639-86a4-08ed29716fc9_del
2022-02-22 16:42:15.645 7 INFO nova.virt.libvirt.driver [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Deletion of /var/lib/nova/instances/3f1bcfc2-d74d-4639-86a4-08ed29716fc9_del complete
2022-02-22 16:42:15.713 7 INFO nova.compute.manager [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-22 16:42:15.784 7 INFO nova.compute.manager [-] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:42:17.042 7 INFO nova.compute.manager [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] Took 1.26 seconds to detach 1 volumes for instance.
2022-02-22 16:42:17.233 7 INFO nova.scheduler.client.report [req-fd528585-20ed-4952-bb68-72cd40e50bbc 6cad10366fea4c868aee30006845000e 7d68bf9cae5141598b81dbf721b6d9c9 - default default] Deleted allocations for instance 3f1bcfc2-d74d-4639-86a4-08ed29716fc9
2022-02-22 16:42:23.206 7 INFO nova.compute.manager [-] [instance: 220410a7-538f-40ce-a07d-dff0313181cd] VM Stopped (Lifecycle Event)
2022-02-22 16:42:24.065 7 INFO nova.compute.claims [req-d735f26a-c8b3-4d07-907e-2a5834c123e3 cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Claim successful on node rack08-server63
2022-02-22 16:42:24.477 7 INFO nova.virt.libvirt.driver [req-d735f26a-c8b3-4d07-907e-2a5834c123e3 cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Creating image
2022-02-22 16:42:26.446 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] VM Resumed (Lifecycle Event)
2022-02-22 16:42:26.453 7 INFO nova.virt.libvirt.driver [-] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Instance spawned successfully.
2022-02-22 16:42:26.454 7 INFO nova.compute.manager [req-d735f26a-c8b3-4d07-907e-2a5834c123e3 cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Took 1.98 seconds to spawn the instance on the hypervisor.
2022-02-22 16:42:26.502 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:42:26.502 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] VM Started (Lifecycle Event)
2022-02-22 16:42:26.538 7 INFO nova.compute.manager [req-d735f26a-c8b3-4d07-907e-2a5834c123e3 cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Took 2.51 seconds to build instance.
2022-02-22 16:42:27.165 7 INFO nova.virt.libvirt.driver [req-6f140d2d-0341-48fa-b541-6d969cdddcbe cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Ignoring supplied device name: /dev/vdb
2022-02-22 16:42:27.334 7 INFO nova.compute.manager [req-6f140d2d-0341-48fa-b541-6d969cdddcbe cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Attaching volume cfb56570-17e6-470a-a037-f4c1128cb0cc to /dev/vdb
2022-02-22 16:42:27.428 7 WARNING os_brick.initiator.connectors.nvmeof [req-6f140d2d-0341-48fa-b541-6d969cdddcbe cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:42:28.090 7 INFO nova.compute.manager [-] [instance: 7769286a-4f2e-4c4a-9a9f-6b21ca895a86] VM Stopped (Lifecycle Event)
2022-02-22 16:42:28.792 7 INFO os_brick.initiator.connectors.lightos [req-6f140d2d-0341-48fa-b541-6d969cdddcbe cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] LIGHTOS: connect_volume called for volume 1ab1356d-e43b-4b6d-85e8-41b39b5fac13, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1ab1356d-e43b-4b6d-85e8-41b39b5fac13', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:42:28.796 7 INFO os_brick.initiator.connectors.lightos [req-6f140d2d-0341-48fa-b541-6d969cdddcbe cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1ab1356d-e43b-4b6d-85e8-41b39b5fac13
2022-02-22 16:42:29.324 7 INFO nova.compute.manager [-] [instance: 5a7f0ae2-09c7-49c1-b219-1db474e6edaf] VM Stopped (Lifecycle Event)
2022-02-22 16:42:30.564 7 INFO nova.compute.manager [-] [instance: 3f1bcfc2-d74d-4639-86a4-08ed29716fc9] VM Stopped (Lifecycle Event)
2022-02-22 16:42:30.595 7 INFO nova.compute.manager [req-41678462-784f-4c09-a31c-53de5b7581de e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Cinder extended volume cfb56570-17e6-470a-a037-f4c1128cb0cc; extending it to detect new size
2022-02-22 16:42:30.666 7 INFO os_brick.initiator.connectors.lightos [req-41678462-784f-4c09-a31c-53de5b7581de e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1ab1356d-e43b-4b6d-85e8-41b39b5fac13
2022-02-22 16:42:31.359 7 INFO nova.compute.manager [req-363d98c1-c06f-4e88-b3f9-8770dd988c2f cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Detaching volume cfb56570-17e6-470a-a037-f4c1128cb0cc
2022-02-22 16:42:31.427 7 INFO nova.virt.block_device [req-363d98c1-c06f-4e88-b3f9-8770dd988c2f cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Attempting to driver detach volume cfb56570-17e6-470a-a037-f4c1128cb0cc from mountpoint /dev/vdb
2022-02-22 16:42:31.449 7 INFO nova.virt.libvirt.driver [req-363d98c1-c06f-4e88-b3f9-8770dd988c2f cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] Successfully detached device vdb from instance 5f0174b2-dfd6-4989-9e54-29a508f9bab4 from the persistent domain config.
2022-02-22 16:42:31.590 7 INFO nova.virt.libvirt.driver [req-363d98c1-c06f-4e88-b3f9-8770dd988c2f cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] Successfully detached device vdb from instance 5f0174b2-dfd6-4989-9e54-29a508f9bab4 from the live domain config.
2022-02-22 16:42:31.592 7 INFO os_brick.initiator.connectors.lightos [req-363d98c1-c06f-4e88-b3f9-8770dd988c2f cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1ab1356d-e43b-4b6d-85e8-41b39b5fac13
2022-02-22 16:42:33.631 7 INFO nova.compute.manager [req-67bb51c7-9c82-430b-8a48-c3ac84ab403a cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Terminating instance
2022-02-22 16:42:33.976 7 INFO nova.virt.libvirt.driver [-] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Instance destroyed successfully.
2022-02-22 16:42:33.991 7 INFO nova.virt.libvirt.driver [req-67bb51c7-9c82-430b-8a48-c3ac84ab403a cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Deleting instance files /var/lib/nova/instances/5f0174b2-dfd6-4989-9e54-29a508f9bab4_del
2022-02-22 16:42:33.992 7 INFO nova.virt.libvirt.driver [req-67bb51c7-9c82-430b-8a48-c3ac84ab403a cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Deletion of /var/lib/nova/instances/5f0174b2-dfd6-4989-9e54-29a508f9bab4_del complete
2022-02-22 16:42:34.057 7 INFO nova.compute.manager [req-67bb51c7-9c82-430b-8a48-c3ac84ab403a cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 16:42:34.126 7 INFO nova.compute.manager [-] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:42:34.303 7 INFO nova.scheduler.client.report [req-67bb51c7-9c82-430b-8a48-c3ac84ab403a cf8f48dca75a4b22bea0075fbcae5641 a6c8ddb9b74e4ad9bc52c2dc86412ab6 - default default] Deleted allocations for instance 5f0174b2-dfd6-4989-9e54-29a508f9bab4
2022-02-22 16:42:48.975 7 INFO nova.compute.manager [-] [instance: 5f0174b2-dfd6-4989-9e54-29a508f9bab4] VM Stopped (Lifecycle Event)
2022-02-22 16:43:50.819 7 INFO nova.compute.claims [req-7eb5497e-bc44-4379-ac86-bd1a381ff2a9 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Claim successful on node rack08-server63
2022-02-22 16:43:51.216 7 INFO nova.virt.libvirt.driver [req-7eb5497e-bc44-4379-ac86-bd1a381ff2a9 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Creating image
2022-02-22 16:43:52.401 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] VM Resumed (Lifecycle Event)
2022-02-22 16:43:52.412 7 INFO nova.virt.libvirt.driver [-] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Instance spawned successfully.
2022-02-22 16:43:52.412 7 INFO nova.compute.manager [req-7eb5497e-bc44-4379-ac86-bd1a381ff2a9 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 16:43:52.457 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:43:52.458 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] VM Started (Lifecycle Event)
2022-02-22 16:43:52.502 7 INFO nova.compute.manager [req-7eb5497e-bc44-4379-ac86-bd1a381ff2a9 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Took 1.72 seconds to build instance.
2022-02-22 16:44:05.847 7 INFO nova.virt.libvirt.driver [req-084c54f2-eae1-4d35-a8c8-578f2cc181a5 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Ignoring supplied device name: /dev/vdb
2022-02-22 16:44:06.012 7 INFO nova.compute.manager [req-084c54f2-eae1-4d35-a8c8-578f2cc181a5 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Attaching volume 1a73f4c5-796b-451e-93a9-2413b3f7230b to /dev/vdb
2022-02-22 16:44:06.098 7 WARNING os_brick.initiator.connectors.nvmeof [req-084c54f2-eae1-4d35-a8c8-578f2cc181a5 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:44:07.452 7 INFO os_brick.initiator.connectors.lightos [req-084c54f2-eae1-4d35-a8c8-578f2cc181a5 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: connect_volume called for volume 4e38fece-df14-4e2c-9fa7-de4b7cf39b70, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '4e38fece-df14-4e2c-9fa7-de4b7cf39b70', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:44:07.456 7 INFO os_brick.initiator.connectors.lightos [req-084c54f2-eae1-4d35-a8c8-578f2cc181a5 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4e38fece-df14-4e2c-9fa7-de4b7cf39b70
2022-02-22 16:44:18.910 7 INFO nova.compute.manager [req-8bbf1fdb-a63b-422d-b093-31145c2f8ea3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Detaching volume 1a73f4c5-796b-451e-93a9-2413b3f7230b
2022-02-22 16:44:18.969 7 INFO nova.virt.block_device [req-8bbf1fdb-a63b-422d-b093-31145c2f8ea3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Attempting to driver detach volume 1a73f4c5-796b-451e-93a9-2413b3f7230b from mountpoint /dev/vdb
2022-02-22 16:44:18.990 7 INFO nova.virt.libvirt.driver [req-8bbf1fdb-a63b-422d-b093-31145c2f8ea3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Successfully detached device vdb from instance d3034dbf-5ade-4c2f-b4dd-954d02c4425a from the persistent domain config.
2022-02-22 16:44:19.133 7 INFO nova.virt.libvirt.driver [req-8bbf1fdb-a63b-422d-b093-31145c2f8ea3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Successfully detached device vdb from instance d3034dbf-5ade-4c2f-b4dd-954d02c4425a from the live domain config.
2022-02-22 16:44:19.136 7 INFO os_brick.initiator.connectors.lightos [req-8bbf1fdb-a63b-422d-b093-31145c2f8ea3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 4e38fece-df14-4e2c-9fa7-de4b7cf39b70
2022-02-22 16:44:21.172 7 INFO nova.compute.manager [req-2354610d-8ead-47e7-9f8e-480a5e648619 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Terminating instance
2022-02-22 16:44:21.517 7 INFO nova.virt.libvirt.driver [-] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Instance destroyed successfully.
2022-02-22 16:44:21.533 7 INFO nova.virt.libvirt.driver [req-2354610d-8ead-47e7-9f8e-480a5e648619 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Deleting instance files /var/lib/nova/instances/d3034dbf-5ade-4c2f-b4dd-954d02c4425a_del
2022-02-22 16:44:21.534 7 INFO nova.virt.libvirt.driver [req-2354610d-8ead-47e7-9f8e-480a5e648619 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Deletion of /var/lib/nova/instances/d3034dbf-5ade-4c2f-b4dd-954d02c4425a_del complete
2022-02-22 16:44:21.600 7 INFO nova.compute.manager [req-2354610d-8ead-47e7-9f8e-480a5e648619 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 16:44:21.670 7 INFO nova.compute.manager [-] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:44:22.028 7 INFO nova.scheduler.client.report [req-2354610d-8ead-47e7-9f8e-480a5e648619 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Deleted allocations for instance d3034dbf-5ade-4c2f-b4dd-954d02c4425a
2022-02-22 16:44:29.327 7 INFO nova.compute.claims [req-e663b69f-6f2e-493c-8b0d-25b5a13539b3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Claim successful on node rack08-server63
2022-02-22 16:44:29.731 7 INFO nova.virt.libvirt.driver [req-e663b69f-6f2e-493c-8b0d-25b5a13539b3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Creating image
2022-02-22 16:44:30.858 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] VM Resumed (Lifecycle Event)
2022-02-22 16:44:30.866 7 INFO nova.virt.libvirt.driver [-] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Instance spawned successfully.
2022-02-22 16:44:30.867 7 INFO nova.compute.manager [req-e663b69f-6f2e-493c-8b0d-25b5a13539b3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 16:44:30.911 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:44:30.912 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] VM Started (Lifecycle Event)
2022-02-22 16:44:30.951 7 INFO nova.compute.manager [req-e663b69f-6f2e-493c-8b0d-25b5a13539b3 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Took 1.66 seconds to build instance.
2022-02-22 16:44:31.273 7 INFO nova.virt.libvirt.driver [req-e433ec03-71f8-4c23-bcf0-4350404f9e7e 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Ignoring supplied device name: /dev/vdb
2022-02-22 16:44:31.425 7 INFO nova.compute.manager [req-e433ec03-71f8-4c23-bcf0-4350404f9e7e 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Attaching volume 1f7c7924-9f94-41ac-8315-34b83a6f760d to /dev/vdb
2022-02-22 16:44:31.507 7 WARNING os_brick.initiator.connectors.nvmeof [req-e433ec03-71f8-4c23-bcf0-4350404f9e7e 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 16:44:32.853 7 INFO os_brick.initiator.connectors.lightos [req-e433ec03-71f8-4c23-bcf0-4350404f9e7e 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: connect_volume called for volume c40c90de-92ea-4d8f-b780-8bdbf801510f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'c40c90de-92ea-4d8f-b780-8bdbf801510f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 16:44:32.857 7 INFO os_brick.initiator.connectors.lightos [req-e433ec03-71f8-4c23-bcf0-4350404f9e7e 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c40c90de-92ea-4d8f-b780-8bdbf801510f
2022-02-22 16:44:36.514 7 INFO nova.compute.manager [-] [instance: d3034dbf-5ade-4c2f-b4dd-954d02c4425a] VM Stopped (Lifecycle Event)
2022-02-22 16:44:41.672 7 INFO nova.compute.manager [req-f90bd57e-aafa-4090-8e4a-6a6658444dfd 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Detaching volume 1f7c7924-9f94-41ac-8315-34b83a6f760d
2022-02-22 16:44:41.732 7 INFO nova.virt.block_device [req-f90bd57e-aafa-4090-8e4a-6a6658444dfd 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Attempting to driver detach volume 1f7c7924-9f94-41ac-8315-34b83a6f760d from mountpoint /dev/vdb
2022-02-22 16:44:41.750 7 INFO nova.virt.libvirt.driver [req-f90bd57e-aafa-4090-8e4a-6a6658444dfd 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Successfully detached device vdb from instance b12ce3ee-3806-4c7d-82cf-5cff9b434309 from the persistent domain config.
2022-02-22 16:44:41.760 7 INFO nova.compute.claims [req-57cc6cd2-a140-4af3-b790-7a4fb19b85d2 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Claim successful on node rack08-server63
2022-02-22 16:44:41.896 7 INFO nova.virt.libvirt.driver [req-f90bd57e-aafa-4090-8e4a-6a6658444dfd 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Successfully detached device vdb from instance b12ce3ee-3806-4c7d-82cf-5cff9b434309 from the live domain config.
2022-02-22 16:44:41.899 7 INFO os_brick.initiator.connectors.lightos [req-f90bd57e-aafa-4090-8e4a-6a6658444dfd 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid c40c90de-92ea-4d8f-b780-8bdbf801510f
2022-02-22 16:44:42.164 7 INFO nova.virt.libvirt.driver [req-57cc6cd2-a140-4af3-b790-7a4fb19b85d2 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Creating image
2022-02-22 16:44:43.404 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] VM Resumed (Lifecycle Event)
2022-02-22 16:44:43.412 7 INFO nova.virt.libvirt.driver [-] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Instance spawned successfully.
2022-02-22 16:44:43.412 7 INFO nova.compute.manager [req-57cc6cd2-a140-4af3-b790-7a4fb19b85d2 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-22 16:44:43.459 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:44:43.460 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] VM Started (Lifecycle Event)
2022-02-22 16:44:43.500 7 INFO nova.compute.manager [req-57cc6cd2-a140-4af3-b790-7a4fb19b85d2 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Took 1.78 seconds to build instance.
2022-02-22 16:44:43.932 7 INFO nova.compute.manager [req-0830c440-bef2-49c7-9df0-935b3cacc874 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Terminating instance
2022-02-22 16:44:44.029 7 INFO nova.compute.manager [req-bedf53cb-6bb7-40e6-b98b-c512e90769cf 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Terminating instance
2022-02-22 16:44:44.522 7 INFO nova.virt.libvirt.driver [-] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Instance destroyed successfully.
2022-02-22 16:44:44.527 7 INFO nova.virt.libvirt.driver [-] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Instance destroyed successfully.
2022-02-22 16:44:44.542 7 INFO nova.virt.libvirt.driver [req-0830c440-bef2-49c7-9df0-935b3cacc874 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Deleting instance files /var/lib/nova/instances/b12ce3ee-3806-4c7d-82cf-5cff9b434309_del
2022-02-22 16:44:44.543 7 INFO nova.virt.libvirt.driver [req-0830c440-bef2-49c7-9df0-935b3cacc874 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Deletion of /var/lib/nova/instances/b12ce3ee-3806-4c7d-82cf-5cff9b434309_del complete
2022-02-22 16:44:44.548 7 INFO nova.virt.libvirt.driver [req-bedf53cb-6bb7-40e6-b98b-c512e90769cf 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Deleting instance files /var/lib/nova/instances/89ac7762-6c39-4935-b591-b61ce7b0a07f_del
2022-02-22 16:44:44.550 7 INFO nova.virt.libvirt.driver [req-bedf53cb-6bb7-40e6-b98b-c512e90769cf 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Deletion of /var/lib/nova/instances/89ac7762-6c39-4935-b591-b61ce7b0a07f_del complete
2022-02-22 16:44:44.615 7 INFO nova.compute.manager [req-0830c440-bef2-49c7-9df0-935b3cacc874 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Took 0.53 seconds to destroy the instance on the hypervisor.
2022-02-22 16:44:44.621 7 INFO nova.compute.manager [req-bedf53cb-6bb7-40e6-b98b-c512e90769cf 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Took 0.46 seconds to destroy the instance on the hypervisor.
2022-02-22 16:44:44.676 7 INFO nova.compute.manager [-] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] Took 0.06 seconds to deallocate network for instance.
2022-02-22 16:44:44.699 7 INFO nova.compute.manager [-] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] Took 0.08 seconds to deallocate network for instance.
2022-02-22 16:44:44.853 7 INFO nova.scheduler.client.report [req-0830c440-bef2-49c7-9df0-935b3cacc874 79f227999ff244dfa0b0db19caaea6b0 4f0d6c7f5eb8493195c7fd8846a5abaf - default default] Deleted allocations for instance b12ce3ee-3806-4c7d-82cf-5cff9b434309
2022-02-22 16:44:44.879 7 INFO nova.scheduler.client.report [req-bedf53cb-6bb7-40e6-b98b-c512e90769cf 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] Deleted allocations for instance 89ac7762-6c39-4935-b591-b61ce7b0a07f
2022-02-22 16:44:46.394 7 INFO nova.compute.claims [req-64d47e58-21c9-4693-b60f-f117e9da16ac 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Claim successful on node rack08-server63
2022-02-22 16:44:46.777 7 INFO nova.virt.libvirt.driver [req-64d47e58-21c9-4693-b60f-f117e9da16ac 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Creating image
2022-02-22 16:44:47.980 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] VM Resumed (Lifecycle Event)
2022-02-22 16:44:47.990 7 INFO nova.virt.libvirt.driver [-] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Instance spawned successfully.
2022-02-22 16:44:47.991 7 INFO nova.compute.manager [req-64d47e58-21c9-4693-b60f-f117e9da16ac 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 16:44:48.039 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:44:48.040 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] VM Started (Lifecycle Event)
2022-02-22 16:44:48.073 7 INFO nova.compute.manager [req-64d47e58-21c9-4693-b60f-f117e9da16ac 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Took 1.71 seconds to build instance.
2022-02-22 16:44:48.706 7 INFO nova.compute.manager [req-4b10ab74-77da-4361-ab43-8d122026b37c 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Terminating instance
2022-02-22 16:44:49.046 7 INFO nova.virt.libvirt.driver [-] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Instance destroyed successfully.
2022-02-22 16:44:49.060 7 INFO nova.virt.libvirt.driver [req-4b10ab74-77da-4361-ab43-8d122026b37c 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Deleting instance files /var/lib/nova/instances/19ca43d8-d40f-4483-9897-ab6b2338c9ca_del
2022-02-22 16:44:49.061 7 INFO nova.virt.libvirt.driver [req-4b10ab74-77da-4361-ab43-8d122026b37c 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Deletion of /var/lib/nova/instances/19ca43d8-d40f-4483-9897-ab6b2338c9ca_del complete
2022-02-22 16:44:49.123 7 INFO nova.compute.manager [req-4b10ab74-77da-4361-ab43-8d122026b37c 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 16:44:49.189 7 INFO nova.compute.manager [-] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] Took 0.06 seconds to deallocate network for instance.
2022-02-22 16:44:49.373 7 INFO nova.scheduler.client.report [req-4b10ab74-77da-4361-ab43-8d122026b37c 378cfbbc982345f79a0aa41fe95d35e1 059d94d6266c43878a0e3613df04f016 - default default] Deleted allocations for instance 19ca43d8-d40f-4483-9897-ab6b2338c9ca
2022-02-22 16:44:59.307 7 INFO nova.compute.manager [-] [instance: b12ce3ee-3806-4c7d-82cf-5cff9b434309] VM Stopped (Lifecycle Event)
2022-02-22 16:44:59.522 7 INFO nova.compute.manager [-] [instance: 89ac7762-6c39-4935-b591-b61ce7b0a07f] VM Stopped (Lifecycle Event)
2022-02-22 16:45:04.044 7 INFO nova.compute.manager [-] [instance: 19ca43d8-d40f-4483-9897-ab6b2338c9ca] VM Stopped (Lifecycle Event)
2022-02-22 16:45:29.560 7 INFO nova.compute.claims [req-70a9342d-6037-42c0-952c-449d32105f13 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Claim successful on node rack08-server63
2022-02-22 16:45:29.986 7 INFO nova.virt.libvirt.driver [req-70a9342d-6037-42c0-952c-449d32105f13 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Creating image
2022-02-22 16:45:31.211 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] VM Resumed (Lifecycle Event)
2022-02-22 16:45:31.219 7 INFO nova.virt.libvirt.driver [-] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Instance spawned successfully.
2022-02-22 16:45:31.220 7 INFO nova.compute.manager [req-70a9342d-6037-42c0-952c-449d32105f13 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-22 16:45:31.270 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 16:45:31.271 7 INFO nova.compute.manager [req-a1f533fc-54a5-42dd-b0b6-cdb2222f9f5a - - - - -] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] VM Started (Lifecycle Event)
2022-02-22 16:45:31.308 7 INFO nova.compute.manager [req-70a9342d-6037-42c0-952c-449d32105f13 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Took 1.79 seconds to build instance.
2022-02-22 16:45:31.910 7 INFO nova.compute.manager [req-132e6931-e8c4-4730-b894-be3588b2837f 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Terminating instance
2022-02-22 16:45:32.257 7 INFO nova.virt.libvirt.driver [-] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Instance destroyed successfully.
2022-02-22 16:45:32.272 7 INFO nova.virt.libvirt.driver [req-132e6931-e8c4-4730-b894-be3588b2837f 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Deleting instance files /var/lib/nova/instances/5bce3093-55da-47b6-b207-f3604b19abb0_del
2022-02-22 16:45:32.273 7 INFO nova.virt.libvirt.driver [req-132e6931-e8c4-4730-b894-be3588b2837f 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Deletion of /var/lib/nova/instances/5bce3093-55da-47b6-b207-f3604b19abb0_del complete
2022-02-22 16:45:32.344 7 INFO nova.compute.manager [req-132e6931-e8c4-4730-b894-be3588b2837f 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 16:45:32.412 7 INFO nova.compute.manager [-] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] Took 0.07 seconds to deallocate network for instance.
2022-02-22 16:45:32.610 7 INFO nova.scheduler.client.report [req-132e6931-e8c4-4730-b894-be3588b2837f 02c6bea60e474d399adabb3b17ab3b39 b736f2cd7be84efc89e53ffdc846bdda - default default] Deleted allocations for instance 5bce3093-55da-47b6-b207-f3604b19abb0
2022-02-22 16:45:47.255 7 INFO nova.compute.manager [-] [instance: 5bce3093-55da-47b6-b207-f3604b19abb0] VM Stopped (Lifecycle Event)
