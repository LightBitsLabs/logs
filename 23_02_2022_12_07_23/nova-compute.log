Build Started 23_02_2022_12_07_23
2022-02-23 14:12:36.809 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-23 14:12:40.787 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-23 14:12:41.697 7 INFO nova.virt.driver [req-60787cd9-bbe1-48ab-8bb8-db6bc4426d4e - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-23 14:12:42.094 7 INFO nova.compute.provider_config [req-60787cd9-bbe1-48ab-8bb8-db6bc4426d4e - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-23 14:12:42.114 7 WARNING oslo_config.cfg [req-60787cd9-bbe1-48ab-8bb8-db6bc4426d4e - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-23 14:12:42.135 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-23 14:12:42.147 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-23 14:12:42.164 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-23 14:12:42.269 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-23 14:12:42.284 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-23 14:12:42.286 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-23 14:12:42.620 7 INFO nova.compute.manager [req-21244177-7396-4049-9347-5a4e6235a3ab - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-23 14:12:44.404 7 INFO nova.virt.libvirt.host [req-21244177-7396-4049-9347-5a4e6235a3ab - - - - -] kernel doesn't support AMD SEV
2022-02-23 14:13:35.311 7 INFO nova.compute.claims [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Claim successful on node rack08-server63
2022-02-23 14:13:35.727 7 INFO nova.virt.libvirt.driver [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Creating image
2022-02-23 14:13:35.732 7 INFO oslo.privsep.daemon [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpi6kublg2/privsep.sock']
2022-02-23 14:13:37.363 7 INFO oslo.privsep.daemon [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Spawned new privsep daemon via rootwrap
2022-02-23 14:13:37.211 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 14:13:37.217 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 14:13:37.222 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-23 14:13:37.222 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-23 14:13:38.724 7 INFO nova.compute.manager [-] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] VM Resumed (Lifecycle Event)
2022-02-23 14:13:38.735 7 INFO nova.virt.libvirt.driver [-] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Instance spawned successfully.
2022-02-23 14:13:38.786 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:38.786 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] VM Started (Lifecycle Event)
2022-02-23 14:13:38.840 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:38.844 7 INFO nova.compute.manager [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Took 3.12 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:38.935 7 INFO nova.compute.manager [req-c7ff358b-add5-40a2-9ec6-5411c1b51796 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Took 3.67 seconds to build instance.
2022-02-23 14:13:41.167 7 INFO nova.compute.manager [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Attaching volume c2ae9bd7-1ece-4159-ab54-cd1de9fb7a96 to /dev/vdb
2022-02-23 14:13:41.265 7 INFO oslo.privsep.daemon [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpoetbbs9c/privsep.sock']
2022-02-23 14:13:41.918 7 INFO oslo.privsep.daemon [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Spawned new privsep daemon via rootwrap
2022-02-23 14:13:41.845 101 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 14:13:41.852 101 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 14:13:41.857 101 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-23 14:13:41.857 101 INFO oslo.privsep.daemon [-] privsep daemon running as pid 101
2022-02-23 14:13:42.259 7 WARNING os_brick.initiator.connectors.nvmeof [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:13:43.634 7 INFO os_brick.initiator.connectors.lightos [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: connect_volume called for volume 1b7101a7-dc92-4162-8a37-03d49ee20b72, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1b7101a7-dc92-4162-8a37-03d49ee20b72', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:13:43.667 7 INFO os_brick.initiator.connectors.lightos [req-6b3fa0c8-029a-4c28-822f-bcfbee5c4d2f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1b7101a7-dc92-4162-8a37-03d49ee20b72
2022-02-23 14:13:45.826 7 INFO nova.compute.claims [req-c64d1956-4775-426c-8e00-e512318412d8 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Claim successful on node rack08-server63
2022-02-23 14:13:46.270 7 INFO nova.virt.libvirt.driver [req-c64d1956-4775-426c-8e00-e512318412d8 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Creating image
2022-02-23 14:13:47.419 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] VM Resumed (Lifecycle Event)
2022-02-23 14:13:47.427 7 INFO nova.virt.libvirt.driver [-] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Instance spawned successfully.
2022-02-23 14:13:47.476 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:47.476 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] VM Started (Lifecycle Event)
2022-02-23 14:13:47.528 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:47.538 7 INFO nova.compute.manager [req-c64d1956-4775-426c-8e00-e512318412d8 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:47.621 7 INFO nova.compute.manager [req-c64d1956-4775-426c-8e00-e512318412d8 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Took 1.87 seconds to build instance.
2022-02-23 14:13:49.016 7 INFO nova.compute.manager [req-12b51a5d-2beb-4e85-b36c-a362294d7fca 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Detaching volume c2ae9bd7-1ece-4159-ab54-cd1de9fb7a96
2022-02-23 14:13:49.076 7 INFO nova.virt.block_device [req-12b51a5d-2beb-4e85-b36c-a362294d7fca 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Attempting to driver detach volume c2ae9bd7-1ece-4159-ab54-cd1de9fb7a96 from mountpoint /dev/vdb
2022-02-23 14:13:49.095 7 INFO nova.virt.libvirt.driver [req-12b51a5d-2beb-4e85-b36c-a362294d7fca 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance 4159d964-d306-4900-acd8-d135ee6e6c70 from the persistent domain config.
2022-02-23 14:13:49.248 7 INFO nova.virt.libvirt.driver [req-12b51a5d-2beb-4e85-b36c-a362294d7fca 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance 4159d964-d306-4900-acd8-d135ee6e6c70 from the live domain config.
2022-02-23 14:13:49.251 7 INFO os_brick.initiator.connectors.lightos [req-12b51a5d-2beb-4e85-b36c-a362294d7fca 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 1b7101a7-dc92-4162-8a37-03d49ee20b72
2022-02-23 14:13:49.403 7 INFO nova.compute.claims [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Claim successful on node rack08-server63
2022-02-23 14:13:49.662 7 INFO nova.virt.libvirt.driver [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 14:13:49.749 7 INFO nova.virt.block_device [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Booting with volume 4ed6c1a4-46d6-4150-b74d-ba4ee0cb72f2 at /dev/vda
2022-02-23 14:13:49.834 7 WARNING os_brick.initiator.connectors.nvmeof [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:13:51.339 7 INFO nova.virt.libvirt.driver [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Creating image
2022-02-23 14:13:51.350 7 INFO os_brick.initiator.connectors.lightos [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: connect_volume called for volume beb7f655-8e65-4327-a496-17ffd59f4dab, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'beb7f655-8e65-4327-a496-17ffd59f4dab', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:13:51.353 7 INFO os_brick.initiator.connectors.lightos [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid beb7f655-8e65-4327-a496-17ffd59f4dab
2022-02-23 14:13:52.168 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] VM Resumed (Lifecycle Event)
2022-02-23 14:13:52.175 7 INFO nova.virt.libvirt.driver [-] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Instance spawned successfully.
2022-02-23 14:13:52.224 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:52.224 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] VM Started (Lifecycle Event)
2022-02-23 14:13:52.276 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:52.294 7 INFO nova.compute.manager [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Took 0.96 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:52.376 7 INFO nova.compute.manager [req-d15838e7-3a7a-4271-82a2-a16bc2d1f1aa c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Took 3.01 seconds to build instance.
2022-02-23 14:13:52.532 7 INFO nova.compute.claims [req-dfd85f46-ade8-4fbf-b02d-5023b95aaa02 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Claim successful on node rack08-server63
2022-02-23 14:13:52.926 7 INFO nova.virt.libvirt.driver [req-dfd85f46-ade8-4fbf-b02d-5023b95aaa02 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Creating image
2022-02-23 14:13:54.082 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] VM Resumed (Lifecycle Event)
2022-02-23 14:13:54.089 7 INFO nova.virt.libvirt.driver [-] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Instance spawned successfully.
2022-02-23 14:13:54.151 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:54.151 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] VM Started (Lifecycle Event)
2022-02-23 14:13:54.196 7 INFO nova.compute.manager [req-dfd85f46-ade8-4fbf-b02d-5023b95aaa02 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:54.208 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:54.278 7 INFO nova.compute.manager [req-dfd85f46-ade8-4fbf-b02d-5023b95aaa02 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Took 1.78 seconds to build instance.
2022-02-23 14:13:54.596 7 INFO nova.compute.claims [req-d174d2f1-8809-4a84-be8b-37de3a08039e c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Claim successful on node rack08-server63
2022-02-23 14:13:54.970 7 INFO nova.virt.libvirt.driver [req-d174d2f1-8809-4a84-be8b-37de3a08039e c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Creating image
2022-02-23 14:13:55.142 7 INFO nova.compute.claims [req-12573973-8172-40b4-80a8-e712fe7759bc c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Claim successful on node rack08-server63
2022-02-23 14:13:55.546 7 INFO nova.virt.libvirt.driver [req-12573973-8172-40b4-80a8-e712fe7759bc c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Creating image
2022-02-23 14:13:56.077 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] VM Resumed (Lifecycle Event)
2022-02-23 14:13:56.084 7 INFO nova.virt.libvirt.driver [-] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Instance spawned successfully.
2022-02-23 14:13:56.133 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:56.134 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] VM Started (Lifecycle Event)
2022-02-23 14:13:56.191 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:56.194 7 INFO nova.compute.manager [req-d174d2f1-8809-4a84-be8b-37de3a08039e c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Took 1.23 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:56.279 7 INFO nova.compute.manager [req-d174d2f1-8809-4a84-be8b-37de3a08039e c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Took 1.72 seconds to build instance.
2022-02-23 14:13:56.695 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] VM Resumed (Lifecycle Event)
2022-02-23 14:13:56.701 7 INFO nova.virt.libvirt.driver [-] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Instance spawned successfully.
2022-02-23 14:13:56.757 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:56.758 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] VM Started (Lifecycle Event)
2022-02-23 14:13:56.813 7 INFO nova.compute.manager [req-12573973-8172-40b4-80a8-e712fe7759bc c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-23 14:13:56.814 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:13:56.896 7 INFO nova.compute.manager [req-12573973-8172-40b4-80a8-e712fe7759bc c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Took 1.80 seconds to build instance.
2022-02-23 14:13:58.109 7 INFO nova.compute.manager [req-5f98d5c4-3cb0-45ff-b36d-7ec1addb2e7f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Attaching volume f57c57f0-430a-4dbe-bd28-009c3932d906 to /dev/vdb
2022-02-23 14:13:58.201 7 WARNING os_brick.initiator.connectors.nvmeof [req-5f98d5c4-3cb0-45ff-b36d-7ec1addb2e7f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:13:59.570 7 INFO os_brick.initiator.connectors.lightos [req-5f98d5c4-3cb0-45ff-b36d-7ec1addb2e7f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: connect_volume called for volume a8ece877-a413-41af-9588-2167fc80f423, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a8ece877-a413-41af-9588-2167fc80f423', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:13:59.574 7 INFO os_brick.initiator.connectors.lightos [req-5f98d5c4-3cb0-45ff-b36d-7ec1addb2e7f 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a8ece877-a413-41af-9588-2167fc80f423
2022-02-23 14:13:59.914 7 INFO nova.compute.manager [req-b0d85541-4f66-4a05-82b0-375a4fd41795 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Attaching volume bd2c417c-418f-467d-bb98-7f58b0b12231 to /dev/vdb
2022-02-23 14:14:00.000 7 WARNING os_brick.initiator.connectors.nvmeof [req-b0d85541-4f66-4a05-82b0-375a4fd41795 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:14:00.747 7 INFO nova.compute.manager [req-ec0b0fbe-1f84-4752-b7f8-4d9702e1e66c 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Detaching volume f57c57f0-430a-4dbe-bd28-009c3932d906
2022-02-23 14:14:01.045 7 INFO nova.virt.block_device [req-ec0b0fbe-1f84-4752-b7f8-4d9702e1e66c 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Attempting to driver detach volume f57c57f0-430a-4dbe-bd28-009c3932d906 from mountpoint /dev/vdb
2022-02-23 14:14:01.065 7 INFO nova.virt.libvirt.driver [req-ec0b0fbe-1f84-4752-b7f8-4d9702e1e66c 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance 0e38deb9-b761-43bd-84aa-3fe93ca38d82 from the persistent domain config.
2022-02-23 14:14:01.209 7 INFO nova.virt.libvirt.driver [req-ec0b0fbe-1f84-4752-b7f8-4d9702e1e66c 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance 0e38deb9-b761-43bd-84aa-3fe93ca38d82 from the live domain config.
2022-02-23 14:14:01.212 7 INFO os_brick.initiator.connectors.lightos [req-ec0b0fbe-1f84-4752-b7f8-4d9702e1e66c 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a8ece877-a413-41af-9588-2167fc80f423
2022-02-23 14:14:01.358 7 INFO os_brick.initiator.connectors.lightos [req-b0d85541-4f66-4a05-82b0-375a4fd41795 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: connect_volume called for volume 1f1347d6-a72a-477e-983f-d8a15fcb7f76, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1f1347d6-a72a-477e-983f-d8a15fcb7f76', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:14:01.361 7 INFO os_brick.initiator.connectors.lightos [req-b0d85541-4f66-4a05-82b0-375a4fd41795 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 1f1347d6-a72a-477e-983f-d8a15fcb7f76
2022-02-23 14:14:02.425 7 INFO nova.compute.manager [req-91fa34cf-5c4b-44b3-9ba4-8ae03618375c c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Attaching volume bd2c417c-418f-467d-bb98-7f58b0b12231 to /dev/vdb
2022-02-23 14:14:02.511 7 WARNING os_brick.initiator.connectors.nvmeof [req-91fa34cf-5c4b-44b3-9ba4-8ae03618375c c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:14:03.899 7 INFO os_brick.initiator.connectors.lightos [req-91fa34cf-5c4b-44b3-9ba4-8ae03618375c c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: connect_volume called for volume 1f1347d6-a72a-477e-983f-d8a15fcb7f76, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '1f1347d6-a72a-477e-983f-d8a15fcb7f76', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:14:03.900 7 INFO os_brick.initiator.connectors.lightos [req-91fa34cf-5c4b-44b3-9ba4-8ae03618375c c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 1f1347d6-a72a-477e-983f-d8a15fcb7f76
2022-02-23 14:14:04.081 7 INFO nova.compute.claims [req-0429faf2-6679-455a-b66a-e445a93733ac 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Claim successful on node rack08-server63
2022-02-23 14:14:04.460 7 INFO nova.virt.libvirt.driver [req-0429faf2-6679-455a-b66a-e445a93733ac 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Creating image
2022-02-23 14:14:04.991 7 INFO nova.compute.manager [req-630fa87e-9342-4279-ac06-89723fc07cf7 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Detaching volume bd2c417c-418f-467d-bb98-7f58b0b12231
2022-02-23 14:14:05.055 7 INFO nova.virt.block_device [req-630fa87e-9342-4279-ac06-89723fc07cf7 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Attempting to driver detach volume bd2c417c-418f-467d-bb98-7f58b0b12231 from mountpoint /dev/vdb
2022-02-23 14:14:05.076 7 INFO nova.virt.libvirt.driver [req-630fa87e-9342-4279-ac06-89723fc07cf7 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Successfully detached device vdb from instance 5bb042db-681c-484f-bfc4-64b9fe5fc7f8 from the persistent domain config.
2022-02-23 14:14:05.226 7 INFO nova.virt.libvirt.driver [req-630fa87e-9342-4279-ac06-89723fc07cf7 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Successfully detached device vdb from instance 5bb042db-681c-484f-bfc4-64b9fe5fc7f8 from the live domain config.
2022-02-23 14:14:05.306 7 INFO nova.virt.libvirt.driver [req-630fa87e-9342-4279-ac06-89723fc07cf7 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Detected multiple connections on this host for volume: bd2c417c-418f-467d-bb98-7f58b0b12231, skipping target disconnect.
2022-02-23 14:14:05.623 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] VM Resumed (Lifecycle Event)
2022-02-23 14:14:05.633 7 INFO nova.virt.libvirt.driver [-] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Instance spawned successfully.
2022-02-23 14:14:05.685 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:14:05.686 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] VM Started (Lifecycle Event)
2022-02-23 14:14:05.741 7 INFO nova.compute.manager [req-0429faf2-6679-455a-b66a-e445a93733ac 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-23 14:14:05.743 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:14:05.823 7 INFO nova.compute.manager [req-0429faf2-6679-455a-b66a-e445a93733ac 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Took 1.79 seconds to build instance.
2022-02-23 14:14:07.474 7 INFO nova.compute.manager [req-23229e1d-45a7-4a2b-a465-82d876958526 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Detaching volume bd2c417c-418f-467d-bb98-7f58b0b12231
2022-02-23 14:14:07.533 7 INFO nova.virt.block_device [req-23229e1d-45a7-4a2b-a465-82d876958526 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Attempting to driver detach volume bd2c417c-418f-467d-bb98-7f58b0b12231 from mountpoint /dev/vdb
2022-02-23 14:14:07.551 7 INFO nova.virt.libvirt.driver [req-23229e1d-45a7-4a2b-a465-82d876958526 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Successfully detached device vdb from instance b4bbb5ec-549e-4007-a7ef-e7dae5828f4d from the persistent domain config.
2022-02-23 14:14:07.726 7 INFO nova.virt.libvirt.driver [req-23229e1d-45a7-4a2b-a465-82d876958526 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Successfully detached device vdb from instance b4bbb5ec-549e-4007-a7ef-e7dae5828f4d from the live domain config.
2022-02-23 14:14:08.689 7 INFO nova.compute.manager [req-1eb47f33-53a3-45f0-9223-992edec151b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Attaching volume f11e3236-968e-418e-bb79-2ae8654df385 to /dev/vdb
2022-02-23 14:14:08.778 7 WARNING os_brick.initiator.connectors.nvmeof [req-1eb47f33-53a3-45f0-9223-992edec151b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:15:08.204 7 INFO os_brick.initiator.connectors.lightos [req-1eb47f33-53a3-45f0-9223-992edec151b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: connect_volume called for volume 87b091e4-3093-475d-8204-e36dc384e343, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '87b091e4-3093-475d-8204-e36dc384e343', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:15:08.208 7 INFO os_brick.initiator.connectors.lightos [req-1eb47f33-53a3-45f0-9223-992edec151b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 87b091e4-3093-475d-8204-e36dc384e343
2022-02-23 14:15:09.505 7 INFO nova.compute.manager [req-ff18e36f-4bf8-4aac-a96e-0d264571297b 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Detaching volume f11e3236-968e-418e-bb79-2ae8654df385
2022-02-23 14:15:09.570 7 INFO nova.virt.block_device [req-ff18e36f-4bf8-4aac-a96e-0d264571297b 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Attempting to driver detach volume f11e3236-968e-418e-bb79-2ae8654df385 from mountpoint /dev/vdb
2022-02-23 14:15:09.594 7 INFO nova.virt.libvirt.driver [req-ff18e36f-4bf8-4aac-a96e-0d264571297b 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance c2db6989-1296-4f37-a6a0-3557553d122e from the persistent domain config.
2022-02-23 14:15:09.735 7 INFO nova.virt.libvirt.driver [req-ff18e36f-4bf8-4aac-a96e-0d264571297b 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Successfully detached device vdb from instance c2db6989-1296-4f37-a6a0-3557553d122e from the live domain config.
2022-02-23 14:15:09.738 7 INFO os_brick.initiator.connectors.lightos [req-ff18e36f-4bf8-4aac-a96e-0d264571297b 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 87b091e4-3093-475d-8204-e36dc384e343
2022-02-23 14:15:12.976 7 INFO nova.compute.manager [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Terminating instance
2022-02-23 14:15:13.330 7 INFO nova.virt.libvirt.driver [-] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Instance destroyed successfully.
2022-02-23 14:15:13.346 7 INFO nova.virt.libvirt.driver [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Deleting instance files /var/lib/nova/instances/c2db6989-1296-4f37-a6a0-3557553d122e_del
2022-02-23 14:15:13.348 7 INFO nova.virt.libvirt.driver [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Deletion of /var/lib/nova/instances/c2db6989-1296-4f37-a6a0-3557553d122e_del complete
2022-02-23 14:15:13.418 7 INFO nova.virt.libvirt.host [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] UEFI support detected
2022-02-23 14:15:13.421 7 INFO nova.compute.manager [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:13.488 7 INFO nova.compute.manager [-] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:15:13.668 7 INFO nova.scheduler.client.report [req-37f2eca8-339c-493c-a36f-12d021a8f92d 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Deleted allocations for instance c2db6989-1296-4f37-a6a0-3557553d122e
2022-02-23 14:15:15.364 7 INFO nova.compute.manager [req-9ed605c7-6e30-4428-89cd-7c443e55bd24 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Terminating instance
2022-02-23 14:15:15.721 7 INFO nova.virt.libvirt.driver [-] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Instance destroyed successfully.
2022-02-23 14:15:15.736 7 INFO nova.virt.libvirt.driver [req-9ed605c7-6e30-4428-89cd-7c443e55bd24 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Deleting instance files /var/lib/nova/instances/0e38deb9-b761-43bd-84aa-3fe93ca38d82_del
2022-02-23 14:15:15.738 7 INFO nova.virt.libvirt.driver [req-9ed605c7-6e30-4428-89cd-7c443e55bd24 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Deletion of /var/lib/nova/instances/0e38deb9-b761-43bd-84aa-3fe93ca38d82_del complete
2022-02-23 14:15:15.809 7 INFO nova.compute.manager [req-9ed605c7-6e30-4428-89cd-7c443e55bd24 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:15.875 7 INFO nova.compute.manager [-] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:15:16.071 7 INFO nova.scheduler.client.report [req-9ed605c7-6e30-4428-89cd-7c443e55bd24 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Deleted allocations for instance 0e38deb9-b761-43bd-84aa-3fe93ca38d82
2022-02-23 14:15:16.615 7 INFO nova.compute.manager [req-da844a1e-08ba-4e34-9aab-680efebd3133 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Terminating instance
2022-02-23 14:15:16.963 7 INFO nova.virt.libvirt.driver [-] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Instance destroyed successfully.
2022-02-23 14:15:16.979 7 INFO nova.virt.libvirt.driver [req-da844a1e-08ba-4e34-9aab-680efebd3133 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Deleting instance files /var/lib/nova/instances/57e587cd-9972-4adb-ae12-cef1c5e99c5b_del
2022-02-23 14:15:16.980 7 INFO nova.virt.libvirt.driver [req-da844a1e-08ba-4e34-9aab-680efebd3133 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Deletion of /var/lib/nova/instances/57e587cd-9972-4adb-ae12-cef1c5e99c5b_del complete
2022-02-23 14:15:17.055 7 INFO nova.compute.manager [req-da844a1e-08ba-4e34-9aab-680efebd3133 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:17.117 7 INFO nova.compute.manager [-] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:15:17.304 7 INFO nova.scheduler.client.report [req-da844a1e-08ba-4e34-9aab-680efebd3133 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Deleted allocations for instance 57e587cd-9972-4adb-ae12-cef1c5e99c5b
2022-02-23 14:15:18.992 7 INFO nova.compute.manager [req-32a4faa0-1eb3-4d79-96f7-f2ff853cf0b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Terminating instance
2022-02-23 14:15:19.346 7 INFO nova.virt.libvirt.driver [-] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Instance destroyed successfully.
2022-02-23 14:15:19.360 7 INFO nova.virt.libvirt.driver [req-32a4faa0-1eb3-4d79-96f7-f2ff853cf0b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Deleting instance files /var/lib/nova/instances/4159d964-d306-4900-acd8-d135ee6e6c70_del
2022-02-23 14:15:19.362 7 INFO nova.virt.libvirt.driver [req-32a4faa0-1eb3-4d79-96f7-f2ff853cf0b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Deletion of /var/lib/nova/instances/4159d964-d306-4900-acd8-d135ee6e6c70_del complete
2022-02-23 14:15:19.434 7 INFO nova.compute.manager [req-32a4faa0-1eb3-4d79-96f7-f2ff853cf0b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:19.502 7 INFO nova.compute.manager [-] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:15:19.694 7 INFO nova.scheduler.client.report [req-32a4faa0-1eb3-4d79-96f7-f2ff853cf0b9 2dfc749e6bb3404e9ebfed857ef78dbc 1e7df97eeece432eb476939142b7e05e - default default] Deleted allocations for instance 4159d964-d306-4900-acd8-d135ee6e6c70
2022-02-23 14:15:25.773 7 INFO nova.compute.claims [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Claim successful on node rack08-server63
2022-02-23 14:15:26.035 7 INFO nova.virt.libvirt.driver [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 14:15:26.124 7 INFO nova.virt.block_device [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Booting with volume 36c87242-6ca7-4b10-ab46-8bdb7f43883f at /dev/vda
2022-02-23 14:15:26.214 7 WARNING os_brick.initiator.connectors.nvmeof [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:15:27.759 7 INFO nova.virt.libvirt.driver [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Creating image
2022-02-23 14:15:27.771 7 INFO os_brick.initiator.connectors.lightos [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: connect_volume called for volume fee0b0d1-88fa-4d37-a5c7-7d5435b89d26, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'fee0b0d1-88fa-4d37-a5c7-7d5435b89d26', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:15:27.774 7 INFO os_brick.initiator.connectors.lightos [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid fee0b0d1-88fa-4d37-a5c7-7d5435b89d26
2022-02-23 14:15:28.327 7 INFO nova.compute.manager [-] [instance: c2db6989-1296-4f37-a6a0-3557553d122e] VM Stopped (Lifecycle Event)
2022-02-23 14:15:28.590 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] VM Resumed (Lifecycle Event)
2022-02-23 14:15:28.597 7 INFO nova.virt.libvirt.driver [-] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Instance spawned successfully.
2022-02-23 14:15:28.658 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:15:28.659 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] VM Started (Lifecycle Event)
2022-02-23 14:15:28.697 7 INFO nova.compute.manager [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Took 0.94 seconds to spawn the instance on the hypervisor.
2022-02-23 14:15:28.711 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:15:28.781 7 INFO nova.compute.manager [req-04be3665-6899-451d-821f-8b24ecea055b c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Took 3.05 seconds to build instance.
2022-02-23 14:15:30.718 7 INFO nova.compute.manager [-] [instance: 0e38deb9-b761-43bd-84aa-3fe93ca38d82] VM Stopped (Lifecycle Event)
2022-02-23 14:15:31.085 7 INFO nova.compute.manager [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Terminating instance
2022-02-23 14:15:31.449 7 INFO nova.virt.libvirt.driver [-] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Instance destroyed successfully.
2022-02-23 14:15:31.515 7 INFO os_brick.initiator.connectors.lightos [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid fee0b0d1-88fa-4d37-a5c7-7d5435b89d26
2022-02-23 14:15:31.525 7 INFO nova.virt.libvirt.driver [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Deleting instance files /var/lib/nova/instances/4d8e7f34-fc41-412a-977b-f29be55a540d_del
2022-02-23 14:15:31.526 7 INFO nova.virt.libvirt.driver [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Deletion of /var/lib/nova/instances/4d8e7f34-fc41-412a-977b-f29be55a540d_del complete
2022-02-23 14:15:31.593 7 INFO nova.compute.manager [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:31.653 7 INFO nova.compute.manager [-] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:15:31.960 7 INFO nova.compute.manager [-] [instance: 57e587cd-9972-4adb-ae12-cef1c5e99c5b] VM Stopped (Lifecycle Event)
2022-02-23 14:15:32.912 7 INFO nova.compute.manager [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] Took 1.26 seconds to detach 1 volumes for instance.
2022-02-23 14:15:33.110 7 INFO nova.scheduler.client.report [req-5b12bc7c-7673-4b6a-adde-7aa1eda95a81 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Deleted allocations for instance 4d8e7f34-fc41-412a-977b-f29be55a540d
2022-02-23 14:15:34.343 7 INFO nova.compute.manager [-] [instance: 4159d964-d306-4900-acd8-d135ee6e6c70] VM Stopped (Lifecycle Event)
2022-02-23 14:15:36.018 7 INFO nova.compute.manager [req-1d3edfbc-2a98-4a99-9480-72a963d6dd60 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Terminating instance
2022-02-23 14:15:36.384 7 INFO nova.virt.libvirt.driver [-] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Instance destroyed successfully.
2022-02-23 14:15:36.397 7 INFO nova.virt.libvirt.driver [req-1d3edfbc-2a98-4a99-9480-72a963d6dd60 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Deleting instance files /var/lib/nova/instances/b4bbb5ec-549e-4007-a7ef-e7dae5828f4d_del
2022-02-23 14:15:36.399 7 INFO nova.virt.libvirt.driver [req-1d3edfbc-2a98-4a99-9480-72a963d6dd60 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Deletion of /var/lib/nova/instances/b4bbb5ec-549e-4007-a7ef-e7dae5828f4d_del complete
2022-02-23 14:15:36.466 7 INFO nova.compute.manager [req-1d3edfbc-2a98-4a99-9480-72a963d6dd60 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:36.533 7 INFO nova.compute.manager [-] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:15:36.736 7 INFO nova.scheduler.client.report [req-1d3edfbc-2a98-4a99-9480-72a963d6dd60 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Deleted allocations for instance b4bbb5ec-549e-4007-a7ef-e7dae5828f4d
2022-02-23 14:15:37.284 7 INFO nova.compute.manager [req-fc653a12-926f-4ff0-af50-37143d4c5e08 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Terminating instance
2022-02-23 14:15:37.630 7 INFO nova.virt.libvirt.driver [-] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Instance destroyed successfully.
2022-02-23 14:15:37.646 7 INFO nova.virt.libvirt.driver [req-fc653a12-926f-4ff0-af50-37143d4c5e08 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Deleting instance files /var/lib/nova/instances/5bb042db-681c-484f-bfc4-64b9fe5fc7f8_del
2022-02-23 14:15:37.648 7 INFO nova.virt.libvirt.driver [req-fc653a12-926f-4ff0-af50-37143d4c5e08 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Deletion of /var/lib/nova/instances/5bb042db-681c-484f-bfc4-64b9fe5fc7f8_del complete
2022-02-23 14:15:37.712 7 INFO nova.compute.manager [req-fc653a12-926f-4ff0-af50-37143d4c5e08 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:37.775 7 INFO nova.compute.manager [-] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:15:37.974 7 INFO nova.scheduler.client.report [req-fc653a12-926f-4ff0-af50-37143d4c5e08 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Deleted allocations for instance 5bb042db-681c-484f-bfc4-64b9fe5fc7f8
2022-02-23 14:15:38.534 7 INFO nova.compute.manager [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Terminating instance
2022-02-23 14:15:38.887 7 INFO nova.virt.libvirt.driver [-] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Instance destroyed successfully.
2022-02-23 14:15:38.961 7 INFO os_brick.initiator.connectors.lightos [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid beb7f655-8e65-4327-a496-17ffd59f4dab
2022-02-23 14:15:38.972 7 INFO nova.virt.libvirt.driver [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Deleting instance files /var/lib/nova/instances/644eaac8-138f-40d9-a84a-6c00c7894401_del
2022-02-23 14:15:38.973 7 INFO nova.virt.libvirt.driver [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Deletion of /var/lib/nova/instances/644eaac8-138f-40d9-a84a-6c00c7894401_del complete
2022-02-23 14:15:39.042 7 INFO nova.compute.manager [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-23 14:15:39.112 7 INFO nova.compute.manager [-] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:15:40.362 7 INFO nova.compute.manager [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-23 14:15:40.561 7 INFO nova.scheduler.client.report [req-7b51a8f7-84e0-41cb-84e4-7483c1427ae0 c673d7a4463544d08cee4c2ae8217712 dfa1d9ee97924f1f9569d8d11e63ce3f - default default] Deleted allocations for instance 644eaac8-138f-40d9-a84a-6c00c7894401
2022-02-23 14:15:46.447 7 INFO nova.compute.manager [-] [instance: 4d8e7f34-fc41-412a-977b-f29be55a540d] VM Stopped (Lifecycle Event)
2022-02-23 14:15:51.382 7 INFO nova.compute.manager [-] [instance: b4bbb5ec-549e-4007-a7ef-e7dae5828f4d] VM Stopped (Lifecycle Event)
2022-02-23 14:15:52.628 7 INFO nova.compute.manager [-] [instance: 5bb042db-681c-484f-bfc4-64b9fe5fc7f8] VM Stopped (Lifecycle Event)
2022-02-23 14:15:53.884 7 INFO nova.compute.manager [-] [instance: 644eaac8-138f-40d9-a84a-6c00c7894401] VM Stopped (Lifecycle Event)
2022-02-23 14:15:57.546 7 INFO nova.compute.claims [req-0222d1f1-6d07-4e4f-8fe1-f1f47ba8dbe8 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Claim successful on node rack08-server63
2022-02-23 14:15:57.940 7 INFO nova.virt.libvirt.driver [req-0222d1f1-6d07-4e4f-8fe1-f1f47ba8dbe8 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Creating image
2022-02-23 14:15:59.159 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] VM Resumed (Lifecycle Event)
2022-02-23 14:15:59.168 7 INFO nova.virt.libvirt.driver [-] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Instance spawned successfully.
2022-02-23 14:15:59.214 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:15:59.215 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] VM Started (Lifecycle Event)
2022-02-23 14:15:59.265 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:15:59.272 7 INFO nova.compute.manager [req-0222d1f1-6d07-4e4f-8fe1-f1f47ba8dbe8 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Took 1.33 seconds to spawn the instance on the hypervisor.
2022-02-23 14:15:59.352 7 INFO nova.compute.manager [req-0222d1f1-6d07-4e4f-8fe1-f1f47ba8dbe8 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Took 1.85 seconds to build instance.
2022-02-23 14:16:05.127 7 INFO nova.compute.manager [req-185dc2e1-d814-4fed-8131-e96e6afdac43 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Terminating instance
2022-02-23 14:16:05.475 7 INFO nova.virt.libvirt.driver [-] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Instance destroyed successfully.
2022-02-23 14:16:05.492 7 INFO nova.virt.libvirt.driver [req-185dc2e1-d814-4fed-8131-e96e6afdac43 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Deleting instance files /var/lib/nova/instances/edc6ee62-766e-44f9-a858-79602eb354e7_del
2022-02-23 14:16:05.493 7 INFO nova.virt.libvirt.driver [req-185dc2e1-d814-4fed-8131-e96e6afdac43 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Deletion of /var/lib/nova/instances/edc6ee62-766e-44f9-a858-79602eb354e7_del complete
2022-02-23 14:16:05.558 7 INFO nova.compute.manager [req-185dc2e1-d814-4fed-8131-e96e6afdac43 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 14:16:05.624 7 INFO nova.compute.manager [-] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] Took 0.07 seconds to deallocate network for instance.
2022-02-23 14:16:05.819 7 INFO nova.scheduler.client.report [req-185dc2e1-d814-4fed-8131-e96e6afdac43 d2f899722324415895e07703c93a2766 7ead0bdcb8fa4986a0b040f4d0aeb2d4 - default default] Deleted allocations for instance edc6ee62-766e-44f9-a858-79602eb354e7
2022-02-23 14:16:20.474 7 INFO nova.compute.manager [-] [instance: edc6ee62-766e-44f9-a858-79602eb354e7] VM Stopped (Lifecycle Event)
2022-02-23 14:17:36.490 7 INFO nova.compute.claims [req-f0b4640b-0878-42a2-adf1-c0c707c9f387 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Claim successful on node rack08-server63
2022-02-23 14:17:36.856 7 INFO nova.virt.libvirt.driver [req-f0b4640b-0878-42a2-adf1-c0c707c9f387 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Creating image
2022-02-23 14:17:38.007 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] VM Resumed (Lifecycle Event)
2022-02-23 14:17:38.015 7 INFO nova.virt.libvirt.driver [-] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Instance spawned successfully.
2022-02-23 14:17:38.061 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:38.062 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] VM Started (Lifecycle Event)
2022-02-23 14:17:38.117 7 INFO nova.compute.manager [req-f0b4640b-0878-42a2-adf1-c0c707c9f387 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-23 14:17:38.119 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:38.212 7 INFO nova.compute.manager [req-f0b4640b-0878-42a2-adf1-c0c707c9f387 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Took 1.76 seconds to build instance.
2022-02-23 14:17:38.468 7 INFO nova.compute.manager [req-04815662-7336-4715-bacd-dd9c0173dc22 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Terminating instance
2022-02-23 14:17:38.825 7 INFO nova.virt.libvirt.driver [-] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Instance destroyed successfully.
2022-02-23 14:17:38.841 7 INFO nova.virt.libvirt.driver [req-04815662-7336-4715-bacd-dd9c0173dc22 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Deleting instance files /var/lib/nova/instances/8b5da24b-37ca-4116-9784-782d12972c44_del
2022-02-23 14:17:38.842 7 INFO nova.virt.libvirt.driver [req-04815662-7336-4715-bacd-dd9c0173dc22 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Deletion of /var/lib/nova/instances/8b5da24b-37ca-4116-9784-782d12972c44_del complete
2022-02-23 14:17:38.910 7 INFO nova.compute.manager [req-04815662-7336-4715-bacd-dd9c0173dc22 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:17:38.975 7 INFO nova.compute.manager [-] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:17:39.150 7 INFO nova.scheduler.client.report [req-04815662-7336-4715-bacd-dd9c0173dc22 a995ffb1014b40d9b66d524023ed81b2 a79a4c5a45784616a373a493892ddd4b - default default] Deleted allocations for instance 8b5da24b-37ca-4116-9784-782d12972c44
2022-02-23 14:17:40.101 7 INFO nova.compute.claims [req-c1e5bdc4-aa15-45ef-b56a-22564e0b7a11 e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Claim successful on node rack08-server63
2022-02-23 14:17:40.511 7 INFO nova.virt.libvirt.driver [req-c1e5bdc4-aa15-45ef-b56a-22564e0b7a11 e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Creating image
2022-02-23 14:17:41.674 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] VM Resumed (Lifecycle Event)
2022-02-23 14:17:41.682 7 INFO nova.virt.libvirt.driver [-] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Instance spawned successfully.
2022-02-23 14:17:41.746 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:41.747 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] VM Started (Lifecycle Event)
2022-02-23 14:17:41.798 7 INFO nova.compute.manager [req-c1e5bdc4-aa15-45ef-b56a-22564e0b7a11 e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-23 14:17:41.803 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:41.885 7 INFO nova.compute.manager [req-c1e5bdc4-aa15-45ef-b56a-22564e0b7a11 e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Took 1.82 seconds to build instance.
2022-02-23 14:17:43.494 7 INFO nova.compute.manager [req-a1692927-bb12-452f-b5b8-c3d218cb65cb e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Terminating instance
2022-02-23 14:17:43.855 7 INFO nova.virt.libvirt.driver [-] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Instance destroyed successfully.
2022-02-23 14:17:43.871 7 INFO nova.virt.libvirt.driver [req-a1692927-bb12-452f-b5b8-c3d218cb65cb e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Deleting instance files /var/lib/nova/instances/fbc64392-3a2d-4647-8ee2-b724ea3023f9_del
2022-02-23 14:17:43.872 7 INFO nova.virt.libvirt.driver [req-a1692927-bb12-452f-b5b8-c3d218cb65cb e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Deletion of /var/lib/nova/instances/fbc64392-3a2d-4647-8ee2-b724ea3023f9_del complete
2022-02-23 14:17:43.944 7 INFO nova.compute.manager [req-a1692927-bb12-452f-b5b8-c3d218cb65cb e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:17:44.009 7 INFO nova.compute.manager [-] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:17:44.377 7 INFO nova.scheduler.client.report [req-a1692927-bb12-452f-b5b8-c3d218cb65cb e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] Deleted allocations for instance fbc64392-3a2d-4647-8ee2-b724ea3023f9
2022-02-23 14:17:45.825 7 INFO nova.compute.claims [req-b8abd812-bc5d-4127-934b-2fe464070d7b e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Claim successful on node rack08-server63
2022-02-23 14:17:46.350 7 INFO nova.virt.libvirt.driver [req-b8abd812-bc5d-4127-934b-2fe464070d7b e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Creating image
2022-02-23 14:17:48.355 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] VM Resumed (Lifecycle Event)
2022-02-23 14:17:48.363 7 INFO nova.virt.libvirt.driver [-] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Instance spawned successfully.
2022-02-23 14:17:48.422 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:48.423 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] VM Started (Lifecycle Event)
2022-02-23 14:17:48.465 7 INFO nova.compute.manager [req-b8abd812-bc5d-4127-934b-2fe464070d7b e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Took 2.12 seconds to spawn the instance on the hypervisor.
2022-02-23 14:17:48.478 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:48.544 7 INFO nova.compute.manager [req-b8abd812-bc5d-4127-934b-2fe464070d7b e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Took 2.75 seconds to build instance.
2022-02-23 14:17:49.300 7 INFO nova.compute.manager [req-cc87b821-acf3-492a-80f3-bf299d13334e e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Terminating instance
2022-02-23 14:17:49.649 7 INFO nova.virt.libvirt.driver [-] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Instance destroyed successfully.
2022-02-23 14:17:49.663 7 INFO nova.virt.libvirt.driver [req-cc87b821-acf3-492a-80f3-bf299d13334e e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Deleting instance files /var/lib/nova/instances/d76b1fcf-ff5f-4ee3-9981-226b99bd61f8_del
2022-02-23 14:17:49.664 7 INFO nova.virt.libvirt.driver [req-cc87b821-acf3-492a-80f3-bf299d13334e e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Deletion of /var/lib/nova/instances/d76b1fcf-ff5f-4ee3-9981-226b99bd61f8_del complete
2022-02-23 14:17:49.731 7 INFO nova.compute.manager [req-cc87b821-acf3-492a-80f3-bf299d13334e e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 14:17:49.796 7 INFO nova.compute.manager [-] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:17:50.027 7 INFO nova.scheduler.client.report [req-cc87b821-acf3-492a-80f3-bf299d13334e e9a3bb8e87cb442bb34e43100287826e 4b2a23b40fc2444c8a72822a95fd9b7c - default default] Deleted allocations for instance d76b1fcf-ff5f-4ee3-9981-226b99bd61f8
2022-02-23 14:17:50.119 7 INFO nova.compute.claims [req-84e43caa-34d9-49e3-b8a3-9734cf87ba76 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Claim successful on node rack08-server63
2022-02-23 14:17:50.503 7 INFO nova.virt.libvirt.driver [req-84e43caa-34d9-49e3-b8a3-9734cf87ba76 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Creating image
2022-02-23 14:17:51.630 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] VM Resumed (Lifecycle Event)
2022-02-23 14:17:51.638 7 INFO nova.virt.libvirt.driver [-] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Instance spawned successfully.
2022-02-23 14:17:51.689 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:51.689 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] VM Started (Lifecycle Event)
2022-02-23 14:17:51.746 7 INFO nova.compute.manager [req-84e43caa-34d9-49e3-b8a3-9734cf87ba76 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-23 14:17:51.748 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:17:51.828 7 INFO nova.compute.manager [req-84e43caa-34d9-49e3-b8a3-9734cf87ba76 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Took 1.75 seconds to build instance.
2022-02-23 14:17:53.823 7 INFO nova.compute.manager [-] [instance: 8b5da24b-37ca-4116-9784-782d12972c44] VM Stopped (Lifecycle Event)
2022-02-23 14:17:58.853 7 INFO nova.compute.manager [-] [instance: fbc64392-3a2d-4647-8ee2-b724ea3023f9] VM Stopped (Lifecycle Event)
2022-02-23 14:18:04.647 7 INFO nova.compute.manager [-] [instance: d76b1fcf-ff5f-4ee3-9981-226b99bd61f8] VM Stopped (Lifecycle Event)
2022-02-23 14:18:08.367 7 INFO nova.virt.libvirt.driver [req-51773276-9e55-4399-a627-ccc4406b18e6 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Ignoring supplied device name: /dev/vdb
2022-02-23 14:18:08.553 7 INFO nova.compute.manager [req-51773276-9e55-4399-a627-ccc4406b18e6 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Attaching volume ea8b5268-53d7-49d1-bec4-dab0de4949a8 to /dev/vdb
2022-02-23 14:18:08.640 7 WARNING os_brick.initiator.connectors.nvmeof [req-51773276-9e55-4399-a627-ccc4406b18e6 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:18:09.985 7 INFO os_brick.initiator.connectors.lightos [req-51773276-9e55-4399-a627-ccc4406b18e6 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: connect_volume called for volume 13bb5518-3594-42ca-8dad-aa1d2750c336, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '13bb5518-3594-42ca-8dad-aa1d2750c336', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:18:09.989 7 INFO os_brick.initiator.connectors.lightos [req-51773276-9e55-4399-a627-ccc4406b18e6 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 13bb5518-3594-42ca-8dad-aa1d2750c336
2022-02-23 14:18:21.143 7 INFO nova.compute.manager [req-416962b3-ca1b-4e28-a579-c2e2a57de68b 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Detaching volume ea8b5268-53d7-49d1-bec4-dab0de4949a8
2022-02-23 14:18:21.203 7 INFO nova.virt.block_device [req-416962b3-ca1b-4e28-a579-c2e2a57de68b 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Attempting to driver detach volume ea8b5268-53d7-49d1-bec4-dab0de4949a8 from mountpoint /dev/vdb
2022-02-23 14:18:21.224 7 INFO nova.virt.libvirt.driver [req-416962b3-ca1b-4e28-a579-c2e2a57de68b 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Successfully detached device vdb from instance 602acf4b-63ef-4149-8c8b-759e49258ebf from the persistent domain config.
2022-02-23 14:18:21.366 7 INFO nova.virt.libvirt.driver [req-416962b3-ca1b-4e28-a579-c2e2a57de68b 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Successfully detached device vdb from instance 602acf4b-63ef-4149-8c8b-759e49258ebf from the live domain config.
2022-02-23 14:18:21.369 7 INFO os_brick.initiator.connectors.lightos [req-416962b3-ca1b-4e28-a579-c2e2a57de68b 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 13bb5518-3594-42ca-8dad-aa1d2750c336
2022-02-23 14:18:22.690 7 INFO nova.compute.claims [req-efa8eb1a-d28b-49a5-bca0-6142b05984b9 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Claim successful on node rack08-server63
2022-02-23 14:18:23.083 7 INFO nova.virt.libvirt.driver [req-efa8eb1a-d28b-49a5-bca0-6142b05984b9 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Creating image
2022-02-23 14:18:23.416 7 INFO nova.compute.manager [req-78e1a11b-3853-4890-99d4-fedcf05450d5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Terminating instance
2022-02-23 14:18:23.772 7 INFO nova.virt.libvirt.driver [-] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Instance destroyed successfully.
2022-02-23 14:18:23.788 7 INFO nova.virt.libvirt.driver [req-78e1a11b-3853-4890-99d4-fedcf05450d5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Deleting instance files /var/lib/nova/instances/602acf4b-63ef-4149-8c8b-759e49258ebf_del
2022-02-23 14:18:23.789 7 INFO nova.virt.libvirt.driver [req-78e1a11b-3853-4890-99d4-fedcf05450d5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Deletion of /var/lib/nova/instances/602acf4b-63ef-4149-8c8b-759e49258ebf_del complete
2022-02-23 14:18:23.857 7 INFO nova.compute.manager [req-78e1a11b-3853-4890-99d4-fedcf05450d5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:18:23.922 7 INFO nova.compute.manager [-] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:18:24.104 7 INFO nova.scheduler.client.report [req-78e1a11b-3853-4890-99d4-fedcf05450d5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Deleted allocations for instance 602acf4b-63ef-4149-8c8b-759e49258ebf
2022-02-23 14:18:24.338 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] VM Resumed (Lifecycle Event)
2022-02-23 14:18:24.346 7 INFO nova.virt.libvirt.driver [-] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Instance spawned successfully.
2022-02-23 14:18:24.398 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:18:24.398 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] VM Started (Lifecycle Event)
2022-02-23 14:18:24.454 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:18:24.458 7 INFO nova.compute.manager [req-efa8eb1a-d28b-49a5-bca0-6142b05984b9 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Took 1.38 seconds to spawn the instance on the hypervisor.
2022-02-23 14:18:24.539 7 INFO nova.compute.manager [req-efa8eb1a-d28b-49a5-bca0-6142b05984b9 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Took 1.89 seconds to build instance.
2022-02-23 14:18:25.771 7 INFO nova.virt.libvirt.driver [req-b83f4f9f-64c9-425a-8376-4e35546a6105 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Ignoring supplied device name: /dev/vdb
2022-02-23 14:18:25.934 7 INFO nova.compute.manager [req-b83f4f9f-64c9-425a-8376-4e35546a6105 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Attaching volume 0becc905-a063-4983-8d30-f6e0eba066a2 to /dev/vdb
2022-02-23 14:18:26.021 7 WARNING os_brick.initiator.connectors.nvmeof [req-b83f4f9f-64c9-425a-8376-4e35546a6105 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:18:27.362 7 INFO os_brick.initiator.connectors.lightos [req-b83f4f9f-64c9-425a-8376-4e35546a6105 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] LIGHTOS: connect_volume called for volume 7a57b632-c97c-4269-abfc-2f2e774c4012, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '7a57b632-c97c-4269-abfc-2f2e774c4012', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:18:27.366 7 INFO os_brick.initiator.connectors.lightos [req-b83f4f9f-64c9-425a-8376-4e35546a6105 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 7a57b632-c97c-4269-abfc-2f2e774c4012
2022-02-23 14:18:29.240 7 INFO nova.compute.manager [req-50c802ea-f3d9-4d55-911a-b45be58805cf e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Cinder extended volume 0becc905-a063-4983-8d30-f6e0eba066a2; extending it to detect new size
2022-02-23 14:18:29.310 7 INFO os_brick.initiator.connectors.lightos [req-50c802ea-f3d9-4d55-911a-b45be58805cf e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 7a57b632-c97c-4269-abfc-2f2e774c4012
2022-02-23 14:18:29.948 7 INFO nova.compute.manager [req-f847e730-9d55-420c-b016-5ee6df6a45af 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Detaching volume 0becc905-a063-4983-8d30-f6e0eba066a2
2022-02-23 14:18:30.008 7 INFO nova.virt.block_device [req-f847e730-9d55-420c-b016-5ee6df6a45af 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Attempting to driver detach volume 0becc905-a063-4983-8d30-f6e0eba066a2 from mountpoint /dev/vdb
2022-02-23 14:18:30.026 7 INFO nova.virt.libvirt.driver [req-f847e730-9d55-420c-b016-5ee6df6a45af 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] Successfully detached device vdb from instance d6de6161-2dda-4992-af4c-d8ad363f2312 from the persistent domain config.
2022-02-23 14:18:30.178 7 INFO nova.virt.libvirt.driver [req-f847e730-9d55-420c-b016-5ee6df6a45af 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] Successfully detached device vdb from instance d6de6161-2dda-4992-af4c-d8ad363f2312 from the live domain config.
2022-02-23 14:18:30.181 7 INFO os_brick.initiator.connectors.lightos [req-f847e730-9d55-420c-b016-5ee6df6a45af 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 7a57b632-c97c-4269-abfc-2f2e774c4012
2022-02-23 14:18:31.516 7 INFO nova.compute.claims [req-b95ed58d-8cb0-4629-ba42-6fb24993178f 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Claim successful on node rack08-server63
2022-02-23 14:18:31.936 7 INFO nova.virt.libvirt.driver [req-b95ed58d-8cb0-4629-ba42-6fb24993178f 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Creating image
2022-02-23 14:18:32.227 7 INFO nova.compute.manager [req-cacfc3e8-0177-4cb4-a740-84baeea3072b 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Terminating instance
2022-02-23 14:18:32.564 7 INFO nova.virt.libvirt.driver [-] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Instance destroyed successfully.
2022-02-23 14:18:32.578 7 INFO nova.virt.libvirt.driver [req-cacfc3e8-0177-4cb4-a740-84baeea3072b 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Deleting instance files /var/lib/nova/instances/d6de6161-2dda-4992-af4c-d8ad363f2312_del
2022-02-23 14:18:32.579 7 INFO nova.virt.libvirt.driver [req-cacfc3e8-0177-4cb4-a740-84baeea3072b 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Deletion of /var/lib/nova/instances/d6de6161-2dda-4992-af4c-d8ad363f2312_del complete
2022-02-23 14:18:32.646 7 INFO nova.compute.manager [req-cacfc3e8-0177-4cb4-a740-84baeea3072b 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 14:18:32.711 7 INFO nova.compute.manager [-] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:18:32.889 7 INFO nova.scheduler.client.report [req-cacfc3e8-0177-4cb4-a740-84baeea3072b 32732e8c81e44dacb79e87c0d53ae24f 71bc1003a3a54f5bbfe1856de70afcad - default default] Deleted allocations for instance d6de6161-2dda-4992-af4c-d8ad363f2312
2022-02-23 14:18:33.302 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] VM Resumed (Lifecycle Event)
2022-02-23 14:18:33.308 7 INFO nova.virt.libvirt.driver [-] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Instance spawned successfully.
2022-02-23 14:18:33.397 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:18:33.398 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] VM Started (Lifecycle Event)
2022-02-23 14:18:33.414 7 INFO nova.compute.manager [req-b95ed58d-8cb0-4629-ba42-6fb24993178f 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Took 1.48 seconds to spawn the instance on the hypervisor.
2022-02-23 14:18:33.453 7 INFO nova.compute.manager [req-92aa3b60-8013-46b4-bb2c-97bdb4fb2414 - - - - -] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 14:18:33.495 7 INFO nova.compute.manager [req-b95ed58d-8cb0-4629-ba42-6fb24993178f 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Took 2.02 seconds to build instance.
2022-02-23 14:18:34.901 7 INFO nova.virt.libvirt.driver [req-8cfcc76c-9f06-4682-90df-29d0991be1f5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Ignoring supplied device name: /dev/vdb
2022-02-23 14:18:35.054 7 INFO nova.compute.manager [req-8cfcc76c-9f06-4682-90df-29d0991be1f5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Attaching volume c0e69af2-4794-4d8e-a770-543db6d6ce2d to /dev/vdb
2022-02-23 14:18:35.144 7 WARNING os_brick.initiator.connectors.nvmeof [req-8cfcc76c-9f06-4682-90df-29d0991be1f5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 14:18:36.477 7 INFO os_brick.initiator.connectors.lightos [req-8cfcc76c-9f06-4682-90df-29d0991be1f5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: connect_volume called for volume 58b78ad6-f73e-40cf-9fb8-19c776d883d5, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '58b78ad6-f73e-40cf-9fb8-19c776d883d5', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 14:18:36.481 7 INFO os_brick.initiator.connectors.lightos [req-8cfcc76c-9f06-4682-90df-29d0991be1f5 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 58b78ad6-f73e-40cf-9fb8-19c776d883d5
2022-02-23 14:18:38.769 7 INFO nova.compute.manager [-] [instance: 602acf4b-63ef-4149-8c8b-759e49258ebf] VM Stopped (Lifecycle Event)
2022-02-23 14:18:45.478 7 INFO nova.compute.manager [req-fdff60ac-5618-490a-9b31-bf51d3d137a7 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Detaching volume c0e69af2-4794-4d8e-a770-543db6d6ce2d
2022-02-23 14:18:45.538 7 INFO nova.virt.block_device [req-fdff60ac-5618-490a-9b31-bf51d3d137a7 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Attempting to driver detach volume c0e69af2-4794-4d8e-a770-543db6d6ce2d from mountpoint /dev/vdb
2022-02-23 14:18:45.559 7 INFO nova.virt.libvirt.driver [req-fdff60ac-5618-490a-9b31-bf51d3d137a7 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Successfully detached device vdb from instance e0fddd30-8937-47f1-92dd-95cf315fa88d from the persistent domain config.
2022-02-23 14:18:45.700 7 INFO nova.virt.libvirt.driver [req-fdff60ac-5618-490a-9b31-bf51d3d137a7 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Successfully detached device vdb from instance e0fddd30-8937-47f1-92dd-95cf315fa88d from the live domain config.
2022-02-23 14:18:45.703 7 INFO os_brick.initiator.connectors.lightos [req-fdff60ac-5618-490a-9b31-bf51d3d137a7 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 58b78ad6-f73e-40cf-9fb8-19c776d883d5
2022-02-23 14:18:47.560 7 INFO nova.compute.manager [-] [instance: d6de6161-2dda-4992-af4c-d8ad363f2312] VM Stopped (Lifecycle Event)
2022-02-23 14:18:47.716 7 INFO nova.compute.manager [req-6b36cf05-db70-4a66-b4c2-5cfd7266df7d 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Terminating instance
2022-02-23 14:18:48.885 7 INFO nova.virt.libvirt.driver [-] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Instance destroyed successfully.
2022-02-23 14:18:48.903 7 INFO nova.virt.libvirt.driver [req-6b36cf05-db70-4a66-b4c2-5cfd7266df7d 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Deleting instance files /var/lib/nova/instances/e0fddd30-8937-47f1-92dd-95cf315fa88d_del
2022-02-23 14:18:48.904 7 INFO nova.virt.libvirt.driver [req-6b36cf05-db70-4a66-b4c2-5cfd7266df7d 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Deletion of /var/lib/nova/instances/e0fddd30-8937-47f1-92dd-95cf315fa88d_del complete
2022-02-23 14:18:48.978 7 INFO nova.compute.manager [req-6b36cf05-db70-4a66-b4c2-5cfd7266df7d 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-23 14:18:49.043 7 INFO nova.compute.manager [-] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] Took 0.06 seconds to deallocate network for instance.
2022-02-23 14:18:49.213 7 INFO nova.scheduler.client.report [req-6b36cf05-db70-4a66-b4c2-5cfd7266df7d 611b758d37a4412ca463698806b0b446 e275a93ce0534672b12e00b762be1d16 - default default] Deleted allocations for instance e0fddd30-8937-47f1-92dd-95cf315fa88d
2022-02-23 14:19:03.883 7 INFO nova.compute.manager [-] [instance: e0fddd30-8937-47f1-92dd-95cf315fa88d] VM Stopped (Lifecycle Event)
