Build Started 22_02_2022_13_32_44
2022-02-22 15:35:05.097 8 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 15:35:09.141 8 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 15:35:10.051 8 INFO nova.virt.driver [req-50b19b17-7288-4e91-97a0-3bd5e2c4c7b5 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 15:35:10.436 8 INFO nova.compute.provider_config [req-50b19b17-7288-4e91-97a0-3bd5e2c4c7b5 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 15:35:10.455 8 WARNING oslo_config.cfg [req-50b19b17-7288-4e91-97a0-3bd5e2c4c7b5 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 15:35:10.476 8 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 15:35:10.489 8 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 15:35:10.528 8 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 15:35:10.638 8 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 15:35:10.650 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 15:35:10.653 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 15:35:11.061 8 INFO nova.compute.manager [req-cbb28676-1eb6-41eb-9219-7ccb25a18c2d - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 15:35:11.199 8 INFO nova.service [req-cbb28676-1eb6-41eb-9219-7ccb25a18c2d - - - - -] Updating service version for nova-compute on rack08-server63 from 61 to 60
2022-02-22 15:35:12.744 8 INFO nova.virt.libvirt.host [req-cbb28676-1eb6-41eb-9219-7ccb25a18c2d - - - - -] kernel doesn't support AMD SEV
2022-02-22 15:36:03.897 8 INFO nova.compute.claims [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Claim successful on node rack08-server63
2022-02-22 15:36:04.284 8 INFO nova.virt.libvirt.driver [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Creating image
2022-02-22 15:36:04.289 8 INFO oslo.privsep.daemon [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp7_hyx2m_/privsep.sock']
2022-02-22 15:36:04.842 8 WARNING nova.compute.manager [req-d490125b-135a-46bc-801e-6a1bb34c9a17 - - - - -] While synchronizing instance power states, found 4 instances in the database and 3 instances on the hypervisor.
2022-02-22 15:36:05.929 8 INFO oslo.privsep.daemon [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 15:36:05.777 71 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 15:36:05.783 71 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 15:36:05.788 71 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 15:36:05.788 71 INFO oslo.privsep.daemon [-] privsep daemon running as pid 71
2022-02-22 15:36:07.324 8 INFO nova.compute.manager [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] VM Resumed (Lifecycle Event)
2022-02-22 15:36:07.333 8 INFO nova.virt.libvirt.driver [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Instance spawned successfully.
2022-02-22 15:36:07.334 8 INFO nova.compute.manager [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Took 3.05 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:07.383 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:07.384 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] VM Started (Lifecycle Event)
2022-02-22 15:36:07.443 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:07.462 8 INFO nova.compute.manager [req-795379f8-57f1-44db-8aeb-3e96ba0a9a7b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Took 3.61 seconds to build instance.
2022-02-22 15:36:07.483 8 INFO nova.compute.manager [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:10.001 8 INFO nova.compute.manager [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Attaching volume 3486c2b5-b1c0-4866-b79b-ac5650af861e to /dev/vdb
2022-02-22 15:36:10.100 8 INFO oslo.privsep.daemon [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpob7mhrtb/privsep.sock']
2022-02-22 15:36:10.765 8 INFO oslo.privsep.daemon [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 15:36:10.685 106 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 15:36:10.692 106 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 15:36:10.697 106 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 15:36:10.697 106 INFO oslo.privsep.daemon [-] privsep daemon running as pid 106
2022-02-22 15:36:11.670 8 WARNING os_brick.initiator.connectors.nvmeof [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:13.087 8 INFO os_brick.initiator.connectors.lightos [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: connect_volume called for volume 27699dec-129f-4bd7-bc0b-e3ed1dc50cde, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '27699dec-129f-4bd7-bc0b-e3ed1dc50cde', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:36:13.122 8 INFO os_brick.initiator.connectors.lightos [req-06891cf7-6454-46a6-8377-2ba6989b3b07 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 27699dec-129f-4bd7-bc0b-e3ed1dc50cde
2022-02-22 15:36:15.668 8 INFO nova.compute.claims [req-7e4c0961-86ee-4b81-9fa7-c7ea0946665f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Claim successful on node rack08-server63
2022-02-22 15:36:16.048 8 INFO nova.virt.libvirt.driver [req-7e4c0961-86ee-4b81-9fa7-c7ea0946665f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Creating image
2022-02-22 15:36:17.210 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] VM Resumed (Lifecycle Event)
2022-02-22 15:36:17.218 8 INFO nova.virt.libvirt.driver [-] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Instance spawned successfully.
2022-02-22 15:36:17.219 8 INFO nova.compute.manager [req-7e4c0961-86ee-4b81-9fa7-c7ea0946665f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:17.266 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:17.266 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] VM Started (Lifecycle Event)
2022-02-22 15:36:17.308 8 INFO nova.compute.manager [req-7e4c0961-86ee-4b81-9fa7-c7ea0946665f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Took 1.68 seconds to build instance.
2022-02-22 15:36:17.763 8 INFO nova.compute.manager [req-8197e39e-9cad-4db0-974d-79fdb7d6ccdf b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Detaching volume 3486c2b5-b1c0-4866-b79b-ac5650af861e
2022-02-22 15:36:17.822 8 INFO nova.virt.block_device [req-8197e39e-9cad-4db0-974d-79fdb7d6ccdf b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Attempting to driver detach volume 3486c2b5-b1c0-4866-b79b-ac5650af861e from mountpoint /dev/vdb
2022-02-22 15:36:17.840 8 INFO nova.virt.libvirt.driver [req-8197e39e-9cad-4db0-974d-79fdb7d6ccdf b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance 6ee5d5b3-f471-445e-bd78-96fb9f338a02 from the persistent domain config.
2022-02-22 15:36:17.982 8 INFO nova.virt.libvirt.driver [req-8197e39e-9cad-4db0-974d-79fdb7d6ccdf b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance 6ee5d5b3-f471-445e-bd78-96fb9f338a02 from the live domain config.
2022-02-22 15:36:17.986 8 INFO os_brick.initiator.connectors.lightos [req-8197e39e-9cad-4db0-974d-79fdb7d6ccdf b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 27699dec-129f-4bd7-bc0b-e3ed1dc50cde
2022-02-22 15:36:19.461 8 INFO nova.compute.claims [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Claim successful on node rack08-server63
2022-02-22 15:36:19.720 8 INFO nova.virt.libvirt.driver [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 15:36:19.804 8 INFO nova.virt.block_device [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Booting with volume ca45a624-8370-4956-afef-ca6f2319b5ac at /dev/vda
2022-02-22 15:36:19.894 8 WARNING os_brick.initiator.connectors.nvmeof [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:21.259 8 INFO nova.compute.claims [req-1a6ba9e4-26c9-4fac-95ee-be147d26ccc7 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Claim successful on node rack08-server63
2022-02-22 15:36:21.410 8 INFO nova.virt.libvirt.driver [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Creating image
2022-02-22 15:36:21.420 8 INFO os_brick.initiator.connectors.lightos [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: connect_volume called for volume ba04c398-9346-494a-bb22-70c75c723231, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ba04c398-9346-494a-bb22-70c75c723231', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:36:21.423 8 INFO os_brick.initiator.connectors.lightos [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ba04c398-9346-494a-bb22-70c75c723231
2022-02-22 15:36:21.669 8 INFO nova.virt.libvirt.driver [req-1a6ba9e4-26c9-4fac-95ee-be147d26ccc7 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Creating image
2022-02-22 15:36:22.222 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] VM Resumed (Lifecycle Event)
2022-02-22 15:36:22.230 8 INFO nova.virt.libvirt.driver [-] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Instance spawned successfully.
2022-02-22 15:36:22.231 8 INFO nova.compute.manager [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Took 0.82 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:22.275 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:22.276 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] VM Started (Lifecycle Event)
2022-02-22 15:36:22.317 8 INFO nova.compute.manager [req-f3329c29-be4b-4888-baea-595c9d089dce 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Took 2.90 seconds to build instance.
2022-02-22 15:36:22.824 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: ad444847-b92c-4dfe-8460-7efa24437963] VM Resumed (Lifecycle Event)
2022-02-22 15:36:22.830 8 INFO nova.virt.libvirt.driver [-] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Instance spawned successfully.
2022-02-22 15:36:22.831 8 INFO nova.compute.manager [req-1a6ba9e4-26c9-4fac-95ee-be147d26ccc7 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:22.880 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: ad444847-b92c-4dfe-8460-7efa24437963] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:22.881 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: ad444847-b92c-4dfe-8460-7efa24437963] VM Started (Lifecycle Event)
2022-02-22 15:36:22.918 8 INFO nova.compute.manager [req-1a6ba9e4-26c9-4fac-95ee-be147d26ccc7 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Took 1.70 seconds to build instance.
2022-02-22 15:36:24.696 8 INFO nova.compute.claims [req-a49addf3-ee49-4591-8306-bdb218ccecb5 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Claim successful on node rack08-server63
2022-02-22 15:36:25.135 8 INFO nova.virt.libvirt.driver [req-a49addf3-ee49-4591-8306-bdb218ccecb5 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Creating image
2022-02-22 15:36:25.207 8 INFO nova.compute.claims [req-b18b9808-b9fc-4a3a-850b-56dd0c5f1c9c 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Claim successful on node rack08-server63
2022-02-22 15:36:25.694 8 INFO nova.virt.libvirt.driver [req-b18b9808-b9fc-4a3a-850b-56dd0c5f1c9c 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Creating image
2022-02-22 15:36:25.823 8 INFO nova.compute.manager [req-547cc30e-f2a9-4bcb-95b0-c64a44f06799 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Attaching volume fdbf85cc-9bf0-4345-8656-82824fd2a214 to /dev/vdb
2022-02-22 15:36:25.925 8 WARNING os_brick.initiator.connectors.nvmeof [req-547cc30e-f2a9-4bcb-95b0-c64a44f06799 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:26.372 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] VM Resumed (Lifecycle Event)
2022-02-22 15:36:26.380 8 INFO nova.virt.libvirt.driver [-] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Instance spawned successfully.
2022-02-22 15:36:26.381 8 INFO nova.compute.manager [req-a49addf3-ee49-4591-8306-bdb218ccecb5 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:26.427 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:26.428 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] VM Started (Lifecycle Event)
2022-02-22 15:36:26.481 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:26.495 8 INFO nova.compute.manager [req-a49addf3-ee49-4591-8306-bdb218ccecb5 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Took 1.83 seconds to build instance.
2022-02-22 15:36:26.864 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] VM Resumed (Lifecycle Event)
2022-02-22 15:36:26.870 8 INFO nova.virt.libvirt.driver [-] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Instance spawned successfully.
2022-02-22 15:36:26.870 8 INFO nova.compute.manager [req-b18b9808-b9fc-4a3a-850b-56dd0c5f1c9c 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:26.916 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:26.917 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] VM Started (Lifecycle Event)
2022-02-22 15:36:26.953 8 INFO nova.compute.manager [req-b18b9808-b9fc-4a3a-850b-56dd0c5f1c9c 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Took 1.78 seconds to build instance.
2022-02-22 15:36:27.275 8 INFO os_brick.initiator.connectors.lightos [req-547cc30e-f2a9-4bcb-95b0-c64a44f06799 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: connect_volume called for volume 9cbb0bbb-76a4-47de-9634-a712283762a6, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9cbb0bbb-76a4-47de-9634-a712283762a6', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:36:27.277 8 INFO os_brick.initiator.connectors.lightos [req-547cc30e-f2a9-4bcb-95b0-c64a44f06799 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 9cbb0bbb-76a4-47de-9634-a712283762a6
2022-02-22 15:36:28.418 8 INFO nova.compute.manager [req-120c9a92-9e6f-40f3-bb67-4d104b792887 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Detaching volume fdbf85cc-9bf0-4345-8656-82824fd2a214
2022-02-22 15:36:28.478 8 INFO nova.virt.block_device [req-120c9a92-9e6f-40f3-bb67-4d104b792887 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Attempting to driver detach volume fdbf85cc-9bf0-4345-8656-82824fd2a214 from mountpoint /dev/vdb
2022-02-22 15:36:28.495 8 INFO nova.virt.libvirt.driver [req-120c9a92-9e6f-40f3-bb67-4d104b792887 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance ad444847-b92c-4dfe-8460-7efa24437963 from the persistent domain config.
2022-02-22 15:36:28.647 8 INFO nova.virt.libvirt.driver [req-120c9a92-9e6f-40f3-bb67-4d104b792887 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance ad444847-b92c-4dfe-8460-7efa24437963 from the live domain config.
2022-02-22 15:36:28.650 8 INFO os_brick.initiator.connectors.lightos [req-120c9a92-9e6f-40f3-bb67-4d104b792887 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 9cbb0bbb-76a4-47de-9634-a712283762a6
2022-02-22 15:36:29.920 8 INFO nova.compute.manager [req-a98fbdd2-b5cb-4664-9ad7-35b0e48c0d08 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Attaching volume b6e04478-f916-45c1-b902-e98792a0b624 to /dev/vdb
2022-02-22 15:36:30.010 8 WARNING os_brick.initiator.connectors.nvmeof [req-a98fbdd2-b5cb-4664-9ad7-35b0e48c0d08 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:31.367 8 INFO os_brick.initiator.connectors.lightos [req-a98fbdd2-b5cb-4664-9ad7-35b0e48c0d08 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: connect_volume called for volume 63664898-5b6c-4129-9875-69641d09bacf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '63664898-5b6c-4129-9875-69641d09bacf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:36:31.372 8 INFO os_brick.initiator.connectors.lightos [req-a98fbdd2-b5cb-4664-9ad7-35b0e48c0d08 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 63664898-5b6c-4129-9875-69641d09bacf
2022-02-22 15:36:31.895 8 INFO nova.compute.claims [req-ae1a0cc1-1cb2-4660-9d69-8a8eee24669f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Claim successful on node rack08-server63
2022-02-22 15:36:32.268 8 INFO nova.virt.libvirt.driver [req-ae1a0cc1-1cb2-4660-9d69-8a8eee24669f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Creating image
2022-02-22 15:36:32.412 8 INFO nova.compute.manager [req-075b819d-ca52-45fe-b90b-3ff4f4dcf6d6 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Attaching volume b6e04478-f916-45c1-b902-e98792a0b624 to /dev/vdb
2022-02-22 15:36:32.507 8 WARNING os_brick.initiator.connectors.nvmeof [req-075b819d-ca52-45fe-b90b-3ff4f4dcf6d6 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:33.451 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] VM Resumed (Lifecycle Event)
2022-02-22 15:36:33.459 8 INFO nova.virt.libvirt.driver [-] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Instance spawned successfully.
2022-02-22 15:36:33.460 8 INFO nova.compute.manager [req-ae1a0cc1-1cb2-4660-9d69-8a8eee24669f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 15:36:33.508 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:36:33.509 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] VM Started (Lifecycle Event)
2022-02-22 15:36:33.559 8 INFO nova.compute.manager [req-ae1a0cc1-1cb2-4660-9d69-8a8eee24669f b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Took 1.70 seconds to build instance.
2022-02-22 15:36:33.875 8 INFO os_brick.initiator.connectors.lightos [req-075b819d-ca52-45fe-b90b-3ff4f4dcf6d6 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: connect_volume called for volume 63664898-5b6c-4129-9875-69641d09bacf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '63664898-5b6c-4129-9875-69641d09bacf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:36:33.876 8 INFO os_brick.initiator.connectors.lightos [req-075b819d-ca52-45fe-b90b-3ff4f4dcf6d6 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 63664898-5b6c-4129-9875-69641d09bacf
2022-02-22 15:36:34.945 8 INFO nova.compute.manager [req-26a5771c-56da-4e23-9975-98aff82c0dc2 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Detaching volume b6e04478-f916-45c1-b902-e98792a0b624
2022-02-22 15:36:35.005 8 INFO nova.virt.block_device [req-26a5771c-56da-4e23-9975-98aff82c0dc2 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Attempting to driver detach volume b6e04478-f916-45c1-b902-e98792a0b624 from mountpoint /dev/vdb
2022-02-22 15:36:35.022 8 INFO nova.virt.libvirt.driver [req-26a5771c-56da-4e23-9975-98aff82c0dc2 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Successfully detached device vdb from instance 18b13256-dc0b-44a7-a8fd-32edb152a83a from the persistent domain config.
2022-02-22 15:36:35.163 8 INFO nova.virt.libvirt.driver [req-26a5771c-56da-4e23-9975-98aff82c0dc2 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Successfully detached device vdb from instance 18b13256-dc0b-44a7-a8fd-32edb152a83a from the live domain config.
2022-02-22 15:36:35.234 8 INFO nova.virt.libvirt.driver [req-26a5771c-56da-4e23-9975-98aff82c0dc2 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Detected multiple connections on this host for volume: b6e04478-f916-45c1-b902-e98792a0b624, skipping target disconnect.
2022-02-22 15:36:36.587 8 INFO nova.compute.manager [req-3304bd81-f482-46c3-b46f-e263e06f9c02 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Attaching volume d34c806e-9239-4448-a170-82e2494bb0a5 to /dev/vdb
2022-02-22 15:36:36.678 8 WARNING os_brick.initiator.connectors.nvmeof [req-3304bd81-f482-46c3-b46f-e263e06f9c02 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:36:37.419 8 INFO nova.compute.manager [req-d0698208-23f0-4518-8a29-26796f073b6a 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Detaching volume b6e04478-f916-45c1-b902-e98792a0b624
2022-02-22 15:36:37.478 8 INFO nova.virt.block_device [req-d0698208-23f0-4518-8a29-26796f073b6a 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Attempting to driver detach volume b6e04478-f916-45c1-b902-e98792a0b624 from mountpoint /dev/vdb
2022-02-22 15:36:37.497 8 INFO nova.virt.libvirt.driver [req-d0698208-23f0-4518-8a29-26796f073b6a 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Successfully detached device vdb from instance 39af04a7-2571-45d2-a68a-40081eed1a25 from the persistent domain config.
2022-02-22 15:36:37.679 8 INFO nova.virt.libvirt.driver [req-d0698208-23f0-4518-8a29-26796f073b6a 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Successfully detached device vdb from instance 39af04a7-2571-45d2-a68a-40081eed1a25 from the live domain config.
2022-02-22 15:37:38.392 8 INFO os_brick.initiator.connectors.lightos [req-3304bd81-f482-46c3-b46f-e263e06f9c02 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: connect_volume called for volume 6c55953e-2bc3-4e19-a9b4-b84e8256e0e3, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6c55953e-2bc3-4e19-a9b4-b84e8256e0e3', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:37:38.395 8 INFO os_brick.initiator.connectors.lightos [req-3304bd81-f482-46c3-b46f-e263e06f9c02 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 6c55953e-2bc3-4e19-a9b4-b84e8256e0e3
2022-02-22 15:37:39.497 8 INFO nova.compute.manager [req-5a680752-8903-4718-a9fb-8593914bb2f9 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Detaching volume d34c806e-9239-4448-a170-82e2494bb0a5
2022-02-22 15:37:39.553 8 INFO nova.virt.block_device [req-5a680752-8903-4718-a9fb-8593914bb2f9 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Attempting to driver detach volume d34c806e-9239-4448-a170-82e2494bb0a5 from mountpoint /dev/vdb
2022-02-22 15:37:39.573 8 INFO nova.virt.libvirt.driver [req-5a680752-8903-4718-a9fb-8593914bb2f9 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance 4adb6a53-a136-4f84-b2ee-323a2fbb698a from the persistent domain config.
2022-02-22 15:37:39.714 8 INFO nova.virt.libvirt.driver [req-5a680752-8903-4718-a9fb-8593914bb2f9 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Successfully detached device vdb from instance 4adb6a53-a136-4f84-b2ee-323a2fbb698a from the live domain config.
2022-02-22 15:37:39.717 8 INFO os_brick.initiator.connectors.lightos [req-5a680752-8903-4718-a9fb-8593914bb2f9 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 6c55953e-2bc3-4e19-a9b4-b84e8256e0e3
2022-02-22 15:37:42.965 8 INFO nova.compute.manager [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Terminating instance
2022-02-22 15:37:43.333 8 INFO nova.virt.libvirt.driver [-] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Instance destroyed successfully.
2022-02-22 15:37:43.348 8 INFO nova.virt.libvirt.driver [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Deleting instance files /var/lib/nova/instances/4adb6a53-a136-4f84-b2ee-323a2fbb698a_del
2022-02-22 15:37:43.350 8 INFO nova.virt.libvirt.driver [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Deletion of /var/lib/nova/instances/4adb6a53-a136-4f84-b2ee-323a2fbb698a_del complete
2022-02-22 15:37:43.428 8 INFO nova.virt.libvirt.host [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] UEFI support detected
2022-02-22 15:37:43.430 8 INFO nova.compute.manager [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 15:37:43.497 8 INFO nova.compute.manager [-] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:37:43.702 8 INFO nova.scheduler.client.report [req-0d5b691b-c631-4c18-97fe-6fc3eb76c986 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Deleted allocations for instance 4adb6a53-a136-4f84-b2ee-323a2fbb698a
2022-02-22 15:37:45.369 8 INFO nova.compute.manager [req-db3ec2c8-13b6-47b8-8117-c4cb994ba7dd b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Terminating instance
2022-02-22 15:37:45.722 8 INFO nova.virt.libvirt.driver [-] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Instance destroyed successfully.
2022-02-22 15:37:45.738 8 INFO nova.virt.libvirt.driver [req-db3ec2c8-13b6-47b8-8117-c4cb994ba7dd b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Deleting instance files /var/lib/nova/instances/ad444847-b92c-4dfe-8460-7efa24437963_del
2022-02-22 15:37:45.740 8 INFO nova.virt.libvirt.driver [req-db3ec2c8-13b6-47b8-8117-c4cb994ba7dd b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Deletion of /var/lib/nova/instances/ad444847-b92c-4dfe-8460-7efa24437963_del complete
2022-02-22 15:37:45.812 8 INFO nova.compute.manager [req-db3ec2c8-13b6-47b8-8117-c4cb994ba7dd b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:37:45.879 8 INFO nova.compute.manager [-] [instance: ad444847-b92c-4dfe-8460-7efa24437963] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:37:46.066 8 INFO nova.scheduler.client.report [req-db3ec2c8-13b6-47b8-8117-c4cb994ba7dd b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Deleted allocations for instance ad444847-b92c-4dfe-8460-7efa24437963
2022-02-22 15:37:46.595 8 INFO nova.compute.manager [req-c69190d9-8a21-4221-8c4a-e4f8d2a876e0 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Terminating instance
2022-02-22 15:37:46.938 8 INFO nova.virt.libvirt.driver [-] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Instance destroyed successfully.
2022-02-22 15:37:46.950 8 INFO nova.virt.libvirt.driver [req-c69190d9-8a21-4221-8c4a-e4f8d2a876e0 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Deleting instance files /var/lib/nova/instances/fd9eecea-ad31-439b-a480-97aa4c0f8667_del
2022-02-22 15:37:46.952 8 INFO nova.virt.libvirt.driver [req-c69190d9-8a21-4221-8c4a-e4f8d2a876e0 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Deletion of /var/lib/nova/instances/fd9eecea-ad31-439b-a480-97aa4c0f8667_del complete
2022-02-22 15:37:47.017 8 INFO nova.compute.manager [req-c69190d9-8a21-4221-8c4a-e4f8d2a876e0 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:37:47.080 8 INFO nova.compute.manager [-] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:37:47.271 8 INFO nova.scheduler.client.report [req-c69190d9-8a21-4221-8c4a-e4f8d2a876e0 b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Deleted allocations for instance fd9eecea-ad31-439b-a480-97aa4c0f8667
2022-02-22 15:37:48.990 8 INFO nova.compute.manager [req-d05371e9-da81-406f-bbb5-1caf541fca8b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Terminating instance
2022-02-22 15:37:49.329 8 INFO nova.virt.libvirt.driver [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Instance destroyed successfully.
2022-02-22 15:37:49.345 8 INFO nova.virt.libvirt.driver [req-d05371e9-da81-406f-bbb5-1caf541fca8b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Deleting instance files /var/lib/nova/instances/6ee5d5b3-f471-445e-bd78-96fb9f338a02_del
2022-02-22 15:37:49.347 8 INFO nova.virt.libvirt.driver [req-d05371e9-da81-406f-bbb5-1caf541fca8b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Deletion of /var/lib/nova/instances/6ee5d5b3-f471-445e-bd78-96fb9f338a02_del complete
2022-02-22 15:37:49.412 8 INFO nova.compute.manager [req-d05371e9-da81-406f-bbb5-1caf541fca8b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:37:49.476 8 INFO nova.compute.manager [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] Took 0.06 seconds to deallocate network for instance.
2022-02-22 15:37:49.676 8 INFO nova.scheduler.client.report [req-d05371e9-da81-406f-bbb5-1caf541fca8b b0129f347b4543f3af74e33459964059 834e396dc3f7410f9ceba80ede03ce66 - default default] Deleted allocations for instance 6ee5d5b3-f471-445e-bd78-96fb9f338a02
2022-02-22 15:37:56.906 8 INFO nova.compute.claims [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Claim successful on node rack08-server63
2022-02-22 15:37:57.170 8 INFO nova.virt.libvirt.driver [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 15:37:57.260 8 INFO nova.virt.block_device [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Booting with volume 63fd7345-9fc9-41ac-be46-f9a83d45a503 at /dev/vda
2022-02-22 15:37:57.357 8 WARNING os_brick.initiator.connectors.nvmeof [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:37:58.332 8 INFO nova.compute.manager [-] [instance: 4adb6a53-a136-4f84-b2ee-323a2fbb698a] VM Stopped (Lifecycle Event)
2022-02-22 15:37:58.880 8 INFO nova.virt.libvirt.driver [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Creating image
2022-02-22 15:37:58.894 8 INFO os_brick.initiator.connectors.lightos [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: connect_volume called for volume 99ba9937-2958-45c8-ae07-abecc0e0e048, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '99ba9937-2958-45c8-ae07-abecc0e0e048', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:37:58.898 8 INFO os_brick.initiator.connectors.lightos [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 99ba9937-2958-45c8-ae07-abecc0e0e048
2022-02-22 15:37:59.734 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] VM Resumed (Lifecycle Event)
2022-02-22 15:37:59.740 8 INFO nova.virt.libvirt.driver [-] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Instance spawned successfully.
2022-02-22 15:37:59.741 8 INFO nova.compute.manager [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Took 0.86 seconds to spawn the instance on the hypervisor.
2022-02-22 15:37:59.786 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:37:59.787 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] VM Started (Lifecycle Event)
2022-02-22 15:37:59.822 8 INFO nova.compute.manager [req-23da31c0-334f-4c85-ac3e-c22ada979ccb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Took 2.95 seconds to build instance.
2022-02-22 15:38:00.719 8 INFO nova.compute.manager [-] [instance: ad444847-b92c-4dfe-8460-7efa24437963] VM Stopped (Lifecycle Event)
2022-02-22 15:38:01.053 8 INFO nova.compute.manager [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Terminating instance
2022-02-22 15:38:01.388 8 INFO nova.virt.libvirt.driver [-] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Instance destroyed successfully.
2022-02-22 15:38:01.459 8 INFO os_brick.initiator.connectors.lightos [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 99ba9937-2958-45c8-ae07-abecc0e0e048
2022-02-22 15:38:01.470 8 INFO nova.virt.libvirt.driver [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Deleting instance files /var/lib/nova/instances/2231b975-62e9-434e-b2de-a67e9bfd7867_del
2022-02-22 15:38:01.471 8 INFO nova.virt.libvirt.driver [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Deletion of /var/lib/nova/instances/2231b975-62e9-434e-b2de-a67e9bfd7867_del complete
2022-02-22 15:38:01.548 8 INFO nova.compute.manager [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 15:38:01.618 8 INFO nova.compute.manager [-] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:38:01.936 8 INFO nova.compute.manager [-] [instance: fd9eecea-ad31-439b-a480-97aa4c0f8667] VM Stopped (Lifecycle Event)
2022-02-22 15:38:02.867 8 INFO nova.compute.manager [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-22 15:38:03.057 8 INFO nova.scheduler.client.report [req-d08a29ee-6b31-4ee4-9ee5-2bc078e769fb 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Deleted allocations for instance 2231b975-62e9-434e-b2de-a67e9bfd7867
2022-02-22 15:38:04.327 8 INFO nova.compute.manager [-] [instance: 6ee5d5b3-f471-445e-bd78-96fb9f338a02] VM Stopped (Lifecycle Event)
2022-02-22 15:38:05.945 8 INFO nova.compute.manager [req-3dd0fb4c-db30-4046-ae98-ff72de76e76e 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Terminating instance
2022-02-22 15:38:06.282 8 INFO nova.virt.libvirt.driver [-] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Instance destroyed successfully.
2022-02-22 15:38:06.296 8 INFO nova.virt.libvirt.driver [req-3dd0fb4c-db30-4046-ae98-ff72de76e76e 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Deleting instance files /var/lib/nova/instances/39af04a7-2571-45d2-a68a-40081eed1a25_del
2022-02-22 15:38:06.298 8 INFO nova.virt.libvirt.driver [req-3dd0fb4c-db30-4046-ae98-ff72de76e76e 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Deletion of /var/lib/nova/instances/39af04a7-2571-45d2-a68a-40081eed1a25_del complete
2022-02-22 15:38:06.365 8 INFO nova.compute.manager [req-3dd0fb4c-db30-4046-ae98-ff72de76e76e 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:38:06.445 8 INFO nova.compute.manager [-] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] Took 0.08 seconds to deallocate network for instance.
2022-02-22 15:38:06.618 8 INFO nova.scheduler.client.report [req-3dd0fb4c-db30-4046-ae98-ff72de76e76e 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Deleted allocations for instance 39af04a7-2571-45d2-a68a-40081eed1a25
2022-02-22 15:38:07.186 8 INFO nova.compute.manager [req-8aab7b64-ccaa-43c9-8d72-99d92fceedae 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Terminating instance
2022-02-22 15:38:07.531 8 INFO nova.virt.libvirt.driver [-] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Instance destroyed successfully.
2022-02-22 15:38:07.546 8 INFO nova.virt.libvirt.driver [req-8aab7b64-ccaa-43c9-8d72-99d92fceedae 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Deleting instance files /var/lib/nova/instances/18b13256-dc0b-44a7-a8fd-32edb152a83a_del
2022-02-22 15:38:07.548 8 INFO nova.virt.libvirt.driver [req-8aab7b64-ccaa-43c9-8d72-99d92fceedae 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Deletion of /var/lib/nova/instances/18b13256-dc0b-44a7-a8fd-32edb152a83a_del complete
2022-02-22 15:38:07.616 8 INFO nova.compute.manager [req-8aab7b64-ccaa-43c9-8d72-99d92fceedae 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:38:07.684 8 INFO nova.compute.manager [-] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:38:07.883 8 INFO nova.scheduler.client.report [req-8aab7b64-ccaa-43c9-8d72-99d92fceedae 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Deleted allocations for instance 18b13256-dc0b-44a7-a8fd-32edb152a83a
2022-02-22 15:38:08.437 8 INFO nova.compute.manager [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Terminating instance
2022-02-22 15:38:08.772 8 INFO nova.virt.libvirt.driver [-] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Instance destroyed successfully.
2022-02-22 15:38:08.871 8 INFO os_brick.initiator.connectors.lightos [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ba04c398-9346-494a-bb22-70c75c723231
2022-02-22 15:38:08.883 8 INFO nova.virt.libvirt.driver [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Deleting instance files /var/lib/nova/instances/d9fe1059-034f-42a7-ac91-ae1c7f4f9a95_del
2022-02-22 15:38:08.884 8 INFO nova.virt.libvirt.driver [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Deletion of /var/lib/nova/instances/d9fe1059-034f-42a7-ac91-ae1c7f4f9a95_del complete
2022-02-22 15:38:08.954 8 INFO nova.compute.manager [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Took 0.40 seconds to destroy the instance on the hypervisor.
2022-02-22 15:38:09.021 8 INFO nova.compute.manager [-] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:38:10.261 8 INFO nova.compute.manager [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 15:38:10.456 8 INFO nova.scheduler.client.report [req-2aa2c4b8-cd8d-421b-80ed-84921eb388f9 1c206ee1b86f468c9f30387f3f0a4d67 3950bb9f5b8d4581bd6e97db2d0fcdbc - default default] Deleted allocations for instance d9fe1059-034f-42a7-ac91-ae1c7f4f9a95
2022-02-22 15:38:16.386 8 INFO nova.compute.manager [-] [instance: 2231b975-62e9-434e-b2de-a67e9bfd7867] VM Stopped (Lifecycle Event)
2022-02-22 15:38:21.281 8 INFO nova.compute.manager [-] [instance: 39af04a7-2571-45d2-a68a-40081eed1a25] VM Stopped (Lifecycle Event)
2022-02-22 15:38:22.530 8 INFO nova.compute.manager [-] [instance: 18b13256-dc0b-44a7-a8fd-32edb152a83a] VM Stopped (Lifecycle Event)
2022-02-22 15:38:23.770 8 INFO nova.compute.manager [-] [instance: d9fe1059-034f-42a7-ac91-ae1c7f4f9a95] VM Stopped (Lifecycle Event)
2022-02-22 15:39:10.222 8 INFO nova.compute.claims [req-d756fc24-cabf-4fff-8df9-f8ee9e44eaca d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Claim successful on node rack08-server63
2022-02-22 15:39:10.638 8 INFO nova.virt.libvirt.driver [req-d756fc24-cabf-4fff-8df9-f8ee9e44eaca d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Creating image
2022-02-22 15:39:11.775 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] VM Resumed (Lifecycle Event)
2022-02-22 15:39:11.783 8 INFO nova.virt.libvirt.driver [-] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Instance spawned successfully.
2022-02-22 15:39:11.784 8 INFO nova.compute.manager [req-d756fc24-cabf-4fff-8df9-f8ee9e44eaca d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 15:39:11.833 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:39:11.834 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] VM Started (Lifecycle Event)
2022-02-22 15:39:11.868 8 INFO nova.compute.manager [req-d756fc24-cabf-4fff-8df9-f8ee9e44eaca d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Took 1.69 seconds to build instance.
2022-02-22 15:39:12.459 8 INFO nova.compute.manager [req-1acec226-1273-4ab4-9080-b9ac966d2b56 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Terminating instance
2022-02-22 15:39:12.802 8 INFO nova.virt.libvirt.driver [-] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Instance destroyed successfully.
2022-02-22 15:39:12.817 8 INFO nova.virt.libvirt.driver [req-1acec226-1273-4ab4-9080-b9ac966d2b56 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Deleting instance files /var/lib/nova/instances/6542aa16-c990-4220-b1c1-c142a6a18fd6_del
2022-02-22 15:39:12.818 8 INFO nova.virt.libvirt.driver [req-1acec226-1273-4ab4-9080-b9ac966d2b56 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Deletion of /var/lib/nova/instances/6542aa16-c990-4220-b1c1-c142a6a18fd6_del complete
2022-02-22 15:39:12.885 8 INFO nova.compute.manager [req-1acec226-1273-4ab4-9080-b9ac966d2b56 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:39:12.955 8 INFO nova.compute.manager [-] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:39:13.140 8 INFO nova.scheduler.client.report [req-1acec226-1273-4ab4-9080-b9ac966d2b56 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] Deleted allocations for instance 6542aa16-c990-4220-b1c1-c142a6a18fd6
2022-02-22 15:39:14.787 8 INFO nova.compute.claims [req-323ea688-3cac-4a33-8606-cdb2f8ad7867 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Claim successful on node rack08-server63
2022-02-22 15:39:15.161 8 INFO nova.virt.libvirt.driver [req-323ea688-3cac-4a33-8606-cdb2f8ad7867 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Creating image
2022-02-22 15:39:16.348 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] VM Resumed (Lifecycle Event)
2022-02-22 15:39:16.356 8 INFO nova.virt.libvirt.driver [-] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Instance spawned successfully.
2022-02-22 15:39:16.356 8 INFO nova.compute.manager [req-323ea688-3cac-4a33-8606-cdb2f8ad7867 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Took 1.20 seconds to spawn the instance on the hypervisor.
2022-02-22 15:39:16.408 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:39:16.409 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] VM Started (Lifecycle Event)
2022-02-22 15:39:16.444 8 INFO nova.compute.manager [req-323ea688-3cac-4a33-8606-cdb2f8ad7867 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Took 1.70 seconds to build instance.
2022-02-22 15:39:17.113 8 INFO nova.compute.manager [req-cf1da220-3e4c-41db-9ac3-b8f15bf4d3a9 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Terminating instance
2022-02-22 15:39:17.451 8 INFO nova.virt.libvirt.driver [-] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Instance destroyed successfully.
2022-02-22 15:39:17.467 8 INFO nova.virt.libvirt.driver [req-cf1da220-3e4c-41db-9ac3-b8f15bf4d3a9 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Deleting instance files /var/lib/nova/instances/62e7c5b7-d07c-47b6-9145-8a6764d558c7_del
2022-02-22 15:39:17.468 8 INFO nova.virt.libvirt.driver [req-cf1da220-3e4c-41db-9ac3-b8f15bf4d3a9 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Deletion of /var/lib/nova/instances/62e7c5b7-d07c-47b6-9145-8a6764d558c7_del complete
2022-02-22 15:39:17.538 8 INFO nova.compute.manager [req-cf1da220-3e4c-41db-9ac3-b8f15bf4d3a9 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:39:17.605 8 INFO nova.compute.manager [-] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:39:17.806 8 INFO nova.scheduler.client.report [req-cf1da220-3e4c-41db-9ac3-b8f15bf4d3a9 d5cefe615ed34e3499c16b370d52c1ea 7770b35cdf2244b688c93885fbf720e1 - default default] Deleted allocations for instance 62e7c5b7-d07c-47b6-9145-8a6764d558c7
2022-02-22 15:39:27.800 8 INFO nova.compute.manager [-] [instance: 6542aa16-c990-4220-b1c1-c142a6a18fd6] VM Stopped (Lifecycle Event)
2022-02-22 15:39:32.448 8 INFO nova.compute.manager [-] [instance: 62e7c5b7-d07c-47b6-9145-8a6764d558c7] VM Stopped (Lifecycle Event)
2022-02-22 15:39:49.215 8 INFO nova.compute.claims [req-2d9fd729-1145-484e-87f8-0c10305439ec e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Claim successful on node rack08-server63
2022-02-22 15:39:49.603 8 INFO nova.virt.libvirt.driver [req-2d9fd729-1145-484e-87f8-0c10305439ec e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Creating image
2022-02-22 15:39:50.764 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] VM Resumed (Lifecycle Event)
2022-02-22 15:39:50.771 8 INFO nova.virt.libvirt.driver [-] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Instance spawned successfully.
2022-02-22 15:39:50.772 8 INFO nova.compute.manager [req-2d9fd729-1145-484e-87f8-0c10305439ec e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Took 1.17 seconds to spawn the instance on the hypervisor.
2022-02-22 15:39:50.814 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:39:50.815 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] VM Started (Lifecycle Event)
2022-02-22 15:39:50.859 8 INFO nova.compute.manager [req-2d9fd729-1145-484e-87f8-0c10305439ec e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Took 1.68 seconds to build instance.
2022-02-22 15:39:55.713 8 INFO nova.compute.manager [req-a38a7434-b1a6-4e97-bc01-ce4aaaecc922 e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Terminating instance
2022-02-22 15:39:56.077 8 INFO nova.virt.libvirt.driver [-] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Instance destroyed successfully.
2022-02-22 15:39:56.093 8 INFO nova.virt.libvirt.driver [req-a38a7434-b1a6-4e97-bc01-ce4aaaecc922 e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Deleting instance files /var/lib/nova/instances/cafac6c4-7c07-483f-98ed-db44df39c65c_del
2022-02-22 15:39:56.095 8 INFO nova.virt.libvirt.driver [req-a38a7434-b1a6-4e97-bc01-ce4aaaecc922 e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Deletion of /var/lib/nova/instances/cafac6c4-7c07-483f-98ed-db44df39c65c_del complete
2022-02-22 15:39:56.162 8 INFO nova.compute.manager [req-a38a7434-b1a6-4e97-bc01-ce4aaaecc922 e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:39:56.238 8 INFO nova.compute.manager [-] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:39:56.435 8 INFO nova.scheduler.client.report [req-a38a7434-b1a6-4e97-bc01-ce4aaaecc922 e66a515d0011452cbf6d09bef8cc57b6 87b2586d76fe43c886bc9b3a87a1868a - default default] Deleted allocations for instance cafac6c4-7c07-483f-98ed-db44df39c65c
2022-02-22 15:40:11.075 8 INFO nova.compute.manager [-] [instance: cafac6c4-7c07-483f-98ed-db44df39c65c] VM Stopped (Lifecycle Event)
2022-02-22 15:40:12.699 8 INFO nova.compute.claims [req-0cc3c092-4451-45ed-b939-61ce243cc2ae 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Claim successful on node rack08-server63
2022-02-22 15:40:13.274 8 INFO nova.virt.libvirt.driver [req-0cc3c092-4451-45ed-b939-61ce243cc2ae 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Creating image
2022-02-22 15:40:14.508 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] VM Resumed (Lifecycle Event)
2022-02-22 15:40:14.518 8 INFO nova.virt.libvirt.driver [-] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Instance spawned successfully.
2022-02-22 15:40:14.519 8 INFO nova.compute.manager [req-0cc3c092-4451-45ed-b939-61ce243cc2ae 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-22 15:40:14.567 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:40:14.567 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] VM Started (Lifecycle Event)
2022-02-22 15:40:14.604 8 INFO nova.compute.manager [req-0cc3c092-4451-45ed-b939-61ce243cc2ae 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Took 2.12 seconds to build instance.
2022-02-22 15:40:28.649 8 INFO nova.virt.libvirt.driver [req-4f08b426-9f12-4014-ada9-06a141af6d5f 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Ignoring supplied device name: /dev/vdb
2022-02-22 15:40:28.800 8 INFO nova.compute.manager [req-4f08b426-9f12-4014-ada9-06a141af6d5f 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Attaching volume 7d6b4585-f5dd-4e12-8e15-539acb162533 to /dev/vdb
2022-02-22 15:40:28.888 8 WARNING os_brick.initiator.connectors.nvmeof [req-4f08b426-9f12-4014-ada9-06a141af6d5f 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:40:30.266 8 INFO os_brick.initiator.connectors.lightos [req-4f08b426-9f12-4014-ada9-06a141af6d5f 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: connect_volume called for volume 5d46e05d-a078-42ac-bc17-4b9322ed46bd, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5d46e05d-a078-42ac-bc17-4b9322ed46bd', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:40:30.271 8 INFO os_brick.initiator.connectors.lightos [req-4f08b426-9f12-4014-ada9-06a141af6d5f 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5d46e05d-a078-42ac-bc17-4b9322ed46bd
2022-02-22 15:40:36.189 8 INFO nova.compute.claims [req-5bf08c35-376f-4916-8343-cc5629694007 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Claim successful on node rack08-server63
2022-02-22 15:40:36.600 8 INFO nova.virt.libvirt.driver [req-5bf08c35-376f-4916-8343-cc5629694007 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Creating image
2022-02-22 15:40:37.733 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] VM Resumed (Lifecycle Event)
2022-02-22 15:40:37.741 8 INFO nova.virt.libvirt.driver [-] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Instance spawned successfully.
2022-02-22 15:40:37.742 8 INFO nova.compute.manager [req-5bf08c35-376f-4916-8343-cc5629694007 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 15:40:37.789 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:40:37.790 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] VM Started (Lifecycle Event)
2022-02-22 15:40:37.827 8 INFO nova.compute.manager [req-5bf08c35-376f-4916-8343-cc5629694007 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Took 1.68 seconds to build instance.
2022-02-22 15:40:38.144 8 INFO nova.virt.libvirt.driver [req-81c38cc1-b91b-4d4a-b726-689c6844d4c2 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Ignoring supplied device name: /dev/vdb
2022-02-22 15:40:38.307 8 INFO nova.compute.manager [req-81c38cc1-b91b-4d4a-b726-689c6844d4c2 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Attaching volume 89f23d40-efa0-410a-8f2a-625435fa38eb to /dev/vdb
2022-02-22 15:40:38.389 8 WARNING os_brick.initiator.connectors.nvmeof [req-81c38cc1-b91b-4d4a-b726-689c6844d4c2 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:40:39.745 8 INFO os_brick.initiator.connectors.lightos [req-81c38cc1-b91b-4d4a-b726-689c6844d4c2 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] LIGHTOS: connect_volume called for volume 36950f3a-cb4f-4eba-b47d-42d62be61aac, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '36950f3a-cb4f-4eba-b47d-42d62be61aac', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:40:39.750 8 INFO os_brick.initiator.connectors.lightos [req-81c38cc1-b91b-4d4a-b726-689c6844d4c2 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 36950f3a-cb4f-4eba-b47d-42d62be61aac
2022-02-22 15:40:41.383 8 INFO nova.compute.manager [req-0af30236-7db0-4fac-9b93-2a4c5ed3affc 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Detaching volume 7d6b4585-f5dd-4e12-8e15-539acb162533
2022-02-22 15:40:41.441 8 INFO nova.virt.block_device [req-0af30236-7db0-4fac-9b93-2a4c5ed3affc 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Attempting to driver detach volume 7d6b4585-f5dd-4e12-8e15-539acb162533 from mountpoint /dev/vdb
2022-02-22 15:40:41.460 8 INFO nova.virt.libvirt.driver [req-0af30236-7db0-4fac-9b93-2a4c5ed3affc 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Successfully detached device vdb from instance feecb1be-7def-4b10-ad45-53b4ba1cc892 from the persistent domain config.
2022-02-22 15:40:41.601 8 INFO nova.virt.libvirt.driver [req-0af30236-7db0-4fac-9b93-2a4c5ed3affc 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Successfully detached device vdb from instance feecb1be-7def-4b10-ad45-53b4ba1cc892 from the live domain config.
2022-02-22 15:40:41.604 8 INFO os_brick.initiator.connectors.lightos [req-0af30236-7db0-4fac-9b93-2a4c5ed3affc 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5d46e05d-a078-42ac-bc17-4b9322ed46bd
2022-02-22 15:40:41.632 8 INFO nova.compute.manager [req-e7955362-fede-44e9-be67-9a6e5698afeb e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Cinder extended volume 89f23d40-efa0-410a-8f2a-625435fa38eb; extending it to detect new size
2022-02-22 15:40:41.705 8 INFO os_brick.initiator.connectors.lightos [req-e7955362-fede-44e9-be67-9a6e5698afeb e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 36950f3a-cb4f-4eba-b47d-42d62be61aac
2022-02-22 15:40:42.305 8 INFO nova.compute.manager [req-f874aa4e-9172-498f-a87e-3dc5533ebcb9 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Detaching volume 89f23d40-efa0-410a-8f2a-625435fa38eb
2022-02-22 15:40:42.368 8 INFO nova.virt.block_device [req-f874aa4e-9172-498f-a87e-3dc5533ebcb9 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Attempting to driver detach volume 89f23d40-efa0-410a-8f2a-625435fa38eb from mountpoint /dev/vdb
2022-02-22 15:40:42.386 8 INFO nova.virt.libvirt.driver [req-f874aa4e-9172-498f-a87e-3dc5533ebcb9 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] Successfully detached device vdb from instance 4979125c-a809-4976-a5bc-616433c6b9c9 from the persistent domain config.
2022-02-22 15:40:42.542 8 INFO nova.virt.libvirt.driver [req-f874aa4e-9172-498f-a87e-3dc5533ebcb9 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] Successfully detached device vdb from instance 4979125c-a809-4976-a5bc-616433c6b9c9 from the live domain config.
2022-02-22 15:40:42.545 8 INFO os_brick.initiator.connectors.lightos [req-f874aa4e-9172-498f-a87e-3dc5533ebcb9 f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 36950f3a-cb4f-4eba-b47d-42d62be61aac
2022-02-22 15:40:43.643 8 INFO nova.compute.manager [req-f8420409-ed54-48ff-852d-85ff82fc9676 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Terminating instance
2022-02-22 15:40:44.010 8 INFO nova.virt.libvirt.driver [-] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Instance destroyed successfully.
2022-02-22 15:40:44.024 8 INFO nova.virt.libvirt.driver [req-f8420409-ed54-48ff-852d-85ff82fc9676 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Deleting instance files /var/lib/nova/instances/feecb1be-7def-4b10-ad45-53b4ba1cc892_del
2022-02-22 15:40:44.025 8 INFO nova.virt.libvirt.driver [req-f8420409-ed54-48ff-852d-85ff82fc9676 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Deletion of /var/lib/nova/instances/feecb1be-7def-4b10-ad45-53b4ba1cc892_del complete
2022-02-22 15:40:44.093 8 INFO nova.compute.manager [req-f8420409-ed54-48ff-852d-85ff82fc9676 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:40:44.159 8 INFO nova.compute.manager [-] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:40:44.360 8 INFO nova.scheduler.client.report [req-f8420409-ed54-48ff-852d-85ff82fc9676 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Deleted allocations for instance feecb1be-7def-4b10-ad45-53b4ba1cc892
2022-02-22 15:40:44.577 8 INFO nova.compute.manager [req-8724001e-b246-4a5a-94b4-913ff21b74db f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Terminating instance
2022-02-22 15:40:44.913 8 INFO nova.virt.libvirt.driver [-] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Instance destroyed successfully.
2022-02-22 15:40:44.928 8 INFO nova.virt.libvirt.driver [req-8724001e-b246-4a5a-94b4-913ff21b74db f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Deleting instance files /var/lib/nova/instances/4979125c-a809-4976-a5bc-616433c6b9c9_del
2022-02-22 15:40:44.929 8 INFO nova.virt.libvirt.driver [req-8724001e-b246-4a5a-94b4-913ff21b74db f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Deletion of /var/lib/nova/instances/4979125c-a809-4976-a5bc-616433c6b9c9_del complete
2022-02-22 15:40:44.996 8 INFO nova.compute.manager [req-8724001e-b246-4a5a-94b4-913ff21b74db f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:40:45.063 8 INFO nova.compute.manager [-] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:40:45.238 8 INFO nova.scheduler.client.report [req-8724001e-b246-4a5a-94b4-913ff21b74db f802832372dd45e69d64f3115e9054ea 199c2ff5ff5d4d5481708c87c6bf078b - default default] Deleted allocations for instance 4979125c-a809-4976-a5bc-616433c6b9c9
2022-02-22 15:40:51.800 8 INFO nova.compute.claims [req-6a288943-ba4b-4762-a34d-8b8ddf26becd 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Claim successful on node rack08-server63
2022-02-22 15:40:52.192 8 INFO nova.virt.libvirt.driver [req-6a288943-ba4b-4762-a34d-8b8ddf26becd 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Creating image
2022-02-22 15:40:53.337 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] VM Resumed (Lifecycle Event)
2022-02-22 15:40:53.345 8 INFO nova.virt.libvirt.driver [-] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Instance spawned successfully.
2022-02-22 15:40:53.346 8 INFO nova.compute.manager [req-6a288943-ba4b-4762-a34d-8b8ddf26becd 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Took 1.15 seconds to spawn the instance on the hypervisor.
2022-02-22 15:40:53.390 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:40:53.390 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] VM Started (Lifecycle Event)
2022-02-22 15:40:53.430 8 INFO nova.compute.manager [req-6a288943-ba4b-4762-a34d-8b8ddf26becd 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Took 1.67 seconds to build instance.
2022-02-22 15:40:53.774 8 INFO nova.virt.libvirt.driver [req-cdbcc1da-2fbb-41df-9425-2878a8aaccc4 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Ignoring supplied device name: /dev/vdb
2022-02-22 15:40:53.939 8 INFO nova.compute.manager [req-cdbcc1da-2fbb-41df-9425-2878a8aaccc4 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Attaching volume b96d147e-85b2-4a0e-9176-5e4f1ad44448 to /dev/vdb
2022-02-22 15:40:54.027 8 WARNING os_brick.initiator.connectors.nvmeof [req-cdbcc1da-2fbb-41df-9425-2878a8aaccc4 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 15:40:55.410 8 INFO os_brick.initiator.connectors.lightos [req-cdbcc1da-2fbb-41df-9425-2878a8aaccc4 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: connect_volume called for volume 05308db5-9b49-420d-9ef9-75980b69db8d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '05308db5-9b49-420d-9ef9-75980b69db8d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 15:40:55.414 8 INFO os_brick.initiator.connectors.lightos [req-cdbcc1da-2fbb-41df-9425-2878a8aaccc4 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 05308db5-9b49-420d-9ef9-75980b69db8d
2022-02-22 15:40:59.008 8 INFO nova.compute.manager [-] [instance: feecb1be-7def-4b10-ad45-53b4ba1cc892] VM Stopped (Lifecycle Event)
2022-02-22 15:40:59.912 8 INFO nova.compute.manager [-] [instance: 4979125c-a809-4976-a5bc-616433c6b9c9] VM Stopped (Lifecycle Event)
2022-02-22 15:41:04.382 8 INFO nova.compute.manager [req-61eb0e2d-2985-49b8-a350-3eb654d4e839 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Detaching volume b96d147e-85b2-4a0e-9176-5e4f1ad44448
2022-02-22 15:41:04.443 8 INFO nova.virt.block_device [req-61eb0e2d-2985-49b8-a350-3eb654d4e839 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Attempting to driver detach volume b96d147e-85b2-4a0e-9176-5e4f1ad44448 from mountpoint /dev/vdb
2022-02-22 15:41:04.462 8 INFO nova.virt.libvirt.driver [req-61eb0e2d-2985-49b8-a350-3eb654d4e839 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Successfully detached device vdb from instance 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f from the persistent domain config.
2022-02-22 15:41:04.615 8 INFO nova.virt.libvirt.driver [req-61eb0e2d-2985-49b8-a350-3eb654d4e839 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Successfully detached device vdb from instance 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f from the live domain config.
2022-02-22 15:41:04.618 8 INFO os_brick.initiator.connectors.lightos [req-61eb0e2d-2985-49b8-a350-3eb654d4e839 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 05308db5-9b49-420d-9ef9-75980b69db8d
2022-02-22 15:41:06.648 8 INFO nova.compute.manager [req-ca018b61-7164-48dd-9460-04abbc57baf2 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Terminating instance
2022-02-22 15:41:06.986 8 INFO nova.virt.libvirt.driver [-] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Instance destroyed successfully.
2022-02-22 15:41:07.003 8 INFO nova.virt.libvirt.driver [req-ca018b61-7164-48dd-9460-04abbc57baf2 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Deleting instance files /var/lib/nova/instances/9f1d83fd-5d23-4283-a7e7-55fd65e30e8f_del
2022-02-22 15:41:07.005 8 INFO nova.virt.libvirt.driver [req-ca018b61-7164-48dd-9460-04abbc57baf2 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Deletion of /var/lib/nova/instances/9f1d83fd-5d23-4283-a7e7-55fd65e30e8f_del complete
2022-02-22 15:41:07.076 8 INFO nova.compute.manager [req-ca018b61-7164-48dd-9460-04abbc57baf2 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 15:41:07.146 8 INFO nova.compute.manager [-] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:41:07.331 8 INFO nova.scheduler.client.report [req-ca018b61-7164-48dd-9460-04abbc57baf2 04c23bfc12b246f6b94122ca81eff268 7b57ce2a3f9041bd827c7f1421ad553f - default default] Deleted allocations for instance 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f
2022-02-22 15:41:18.533 8 INFO nova.compute.claims [req-a85ae70e-64c0-415d-88e2-c70e4510095b fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Claim successful on node rack08-server63
2022-02-22 15:41:18.946 8 INFO nova.virt.libvirt.driver [req-a85ae70e-64c0-415d-88e2-c70e4510095b fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Creating image
2022-02-22 15:41:20.150 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] VM Resumed (Lifecycle Event)
2022-02-22 15:41:20.158 8 INFO nova.virt.libvirt.driver [-] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Instance spawned successfully.
2022-02-22 15:41:20.159 8 INFO nova.compute.manager [req-a85ae70e-64c0-415d-88e2-c70e4510095b fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 15:41:20.206 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 15:41:20.207 8 INFO nova.compute.manager [req-40698fbc-fe2e-48d8-a299-783f9835eda5 - - - - -] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] VM Started (Lifecycle Event)
2022-02-22 15:41:20.247 8 INFO nova.compute.manager [req-a85ae70e-64c0-415d-88e2-c70e4510095b fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Took 1.75 seconds to build instance.
2022-02-22 15:41:20.629 8 INFO nova.compute.manager [req-155b02ac-e5a3-407c-a861-902e49f19783 fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Terminating instance
2022-02-22 15:41:20.972 8 INFO nova.virt.libvirt.driver [-] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Instance destroyed successfully.
2022-02-22 15:41:20.987 8 INFO nova.virt.libvirt.driver [req-155b02ac-e5a3-407c-a861-902e49f19783 fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Deleting instance files /var/lib/nova/instances/5a598e35-b4f9-46d6-9118-66d4d7bdba1c_del
2022-02-22 15:41:20.988 8 INFO nova.virt.libvirt.driver [req-155b02ac-e5a3-407c-a861-902e49f19783 fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Deletion of /var/lib/nova/instances/5a598e35-b4f9-46d6-9118-66d4d7bdba1c_del complete
2022-02-22 15:41:21.056 8 INFO nova.compute.manager [req-155b02ac-e5a3-407c-a861-902e49f19783 fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 15:41:21.126 8 INFO nova.compute.manager [-] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] Took 0.07 seconds to deallocate network for instance.
2022-02-22 15:41:21.328 8 INFO nova.scheduler.client.report [req-155b02ac-e5a3-407c-a861-902e49f19783 fff047ab5c044a5fa6122977b0af3bbd 7723cca9a1a74ad08e6217578d8e334c - default default] Deleted allocations for instance 5a598e35-b4f9-46d6-9118-66d4d7bdba1c
2022-02-22 15:41:21.983 8 INFO nova.compute.manager [-] [instance: 9f1d83fd-5d23-4283-a7e7-55fd65e30e8f] VM Stopped (Lifecycle Event)
2022-02-22 15:41:35.970 8 INFO nova.compute.manager [-] [instance: 5a598e35-b4f9-46d6-9118-66d4d7bdba1c] VM Stopped (Lifecycle Event)
