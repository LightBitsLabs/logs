Build Started 22_02_2022_03_08_28
2022-02-22 05:11:20.069 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 05:11:24.052 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 05:11:24.989 7 INFO nova.virt.driver [req-97132335-9fc5-4930-89f8-9f9ff10d9c98 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 05:11:25.378 7 INFO nova.compute.provider_config [req-97132335-9fc5-4930-89f8-9f9ff10d9c98 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 05:11:25.397 7 WARNING oslo_config.cfg [req-97132335-9fc5-4930-89f8-9f9ff10d9c98 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 05:11:25.418 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 05:11:25.431 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 05:11:25.468 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 05:11:25.555 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 05:11:25.568 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 05:11:25.570 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 05:11:26.205 7 INFO nova.compute.manager [req-5debd6e0-ada9-42ae-bc30-596af106162e - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 05:11:28.016 7 INFO nova.virt.libvirt.host [req-5debd6e0-ada9-42ae-bc30-596af106162e - - - - -] kernel doesn't support AMD SEV
2022-02-22 05:12:18.780 7 INFO nova.compute.claims [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Claim successful on node rack08-server63
2022-02-22 05:12:19.218 7 INFO nova.virt.libvirt.driver [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Creating image
2022-02-22 05:12:19.222 7 INFO oslo.privsep.daemon [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmpbdolzalj/privsep.sock']
2022-02-22 05:12:20.856 7 INFO oslo.privsep.daemon [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 05:12:20.710 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 05:12:20.716 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 05:12:20.721 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 05:12:20.721 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-22 05:12:22.131 7 INFO nova.compute.manager [-] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] VM Resumed (Lifecycle Event)
2022-02-22 05:12:22.139 7 INFO nova.virt.libvirt.driver [-] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Instance spawned successfully.
2022-02-22 05:12:22.190 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:22.191 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] VM Started (Lifecycle Event)
2022-02-22 05:12:22.244 7 INFO nova.compute.manager [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Took 3.03 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:22.247 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:22.326 7 INFO nova.compute.manager [req-5868425b-9c3b-47c2-9d0a-66da42fb7963 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Took 3.59 seconds to build instance.
2022-02-22 05:12:25.543 7 INFO nova.compute.manager [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Attaching volume d8e8524a-3572-47c9-ab73-91023e7c9eb7 to /dev/vdb
2022-02-22 05:12:25.615 7 INFO oslo.privsep.daemon [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmptnb_jco6/privsep.sock']
2022-02-22 05:12:26.745 7 INFO oslo.privsep.daemon [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Spawned new privsep daemon via rootwrap
2022-02-22 05:12:26.193 119 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 05:12:26.200 119 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 05:12:26.205 119 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 05:12:26.206 119 INFO oslo.privsep.daemon [-] privsep daemon running as pid 119
2022-02-22 05:12:27.075 7 WARNING os_brick.initiator.connectors.nvmeof [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:12:28.476 7 INFO os_brick.initiator.connectors.lightos [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: connect_volume called for volume 593ded05-b386-465b-aeae-ed8b4495e990, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '593ded05-b386-465b-aeae-ed8b4495e990', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:12:28.511 7 INFO os_brick.initiator.connectors.lightos [req-e968a422-f856-45ba-acc2-abf0307cbfd5 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 593ded05-b386-465b-aeae-ed8b4495e990
2022-02-22 05:12:31.202 7 INFO nova.compute.claims [req-f847f0ee-4bc9-44ba-915d-3bb8335575c8 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Claim successful on node rack08-server63
2022-02-22 05:12:31.582 7 INFO nova.virt.libvirt.driver [req-f847f0ee-4bc9-44ba-915d-3bb8335575c8 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Creating image
2022-02-22 05:12:32.711 7 INFO nova.compute.claims [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Claim successful on node rack08-server63
2022-02-22 05:12:32.739 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 49410016-5375-499b-8425-d9351ab15b79] VM Resumed (Lifecycle Event)
2022-02-22 05:12:32.745 7 INFO nova.virt.libvirt.driver [-] [instance: 49410016-5375-499b-8425-d9351ab15b79] Instance spawned successfully.
2022-02-22 05:12:32.808 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 49410016-5375-499b-8425-d9351ab15b79] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:32.808 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 49410016-5375-499b-8425-d9351ab15b79] VM Started (Lifecycle Event)
2022-02-22 05:12:32.852 7 INFO nova.compute.manager [req-f847f0ee-4bc9-44ba-915d-3bb8335575c8 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:32.866 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 49410016-5375-499b-8425-d9351ab15b79] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:32.934 7 INFO nova.compute.manager [req-f847f0ee-4bc9-44ba-915d-3bb8335575c8 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Took 1.77 seconds to build instance.
2022-02-22 05:12:32.943 7 INFO nova.virt.libvirt.driver [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 05:12:33.028 7 INFO nova.virt.block_device [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Booting with volume 51fd30fc-b0af-4645-8526-969c04f572ac at /dev/vda
2022-02-22 05:12:33.113 7 WARNING os_brick.initiator.connectors.nvmeof [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:12:34.412 7 INFO nova.compute.manager [req-2eff485e-5a88-4d09-8b08-d165424c10c9 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Detaching volume d8e8524a-3572-47c9-ab73-91023e7c9eb7
2022-02-22 05:12:34.474 7 INFO nova.virt.block_device [req-2eff485e-5a88-4d09-8b08-d165424c10c9 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Attempting to driver detach volume d8e8524a-3572-47c9-ab73-91023e7c9eb7 from mountpoint /dev/vdb
2022-02-22 05:12:34.493 7 INFO nova.virt.libvirt.driver [req-2eff485e-5a88-4d09-8b08-d165424c10c9 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance 7d527c73-c0fd-410a-a5e4-72dbb3120b32 from the persistent domain config.
2022-02-22 05:12:34.615 7 INFO nova.virt.libvirt.driver [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Creating image
2022-02-22 05:12:34.625 7 INFO os_brick.initiator.connectors.lightos [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: connect_volume called for volume d3152eca-cefa-4f0f-b3c6-249515d0312b, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd3152eca-cefa-4f0f-b3c6-249515d0312b', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:12:34.628 7 INFO os_brick.initiator.connectors.lightos [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid d3152eca-cefa-4f0f-b3c6-249515d0312b
2022-02-22 05:12:34.642 7 INFO nova.virt.libvirt.driver [req-2eff485e-5a88-4d09-8b08-d165424c10c9 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance 7d527c73-c0fd-410a-a5e4-72dbb3120b32 from the live domain config.
2022-02-22 05:12:34.644 7 INFO os_brick.initiator.connectors.lightos [req-2eff485e-5a88-4d09-8b08-d165424c10c9 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 593ded05-b386-465b-aeae-ed8b4495e990
2022-02-22 05:12:35.479 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] VM Resumed (Lifecycle Event)
2022-02-22 05:12:35.485 7 INFO nova.virt.libvirt.driver [-] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Instance spawned successfully.
2022-02-22 05:12:35.545 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:35.546 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] VM Started (Lifecycle Event)
2022-02-22 05:12:35.592 7 INFO nova.compute.manager [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Took 0.98 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:35.602 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:35.689 7 INFO nova.compute.manager [req-13927ad9-c4da-4c4f-add4-9a7840dccf3a 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Took 3.02 seconds to build instance.
2022-02-22 05:12:37.849 7 INFO nova.compute.claims [req-fecdcc89-e167-4260-bbec-c6a5e2288545 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Claim successful on node rack08-server63
2022-02-22 05:12:37.878 7 INFO nova.compute.claims [req-1692effa-525d-4afa-9a83-57794f928cc5 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Claim successful on node rack08-server63
2022-02-22 05:12:38.237 7 INFO nova.virt.libvirt.driver [req-1692effa-525d-4afa-9a83-57794f928cc5 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Creating image
2022-02-22 05:12:38.265 7 INFO nova.virt.libvirt.driver [req-fecdcc89-e167-4260-bbec-c6a5e2288545 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Creating image
2022-02-22 05:12:38.426 7 INFO nova.compute.claims [req-6b09e55e-4c7f-4c83-ba76-b04fec841318 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Claim successful on node rack08-server63
2022-02-22 05:12:38.829 7 INFO nova.virt.libvirt.driver [req-6b09e55e-4c7f-4c83-ba76-b04fec841318 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Creating image
2022-02-22 05:12:39.473 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] VM Resumed (Lifecycle Event)
2022-02-22 05:12:39.482 7 INFO nova.virt.libvirt.driver [-] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Instance spawned successfully.
2022-02-22 05:12:39.550 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:39.550 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] VM Started (Lifecycle Event)
2022-02-22 05:12:39.595 7 INFO nova.compute.manager [req-1692effa-525d-4afa-9a83-57794f928cc5 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Took 1.36 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:39.607 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:39.608 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c5550978-c8bd-464b-8738-418d941d9637] VM Resumed (Lifecycle Event)
2022-02-22 05:12:39.613 7 INFO nova.virt.libvirt.driver [-] [instance: c5550978-c8bd-464b-8738-418d941d9637] Instance spawned successfully.
2022-02-22 05:12:39.666 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c5550978-c8bd-464b-8738-418d941d9637] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:39.667 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c5550978-c8bd-464b-8738-418d941d9637] VM Started (Lifecycle Event)
2022-02-22 05:12:39.680 7 INFO nova.compute.manager [req-1692effa-525d-4afa-9a83-57794f928cc5 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Took 1.84 seconds to build instance.
2022-02-22 05:12:39.715 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c5550978-c8bd-464b-8738-418d941d9637] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:39.718 7 INFO nova.compute.manager [req-fecdcc89-e167-4260-bbec-c6a5e2288545 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Took 1.45 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:39.799 7 INFO nova.compute.manager [req-fecdcc89-e167-4260-bbec-c6a5e2288545 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Took 1.99 seconds to build instance.
2022-02-22 05:12:40.010 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] VM Resumed (Lifecycle Event)
2022-02-22 05:12:40.017 7 INFO nova.virt.libvirt.driver [-] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Instance spawned successfully.
2022-02-22 05:12:40.078 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:40.078 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] VM Started (Lifecycle Event)
2022-02-22 05:12:40.124 7 INFO nova.compute.manager [req-6b09e55e-4c7f-4c83-ba76-b04fec841318 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:40.135 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:40.207 7 INFO nova.compute.manager [req-6b09e55e-4c7f-4c83-ba76-b04fec841318 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Took 1.83 seconds to build instance.
2022-02-22 05:12:43.143 7 INFO nova.compute.manager [req-fa479b48-6882-4d4b-a598-d0645e45b717 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Attaching volume 0906a232-ef95-4d0a-a53a-8f7316c73844 to /dev/vdb
2022-02-22 05:12:43.230 7 WARNING os_brick.initiator.connectors.nvmeof [req-fa479b48-6882-4d4b-a598-d0645e45b717 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:12:43.498 7 INFO nova.compute.manager [req-093dc7ff-87f0-4351-8c72-f5d34c54627e d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Attaching volume 23b7b51d-2c6a-4c8b-be8d-24ee613f28ca to /dev/vdb
2022-02-22 05:12:43.584 7 WARNING os_brick.initiator.connectors.nvmeof [req-093dc7ff-87f0-4351-8c72-f5d34c54627e d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:12:44.659 7 INFO os_brick.initiator.connectors.lightos [req-fa479b48-6882-4d4b-a598-d0645e45b717 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: connect_volume called for volume d8d140bc-0f54-4504-a1b3-380ece1f8548, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd8d140bc-0f54-4504-a1b3-380ece1f8548', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:12:44.663 7 INFO os_brick.initiator.connectors.lightos [req-fa479b48-6882-4d4b-a598-d0645e45b717 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d8d140bc-0f54-4504-a1b3-380ece1f8548
2022-02-22 05:12:44.922 7 INFO os_brick.initiator.connectors.lightos [req-093dc7ff-87f0-4351-8c72-f5d34c54627e d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: connect_volume called for volume 129d1003-c831-4d31-ac35-599a0709caba, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '129d1003-c831-4d31-ac35-599a0709caba', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:12:44.925 7 INFO os_brick.initiator.connectors.lightos [req-093dc7ff-87f0-4351-8c72-f5d34c54627e d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 129d1003-c831-4d31-ac35-599a0709caba
2022-02-22 05:12:45.641 7 INFO nova.compute.manager [req-8e9c8377-dd7b-4fcf-9265-7b4a85a4fc39 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Attaching volume 0906a232-ef95-4d0a-a53a-8f7316c73844 to /dev/vdb
2022-02-22 05:12:45.732 7 WARNING os_brick.initiator.connectors.nvmeof [req-8e9c8377-dd7b-4fcf-9265-7b4a85a4fc39 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:12:46.066 7 INFO nova.compute.manager [req-3e8b7c14-eec8-482e-b775-ee6c8ddf0833 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Detaching volume 23b7b51d-2c6a-4c8b-be8d-24ee613f28ca
2022-02-22 05:12:46.124 7 INFO nova.virt.block_device [req-3e8b7c14-eec8-482e-b775-ee6c8ddf0833 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Attempting to driver detach volume 23b7b51d-2c6a-4c8b-be8d-24ee613f28ca from mountpoint /dev/vdb
2022-02-22 05:12:46.143 7 INFO nova.virt.libvirt.driver [req-3e8b7c14-eec8-482e-b775-ee6c8ddf0833 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance c5550978-c8bd-464b-8738-418d941d9637 from the persistent domain config.
2022-02-22 05:12:46.290 7 INFO nova.virt.libvirt.driver [req-3e8b7c14-eec8-482e-b775-ee6c8ddf0833 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance c5550978-c8bd-464b-8738-418d941d9637 from the live domain config.
2022-02-22 05:12:46.293 7 INFO os_brick.initiator.connectors.lightos [req-3e8b7c14-eec8-482e-b775-ee6c8ddf0833 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 129d1003-c831-4d31-ac35-599a0709caba
2022-02-22 05:12:47.092 7 INFO os_brick.initiator.connectors.lightos [req-8e9c8377-dd7b-4fcf-9265-7b4a85a4fc39 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: connect_volume called for volume d8d140bc-0f54-4504-a1b3-380ece1f8548, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd8d140bc-0f54-4504-a1b3-380ece1f8548', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:12:47.093 7 INFO os_brick.initiator.connectors.lightos [req-8e9c8377-dd7b-4fcf-9265-7b4a85a4fc39 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d8d140bc-0f54-4504-a1b3-380ece1f8548
2022-02-22 05:12:48.505 7 INFO nova.compute.manager [req-0eddc3a3-1586-4906-8fae-051ba33acd24 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Detaching volume 0906a232-ef95-4d0a-a53a-8f7316c73844
2022-02-22 05:12:48.569 7 INFO nova.virt.block_device [req-0eddc3a3-1586-4906-8fae-051ba33acd24 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Attempting to driver detach volume 0906a232-ef95-4d0a-a53a-8f7316c73844 from mountpoint /dev/vdb
2022-02-22 05:12:48.588 7 INFO nova.virt.libvirt.driver [req-0eddc3a3-1586-4906-8fae-051ba33acd24 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Successfully detached device vdb from instance 13e37cd9-bb3a-4392-85a2-bff80a09a05c from the persistent domain config.
2022-02-22 05:12:48.727 7 INFO nova.virt.libvirt.driver [req-0eddc3a3-1586-4906-8fae-051ba33acd24 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Successfully detached device vdb from instance 13e37cd9-bb3a-4392-85a2-bff80a09a05c from the live domain config.
2022-02-22 05:12:48.798 7 INFO nova.virt.libvirt.driver [req-0eddc3a3-1586-4906-8fae-051ba33acd24 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Detected multiple connections on this host for volume: 0906a232-ef95-4d0a-a53a-8f7316c73844, skipping target disconnect.
2022-02-22 05:12:49.396 7 INFO nova.compute.claims [req-d514519e-f221-43f9-a681-fab969494a9b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Claim successful on node rack08-server63
2022-02-22 05:12:49.836 7 INFO nova.virt.libvirt.driver [req-d514519e-f221-43f9-a681-fab969494a9b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Creating image
2022-02-22 05:12:50.966 7 INFO nova.compute.manager [req-c6c73128-8c77-4842-bfd2-ee2e575817bc 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Detaching volume 0906a232-ef95-4d0a-a53a-8f7316c73844
2022-02-22 05:12:50.999 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] VM Resumed (Lifecycle Event)
2022-02-22 05:12:51.005 7 INFO nova.virt.libvirt.driver [-] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Instance spawned successfully.
2022-02-22 05:12:51.029 7 INFO nova.virt.block_device [req-c6c73128-8c77-4842-bfd2-ee2e575817bc 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Attempting to driver detach volume 0906a232-ef95-4d0a-a53a-8f7316c73844 from mountpoint /dev/vdb
2022-02-22 05:12:51.055 7 INFO nova.virt.libvirt.driver [req-c6c73128-8c77-4842-bfd2-ee2e575817bc 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Successfully detached device vdb from instance cff48e85-4405-4219-80a9-72f10bdf3a5a from the persistent domain config.
2022-02-22 05:12:51.065 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:51.066 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] VM Started (Lifecycle Event)
2022-02-22 05:12:51.117 7 INFO nova.compute.manager [req-d514519e-f221-43f9-a681-fab969494a9b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-22 05:12:51.119 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:12:51.213 7 INFO nova.compute.manager [req-d514519e-f221-43f9-a681-fab969494a9b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Took 1.86 seconds to build instance.
2022-02-22 05:12:51.234 7 INFO nova.virt.libvirt.driver [req-c6c73128-8c77-4842-bfd2-ee2e575817bc 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Successfully detached device vdb from instance cff48e85-4405-4219-80a9-72f10bdf3a5a from the live domain config.
2022-02-22 05:12:55.108 7 INFO nova.compute.manager [req-494995bf-2d93-4c7a-ae2c-283f5dc72b99 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Attaching volume 7d328225-7d30-418c-8fe8-191a61b850ea to /dev/vdb
2022-02-22 05:12:55.196 7 WARNING os_brick.initiator.connectors.nvmeof [req-494995bf-2d93-4c7a-ae2c-283f5dc72b99 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:13:51.497 7 INFO os_brick.initiator.connectors.lightos [req-494995bf-2d93-4c7a-ae2c-283f5dc72b99 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: connect_volume called for volume 8725e410-d3ec-4df8-8e38-3a586cdeb049, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8725e410-d3ec-4df8-8e38-3a586cdeb049', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:13:51.501 7 INFO os_brick.initiator.connectors.lightos [req-494995bf-2d93-4c7a-ae2c-283f5dc72b99 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8725e410-d3ec-4df8-8e38-3a586cdeb049
2022-02-22 05:13:52.783 7 INFO nova.compute.manager [req-6d82f06c-abee-4a83-8151-9f7f9c67a1f2 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Detaching volume 7d328225-7d30-418c-8fe8-191a61b850ea
2022-02-22 05:13:52.839 7 INFO nova.virt.block_device [req-6d82f06c-abee-4a83-8151-9f7f9c67a1f2 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Attempting to driver detach volume 7d328225-7d30-418c-8fe8-191a61b850ea from mountpoint /dev/vdb
2022-02-22 05:13:52.857 7 INFO nova.virt.libvirt.driver [req-6d82f06c-abee-4a83-8151-9f7f9c67a1f2 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance 37f2eae9-4fde-43f6-b442-e6c4b8c027ff from the persistent domain config.
2022-02-22 05:13:52.999 7 INFO nova.virt.libvirt.driver [req-6d82f06c-abee-4a83-8151-9f7f9c67a1f2 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Successfully detached device vdb from instance 37f2eae9-4fde-43f6-b442-e6c4b8c027ff from the live domain config.
2022-02-22 05:13:53.002 7 INFO os_brick.initiator.connectors.lightos [req-6d82f06c-abee-4a83-8151-9f7f9c67a1f2 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8725e410-d3ec-4df8-8e38-3a586cdeb049
2022-02-22 05:13:56.251 7 INFO nova.compute.manager [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Terminating instance
2022-02-22 05:13:56.592 7 INFO nova.virt.libvirt.driver [-] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Instance destroyed successfully.
2022-02-22 05:13:56.608 7 INFO nova.virt.libvirt.driver [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Deleting instance files /var/lib/nova/instances/37f2eae9-4fde-43f6-b442-e6c4b8c027ff_del
2022-02-22 05:13:56.610 7 INFO nova.virt.libvirt.driver [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Deletion of /var/lib/nova/instances/37f2eae9-4fde-43f6-b442-e6c4b8c027ff_del complete
2022-02-22 05:13:56.681 7 INFO nova.virt.libvirt.host [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] UEFI support detected
2022-02-22 05:13:56.685 7 INFO nova.compute.manager [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:13:56.750 7 INFO nova.compute.manager [-] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:13:56.947 7 INFO nova.scheduler.client.report [req-fddf1a30-1fb6-42e5-8653-86b9617ac1fb d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Deleted allocations for instance 37f2eae9-4fde-43f6-b442-e6c4b8c027ff
2022-02-22 05:13:58.638 7 INFO nova.compute.manager [req-24a7b0b3-392e-498c-8222-323a34730c12 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Terminating instance
2022-02-22 05:13:58.971 7 INFO nova.virt.libvirt.driver [-] [instance: c5550978-c8bd-464b-8738-418d941d9637] Instance destroyed successfully.
2022-02-22 05:13:58.986 7 INFO nova.virt.libvirt.driver [req-24a7b0b3-392e-498c-8222-323a34730c12 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Deleting instance files /var/lib/nova/instances/c5550978-c8bd-464b-8738-418d941d9637_del
2022-02-22 05:13:58.988 7 INFO nova.virt.libvirt.driver [req-24a7b0b3-392e-498c-8222-323a34730c12 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Deletion of /var/lib/nova/instances/c5550978-c8bd-464b-8738-418d941d9637_del complete
2022-02-22 05:13:59.052 7 INFO nova.compute.manager [req-24a7b0b3-392e-498c-8222-323a34730c12 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: c5550978-c8bd-464b-8738-418d941d9637] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 05:13:59.118 7 INFO nova.compute.manager [-] [instance: c5550978-c8bd-464b-8738-418d941d9637] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:13:59.315 7 INFO nova.scheduler.client.report [req-24a7b0b3-392e-498c-8222-323a34730c12 d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Deleted allocations for instance c5550978-c8bd-464b-8738-418d941d9637
2022-02-22 05:13:59.880 7 INFO nova.compute.manager [req-493ed534-b3f5-4bad-a35b-df7efcda633b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Terminating instance
2022-02-22 05:14:00.224 7 INFO nova.virt.libvirt.driver [-] [instance: 49410016-5375-499b-8425-d9351ab15b79] Instance destroyed successfully.
2022-02-22 05:14:00.245 7 INFO nova.virt.libvirt.driver [req-493ed534-b3f5-4bad-a35b-df7efcda633b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Deleting instance files /var/lib/nova/instances/49410016-5375-499b-8425-d9351ab15b79_del
2022-02-22 05:14:00.247 7 INFO nova.virt.libvirt.driver [req-493ed534-b3f5-4bad-a35b-df7efcda633b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Deletion of /var/lib/nova/instances/49410016-5375-499b-8425-d9351ab15b79_del complete
2022-02-22 05:14:00.317 7 INFO nova.compute.manager [req-493ed534-b3f5-4bad-a35b-df7efcda633b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 49410016-5375-499b-8425-d9351ab15b79] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:00.380 7 INFO nova.compute.manager [-] [instance: 49410016-5375-499b-8425-d9351ab15b79] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:14:00.572 7 INFO nova.scheduler.client.report [req-493ed534-b3f5-4bad-a35b-df7efcda633b d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Deleted allocations for instance 49410016-5375-499b-8425-d9351ab15b79
2022-02-22 05:14:02.293 7 INFO nova.compute.manager [req-ce036fde-e850-454d-ac83-ddf15e64617f d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Terminating instance
2022-02-22 05:14:02.652 7 INFO nova.virt.libvirt.driver [-] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Instance destroyed successfully.
2022-02-22 05:14:02.667 7 INFO nova.virt.libvirt.driver [req-ce036fde-e850-454d-ac83-ddf15e64617f d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Deleting instance files /var/lib/nova/instances/7d527c73-c0fd-410a-a5e4-72dbb3120b32_del
2022-02-22 05:14:02.669 7 INFO nova.virt.libvirt.driver [req-ce036fde-e850-454d-ac83-ddf15e64617f d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Deletion of /var/lib/nova/instances/7d527c73-c0fd-410a-a5e4-72dbb3120b32_del complete
2022-02-22 05:14:02.739 7 INFO nova.compute.manager [req-ce036fde-e850-454d-ac83-ddf15e64617f d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:02.809 7 INFO nova.compute.manager [-] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:14:03.007 7 INFO nova.scheduler.client.report [req-ce036fde-e850-454d-ac83-ddf15e64617f d8cafa4dfa5c4a1883f2790d23d3aece 643023d54c6d4a808cce35b140a36256 - default default] Deleted allocations for instance 7d527c73-c0fd-410a-a5e4-72dbb3120b32
2022-02-22 05:14:07.120 7 INFO nova.compute.claims [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Claim successful on node rack08-server63
2022-02-22 05:14:07.367 7 INFO nova.virt.libvirt.driver [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 05:14:07.455 7 INFO nova.virt.block_device [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Booting with volume 8ea19e05-4e0a-43f9-8074-22f2609b5614 at /dev/vda
2022-02-22 05:14:07.548 7 WARNING os_brick.initiator.connectors.nvmeof [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:14:09.079 7 INFO nova.virt.libvirt.driver [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Creating image
2022-02-22 05:14:09.092 7 INFO os_brick.initiator.connectors.lightos [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: connect_volume called for volume 8fe9e3c7-8052-491f-9b8a-67e10059750e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '8fe9e3c7-8052-491f-9b8a-67e10059750e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:14:09.095 7 INFO os_brick.initiator.connectors.lightos [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8fe9e3c7-8052-491f-9b8a-67e10059750e
2022-02-22 05:14:09.914 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] VM Resumed (Lifecycle Event)
2022-02-22 05:14:09.921 7 INFO nova.virt.libvirt.driver [-] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Instance spawned successfully.
2022-02-22 05:14:09.976 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:14:09.977 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] VM Started (Lifecycle Event)
2022-02-22 05:14:10.030 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:14:10.042 7 INFO nova.compute.manager [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Took 0.96 seconds to spawn the instance on the hypervisor.
2022-02-22 05:14:10.127 7 INFO nova.compute.manager [req-a3fc9a2c-34e1-49d9-81f7-856322326996 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Took 3.04 seconds to build instance.
2022-02-22 05:14:11.591 7 INFO nova.compute.manager [-] [instance: 37f2eae9-4fde-43f6-b442-e6c4b8c027ff] VM Stopped (Lifecycle Event)
2022-02-22 05:14:12.455 7 INFO nova.compute.manager [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Terminating instance
2022-02-22 05:14:12.800 7 INFO nova.virt.libvirt.driver [-] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Instance destroyed successfully.
2022-02-22 05:14:12.870 7 INFO os_brick.initiator.connectors.lightos [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 8fe9e3c7-8052-491f-9b8a-67e10059750e
2022-02-22 05:14:12.880 7 INFO nova.virt.libvirt.driver [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Deleting instance files /var/lib/nova/instances/4aa26f87-df66-40d2-b99b-e53045ffb759_del
2022-02-22 05:14:12.881 7 INFO nova.virt.libvirt.driver [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Deletion of /var/lib/nova/instances/4aa26f87-df66-40d2-b99b-e53045ffb759_del complete
2022-02-22 05:14:12.949 7 INFO nova.compute.manager [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:13.008 7 INFO nova.compute.manager [-] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:14:13.969 7 INFO nova.compute.manager [-] [instance: c5550978-c8bd-464b-8738-418d941d9637] VM Stopped (Lifecycle Event)
2022-02-22 05:14:14.243 7 INFO nova.compute.manager [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] Took 1.23 seconds to detach 1 volumes for instance.
2022-02-22 05:14:14.439 7 INFO nova.scheduler.client.report [req-2ac119fc-4fa3-4125-8684-91a4f506a61c 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Deleted allocations for instance 4aa26f87-df66-40d2-b99b-e53045ffb759
2022-02-22 05:14:15.222 7 INFO nova.compute.manager [-] [instance: 49410016-5375-499b-8425-d9351ab15b79] VM Stopped (Lifecycle Event)
2022-02-22 05:14:17.398 7 INFO nova.compute.manager [req-49e99fae-ba9c-4e76-8c74-7a9f0cdc5b87 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Terminating instance
2022-02-22 05:14:17.650 7 INFO nova.compute.manager [-] [instance: 7d527c73-c0fd-410a-a5e4-72dbb3120b32] VM Stopped (Lifecycle Event)
2022-02-22 05:14:17.741 7 INFO nova.virt.libvirt.driver [-] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Instance destroyed successfully.
2022-02-22 05:14:17.758 7 INFO nova.virt.libvirt.driver [req-49e99fae-ba9c-4e76-8c74-7a9f0cdc5b87 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Deleting instance files /var/lib/nova/instances/cff48e85-4405-4219-80a9-72f10bdf3a5a_del
2022-02-22 05:14:17.759 7 INFO nova.virt.libvirt.driver [req-49e99fae-ba9c-4e76-8c74-7a9f0cdc5b87 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Deletion of /var/lib/nova/instances/cff48e85-4405-4219-80a9-72f10bdf3a5a_del complete
2022-02-22 05:14:17.844 7 INFO nova.compute.manager [req-49e99fae-ba9c-4e76-8c74-7a9f0cdc5b87 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:17.911 7 INFO nova.compute.manager [-] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:14:18.168 7 INFO nova.scheduler.client.report [req-49e99fae-ba9c-4e76-8c74-7a9f0cdc5b87 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Deleted allocations for instance cff48e85-4405-4219-80a9-72f10bdf3a5a
2022-02-22 05:14:18.641 7 INFO nova.compute.manager [req-f0cf90e5-cc83-438c-a3ee-4706723c7c70 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Terminating instance
2022-02-22 05:14:18.983 7 INFO nova.virt.libvirt.driver [-] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Instance destroyed successfully.
2022-02-22 05:14:18.999 7 INFO nova.virt.libvirt.driver [req-f0cf90e5-cc83-438c-a3ee-4706723c7c70 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Deleting instance files /var/lib/nova/instances/13e37cd9-bb3a-4392-85a2-bff80a09a05c_del
2022-02-22 05:14:19.000 7 INFO nova.virt.libvirt.driver [req-f0cf90e5-cc83-438c-a3ee-4706723c7c70 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Deletion of /var/lib/nova/instances/13e37cd9-bb3a-4392-85a2-bff80a09a05c_del complete
2022-02-22 05:14:19.069 7 INFO nova.compute.manager [req-f0cf90e5-cc83-438c-a3ee-4706723c7c70 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:19.137 7 INFO nova.compute.manager [-] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:14:19.329 7 INFO nova.scheduler.client.report [req-f0cf90e5-cc83-438c-a3ee-4706723c7c70 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Deleted allocations for instance 13e37cd9-bb3a-4392-85a2-bff80a09a05c
2022-02-22 05:14:19.897 7 INFO nova.compute.manager [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Terminating instance
2022-02-22 05:14:20.240 7 INFO nova.virt.libvirt.driver [-] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Instance destroyed successfully.
2022-02-22 05:14:20.322 7 INFO os_brick.initiator.connectors.lightos [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid d3152eca-cefa-4f0f-b3c6-249515d0312b
2022-02-22 05:14:20.333 7 INFO nova.virt.libvirt.driver [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Deleting instance files /var/lib/nova/instances/e2dae2ef-ed51-417b-975d-f0741651b9db_del
2022-02-22 05:14:20.335 7 INFO nova.virt.libvirt.driver [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Deletion of /var/lib/nova/instances/e2dae2ef-ed51-417b-975d-f0741651b9db_del complete
2022-02-22 05:14:20.407 7 INFO nova.compute.manager [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 05:14:20.471 7 INFO nova.compute.manager [-] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:14:21.718 7 INFO nova.compute.manager [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-22 05:14:21.923 7 INFO nova.scheduler.client.report [req-46ae570d-6f01-42dc-8307-ccd795cbef2b 5da9919d216443dca789ba9b3f034ccf 5f9e9c74480e4612ae6dd838b5c5a815 - default default] Deleted allocations for instance e2dae2ef-ed51-417b-975d-f0741651b9db
2022-02-22 05:14:27.799 7 INFO nova.compute.manager [-] [instance: 4aa26f87-df66-40d2-b99b-e53045ffb759] VM Stopped (Lifecycle Event)
2022-02-22 05:14:32.739 7 INFO nova.compute.manager [-] [instance: cff48e85-4405-4219-80a9-72f10bdf3a5a] VM Stopped (Lifecycle Event)
2022-02-22 05:14:33.980 7 INFO nova.compute.manager [-] [instance: 13e37cd9-bb3a-4392-85a2-bff80a09a05c] VM Stopped (Lifecycle Event)
2022-02-22 05:14:35.237 7 INFO nova.compute.manager [-] [instance: e2dae2ef-ed51-417b-975d-f0741651b9db] VM Stopped (Lifecycle Event)
2022-02-22 05:14:58.568 7 INFO nova.compute.claims [req-43bdc02c-45a7-4525-b60c-97bdc94ee622 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Claim successful on node rack08-server63
2022-02-22 05:14:58.954 7 INFO nova.virt.libvirt.driver [req-43bdc02c-45a7-4525-b60c-97bdc94ee622 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Creating image
2022-02-22 05:15:00.078 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] VM Resumed (Lifecycle Event)
2022-02-22 05:15:00.085 7 INFO nova.virt.libvirt.driver [-] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Instance spawned successfully.
2022-02-22 05:15:00.140 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:00.141 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] VM Started (Lifecycle Event)
2022-02-22 05:15:00.193 7 INFO nova.compute.manager [req-43bdc02c-45a7-4525-b60c-97bdc94ee622 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-22 05:15:00.204 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:00.274 7 INFO nova.compute.manager [req-43bdc02c-45a7-4525-b60c-97bdc94ee622 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Took 1.75 seconds to build instance.
2022-02-22 05:15:00.868 7 INFO nova.compute.manager [req-c935293d-3979-4f1f-9224-e9a3b25113ec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Terminating instance
2022-02-22 05:15:01.201 7 INFO nova.virt.libvirt.driver [-] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Instance destroyed successfully.
2022-02-22 05:15:01.216 7 INFO nova.virt.libvirt.driver [req-c935293d-3979-4f1f-9224-e9a3b25113ec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Deleting instance files /var/lib/nova/instances/f72a8d5d-754c-4e8e-a2e5-fc290233f612_del
2022-02-22 05:15:01.217 7 INFO nova.virt.libvirt.driver [req-c935293d-3979-4f1f-9224-e9a3b25113ec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Deletion of /var/lib/nova/instances/f72a8d5d-754c-4e8e-a2e5-fc290233f612_del complete
2022-02-22 05:15:01.284 7 INFO nova.compute.manager [req-c935293d-3979-4f1f-9224-e9a3b25113ec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 05:15:01.352 7 INFO nova.compute.manager [-] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:15:01.524 7 INFO nova.scheduler.client.report [req-c935293d-3979-4f1f-9224-e9a3b25113ec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] Deleted allocations for instance f72a8d5d-754c-4e8e-a2e5-fc290233f612
2022-02-22 05:15:03.167 7 INFO nova.compute.claims [req-1e3d2376-8b91-42f9-9598-fcaa974698a0 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Claim successful on node rack08-server63
2022-02-22 05:15:03.565 7 INFO nova.virt.libvirt.driver [req-1e3d2376-8b91-42f9-9598-fcaa974698a0 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Creating image
2022-02-22 05:15:04.715 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] VM Resumed (Lifecycle Event)
2022-02-22 05:15:04.722 7 INFO nova.virt.libvirt.driver [-] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Instance spawned successfully.
2022-02-22 05:15:04.774 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:04.775 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] VM Started (Lifecycle Event)
2022-02-22 05:15:04.830 7 INFO nova.compute.manager [req-1e3d2376-8b91-42f9-9598-fcaa974698a0 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-22 05:15:04.832 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:04.913 7 INFO nova.compute.manager [req-1e3d2376-8b91-42f9-9598-fcaa974698a0 bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Took 1.78 seconds to build instance.
2022-02-22 05:15:05.505 7 INFO nova.compute.manager [req-ca828323-2a5f-4996-8a94-07d1e03b6eec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Terminating instance
2022-02-22 05:15:05.847 7 INFO nova.virt.libvirt.driver [-] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Instance destroyed successfully.
2022-02-22 05:15:05.863 7 INFO nova.virt.libvirt.driver [req-ca828323-2a5f-4996-8a94-07d1e03b6eec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Deleting instance files /var/lib/nova/instances/5729f7a3-d4e2-405d-a1f1-5ed1c3091d61_del
2022-02-22 05:15:05.864 7 INFO nova.virt.libvirt.driver [req-ca828323-2a5f-4996-8a94-07d1e03b6eec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Deletion of /var/lib/nova/instances/5729f7a3-d4e2-405d-a1f1-5ed1c3091d61_del complete
2022-02-22 05:15:05.935 7 INFO nova.compute.manager [req-ca828323-2a5f-4996-8a94-07d1e03b6eec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:15:06.001 7 INFO nova.compute.manager [-] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:15:06.170 7 INFO nova.scheduler.client.report [req-ca828323-2a5f-4996-8a94-07d1e03b6eec bb64c95462324464bb8eed4f5828e0b1 6145a9469a2a41d7b9e0c5ec760ce201 - default default] Deleted allocations for instance 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61
2022-02-22 05:15:16.198 7 INFO nova.compute.manager [-] [instance: f72a8d5d-754c-4e8e-a2e5-fc290233f612] VM Stopped (Lifecycle Event)
2022-02-22 05:15:20.845 7 INFO nova.compute.manager [-] [instance: 5729f7a3-d4e2-405d-a1f1-5ed1c3091d61] VM Stopped (Lifecycle Event)
2022-02-22 05:15:39.311 7 INFO nova.compute.claims [req-236713e4-ddde-4b61-b503-85e0fdc141d7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Claim successful on node rack08-server63
2022-02-22 05:15:39.711 7 INFO nova.virt.libvirt.driver [req-236713e4-ddde-4b61-b503-85e0fdc141d7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Creating image
2022-02-22 05:15:40.858 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] VM Resumed (Lifecycle Event)
2022-02-22 05:15:40.866 7 INFO nova.virt.libvirt.driver [-] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Instance spawned successfully.
2022-02-22 05:15:40.918 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:40.919 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] VM Started (Lifecycle Event)
2022-02-22 05:15:40.973 7 INFO nova.compute.manager [req-236713e4-ddde-4b61-b503-85e0fdc141d7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-22 05:15:40.974 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:15:41.062 7 INFO nova.compute.manager [req-236713e4-ddde-4b61-b503-85e0fdc141d7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Took 1.80 seconds to build instance.
2022-02-22 05:15:45.777 7 INFO nova.compute.manager [req-7f976265-829f-463c-af3d-1047c8d654c7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Terminating instance
2022-02-22 05:15:46.132 7 INFO nova.virt.libvirt.driver [-] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Instance destroyed successfully.
2022-02-22 05:15:46.147 7 INFO nova.virt.libvirt.driver [req-7f976265-829f-463c-af3d-1047c8d654c7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Deleting instance files /var/lib/nova/instances/5dc871f0-d995-4783-b3d3-4088eb695562_del
2022-02-22 05:15:46.148 7 INFO nova.virt.libvirt.driver [req-7f976265-829f-463c-af3d-1047c8d654c7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Deletion of /var/lib/nova/instances/5dc871f0-d995-4783-b3d3-4088eb695562_del complete
2022-02-22 05:15:46.226 7 INFO nova.compute.manager [req-7f976265-829f-463c-af3d-1047c8d654c7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-22 05:15:46.287 7 INFO nova.compute.manager [-] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:15:46.474 7 INFO nova.scheduler.client.report [req-7f976265-829f-463c-af3d-1047c8d654c7 c4ce46629aa74be2ae9334bc98941fa6 b23b09dfeefa475eb02c01a8273a35fd - default default] Deleted allocations for instance 5dc871f0-d995-4783-b3d3-4088eb695562
2022-02-22 05:16:00.677 7 INFO nova.compute.claims [req-0ed2036a-2785-43b8-b9f9-46078145203a 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Claim successful on node rack08-server63
2022-02-22 05:16:01.063 7 INFO nova.virt.libvirt.driver [req-0ed2036a-2785-43b8-b9f9-46078145203a 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Creating image
2022-02-22 05:16:01.131 7 INFO nova.compute.manager [-] [instance: 5dc871f0-d995-4783-b3d3-4088eb695562] VM Stopped (Lifecycle Event)
2022-02-22 05:16:02.226 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] VM Resumed (Lifecycle Event)
2022-02-22 05:16:02.234 7 INFO nova.virt.libvirt.driver [-] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Instance spawned successfully.
2022-02-22 05:16:02.287 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:02.287 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] VM Started (Lifecycle Event)
2022-02-22 05:16:02.341 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:02.343 7 INFO nova.compute.manager [req-0ed2036a-2785-43b8-b9f9-46078145203a 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-22 05:16:02.438 7 INFO nova.compute.manager [req-0ed2036a-2785-43b8-b9f9-46078145203a 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Took 1.80 seconds to build instance.
2022-02-22 05:16:03.729 7 INFO nova.compute.manager [req-6d7cf842-f167-4763-a2fb-d00bf6adb076 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Terminating instance
2022-02-22 05:16:04.070 7 INFO nova.virt.libvirt.driver [-] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Instance destroyed successfully.
2022-02-22 05:16:04.086 7 INFO nova.virt.libvirt.driver [req-6d7cf842-f167-4763-a2fb-d00bf6adb076 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Deleting instance files /var/lib/nova/instances/c6538740-085f-48d9-8d0e-b3fdf3435460_del
2022-02-22 05:16:04.087 7 INFO nova.virt.libvirt.driver [req-6d7cf842-f167-4763-a2fb-d00bf6adb076 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Deletion of /var/lib/nova/instances/c6538740-085f-48d9-8d0e-b3fdf3435460_del complete
2022-02-22 05:16:04.156 7 INFO nova.compute.manager [req-6d7cf842-f167-4763-a2fb-d00bf6adb076 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:16:04.224 7 INFO nova.compute.manager [-] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:16:04.430 7 INFO nova.scheduler.client.report [req-6d7cf842-f167-4763-a2fb-d00bf6adb076 5da9bfa26d1a41d7a1c3a8684c192a56 553ebd34108a45b2a4b285a69f3cb97e - default default] Deleted allocations for instance c6538740-085f-48d9-8d0e-b3fdf3435460
2022-02-22 05:16:13.989 7 INFO nova.compute.claims [req-c1bf490f-72ab-4ed2-bd81-7f8edd802cd8 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Claim successful on node rack08-server63
2022-02-22 05:16:14.378 7 INFO nova.virt.libvirt.driver [req-c1bf490f-72ab-4ed2-bd81-7f8edd802cd8 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Creating image
2022-02-22 05:16:15.519 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] VM Resumed (Lifecycle Event)
2022-02-22 05:16:15.527 7 INFO nova.virt.libvirt.driver [-] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Instance spawned successfully.
2022-02-22 05:16:15.586 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:15.586 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] VM Started (Lifecycle Event)
2022-02-22 05:16:15.632 7 INFO nova.compute.manager [req-c1bf490f-72ab-4ed2-bd81-7f8edd802cd8 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-22 05:16:15.642 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:15.713 7 INFO nova.compute.manager [req-c1bf490f-72ab-4ed2-bd81-7f8edd802cd8 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Took 1.77 seconds to build instance.
2022-02-22 05:16:19.068 7 INFO nova.compute.manager [-] [instance: c6538740-085f-48d9-8d0e-b3fdf3435460] VM Stopped (Lifecycle Event)
2022-02-22 05:16:29.923 7 INFO nova.virt.libvirt.driver [req-487eb35d-b050-430f-b2e4-dd4a80be61c0 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Ignoring supplied device name: /dev/vdb
2022-02-22 05:16:30.116 7 INFO nova.compute.manager [req-487eb35d-b050-430f-b2e4-dd4a80be61c0 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Attaching volume 9605c348-bbb8-4387-aa5f-ef56f010751b to /dev/vdb
2022-02-22 05:16:30.208 7 WARNING os_brick.initiator.connectors.nvmeof [req-487eb35d-b050-430f-b2e4-dd4a80be61c0 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:16:31.608 7 INFO os_brick.initiator.connectors.lightos [req-487eb35d-b050-430f-b2e4-dd4a80be61c0 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: connect_volume called for volume a0207917-1068-4895-80d3-d86688e0a5b0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a0207917-1068-4895-80d3-d86688e0a5b0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:16:31.612 7 INFO os_brick.initiator.connectors.lightos [req-487eb35d-b050-430f-b2e4-dd4a80be61c0 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a0207917-1068-4895-80d3-d86688e0a5b0
2022-02-22 05:16:42.721 7 INFO nova.compute.manager [req-36c1a58a-aa2d-4553-889b-7ead948a6223 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Detaching volume 9605c348-bbb8-4387-aa5f-ef56f010751b
2022-02-22 05:16:42.779 7 INFO nova.virt.block_device [req-36c1a58a-aa2d-4553-889b-7ead948a6223 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Attempting to driver detach volume 9605c348-bbb8-4387-aa5f-ef56f010751b from mountpoint /dev/vdb
2022-02-22 05:16:42.798 7 INFO nova.virt.libvirt.driver [req-36c1a58a-aa2d-4553-889b-7ead948a6223 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Successfully detached device vdb from instance 30e3fff7-2795-4c9f-896c-192b74c033e3 from the persistent domain config.
2022-02-22 05:16:42.953 7 INFO nova.virt.libvirt.driver [req-36c1a58a-aa2d-4553-889b-7ead948a6223 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Successfully detached device vdb from instance 30e3fff7-2795-4c9f-896c-192b74c033e3 from the live domain config.
2022-02-22 05:16:42.956 7 INFO os_brick.initiator.connectors.lightos [req-36c1a58a-aa2d-4553-889b-7ead948a6223 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid a0207917-1068-4895-80d3-d86688e0a5b0
2022-02-22 05:16:44.970 7 INFO nova.compute.manager [req-b470ead4-c9ec-4118-8a26-96284e228564 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Terminating instance
2022-02-22 05:16:45.309 7 INFO nova.virt.libvirt.driver [-] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Instance destroyed successfully.
2022-02-22 05:16:45.325 7 INFO nova.virt.libvirt.driver [req-b470ead4-c9ec-4118-8a26-96284e228564 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Deleting instance files /var/lib/nova/instances/30e3fff7-2795-4c9f-896c-192b74c033e3_del
2022-02-22 05:16:45.326 7 INFO nova.virt.libvirt.driver [req-b470ead4-c9ec-4118-8a26-96284e228564 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Deletion of /var/lib/nova/instances/30e3fff7-2795-4c9f-896c-192b74c033e3_del complete
2022-02-22 05:16:45.400 7 INFO nova.compute.manager [req-b470ead4-c9ec-4118-8a26-96284e228564 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:16:45.463 7 INFO nova.compute.manager [-] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] Took 0.06 seconds to deallocate network for instance.
2022-02-22 05:16:45.626 7 INFO nova.scheduler.client.report [req-b470ead4-c9ec-4118-8a26-96284e228564 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Deleted allocations for instance 30e3fff7-2795-4c9f-896c-192b74c033e3
2022-02-22 05:16:45.897 7 INFO nova.compute.claims [req-339ffa70-4641-4a09-9092-e6251b317b0e fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Claim successful on node rack08-server63
2022-02-22 05:16:46.291 7 INFO nova.virt.libvirt.driver [req-339ffa70-4641-4a09-9092-e6251b317b0e fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Creating image
2022-02-22 05:16:47.450 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: deb33641-e747-4965-9a02-23eebab5c87b] VM Resumed (Lifecycle Event)
2022-02-22 05:16:47.458 7 INFO nova.virt.libvirt.driver [-] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Instance spawned successfully.
2022-02-22 05:16:47.512 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: deb33641-e747-4965-9a02-23eebab5c87b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:47.512 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: deb33641-e747-4965-9a02-23eebab5c87b] VM Started (Lifecycle Event)
2022-02-22 05:16:47.562 7 INFO nova.compute.manager [req-339ffa70-4641-4a09-9092-e6251b317b0e fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-22 05:16:47.564 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: deb33641-e747-4965-9a02-23eebab5c87b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:47.652 7 INFO nova.compute.manager [req-339ffa70-4641-4a09-9092-e6251b317b0e fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Took 1.80 seconds to build instance.
2022-02-22 05:16:48.937 7 INFO nova.virt.libvirt.driver [req-75609a9f-83e9-4e1e-bf40-8487e2b16deb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Ignoring supplied device name: /dev/vdb
2022-02-22 05:16:49.104 7 INFO nova.compute.manager [req-75609a9f-83e9-4e1e-bf40-8487e2b16deb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Attaching volume 1488741c-a7f2-4f94-842f-25f85e4db9d3 to /dev/vdb
2022-02-22 05:16:49.189 7 WARNING os_brick.initiator.connectors.nvmeof [req-75609a9f-83e9-4e1e-bf40-8487e2b16deb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:16:50.545 7 INFO os_brick.initiator.connectors.lightos [req-75609a9f-83e9-4e1e-bf40-8487e2b16deb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] LIGHTOS: connect_volume called for volume 39549468-4084-4f80-a37d-236348be9d0d, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '39549468-4084-4f80-a37d-236348be9d0d', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:16:50.550 7 INFO os_brick.initiator.connectors.lightos [req-75609a9f-83e9-4e1e-bf40-8487e2b16deb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 39549468-4084-4f80-a37d-236348be9d0d
2022-02-22 05:16:52.407 7 INFO nova.compute.manager [req-3a49dcc0-9970-4f11-a190-0ef7b5e35a03 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Cinder extended volume 1488741c-a7f2-4f94-842f-25f85e4db9d3; extending it to detect new size
2022-02-22 05:16:52.478 7 INFO os_brick.initiator.connectors.lightos [req-3a49dcc0-9970-4f11-a190-0ef7b5e35a03 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 39549468-4084-4f80-a37d-236348be9d0d
2022-02-22 05:16:53.114 7 INFO nova.compute.manager [req-fa6a2041-855b-4e62-a7cb-9f51cf0ab9fa fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Detaching volume 1488741c-a7f2-4f94-842f-25f85e4db9d3
2022-02-22 05:16:53.129 7 INFO nova.compute.claims [req-50f1dd8b-701b-4bcd-b68e-551b0bb0af08 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Claim successful on node rack08-server63
2022-02-22 05:16:53.192 7 INFO nova.virt.block_device [req-fa6a2041-855b-4e62-a7cb-9f51cf0ab9fa fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Attempting to driver detach volume 1488741c-a7f2-4f94-842f-25f85e4db9d3 from mountpoint /dev/vdb
2022-02-22 05:16:53.215 7 INFO nova.virt.libvirt.driver [req-fa6a2041-855b-4e62-a7cb-9f51cf0ab9fa fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] Successfully detached device vdb from instance deb33641-e747-4965-9a02-23eebab5c87b from the persistent domain config.
2022-02-22 05:16:53.356 7 INFO nova.virt.libvirt.driver [req-fa6a2041-855b-4e62-a7cb-9f51cf0ab9fa fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] Successfully detached device vdb from instance deb33641-e747-4965-9a02-23eebab5c87b from the live domain config.
2022-02-22 05:16:53.359 7 INFO os_brick.initiator.connectors.lightos [req-fa6a2041-855b-4e62-a7cb-9f51cf0ab9fa fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 39549468-4084-4f80-a37d-236348be9d0d
2022-02-22 05:16:53.530 7 INFO nova.virt.libvirt.driver [req-50f1dd8b-701b-4bcd-b68e-551b0bb0af08 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Creating image
2022-02-22 05:16:54.672 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] VM Resumed (Lifecycle Event)
2022-02-22 05:16:54.681 7 INFO nova.virt.libvirt.driver [-] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Instance spawned successfully.
2022-02-22 05:16:54.730 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:54.731 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] VM Started (Lifecycle Event)
2022-02-22 05:16:54.785 7 INFO nova.compute.manager [req-a3bdaa3e-5369-4c42-bc74-c3ffa818ecf2 - - - - -] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 05:16:54.790 7 INFO nova.compute.manager [req-50f1dd8b-701b-4bcd-b68e-551b0bb0af08 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Took 1.26 seconds to spawn the instance on the hypervisor.
2022-02-22 05:16:54.881 7 INFO nova.compute.manager [req-50f1dd8b-701b-4bcd-b68e-551b0bb0af08 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Took 1.79 seconds to build instance.
2022-02-22 05:16:55.110 7 INFO nova.virt.libvirt.driver [req-56c9b769-e973-4949-91fa-3dfba0d39e15 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Ignoring supplied device name: /dev/vdb
2022-02-22 05:16:55.272 7 INFO nova.compute.manager [req-56c9b769-e973-4949-91fa-3dfba0d39e15 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Attaching volume bb37c34e-10bf-4c88-b8d1-bad934b0c35c to /dev/vdb
2022-02-22 05:16:55.356 7 WARNING os_brick.initiator.connectors.nvmeof [req-56c9b769-e973-4949-91fa-3dfba0d39e15 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 05:16:55.365 7 INFO nova.compute.manager [req-6cedd45a-5b37-41ee-a94e-9695ff53abeb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Terminating instance
2022-02-22 05:16:55.712 7 INFO nova.virt.libvirt.driver [-] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Instance destroyed successfully.
2022-02-22 05:16:55.730 7 INFO nova.virt.libvirt.driver [req-6cedd45a-5b37-41ee-a94e-9695ff53abeb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Deleting instance files /var/lib/nova/instances/deb33641-e747-4965-9a02-23eebab5c87b_del
2022-02-22 05:16:55.731 7 INFO nova.virt.libvirt.driver [req-6cedd45a-5b37-41ee-a94e-9695ff53abeb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Deletion of /var/lib/nova/instances/deb33641-e747-4965-9a02-23eebab5c87b_del complete
2022-02-22 05:16:55.800 7 INFO nova.compute.manager [req-6cedd45a-5b37-41ee-a94e-9695ff53abeb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:16:55.867 7 INFO nova.compute.manager [-] [instance: deb33641-e747-4965-9a02-23eebab5c87b] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:16:56.061 7 INFO nova.scheduler.client.report [req-6cedd45a-5b37-41ee-a94e-9695ff53abeb fb86ac53074a455cb1e47d85dc4dd53c bdade2fd228f4a3c930c0571ccdd4f88 - default default] Deleted allocations for instance deb33641-e747-4965-9a02-23eebab5c87b
2022-02-22 05:16:56.706 7 INFO os_brick.initiator.connectors.lightos [req-56c9b769-e973-4949-91fa-3dfba0d39e15 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: connect_volume called for volume 12cbc9b4-ddc4-4401-92ce-678b8ac670ad, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '12cbc9b4-ddc4-4401-92ce-678b8ac670ad', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 05:16:56.710 7 INFO os_brick.initiator.connectors.lightos [req-56c9b769-e973-4949-91fa-3dfba0d39e15 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 12cbc9b4-ddc4-4401-92ce-678b8ac670ad
2022-02-22 05:17:00.308 7 INFO nova.compute.manager [-] [instance: 30e3fff7-2795-4c9f-896c-192b74c033e3] VM Stopped (Lifecycle Event)
2022-02-22 05:17:05.533 7 INFO nova.compute.manager [req-4bc310ec-191b-49cc-b592-a345f1114980 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Detaching volume bb37c34e-10bf-4c88-b8d1-bad934b0c35c
2022-02-22 05:17:05.594 7 INFO nova.virt.block_device [req-4bc310ec-191b-49cc-b592-a345f1114980 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Attempting to driver detach volume bb37c34e-10bf-4c88-b8d1-bad934b0c35c from mountpoint /dev/vdb
2022-02-22 05:17:05.612 7 INFO nova.virt.libvirt.driver [req-4bc310ec-191b-49cc-b592-a345f1114980 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Successfully detached device vdb from instance 0f83da82-7707-47c6-9e42-532152ffde64 from the persistent domain config.
2022-02-22 05:17:05.760 7 INFO nova.virt.libvirt.driver [req-4bc310ec-191b-49cc-b592-a345f1114980 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Successfully detached device vdb from instance 0f83da82-7707-47c6-9e42-532152ffde64 from the live domain config.
2022-02-22 05:17:05.763 7 INFO os_brick.initiator.connectors.lightos [req-4bc310ec-191b-49cc-b592-a345f1114980 ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 12cbc9b4-ddc4-4401-92ce-678b8ac670ad
2022-02-22 05:17:07.806 7 INFO nova.compute.manager [req-9c914c87-2d50-40b7-ab14-f857fd69abca ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Terminating instance
2022-02-22 05:17:08.148 7 INFO nova.virt.libvirt.driver [-] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Instance destroyed successfully.
2022-02-22 05:17:08.163 7 INFO nova.virt.libvirt.driver [req-9c914c87-2d50-40b7-ab14-f857fd69abca ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Deleting instance files /var/lib/nova/instances/0f83da82-7707-47c6-9e42-532152ffde64_del
2022-02-22 05:17:08.164 7 INFO nova.virt.libvirt.driver [req-9c914c87-2d50-40b7-ab14-f857fd69abca ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Deletion of /var/lib/nova/instances/0f83da82-7707-47c6-9e42-532152ffde64_del complete
2022-02-22 05:17:08.238 7 INFO nova.compute.manager [req-9c914c87-2d50-40b7-ab14-f857fd69abca ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 05:17:08.310 7 INFO nova.compute.manager [-] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] Took 0.07 seconds to deallocate network for instance.
2022-02-22 05:17:08.509 7 INFO nova.scheduler.client.report [req-9c914c87-2d50-40b7-ab14-f857fd69abca ffa0ca86fbe84338a6889c6b84799af8 8c6e9eb9a225486f9373c768d9bf72cd - default default] Deleted allocations for instance 0f83da82-7707-47c6-9e42-532152ffde64
2022-02-22 05:17:10.711 7 INFO nova.compute.manager [-] [instance: deb33641-e747-4965-9a02-23eebab5c87b] VM Stopped (Lifecycle Event)
2022-02-22 05:17:23.146 7 INFO nova.compute.manager [-] [instance: 0f83da82-7707-47c6-9e42-532152ffde64] VM Stopped (Lifecycle Event)
