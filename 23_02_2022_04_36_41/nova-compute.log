Build Started 23_02_2022_04_36_41
2022-02-23 06:38:47.390 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-23 06:38:51.311 8 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-23 06:38:52.257 8 INFO nova.virt.driver [req-5a2691ac-8338-4dca-9525-0bbd7f3ef35b - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-23 06:38:52.649 8 INFO nova.compute.provider_config [req-5a2691ac-8338-4dca-9525-0bbd7f3ef35b - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-23 06:38:52.668 8 WARNING oslo_config.cfg [req-5a2691ac-8338-4dca-9525-0bbd7f3ef35b - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-23 06:38:52.694 8 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-23 06:38:52.709 8 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-23 06:38:52.744 8 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-23 06:38:52.837 8 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-23 06:38:52.851 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-23 06:38:52.853 8 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-23 06:38:53.194 8 INFO nova.compute.manager [req-8880a564-57c8-48b1-b427-120e0124686b - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-23 06:38:55.036 8 INFO nova.virt.libvirt.host [req-8880a564-57c8-48b1-b427-120e0124686b - - - - -] kernel doesn't support AMD SEV
2022-02-23 06:39:45.982 8 INFO nova.compute.claims [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Claim successful on node rack08-server63
2022-02-23 06:39:46.393 8 INFO nova.virt.libvirt.driver [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Creating image
2022-02-23 06:39:46.398 8 INFO oslo.privsep.daemon [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp3k6t2ocr/privsep.sock']
2022-02-23 06:39:48.029 8 INFO oslo.privsep.daemon [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Spawned new privsep daemon via rootwrap
2022-02-23 06:39:47.881 70 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 06:39:47.887 70 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 06:39:47.892 70 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-23 06:39:47.893 70 INFO oslo.privsep.daemon [-] privsep daemon running as pid 70
2022-02-23 06:39:49.243 8 INFO nova.compute.manager [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] VM Resumed (Lifecycle Event)
2022-02-23 06:39:49.250 8 INFO nova.virt.libvirt.driver [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Instance spawned successfully.
2022-02-23 06:39:49.310 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:39:49.311 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] VM Started (Lifecycle Event)
2022-02-23 06:39:49.359 8 INFO nova.compute.manager [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Took 2.97 seconds to spawn the instance on the hypervisor.
2022-02-23 06:39:49.362 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:39:49.443 8 INFO nova.compute.manager [req-b0fff042-88d9-48b9-b57e-7f3cde925c99 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Took 3.50 seconds to build instance.
2022-02-23 06:39:49.466 8 INFO nova.compute.manager [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:39:54.104 8 INFO nova.compute.manager [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Attaching volume 30bc5bbe-8c8c-4b41-891b-d5797de54a95 to /dev/vdb
2022-02-23 06:39:54.181 8 INFO oslo.privsep.daemon [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpl1weipop/privsep.sock']
2022-02-23 06:39:54.843 8 INFO oslo.privsep.daemon [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Spawned new privsep daemon via rootwrap
2022-02-23 06:39:54.765 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-23 06:39:54.772 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-23 06:39:54.777 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-23 06:39:54.777 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-23 06:39:55.167 8 WARNING os_brick.initiator.connectors.nvmeof [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:39:56.558 8 INFO os_brick.initiator.connectors.lightos [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: connect_volume called for volume 19981ffd-d251-47c9-b34f-c1b56c7ee677, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '19981ffd-d251-47c9-b34f-c1b56c7ee677', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:39:56.587 8 INFO os_brick.initiator.connectors.lightos [req-2d39a8ba-00ba-4ea5-a3b3-830e173aaa81 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 19981ffd-d251-47c9-b34f-c1b56c7ee677
2022-02-23 06:39:58.777 8 INFO nova.compute.claims [req-e53fba47-07c2-43ab-9208-032b00d3197e fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Claim successful on node rack08-server63
2022-02-23 06:39:59.169 8 INFO nova.virt.libvirt.driver [req-e53fba47-07c2-43ab-9208-032b00d3197e fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Creating image
2022-02-23 06:40:00.075 8 INFO nova.compute.claims [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Claim successful on node rack08-server63
2022-02-23 06:40:00.329 8 INFO nova.virt.libvirt.driver [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 06:40:00.334 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] VM Resumed (Lifecycle Event)
2022-02-23 06:40:00.341 8 INFO nova.virt.libvirt.driver [-] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Instance spawned successfully.
2022-02-23 06:40:00.388 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:00.389 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] VM Started (Lifecycle Event)
2022-02-23 06:40:00.422 8 INFO nova.virt.block_device [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Booting with volume 1c10b8e4-ec16-423a-896c-8540bd7996ed at /dev/vda
2022-02-23 06:40:00.443 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:00.451 8 INFO nova.compute.manager [req-e53fba47-07c2-43ab-9208-032b00d3197e fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:00.506 8 WARNING os_brick.initiator.connectors.nvmeof [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:40:00.548 8 INFO nova.compute.manager [req-e53fba47-07c2-43ab-9208-032b00d3197e fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Took 1.81 seconds to build instance.
2022-02-23 06:40:01.964 8 INFO nova.compute.manager [req-878d4729-ef91-4926-a7d6-4db9321b0e8f fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Detaching volume 30bc5bbe-8c8c-4b41-891b-d5797de54a95
2022-02-23 06:40:02.024 8 INFO nova.virt.block_device [req-878d4729-ef91-4926-a7d6-4db9321b0e8f fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Attempting to driver detach volume 30bc5bbe-8c8c-4b41-891b-d5797de54a95 from mountpoint /dev/vdb
2022-02-23 06:40:02.037 8 INFO nova.virt.libvirt.driver [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Creating image
2022-02-23 06:40:02.050 8 INFO os_brick.initiator.connectors.lightos [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: connect_volume called for volume 5c91ab25-7a7b-474e-aad6-1a5d53c4df04, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5c91ab25-7a7b-474e-aad6-1a5d53c4df04', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:40:02.052 8 INFO os_brick.initiator.connectors.lightos [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 5c91ab25-7a7b-474e-aad6-1a5d53c4df04
2022-02-23 06:40:02.054 8 INFO nova.virt.libvirt.driver [req-878d4729-ef91-4926-a7d6-4db9321b0e8f fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 18ab63c2-7e71-4902-af90-610f0733459d from the persistent domain config.
2022-02-23 06:40:02.196 8 INFO nova.virt.libvirt.driver [req-878d4729-ef91-4926-a7d6-4db9321b0e8f fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 18ab63c2-7e71-4902-af90-610f0733459d from the live domain config.
2022-02-23 06:40:02.199 8 INFO os_brick.initiator.connectors.lightos [req-878d4729-ef91-4926-a7d6-4db9321b0e8f fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 19981ffd-d251-47c9-b34f-c1b56c7ee677
2022-02-23 06:40:02.887 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] VM Resumed (Lifecycle Event)
2022-02-23 06:40:02.894 8 INFO nova.virt.libvirt.driver [-] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Instance spawned successfully.
2022-02-23 06:40:02.947 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:02.948 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] VM Started (Lifecycle Event)
2022-02-23 06:40:02.999 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:03.029 8 INFO nova.compute.manager [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Took 0.99 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:03.111 8 INFO nova.compute.manager [req-1829f86f-6bca-460a-bc9d-661732d3ba19 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Took 3.08 seconds to build instance.
2022-02-23 06:40:05.248 8 INFO nova.compute.claims [req-9a1db018-23b7-40f3-bb5e-e6d5bd25be49 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Claim successful on node rack08-server63
2022-02-23 06:40:05.416 8 INFO nova.compute.claims [req-9fd9e24c-b23f-4708-80c6-d9cea029ef3c fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Claim successful on node rack08-server63
2022-02-23 06:40:05.643 8 INFO nova.virt.libvirt.driver [req-9a1db018-23b7-40f3-bb5e-e6d5bd25be49 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Creating image
2022-02-23 06:40:05.790 8 INFO nova.virt.libvirt.driver [req-9fd9e24c-b23f-4708-80c6-d9cea029ef3c fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Creating image
2022-02-23 06:40:05.833 8 INFO nova.compute.claims [req-b9aa7f8d-5244-4466-b754-597e114badf2 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Claim successful on node rack08-server63
2022-02-23 06:40:06.241 8 INFO nova.virt.libvirt.driver [req-b9aa7f8d-5244-4466-b754-597e114badf2 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Creating image
2022-02-23 06:40:06.781 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] VM Resumed (Lifecycle Event)
2022-02-23 06:40:06.789 8 INFO nova.virt.libvirt.driver [-] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Instance spawned successfully.
2022-02-23 06:40:06.840 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:06.841 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] VM Started (Lifecycle Event)
2022-02-23 06:40:06.895 8 INFO nova.compute.manager [req-9a1db018-23b7-40f3-bb5e-e6d5bd25be49 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Took 1.25 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:06.896 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:06.970 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] VM Resumed (Lifecycle Event)
2022-02-23 06:40:06.974 8 INFO nova.compute.manager [req-9a1db018-23b7-40f3-bb5e-e6d5bd25be49 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Took 1.76 seconds to build instance.
2022-02-23 06:40:06.977 8 INFO nova.virt.libvirt.driver [-] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Instance spawned successfully.
2022-02-23 06:40:07.033 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:07.034 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] VM Started (Lifecycle Event)
2022-02-23 06:40:07.086 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:07.090 8 INFO nova.compute.manager [req-9fd9e24c-b23f-4708-80c6-d9cea029ef3c fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Took 1.30 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:07.170 8 INFO nova.compute.manager [req-9fd9e24c-b23f-4708-80c6-d9cea029ef3c fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Took 1.79 seconds to build instance.
2022-02-23 06:40:07.380 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] VM Resumed (Lifecycle Event)
2022-02-23 06:40:07.386 8 INFO nova.virt.libvirt.driver [-] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Instance spawned successfully.
2022-02-23 06:40:07.442 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:07.443 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] VM Started (Lifecycle Event)
2022-02-23 06:40:07.485 8 INFO nova.compute.manager [req-b9aa7f8d-5244-4466-b754-597e114badf2 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:07.497 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:07.570 8 INFO nova.compute.manager [req-b9aa7f8d-5244-4466-b754-597e114badf2 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Took 1.81 seconds to build instance.
2022-02-23 06:40:10.545 8 INFO nova.compute.manager [req-be6fe862-fb32-4818-b4bf-a339e6ea88af b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Attaching volume 375874a3-9de2-4255-a8fb-03d7c4b40670 to /dev/vdb
2022-02-23 06:40:10.663 8 WARNING os_brick.initiator.connectors.nvmeof [req-be6fe862-fb32-4818-b4bf-a339e6ea88af b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:40:10.986 8 INFO nova.compute.manager [req-636a536c-4e9b-481e-b4aa-7179f776a38a fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Attaching volume 001df9b2-261e-4b5d-a120-000d85623486 to /dev/vdb
2022-02-23 06:40:11.215 8 WARNING os_brick.initiator.connectors.nvmeof [req-636a536c-4e9b-481e-b4aa-7179f776a38a fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:40:12.023 8 INFO os_brick.initiator.connectors.lightos [req-be6fe862-fb32-4818-b4bf-a339e6ea88af b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: connect_volume called for volume 5acc219d-a476-4bd7-b629-804ced7921df, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5acc219d-a476-4bd7-b629-804ced7921df', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:40:12.027 8 INFO os_brick.initiator.connectors.lightos [req-be6fe862-fb32-4818-b4bf-a339e6ea88af b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5acc219d-a476-4bd7-b629-804ced7921df
2022-02-23 06:40:12.574 8 INFO os_brick.initiator.connectors.lightos [req-636a536c-4e9b-481e-b4aa-7179f776a38a fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: connect_volume called for volume 3c09cc2f-9b46-42b6-847c-c693391192c0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '3c09cc2f-9b46-42b6-847c-c693391192c0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:40:12.577 8 INFO os_brick.initiator.connectors.lightos [req-636a536c-4e9b-481e-b4aa-7179f776a38a fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 3c09cc2f-9b46-42b6-847c-c693391192c0
2022-02-23 06:40:13.011 8 INFO nova.compute.manager [req-dde30da9-9762-4991-9378-3182fd2928b0 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Attaching volume 375874a3-9de2-4255-a8fb-03d7c4b40670 to /dev/vdb
2022-02-23 06:40:13.109 8 WARNING os_brick.initiator.connectors.nvmeof [req-dde30da9-9762-4991-9378-3182fd2928b0 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:40:13.555 8 INFO nova.compute.manager [req-5c44968e-63e4-48b5-b58b-4b0268ccdeac fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Detaching volume 001df9b2-261e-4b5d-a120-000d85623486
2022-02-23 06:40:13.611 8 INFO nova.virt.block_device [req-5c44968e-63e4-48b5-b58b-4b0268ccdeac fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Attempting to driver detach volume 001df9b2-261e-4b5d-a120-000d85623486 from mountpoint /dev/vdb
2022-02-23 06:40:13.630 8 INFO nova.virt.libvirt.driver [req-5c44968e-63e4-48b5-b58b-4b0268ccdeac fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 4e517d85-f125-47b7-9735-a8667dc3a76b from the persistent domain config.
2022-02-23 06:40:13.772 8 INFO nova.virt.libvirt.driver [req-5c44968e-63e4-48b5-b58b-4b0268ccdeac fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 4e517d85-f125-47b7-9735-a8667dc3a76b from the live domain config.
2022-02-23 06:40:13.775 8 INFO os_brick.initiator.connectors.lightos [req-5c44968e-63e4-48b5-b58b-4b0268ccdeac fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n4 detected for uuid 3c09cc2f-9b46-42b6-847c-c693391192c0
2022-02-23 06:40:14.488 8 INFO os_brick.initiator.connectors.lightos [req-dde30da9-9762-4991-9378-3182fd2928b0 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: connect_volume called for volume 5acc219d-a476-4bd7-b629-804ced7921df, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '5acc219d-a476-4bd7-b629-804ced7921df', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:40:14.489 8 INFO os_brick.initiator.connectors.lightos [req-dde30da9-9762-4991-9378-3182fd2928b0 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 5acc219d-a476-4bd7-b629-804ced7921df
2022-02-23 06:40:15.568 8 INFO nova.compute.manager [req-d6860753-67a3-4491-9cb6-c652546f99f5 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Detaching volume 375874a3-9de2-4255-a8fb-03d7c4b40670
2022-02-23 06:40:15.630 8 INFO nova.virt.block_device [req-d6860753-67a3-4491-9cb6-c652546f99f5 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Attempting to driver detach volume 375874a3-9de2-4255-a8fb-03d7c4b40670 from mountpoint /dev/vdb
2022-02-23 06:40:15.649 8 INFO nova.virt.libvirt.driver [req-d6860753-67a3-4491-9cb6-c652546f99f5 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Successfully detached device vdb from instance dd12c84e-0f33-44cb-a971-8e2960e48e74 from the persistent domain config.
2022-02-23 06:40:15.800 8 INFO nova.virt.libvirt.driver [req-d6860753-67a3-4491-9cb6-c652546f99f5 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Successfully detached device vdb from instance dd12c84e-0f33-44cb-a971-8e2960e48e74 from the live domain config.
2022-02-23 06:40:15.865 8 INFO nova.virt.libvirt.driver [req-d6860753-67a3-4491-9cb6-c652546f99f5 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Detected multiple connections on this host for volume: 375874a3-9de2-4255-a8fb-03d7c4b40670, skipping target disconnect.
2022-02-23 06:40:16.919 8 INFO nova.compute.claims [req-b91a6251-49eb-4d56-b065-51c9a18b1888 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Claim successful on node rack08-server63
2022-02-23 06:40:17.317 8 INFO nova.virt.libvirt.driver [req-b91a6251-49eb-4d56-b065-51c9a18b1888 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Creating image
2022-02-23 06:40:18.028 8 INFO nova.compute.manager [req-431c7ca9-0fae-436f-a17a-626e1e588a6b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Detaching volume 375874a3-9de2-4255-a8fb-03d7c4b40670
2022-02-23 06:40:18.093 8 INFO nova.virt.block_device [req-431c7ca9-0fae-436f-a17a-626e1e588a6b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Attempting to driver detach volume 375874a3-9de2-4255-a8fb-03d7c4b40670 from mountpoint /dev/vdb
2022-02-23 06:40:18.113 8 INFO nova.virt.libvirt.driver [req-431c7ca9-0fae-436f-a17a-626e1e588a6b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Successfully detached device vdb from instance d3edab8f-e59e-426a-80d9-51ab3c243dd0 from the persistent domain config.
2022-02-23 06:40:18.294 8 INFO nova.virt.libvirt.driver [req-431c7ca9-0fae-436f-a17a-626e1e588a6b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Successfully detached device vdb from instance d3edab8f-e59e-426a-80d9-51ab3c243dd0 from the live domain config.
2022-02-23 06:40:18.491 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] VM Resumed (Lifecycle Event)
2022-02-23 06:40:18.500 8 INFO nova.virt.libvirt.driver [-] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Instance spawned successfully.
2022-02-23 06:40:18.568 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:18.569 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] VM Started (Lifecycle Event)
2022-02-23 06:40:18.620 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:18.626 8 INFO nova.compute.manager [req-b91a6251-49eb-4d56-b065-51c9a18b1888 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Took 1.31 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:18.709 8 INFO nova.compute.manager [req-b91a6251-49eb-4d56-b065-51c9a18b1888 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Took 1.83 seconds to build instance.
2022-02-23 06:40:22.585 8 INFO nova.compute.manager [req-ab095d04-0555-4b11-9771-561e8451bc91 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Attaching volume 3194b710-c565-4869-9cc3-28a180048f24 to /dev/vdb
2022-02-23 06:40:22.675 8 WARNING os_brick.initiator.connectors.nvmeof [req-ab095d04-0555-4b11-9771-561e8451bc91 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:40:57.658 8 INFO nova.compute.claims [req-fe9517cc-5b5d-4822-9a1a-21f07632beaf 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Claim successful on node rack08-server63
2022-02-23 06:40:58.040 8 INFO nova.virt.libvirt.driver [req-fe9517cc-5b5d-4822-9a1a-21f07632beaf 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Creating image
2022-02-23 06:40:59.324 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] VM Resumed (Lifecycle Event)
2022-02-23 06:40:59.332 8 INFO nova.virt.libvirt.driver [-] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Instance spawned successfully.
2022-02-23 06:40:59.384 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:59.384 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] VM Started (Lifecycle Event)
2022-02-23 06:40:59.437 8 INFO nova.compute.manager [req-fe9517cc-5b5d-4822-9a1a-21f07632beaf 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Took 1.40 seconds to spawn the instance on the hypervisor.
2022-02-23 06:40:59.439 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:40:59.533 8 INFO nova.compute.manager [req-fe9517cc-5b5d-4822-9a1a-21f07632beaf 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Took 1.92 seconds to build instance.
2022-02-23 06:41:05.288 8 INFO nova.compute.manager [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Terminating instance
2022-02-23 06:41:05.657 8 INFO nova.virt.libvirt.driver [-] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Instance destroyed successfully.
2022-02-23 06:41:05.674 8 INFO nova.virt.libvirt.driver [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Deleting instance files /var/lib/nova/instances/004b616d-8752-44ee-94a9-0d43ed4e4765_del
2022-02-23 06:41:05.675 8 INFO nova.virt.libvirt.driver [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Deletion of /var/lib/nova/instances/004b616d-8752-44ee-94a9-0d43ed4e4765_del complete
2022-02-23 06:41:05.741 8 INFO nova.virt.libvirt.host [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] UEFI support detected
2022-02-23 06:41:05.743 8 INFO nova.compute.manager [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:05.813 8 INFO nova.compute.manager [-] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:41:06.009 8 INFO nova.scheduler.client.report [req-67d26784-9727-4357-8099-2a57baa9ae0a 3eda9f48be654bb58808f4b810cb8ff2 1af1e34bcb0e4d8d853b6d143ade50a4 - default default] Deleted allocations for instance 004b616d-8752-44ee-94a9-0d43ed4e4765
2022-02-23 06:41:18.806 8 INFO os_brick.initiator.connectors.lightos [req-ab095d04-0555-4b11-9771-561e8451bc91 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: connect_volume called for volume ba1e3818-8521-4af1-a008-0944e6b28b94, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ba1e3818-8521-4af1-a008-0944e6b28b94', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:41:18.810 8 INFO os_brick.initiator.connectors.lightos [req-ab095d04-0555-4b11-9771-561e8451bc91 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ba1e3818-8521-4af1-a008-0944e6b28b94
2022-02-23 06:41:20.192 8 INFO nova.compute.manager [req-5a27ab6b-23f2-4cc4-bd49-905a44f9676d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Detaching volume 3194b710-c565-4869-9cc3-28a180048f24
2022-02-23 06:41:20.257 8 INFO nova.virt.block_device [req-5a27ab6b-23f2-4cc4-bd49-905a44f9676d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Attempting to driver detach volume 3194b710-c565-4869-9cc3-28a180048f24 from mountpoint /dev/vdb
2022-02-23 06:41:20.275 8 INFO nova.virt.libvirt.driver [req-5a27ab6b-23f2-4cc4-bd49-905a44f9676d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 96286dff-c5c7-4f03-9c17-b091d2200c2e from the persistent domain config.
2022-02-23 06:41:20.414 8 INFO nova.virt.libvirt.driver [req-5a27ab6b-23f2-4cc4-bd49-905a44f9676d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Successfully detached device vdb from instance 96286dff-c5c7-4f03-9c17-b091d2200c2e from the live domain config.
2022-02-23 06:41:20.418 8 INFO os_brick.initiator.connectors.lightos [req-5a27ab6b-23f2-4cc4-bd49-905a44f9676d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ba1e3818-8521-4af1-a008-0944e6b28b94
2022-02-23 06:41:20.654 8 INFO nova.compute.manager [-] [instance: 004b616d-8752-44ee-94a9-0d43ed4e4765] VM Stopped (Lifecycle Event)
2022-02-23 06:41:23.680 8 INFO nova.compute.manager [req-3ae3ce4f-dbde-4b6a-861c-4f3ee1951bca fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Terminating instance
2022-02-23 06:41:24.039 8 INFO nova.virt.libvirt.driver [-] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Instance destroyed successfully.
2022-02-23 06:41:24.055 8 INFO nova.virt.libvirt.driver [req-3ae3ce4f-dbde-4b6a-861c-4f3ee1951bca fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Deleting instance files /var/lib/nova/instances/96286dff-c5c7-4f03-9c17-b091d2200c2e_del
2022-02-23 06:41:24.057 8 INFO nova.virt.libvirt.driver [req-3ae3ce4f-dbde-4b6a-861c-4f3ee1951bca fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Deletion of /var/lib/nova/instances/96286dff-c5c7-4f03-9c17-b091d2200c2e_del complete
2022-02-23 06:41:24.127 8 INFO nova.compute.manager [req-3ae3ce4f-dbde-4b6a-861c-4f3ee1951bca fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:24.194 8 INFO nova.compute.manager [-] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:41:24.394 8 INFO nova.scheduler.client.report [req-3ae3ce4f-dbde-4b6a-861c-4f3ee1951bca fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Deleted allocations for instance 96286dff-c5c7-4f03-9c17-b091d2200c2e
2022-02-23 06:41:26.071 8 INFO nova.compute.manager [req-fd16c5a8-85d4-4d27-a538-c4dccbfe1be5 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Terminating instance
2022-02-23 06:41:26.414 8 INFO nova.virt.libvirt.driver [-] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Instance destroyed successfully.
2022-02-23 06:41:26.436 8 INFO nova.virt.libvirt.driver [req-fd16c5a8-85d4-4d27-a538-c4dccbfe1be5 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Deleting instance files /var/lib/nova/instances/4e517d85-f125-47b7-9735-a8667dc3a76b_del
2022-02-23 06:41:26.438 8 INFO nova.virt.libvirt.driver [req-fd16c5a8-85d4-4d27-a538-c4dccbfe1be5 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Deletion of /var/lib/nova/instances/4e517d85-f125-47b7-9735-a8667dc3a76b_del complete
2022-02-23 06:41:26.511 8 INFO nova.compute.manager [req-fd16c5a8-85d4-4d27-a538-c4dccbfe1be5 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:26.576 8 INFO nova.compute.manager [-] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:41:26.759 8 INFO nova.scheduler.client.report [req-fd16c5a8-85d4-4d27-a538-c4dccbfe1be5 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Deleted allocations for instance 4e517d85-f125-47b7-9735-a8667dc3a76b
2022-02-23 06:41:27.310 8 INFO nova.compute.manager [req-24041c75-6ce4-4e62-b6c8-0aec53efc115 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Terminating instance
2022-02-23 06:41:27.680 8 INFO nova.virt.libvirt.driver [-] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Instance destroyed successfully.
2022-02-23 06:41:27.698 8 INFO nova.virt.libvirt.driver [req-24041c75-6ce4-4e62-b6c8-0aec53efc115 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Deleting instance files /var/lib/nova/instances/e2ab1b87-df16-46b5-aea7-89afc5d1327d_del
2022-02-23 06:41:27.700 8 INFO nova.virt.libvirt.driver [req-24041c75-6ce4-4e62-b6c8-0aec53efc115 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Deletion of /var/lib/nova/instances/e2ab1b87-df16-46b5-aea7-89afc5d1327d_del complete
2022-02-23 06:41:27.769 8 INFO nova.compute.manager [req-24041c75-6ce4-4e62-b6c8-0aec53efc115 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Took 0.33 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:27.834 8 INFO nova.compute.manager [-] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:41:28.006 8 INFO nova.scheduler.client.report [req-24041c75-6ce4-4e62-b6c8-0aec53efc115 fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Deleted allocations for instance e2ab1b87-df16-46b5-aea7-89afc5d1327d
2022-02-23 06:41:29.699 8 INFO nova.compute.manager [req-d0955b8b-953d-46c2-a777-b6cb745b4c6d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Terminating instance
2022-02-23 06:41:30.035 8 INFO nova.virt.libvirt.driver [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Instance destroyed successfully.
2022-02-23 06:41:30.050 8 INFO nova.virt.libvirt.driver [req-d0955b8b-953d-46c2-a777-b6cb745b4c6d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Deleting instance files /var/lib/nova/instances/18ab63c2-7e71-4902-af90-610f0733459d_del
2022-02-23 06:41:30.052 8 INFO nova.virt.libvirt.driver [req-d0955b8b-953d-46c2-a777-b6cb745b4c6d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Deletion of /var/lib/nova/instances/18ab63c2-7e71-4902-af90-610f0733459d_del complete
2022-02-23 06:41:30.121 8 INFO nova.compute.manager [req-d0955b8b-953d-46c2-a777-b6cb745b4c6d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:30.189 8 INFO nova.compute.manager [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:41:30.391 8 INFO nova.scheduler.client.report [req-d0955b8b-953d-46c2-a777-b6cb745b4c6d fd9cab353696428b8369911bcf0405d9 be6d44e0708d40c3876dadbe2e80ee7b - default default] Deleted allocations for instance 18ab63c2-7e71-4902-af90-610f0733459d
2022-02-23 06:41:35.184 8 INFO nova.compute.claims [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Claim successful on node rack08-server63
2022-02-23 06:41:35.465 8 INFO nova.virt.libvirt.driver [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-23 06:41:35.550 8 INFO nova.virt.block_device [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Booting with volume 7cbe7141-8f32-44cc-8d55-d341c6c090b0 at /dev/vda
2022-02-23 06:41:35.652 8 WARNING os_brick.initiator.connectors.nvmeof [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:41:37.185 8 INFO nova.virt.libvirt.driver [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Creating image
2022-02-23 06:41:37.198 8 INFO os_brick.initiator.connectors.lightos [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: connect_volume called for volume 9ae0bc3d-9102-4b74-8d0e-35cc43a7bfeb, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '9ae0bc3d-9102-4b74-8d0e-35cc43a7bfeb', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:41:37.201 8 INFO os_brick.initiator.connectors.lightos [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9ae0bc3d-9102-4b74-8d0e-35cc43a7bfeb
2022-02-23 06:41:38.035 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] VM Resumed (Lifecycle Event)
2022-02-23 06:41:38.042 8 INFO nova.virt.libvirt.driver [-] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Instance spawned successfully.
2022-02-23 06:41:38.095 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:41:38.096 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] VM Started (Lifecycle Event)
2022-02-23 06:41:38.148 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:41:38.162 8 INFO nova.compute.manager [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Took 0.98 seconds to spawn the instance on the hypervisor.
2022-02-23 06:41:38.244 8 INFO nova.compute.manager [req-32e1e33e-f5b3-44dc-8afd-88a9ecc1d580 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Took 3.09 seconds to build instance.
2022-02-23 06:41:39.037 8 INFO nova.compute.manager [-] [instance: 96286dff-c5c7-4f03-9c17-b091d2200c2e] VM Stopped (Lifecycle Event)
2022-02-23 06:41:40.529 8 INFO nova.compute.manager [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Terminating instance
2022-02-23 06:41:40.879 8 INFO nova.virt.libvirt.driver [-] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Instance destroyed successfully.
2022-02-23 06:41:40.950 8 INFO os_brick.initiator.connectors.lightos [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 9ae0bc3d-9102-4b74-8d0e-35cc43a7bfeb
2022-02-23 06:41:40.962 8 INFO nova.virt.libvirt.driver [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Deleting instance files /var/lib/nova/instances/0b40ad57-7df8-4e2d-a814-e14ddec36b2f_del
2022-02-23 06:41:40.963 8 INFO nova.virt.libvirt.driver [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Deletion of /var/lib/nova/instances/0b40ad57-7df8-4e2d-a814-e14ddec36b2f_del complete
2022-02-23 06:41:41.033 8 INFO nova.compute.manager [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Took 0.37 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:41.098 8 INFO nova.compute.manager [-] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:41:41.412 8 INFO nova.compute.manager [-] [instance: 4e517d85-f125-47b7-9735-a8667dc3a76b] VM Stopped (Lifecycle Event)
2022-02-23 06:41:42.330 8 INFO nova.compute.manager [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] Took 1.23 seconds to detach 1 volumes for instance.
2022-02-23 06:41:42.519 8 INFO nova.scheduler.client.report [req-cf3ec0a4-ddde-4a55-adff-811928d05b22 b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Deleted allocations for instance 0b40ad57-7df8-4e2d-a814-e14ddec36b2f
2022-02-23 06:41:42.677 8 INFO nova.compute.manager [-] [instance: e2ab1b87-df16-46b5-aea7-89afc5d1327d] VM Stopped (Lifecycle Event)
2022-02-23 06:41:45.033 8 INFO nova.compute.manager [-] [instance: 18ab63c2-7e71-4902-af90-610f0733459d] VM Stopped (Lifecycle Event)
2022-02-23 06:41:45.505 8 INFO nova.compute.manager [req-23ef960a-ef46-4b96-9708-34a2a634d88e b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Terminating instance
2022-02-23 06:41:45.850 8 INFO nova.virt.libvirt.driver [-] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Instance destroyed successfully.
2022-02-23 06:41:45.866 8 INFO nova.virt.libvirt.driver [req-23ef960a-ef46-4b96-9708-34a2a634d88e b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Deleting instance files /var/lib/nova/instances/d3edab8f-e59e-426a-80d9-51ab3c243dd0_del
2022-02-23 06:41:45.868 8 INFO nova.virt.libvirt.driver [req-23ef960a-ef46-4b96-9708-34a2a634d88e b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Deletion of /var/lib/nova/instances/d3edab8f-e59e-426a-80d9-51ab3c243dd0_del complete
2022-02-23 06:41:45.936 8 INFO nova.compute.manager [req-23ef960a-ef46-4b96-9708-34a2a634d88e b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:46.004 8 INFO nova.compute.manager [-] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:41:46.202 8 INFO nova.scheduler.client.report [req-23ef960a-ef46-4b96-9708-34a2a634d88e b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Deleted allocations for instance d3edab8f-e59e-426a-80d9-51ab3c243dd0
2022-02-23 06:41:46.766 8 INFO nova.compute.manager [req-6517e0d7-aa6a-4f59-93de-9d82c61d98ad b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Terminating instance
2022-02-23 06:41:47.140 8 INFO nova.virt.libvirt.driver [-] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Instance destroyed successfully.
2022-02-23 06:41:47.158 8 INFO nova.virt.libvirt.driver [req-6517e0d7-aa6a-4f59-93de-9d82c61d98ad b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Deleting instance files /var/lib/nova/instances/dd12c84e-0f33-44cb-a971-8e2960e48e74_del
2022-02-23 06:41:47.159 8 INFO nova.virt.libvirt.driver [req-6517e0d7-aa6a-4f59-93de-9d82c61d98ad b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Deletion of /var/lib/nova/instances/dd12c84e-0f33-44cb-a971-8e2960e48e74_del complete
2022-02-23 06:41:47.228 8 INFO nova.compute.manager [req-6517e0d7-aa6a-4f59-93de-9d82c61d98ad b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:47.295 8 INFO nova.compute.manager [-] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:41:47.495 8 INFO nova.scheduler.client.report [req-6517e0d7-aa6a-4f59-93de-9d82c61d98ad b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Deleted allocations for instance dd12c84e-0f33-44cb-a971-8e2960e48e74
2022-02-23 06:41:48.038 8 INFO nova.compute.manager [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Terminating instance
2022-02-23 06:41:48.373 8 INFO nova.virt.libvirt.driver [-] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Instance destroyed successfully.
2022-02-23 06:41:48.439 8 INFO os_brick.initiator.connectors.lightos [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 5c91ab25-7a7b-474e-aad6-1a5d53c4df04
2022-02-23 06:41:48.451 8 INFO nova.virt.libvirt.driver [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Deleting instance files /var/lib/nova/instances/f79570ab-f634-42e0-869b-27b4df6c2b62_del
2022-02-23 06:41:48.452 8 INFO nova.virt.libvirt.driver [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Deletion of /var/lib/nova/instances/f79570ab-f634-42e0-869b-27b4df6c2b62_del complete
2022-02-23 06:41:48.520 8 INFO nova.compute.manager [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-23 06:41:48.585 8 INFO nova.compute.manager [-] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:41:49.837 8 INFO nova.compute.manager [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] Took 1.25 seconds to detach 1 volumes for instance.
2022-02-23 06:41:50.030 8 INFO nova.scheduler.client.report [req-7d6b04bc-11a2-430b-911a-35a42eb74c0b b9e00369da3d47a98af0cad30a8aee9e 94ab3c6dfecf4df19b6e4079dca84eba - default default] Deleted allocations for instance f79570ab-f634-42e0-869b-27b4df6c2b62
2022-02-23 06:41:55.878 8 INFO nova.compute.manager [-] [instance: 0b40ad57-7df8-4e2d-a814-e14ddec36b2f] VM Stopped (Lifecycle Event)
2022-02-23 06:42:00.849 8 INFO nova.compute.manager [-] [instance: d3edab8f-e59e-426a-80d9-51ab3c243dd0] VM Stopped (Lifecycle Event)
2022-02-23 06:42:02.137 8 INFO nova.compute.manager [-] [instance: dd12c84e-0f33-44cb-a971-8e2960e48e74] VM Stopped (Lifecycle Event)
2022-02-23 06:42:03.371 8 INFO nova.compute.manager [-] [instance: f79570ab-f634-42e0-869b-27b4df6c2b62] VM Stopped (Lifecycle Event)
2022-02-23 06:43:37.361 8 INFO nova.compute.claims [req-7f947320-8ab1-4a48-b5d7-84e0fc90200d ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Claim successful on node rack08-server63
2022-02-23 06:43:37.765 8 INFO nova.virt.libvirt.driver [req-7f947320-8ab1-4a48-b5d7-84e0fc90200d ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Creating image
2022-02-23 06:43:38.938 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] VM Resumed (Lifecycle Event)
2022-02-23 06:43:38.946 8 INFO nova.virt.libvirt.driver [-] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Instance spawned successfully.
2022-02-23 06:43:39.007 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:43:39.008 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] VM Started (Lifecycle Event)
2022-02-23 06:43:39.052 8 INFO nova.compute.manager [req-7f947320-8ab1-4a48-b5d7-84e0fc90200d ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-23 06:43:39.063 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:43:39.133 8 INFO nova.compute.manager [req-7f947320-8ab1-4a48-b5d7-84e0fc90200d ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Took 1.82 seconds to build instance.
2022-02-23 06:43:55.675 8 INFO nova.virt.libvirt.driver [req-b897c78d-13eb-4c62-ae6b-e1bc5cd5e95c ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Ignoring supplied device name: /dev/vdb
2022-02-23 06:43:55.826 8 INFO nova.compute.manager [req-b897c78d-13eb-4c62-ae6b-e1bc5cd5e95c ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Attaching volume 64faaeeb-b896-4f04-9e9a-1f560282eef1 to /dev/vdb
2022-02-23 06:43:55.912 8 WARNING os_brick.initiator.connectors.nvmeof [req-b897c78d-13eb-4c62-ae6b-e1bc5cd5e95c ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:43:57.289 8 INFO os_brick.initiator.connectors.lightos [req-b897c78d-13eb-4c62-ae6b-e1bc5cd5e95c ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: connect_volume called for volume d7c58c91-d9cf-44b2-80ba-713a590397cf, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'd7c58c91-d9cf-44b2-80ba-713a590397cf', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:43:57.293 8 INFO os_brick.initiator.connectors.lightos [req-b897c78d-13eb-4c62-ae6b-e1bc5cd5e95c ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d7c58c91-d9cf-44b2-80ba-713a590397cf
2022-02-23 06:44:06.003 8 INFO nova.compute.claims [req-e6ce0a6c-e081-4a67-8220-178307f0ba39 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Claim successful on node rack08-server63
2022-02-23 06:44:06.375 8 INFO nova.virt.libvirt.driver [req-e6ce0a6c-e081-4a67-8220-178307f0ba39 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Creating image
2022-02-23 06:44:07.493 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] VM Resumed (Lifecycle Event)
2022-02-23 06:44:07.500 8 INFO nova.virt.libvirt.driver [-] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Instance spawned successfully.
2022-02-23 06:44:07.556 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:07.557 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] VM Started (Lifecycle Event)
2022-02-23 06:44:07.609 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:07.611 8 INFO nova.compute.manager [req-e6ce0a6c-e081-4a67-8220-178307f0ba39 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-23 06:44:07.696 8 INFO nova.compute.manager [req-e6ce0a6c-e081-4a67-8220-178307f0ba39 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Took 1.73 seconds to build instance.
2022-02-23 06:44:08.276 8 INFO nova.compute.manager [req-2edcc7f3-17cc-40db-a806-fe2eabebcdf5 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Terminating instance
2022-02-23 06:44:08.533 8 INFO nova.compute.manager [req-dd70ecb2-a178-4e35-baf4-345e31c62879 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Detaching volume 64faaeeb-b896-4f04-9e9a-1f560282eef1
2022-02-23 06:44:08.592 8 INFO nova.virt.block_device [req-dd70ecb2-a178-4e35-baf4-345e31c62879 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Attempting to driver detach volume 64faaeeb-b896-4f04-9e9a-1f560282eef1 from mountpoint /dev/vdb
2022-02-23 06:44:08.636 8 INFO nova.virt.libvirt.driver [-] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Instance destroyed successfully.
2022-02-23 06:44:08.651 8 INFO nova.virt.libvirt.driver [req-2edcc7f3-17cc-40db-a806-fe2eabebcdf5 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Deleting instance files /var/lib/nova/instances/9b905811-40b7-4b1e-afd5-859956f8dad3_del
2022-02-23 06:44:08.653 8 INFO nova.virt.libvirt.driver [req-2edcc7f3-17cc-40db-a806-fe2eabebcdf5 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Deletion of /var/lib/nova/instances/9b905811-40b7-4b1e-afd5-859956f8dad3_del complete
2022-02-23 06:44:08.659 8 INFO nova.virt.libvirt.driver [req-dd70ecb2-a178-4e35-baf4-345e31c62879 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Successfully detached device vdb from instance 61133a2b-e12f-400f-a94a-6efd768808bd from the persistent domain config.
2022-02-23 06:44:08.718 8 INFO nova.compute.manager [req-2edcc7f3-17cc-40db-a806-fe2eabebcdf5 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:08.796 8 INFO nova.compute.manager [-] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] Took 0.08 seconds to deallocate network for instance.
2022-02-23 06:44:08.806 8 INFO nova.virt.libvirt.driver [req-dd70ecb2-a178-4e35-baf4-345e31c62879 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Successfully detached device vdb from instance 61133a2b-e12f-400f-a94a-6efd768808bd from the live domain config.
2022-02-23 06:44:08.809 8 INFO os_brick.initiator.connectors.lightos [req-dd70ecb2-a178-4e35-baf4-345e31c62879 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid d7c58c91-d9cf-44b2-80ba-713a590397cf
2022-02-23 06:44:08.999 8 INFO nova.scheduler.client.report [req-2edcc7f3-17cc-40db-a806-fe2eabebcdf5 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] Deleted allocations for instance 9b905811-40b7-4b1e-afd5-859956f8dad3
2022-02-23 06:44:10.647 8 INFO nova.compute.claims [req-e5e35613-b236-4fe4-8b21-e36a939cbec4 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Claim successful on node rack08-server63
2022-02-23 06:44:10.773 8 INFO nova.compute.manager [req-8a7f2973-c811-48a0-b403-9ef41c4d2b51 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Terminating instance
2022-02-23 06:44:11.070 8 INFO nova.virt.libvirt.driver [req-e5e35613-b236-4fe4-8b21-e36a939cbec4 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Creating image
2022-02-23 06:44:11.131 8 INFO nova.virt.libvirt.driver [-] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Instance destroyed successfully.
2022-02-23 06:44:11.148 8 INFO nova.virt.libvirt.driver [req-8a7f2973-c811-48a0-b403-9ef41c4d2b51 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Deleting instance files /var/lib/nova/instances/61133a2b-e12f-400f-a94a-6efd768808bd_del
2022-02-23 06:44:11.149 8 INFO nova.virt.libvirt.driver [req-8a7f2973-c811-48a0-b403-9ef41c4d2b51 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Deletion of /var/lib/nova/instances/61133a2b-e12f-400f-a94a-6efd768808bd_del complete
2022-02-23 06:44:11.220 8 INFO nova.compute.manager [req-8a7f2973-c811-48a0-b403-9ef41c4d2b51 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:11.294 8 INFO nova.compute.manager [-] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:44:11.491 8 INFO nova.scheduler.client.report [req-8a7f2973-c811-48a0-b403-9ef41c4d2b51 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Deleted allocations for instance 61133a2b-e12f-400f-a94a-6efd768808bd
2022-02-23 06:44:12.286 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] VM Resumed (Lifecycle Event)
2022-02-23 06:44:12.293 8 INFO nova.virt.libvirt.driver [-] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Instance spawned successfully.
2022-02-23 06:44:12.349 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:12.350 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] VM Started (Lifecycle Event)
2022-02-23 06:44:12.401 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:12.405 8 INFO nova.compute.manager [req-e5e35613-b236-4fe4-8b21-e36a939cbec4 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Took 1.34 seconds to spawn the instance on the hypervisor.
2022-02-23 06:44:12.485 8 INFO nova.compute.manager [req-e5e35613-b236-4fe4-8b21-e36a939cbec4 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Took 1.88 seconds to build instance.
2022-02-23 06:44:14.032 8 INFO nova.compute.manager [req-793f5199-5036-439c-bf3f-588c3ac0737c 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Terminating instance
2022-02-23 06:44:14.382 8 INFO nova.virt.libvirt.driver [-] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Instance destroyed successfully.
2022-02-23 06:44:14.398 8 INFO nova.virt.libvirt.driver [req-793f5199-5036-439c-bf3f-588c3ac0737c 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Deleting instance files /var/lib/nova/instances/1e492780-30e4-4655-9d62-d421cb1bab3b_del
2022-02-23 06:44:14.399 8 INFO nova.virt.libvirt.driver [req-793f5199-5036-439c-bf3f-588c3ac0737c 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Deletion of /var/lib/nova/instances/1e492780-30e4-4655-9d62-d421cb1bab3b_del complete
2022-02-23 06:44:14.471 8 INFO nova.compute.manager [req-793f5199-5036-439c-bf3f-588c3ac0737c 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:14.544 8 INFO nova.compute.manager [-] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:44:14.737 8 INFO nova.scheduler.client.report [req-793f5199-5036-439c-bf3f-588c3ac0737c 4f0c21229c7e4a769db9946481e7a9d9 04954537fa5c495e9f078233e3bb1a0d - default default] Deleted allocations for instance 1e492780-30e4-4655-9d62-d421cb1bab3b
2022-02-23 06:44:18.917 8 INFO nova.compute.claims [req-c99415ae-a351-421e-9e9a-e07f1b7d60cd ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Claim successful on node rack08-server63
2022-02-23 06:44:19.311 8 INFO nova.virt.libvirt.driver [req-c99415ae-a351-421e-9e9a-e07f1b7d60cd ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Creating image
2022-02-23 06:44:20.483 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] VM Resumed (Lifecycle Event)
2022-02-23 06:44:20.490 8 INFO nova.virt.libvirt.driver [-] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Instance spawned successfully.
2022-02-23 06:44:20.551 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:20.552 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] VM Started (Lifecycle Event)
2022-02-23 06:44:20.597 8 INFO nova.compute.manager [req-c99415ae-a351-421e-9e9a-e07f1b7d60cd ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Took 1.29 seconds to spawn the instance on the hypervisor.
2022-02-23 06:44:20.635 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:20.690 8 INFO nova.compute.manager [req-c99415ae-a351-421e-9e9a-e07f1b7d60cd ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Took 1.82 seconds to build instance.
2022-02-23 06:44:21.957 8 INFO nova.virt.libvirt.driver [req-426e9e76-91ce-4c08-bdeb-ccfca4431717 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Ignoring supplied device name: /dev/vdb
2022-02-23 06:44:22.107 8 INFO nova.compute.manager [req-426e9e76-91ce-4c08-bdeb-ccfca4431717 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Attaching volume 7a018ebe-d723-4597-a5f9-59deb9365a2e to /dev/vdb
2022-02-23 06:44:22.193 8 WARNING os_brick.initiator.connectors.nvmeof [req-426e9e76-91ce-4c08-bdeb-ccfca4431717 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:44:23.539 8 INFO os_brick.initiator.connectors.lightos [req-426e9e76-91ce-4c08-bdeb-ccfca4431717 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: connect_volume called for volume ea13244d-9b74-48f8-b76d-b1da879bd78e, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ea13244d-9b74-48f8-b76d-b1da879bd78e', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:44:23.543 8 INFO os_brick.initiator.connectors.lightos [req-426e9e76-91ce-4c08-bdeb-ccfca4431717 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ea13244d-9b74-48f8-b76d-b1da879bd78e
2022-02-23 06:44:23.633 8 INFO nova.compute.manager [-] [instance: 9b905811-40b7-4b1e-afd5-859956f8dad3] VM Stopped (Lifecycle Event)
2022-02-23 06:44:26.128 8 INFO nova.compute.manager [-] [instance: 61133a2b-e12f-400f-a94a-6efd768808bd] VM Stopped (Lifecycle Event)
2022-02-23 06:44:29.380 8 INFO nova.compute.manager [-] [instance: 1e492780-30e4-4655-9d62-d421cb1bab3b] VM Stopped (Lifecycle Event)
2022-02-23 06:44:33.239 8 INFO nova.compute.claims [req-96a6c949-9116-4dad-9d0b-9a46f26b5571 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Claim successful on node rack08-server63
2022-02-23 06:44:33.697 8 INFO nova.virt.libvirt.driver [req-96a6c949-9116-4dad-9d0b-9a46f26b5571 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Creating image
2022-02-23 06:44:34.147 8 INFO nova.compute.manager [req-fb7d390b-6273-4a9b-94c9-9e1b7983007a ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Detaching volume 7a018ebe-d723-4597-a5f9-59deb9365a2e
2022-02-23 06:44:34.210 8 INFO nova.virt.block_device [req-fb7d390b-6273-4a9b-94c9-9e1b7983007a ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Attempting to driver detach volume 7a018ebe-d723-4597-a5f9-59deb9365a2e from mountpoint /dev/vdb
2022-02-23 06:44:34.231 8 INFO nova.virt.libvirt.driver [req-fb7d390b-6273-4a9b-94c9-9e1b7983007a ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Successfully detached device vdb from instance ab7ef835-649f-414c-8e94-1c9e366eda1c from the persistent domain config.
2022-02-23 06:44:34.384 8 INFO nova.virt.libvirt.driver [req-fb7d390b-6273-4a9b-94c9-9e1b7983007a ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Successfully detached device vdb from instance ab7ef835-649f-414c-8e94-1c9e366eda1c from the live domain config.
2022-02-23 06:44:34.387 8 INFO os_brick.initiator.connectors.lightos [req-fb7d390b-6273-4a9b-94c9-9e1b7983007a ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid ea13244d-9b74-48f8-b76d-b1da879bd78e
2022-02-23 06:44:34.816 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] VM Resumed (Lifecycle Event)
2022-02-23 06:44:34.822 8 INFO nova.virt.libvirt.driver [-] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Instance spawned successfully.
2022-02-23 06:44:34.869 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:34.869 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] VM Started (Lifecycle Event)
2022-02-23 06:44:34.924 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:34.937 8 INFO nova.compute.manager [req-96a6c949-9116-4dad-9d0b-9a46f26b5571 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Took 1.24 seconds to spawn the instance on the hypervisor.
2022-02-23 06:44:35.059 8 INFO nova.compute.manager [req-96a6c949-9116-4dad-9d0b-9a46f26b5571 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Took 1.86 seconds to build instance.
2022-02-23 06:44:36.110 8 INFO nova.compute.manager [req-c32b38a3-bab1-4fae-8be9-209ad69c780a 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Terminating instance
2022-02-23 06:44:36.420 8 INFO nova.compute.manager [req-39adb1dc-1b3d-4aa3-a32a-b8742efd2893 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Terminating instance
2022-02-23 06:44:36.447 8 INFO nova.virt.libvirt.driver [-] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Instance destroyed successfully.
2022-02-23 06:44:36.459 8 INFO nova.virt.libvirt.driver [req-c32b38a3-bab1-4fae-8be9-209ad69c780a 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Deleting instance files /var/lib/nova/instances/094c416d-534d-4f8c-9d61-9fca6f7d36f5_del
2022-02-23 06:44:36.459 8 INFO nova.virt.libvirt.driver [req-c32b38a3-bab1-4fae-8be9-209ad69c780a 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Deletion of /var/lib/nova/instances/094c416d-534d-4f8c-9d61-9fca6f7d36f5_del complete
2022-02-23 06:44:36.522 8 INFO nova.compute.manager [req-c32b38a3-bab1-4fae-8be9-209ad69c780a 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:36.583 8 INFO nova.compute.manager [-] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:44:36.791 8 INFO nova.virt.libvirt.driver [-] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Instance destroyed successfully.
2022-02-23 06:44:36.805 8 INFO nova.virt.libvirt.driver [req-39adb1dc-1b3d-4aa3-a32a-b8742efd2893 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Deleting instance files /var/lib/nova/instances/ab7ef835-649f-414c-8e94-1c9e366eda1c_del
2022-02-23 06:44:36.806 8 INFO nova.virt.libvirt.driver [req-39adb1dc-1b3d-4aa3-a32a-b8742efd2893 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Deletion of /var/lib/nova/instances/ab7ef835-649f-414c-8e94-1c9e366eda1c_del complete
2022-02-23 06:44:36.879 8 INFO nova.compute.manager [req-39adb1dc-1b3d-4aa3-a32a-b8742efd2893 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Took 0.33 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:36.905 8 INFO nova.scheduler.client.report [req-c32b38a3-bab1-4fae-8be9-209ad69c780a 84c865b350204eda8902756c5edd09b4 653902e4dbe94a06a48dd5c19bfaacfd - default default] Deleted allocations for instance 094c416d-534d-4f8c-9d61-9fca6f7d36f5
2022-02-23 06:44:36.941 8 INFO nova.compute.manager [-] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] Took 0.06 seconds to deallocate network for instance.
2022-02-23 06:44:37.113 8 INFO nova.scheduler.client.report [req-39adb1dc-1b3d-4aa3-a32a-b8742efd2893 ef3e92cedd4e40bea6c443345b22ba71 93353072bcc44e19947fcf74dc4a4737 - default default] Deleted allocations for instance ab7ef835-649f-414c-8e94-1c9e366eda1c
2022-02-23 06:44:42.192 8 INFO nova.compute.claims [req-56a28d1e-5550-4afc-8d14-b3691cf1b6c0 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Claim successful on node rack08-server63
2022-02-23 06:44:42.583 8 INFO nova.virt.libvirt.driver [req-56a28d1e-5550-4afc-8d14-b3691cf1b6c0 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Creating image
2022-02-23 06:44:43.742 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] VM Resumed (Lifecycle Event)
2022-02-23 06:44:43.750 8 INFO nova.virt.libvirt.driver [-] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Instance spawned successfully.
2022-02-23 06:44:43.810 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:43.811 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] VM Started (Lifecycle Event)
2022-02-23 06:44:43.867 8 INFO nova.compute.manager [req-56a28d1e-5550-4afc-8d14-b3691cf1b6c0 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Took 1.28 seconds to spawn the instance on the hypervisor.
2022-02-23 06:44:43.868 8 INFO nova.compute.manager [req-3356d2fc-6e65-4c37-9760-fa621ff2b64f - - - - -] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-23 06:44:43.961 8 INFO nova.compute.manager [req-56a28d1e-5550-4afc-8d14-b3691cf1b6c0 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Took 1.81 seconds to build instance.
2022-02-23 06:44:45.601 8 INFO nova.virt.libvirt.driver [req-41afb689-7050-4a28-a1b7-411f3308973c 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Ignoring supplied device name: /dev/vdb
2022-02-23 06:44:45.763 8 INFO nova.compute.manager [req-41afb689-7050-4a28-a1b7-411f3308973c 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Attaching volume 5d75d76e-5cc9-451d-8400-1995212be381 to /dev/vdb
2022-02-23 06:44:45.850 8 WARNING os_brick.initiator.connectors.nvmeof [req-41afb689-7050-4a28-a1b7-411f3308973c 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-23 06:44:47.204 8 INFO os_brick.initiator.connectors.lightos [req-41afb689-7050-4a28-a1b7-411f3308973c 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] LIGHTOS: connect_volume called for volume 3ca6459a-6d49-4325-90b7-9677b37fb047, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '3ca6459a-6d49-4325-90b7-9677b37fb047', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-23 06:44:47.209 8 INFO os_brick.initiator.connectors.lightos [req-41afb689-7050-4a28-a1b7-411f3308973c 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 3ca6459a-6d49-4325-90b7-9677b37fb047
2022-02-23 06:44:48.968 8 INFO nova.compute.manager [req-66308028-1a12-4008-bbc4-2065e2c0c66c e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Cinder extended volume 5d75d76e-5cc9-451d-8400-1995212be381; extending it to detect new size
2022-02-23 06:44:49.041 8 INFO os_brick.initiator.connectors.lightos [req-66308028-1a12-4008-bbc4-2065e2c0c66c e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 3ca6459a-6d49-4325-90b7-9677b37fb047
2022-02-23 06:44:49.746 8 INFO nova.compute.manager [req-3e118ba5-d9a0-4a6f-94a9-94eb6e04b615 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Detaching volume 5d75d76e-5cc9-451d-8400-1995212be381
2022-02-23 06:44:49.802 8 INFO nova.virt.block_device [req-3e118ba5-d9a0-4a6f-94a9-94eb6e04b615 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Attempting to driver detach volume 5d75d76e-5cc9-451d-8400-1995212be381 from mountpoint /dev/vdb
2022-02-23 06:44:49.821 8 INFO nova.virt.libvirt.driver [req-3e118ba5-d9a0-4a6f-94a9-94eb6e04b615 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] Successfully detached device vdb from instance ef4c84d9-abfc-4878-99d3-c74792998e3f from the persistent domain config.
2022-02-23 06:44:49.964 8 INFO nova.virt.libvirt.driver [req-3e118ba5-d9a0-4a6f-94a9-94eb6e04b615 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] Successfully detached device vdb from instance ef4c84d9-abfc-4878-99d3-c74792998e3f from the live domain config.
2022-02-23 06:44:49.967 8 INFO os_brick.initiator.connectors.lightos [req-3e118ba5-d9a0-4a6f-94a9-94eb6e04b615 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 3ca6459a-6d49-4325-90b7-9677b37fb047
2022-02-23 06:44:51.444 8 INFO nova.compute.manager [-] [instance: 094c416d-534d-4f8c-9d61-9fca6f7d36f5] VM Stopped (Lifecycle Event)
2022-02-23 06:44:51.776 8 INFO nova.compute.manager [-] [instance: ab7ef835-649f-414c-8e94-1c9e366eda1c] VM Stopped (Lifecycle Event)
2022-02-23 06:44:51.994 8 INFO nova.compute.manager [req-aec42f9e-288c-4e2a-a6bf-7c9cb7d6164e 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Terminating instance
2022-02-23 06:44:52.346 8 INFO nova.virt.libvirt.driver [-] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Instance destroyed successfully.
2022-02-23 06:44:52.362 8 INFO nova.virt.libvirt.driver [req-aec42f9e-288c-4e2a-a6bf-7c9cb7d6164e 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Deleting instance files /var/lib/nova/instances/ef4c84d9-abfc-4878-99d3-c74792998e3f_del
2022-02-23 06:44:52.363 8 INFO nova.virt.libvirt.driver [req-aec42f9e-288c-4e2a-a6bf-7c9cb7d6164e 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Deletion of /var/lib/nova/instances/ef4c84d9-abfc-4878-99d3-c74792998e3f_del complete
2022-02-23 06:44:52.441 8 INFO nova.compute.manager [req-aec42f9e-288c-4e2a-a6bf-7c9cb7d6164e 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Took 0.32 seconds to destroy the instance on the hypervisor.
2022-02-23 06:44:52.514 8 INFO nova.compute.manager [-] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] Took 0.07 seconds to deallocate network for instance.
2022-02-23 06:44:52.710 8 INFO nova.scheduler.client.report [req-aec42f9e-288c-4e2a-a6bf-7c9cb7d6164e 5da0db97005e471e93953352fbb9bfc4 e29532763a0a496b942f9bf8cc286f00 - default default] Deleted allocations for instance ef4c84d9-abfc-4878-99d3-c74792998e3f
2022-02-23 06:45:07.344 8 INFO nova.compute.manager [-] [instance: ef4c84d9-abfc-4878-99d3-c74792998e3f] VM Stopped (Lifecycle Event)
