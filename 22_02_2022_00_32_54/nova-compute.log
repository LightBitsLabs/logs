Build Started 22_02_2022_00_32_54
2022-02-22 02:35:09.951 7 WARNING amqp [-] Received method (60, 30) during closing channel 1. This method will be ignored
2022-02-22 02:35:13.968 7 INFO os_vif [-] Loaded VIF plugins: linux_bridge, noop, ovs
2022-02-22 02:35:14.870 7 INFO nova.virt.driver [req-1328687e-381b-4a73-b6d6-79dd5e5e8d48 - - - - -] Loading compute driver 'libvirt.LibvirtDriver'
2022-02-22 02:35:15.260 7 INFO nova.compute.provider_config [req-1328687e-381b-4a73-b6d6-79dd5e5e8d48 - - - - -] No provider configs found in /etc/nova/provider_config/. If files are present, ensure the Nova process has access.
2022-02-22 02:35:15.282 7 WARNING oslo_config.cfg [req-1328687e-381b-4a73-b6d6-79dd5e5e8d48 - - - - -] Deprecated: Option "api_servers" from group "glance" is deprecated for removal (
Support for image service configuration via standard keystoneauth1 Adapter
options was added in the 17.0.0 Queens release. The api_servers option was
retained temporarily to allow consumers time to cut over to a real load
balancing solution.
).  Its value may be silently ignored in the future.
2022-02-22 02:35:15.305 7 INFO nova.service [-] Starting compute node (version 24.1.0)
2022-02-22 02:35:15.318 7 INFO nova.virt.libvirt.driver [-] Connection event '1' reason 'None'
2022-02-22 02:35:15.352 7 INFO nova.virt.libvirt.host [-] Libvirt host capabilities <capabilities>

  <host>
    <uuid>00d8c757-53fc-e811-906e-0012795d9712</uuid>
    <cpu>
      <arch>x86_64</arch>
      <model>Broadwell-IBRS</model>
      <vendor>Intel</vendor>
      <microcode version='184549438'/>
      <counter name='tsc' frequency='2095147000' scaling='no'/>
      <topology sockets='1' cores='8' threads='2'/>
      <feature name='vme'/>
      <feature name='ds'/>
      <feature name='acpi'/>
      <feature name='ss'/>
      <feature name='ht'/>
      <feature name='tm'/>
      <feature name='pbe'/>
      <feature name='dtes64'/>
      <feature name='monitor'/>
      <feature name='ds_cpl'/>
      <feature name='vmx'/>
      <feature name='smx'/>
      <feature name='est'/>
      <feature name='tm2'/>
      <feature name='xtpr'/>
      <feature name='pdcm'/>
      <feature name='dca'/>
      <feature name='osxsave'/>
      <feature name='f16c'/>
      <feature name='rdrand'/>
      <feature name='arat'/>
      <feature name='tsc_adjust'/>
      <feature name='cmt'/>
      <feature name='intel-pt'/>
      <feature name='md-clear'/>
      <feature name='stibp'/>
      <feature name='ssbd'/>
      <feature name='xsaveopt'/>
      <feature name='mbm_total'/>
      <feature name='mbm_local'/>
      <feature name='pdpe1gb'/>
      <feature name='abm'/>
      <feature name='invtsc'/>
      <pages unit='KiB' size='4'/>
      <pages unit='KiB' size='2048'/>
      <pages unit='KiB' size='1048576'/>
    </cpu>
    <power_management>
      <suspend_mem/>
      <suspend_disk/>
      <suspend_hybrid/>
    </power_management>
    <iommu support='yes'/>
    <migration_features>
      <live/>
      <uri_transports>
        <uri_transport>tcp</uri_transport>
        <uri_transport>rdma</uri_transport>
      </uri_transports>
    </migration_features>
    <topology>
      <cells num='2'>
        <cell id='0'>
          <memory unit='KiB'>32772584</memory>
          <pages unit='KiB' size='4'>8193146</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='10'/>
            <sibling id='1' value='21'/>
          </distances>
          <cpus num='16'>
            <cpu id='0' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='1' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='2' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='3' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='4' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='5' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='6' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='7' socket_id='0' core_id='7' siblings='7,23'/>
            <cpu id='16' socket_id='0' core_id='0' siblings='0,16'/>
            <cpu id='17' socket_id='0' core_id='1' siblings='1,17'/>
            <cpu id='18' socket_id='0' core_id='2' siblings='2,18'/>
            <cpu id='19' socket_id='0' core_id='3' siblings='3,19'/>
            <cpu id='20' socket_id='0' core_id='4' siblings='4,20'/>
            <cpu id='21' socket_id='0' core_id='5' siblings='5,21'/>
            <cpu id='22' socket_id='0' core_id='6' siblings='6,22'/>
            <cpu id='23' socket_id='0' core_id='7' siblings='7,23'/>
          </cpus>
        </cell>
        <cell id='1'>
          <memory unit='KiB'>16511320</memory>
          <pages unit='KiB' size='4'>4127830</pages>
          <pages unit='KiB' size='2048'>0</pages>
          <pages unit='KiB' size='1048576'>0</pages>
          <distances>
            <sibling id='0' value='21'/>
            <sibling id='1' value='10'/>
          </distances>
          <cpus num='16'>
            <cpu id='8' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='9' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='10' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='11' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='12' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='13' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='14' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='15' socket_id='1' core_id='7' siblings='15,31'/>
            <cpu id='24' socket_id='1' core_id='0' siblings='8,24'/>
            <cpu id='25' socket_id='1' core_id='1' siblings='9,25'/>
            <cpu id='26' socket_id='1' core_id='2' siblings='10,26'/>
            <cpu id='27' socket_id='1' core_id='3' siblings='11,27'/>
            <cpu id='28' socket_id='1' core_id='4' siblings='12,28'/>
            <cpu id='29' socket_id='1' core_id='5' siblings='13,29'/>
            <cpu id='30' socket_id='1' core_id='6' siblings='14,30'/>
            <cpu id='31' socket_id='1' core_id='7' siblings='15,31'/>
          </cpus>
        </cell>
      </cells>
    </topology>
    <cache>
      <bank id='0' level='3' type='both' size='20' unit='MiB' cpus='0-7,16-23'/>
      <bank id='1' level='3' type='both' size='20' unit='MiB' cpus='8-15,24-31'/>
    </cache>
    <secmodel>
      <model>none</model>
      <doi>0</doi>
    </secmodel>
    <secmodel>
      <model>dac</model>
      <doi>0</doi>
      <baselabel type='kvm'>+42436:+42436</baselabel>
      <baselabel type='qemu'>+42436:+42436</baselabel>
    </secmodel>
  </host>

  <guest>
    <os_type>hvm</os_type>
    <arch name='alpha'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-alpha</emulator>
      <machine maxCpus='4'>clipper</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv6l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='armv7l'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-arm</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='aarch64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-aarch64</emulator>
      <machine maxCpus='1'>integratorcp</machine>
      <machine maxCpus='1'>versatileab</machine>
      <machine maxCpus='2'>xlnx-versal-virt</machine>
      <machine maxCpus='2'>smdkc210</machine>
      <machine maxCpus='2'>nuri</machine>
      <machine maxCpus='2'>palmetto-bmc</machine>
      <machine maxCpus='1'>microbit</machine>
      <machine maxCpus='512'>sbsa-ref</machine>
      <machine maxCpus='1'>mainstone</machine>
      <machine maxCpus='1'>canon-a1100</machine>
      <machine maxCpus='512'>virt-4.2</machine>
      <machine canonical='virt-4.2' maxCpus='512'>virt</machine>
      <machine maxCpus='1'>terrier</machine>
      <machine maxCpus='1'>n800</machine>
      <machine maxCpus='1'>verdex</machine>
      <machine maxCpus='1'>kzm</machine>
      <machine maxCpus='1'>versatilepb</machine>
      <machine maxCpus='4'>midway</machine>
      <machine maxCpus='255'>virt-2.7</machine>
      <machine maxCpus='1'>emcraft-sf2</machine>
      <machine maxCpus='2'>mcimx7d-sabre</machine>
      <machine maxCpus='4'>highbank</machine>
      <machine maxCpus='1'>imx25-pdk</machine>
      <machine maxCpus='1'>n810</machine>
      <machine maxCpus='255'>virt-2.11</machine>
      <machine maxCpus='4'>realview-pbx-a9</machine>
      <machine maxCpus='1'>tosa</machine>
      <machine maxCpus='1'>sx1-v1</machine>
      <machine maxCpus='2'>swift-bmc</machine>
      <machine maxCpus='4'>raspi3</machine>
      <machine maxCpus='1'>mps2-an511</machine>
      <machine maxCpus='4'>sabrelite</machine>
      <machine maxCpus='2'>musca-a</machine>
      <machine maxCpus='1'>realview-pb-a8</machine>
      <machine maxCpus='1'>akita</machine>
      <machine maxCpus='1'>cubieboard</machine>
      <machine maxCpus='255'>virt-2.9</machine>
      <machine maxCpus='1'>xilinx-zynq-a9</machine>
      <machine maxCpus='512'>virt-3.1</machine>
      <machine maxCpus='4'>vexpress-a15</machine>
      <machine maxCpus='512'>virt-4.1</machine>
      <machine maxCpus='2'>musca-b1</machine>
      <machine maxCpus='2'>mps2-an521</machine>
      <machine maxCpus='1'>realview-eb</machine>
      <machine maxCpus='2'>ast2600-evb</machine>
      <machine maxCpus='1'>cheetah</machine>
      <machine maxCpus='4'>vexpress-a9</machine>
      <machine maxCpus='255'>virt-2.6</machine>
      <machine maxCpus='1'>mps2-an505</machine>
      <machine maxCpus='1'>spitz</machine>
      <machine maxCpus='1'>netduino2</machine>
      <machine maxCpus='1'>lm3s6965evb</machine>
      <machine maxCpus='255'>virt-2.10</machine>
      <machine maxCpus='1'>lm3s811evb</machine>
      <machine maxCpus='6'>xlnx-zcu102</machine>
      <machine maxCpus='1'>z2</machine>
      <machine maxCpus='4'>raspi2</machine>
      <machine maxCpus='1'>connex</machine>
      <machine maxCpus='1'>borzoi</machine>
      <machine maxCpus='1'>mcimx6ul-evk</machine>
      <machine maxCpus='1'>musicpal</machine>
      <machine maxCpus='255'>virt-2.8</machine>
      <machine maxCpus='2'>ast2500-evb</machine>
      <machine maxCpus='512'>virt-3.0</machine>
      <machine maxCpus='1'>sx1</machine>
      <machine maxCpus='4'>realview-eb-mpcore</machine>
      <machine maxCpus='2'>witherspoon-bmc</machine>
      <machine maxCpus='2'>romulus-bmc</machine>
      <machine maxCpus='512'>virt-4.0</machine>
      <machine maxCpus='1'>mps2-an385</machine>
      <machine maxCpus='255'>virt-2.12</machine>
      <machine maxCpus='1'>collie</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='cris'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-cris</emulator>
      <machine maxCpus='1'>axis-dev88</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='i686'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-i386</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <pae/>
      <nonpae/>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='lm32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-lm32</emulator>
      <machine maxCpus='1'>lm32-evr</machine>
      <machine maxCpus='1'>lm32-uclinux</machine>
      <machine maxCpus='1'>milkymist</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='m68k'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-m68k</emulator>
      <machine maxCpus='1'>mcf5208evb</machine>
      <machine maxCpus='1'>an5206</machine>
      <machine maxCpus='1'>q800</machine>
      <machine maxCpus='1'>next-cube</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblaze'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblaze</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='microblazeel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-microblazeel</emulator>
      <machine maxCpus='1'>petalogix-s3adsp1800</machine>
      <machine maxCpus='1'>petalogix-ml605</machine>
      <machine maxCpus='1'>xlnx-zynqmp-pmu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mips</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mipsel'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-mipsel</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='mips64el'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-mips64el</emulator>
      <machine maxCpus='16'>malta</machine>
      <machine maxCpus='1'>pica61</machine>
      <machine maxCpus='1'>mipssim</machine>
      <machine maxCpus='1'>mips</machine>
      <machine maxCpus='1'>fulong2e</machine>
      <machine maxCpus='16'>boston</machine>
      <machine maxCpus='1'>magnum</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-ppc</emulator>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1'>taihu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='ppc64le'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-ppc64le</emulator>
      <machine maxCpus='1024'>pseries-focal</machine>
      <machine canonical='pseries-focal' maxCpus='1024'>pseries</machine>
      <machine maxCpus='2048'>powernv9</machine>
      <machine canonical='powernv9' maxCpus='2048'>powernv</machine>
      <machine maxCpus='1'>taihu</machine>
      <machine maxCpus='1024'>pseries-4.1</machine>
      <machine maxCpus='15'>mpc8544ds</machine>
      <machine maxCpus='1024'>pseries-2.5</machine>
      <machine maxCpus='1024'>pseries-xenial</machine>
      <machine maxCpus='1024'>pseries-4.2</machine>
      <machine maxCpus='1024'>pseries-yakkety</machine>
      <machine maxCpus='1024'>pseries-2.6</machine>
      <machine maxCpus='32'>ppce500</machine>
      <machine maxCpus='1024'>pseries-bionic-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.7</machine>
      <machine maxCpus='1024'>pseries-3.0</machine>
      <machine maxCpus='1'>40p</machine>
      <machine maxCpus='1024'>pseries-2.8</machine>
      <machine maxCpus='1024'>pseries-3.1</machine>
      <machine maxCpus='1024'>pseries-eoan</machine>
      <machine maxCpus='1024'>pseries-2.9</machine>
      <machine maxCpus='1024'>pseries-zesty</machine>
      <machine maxCpus='1'>bamboo</machine>
      <machine maxCpus='1'>g3beige</machine>
      <machine maxCpus='1024'>pseries-disco</machine>
      <machine maxCpus='1024'>pseries-2.12-sxxm</machine>
      <machine maxCpus='1024'>pseries-2.10</machine>
      <machine maxCpus='1'>virtex-ml507</machine>
      <machine maxCpus='1024'>pseries-2.11</machine>
      <machine maxCpus='1024'>pseries-2.1</machine>
      <machine maxCpus='1024'>pseries-cosmic</machine>
      <machine maxCpus='1024'>pseries-bionic</machine>
      <machine maxCpus='1024'>pseries-2.12</machine>
      <machine maxCpus='1024'>pseries-2.2</machine>
      <machine maxCpus='1'>mac99</machine>
      <machine maxCpus='1024'>pseries-artful</machine>
      <machine maxCpus='1'>sam460ex</machine>
      <machine maxCpus='1'>ref405ep</machine>
      <machine maxCpus='1024'>pseries-2.3</machine>
      <machine maxCpus='2048'>powernv8</machine>
      <machine maxCpus='1024'>pseries-4.0</machine>
      <machine maxCpus='1'>prep</machine>
      <machine maxCpus='1024'>pseries-2.4</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-riscv32</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='riscv64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-riscv64</emulator>
      <machine maxCpus='1'>spike_v1.10</machine>
      <machine maxCpus='8'>virt</machine>
      <machine maxCpus='1'>spike</machine>
      <machine maxCpus='1'>sifive_e</machine>
      <machine maxCpus='5'>sifive_u</machine>
      <machine maxCpus='1'>spike_v1.9.1</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='s390x'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-s390x</emulator>
      <machine maxCpus='248'>s390-ccw-virtio-focal</machine>
      <machine canonical='s390-ccw-virtio-focal' maxCpus='248'>s390-ccw-virtio</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-artful</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.6</machine>
      <machine maxCpus='248'>s390-ccw-virtio-disco</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.12</machine>
      <machine maxCpus='248'>s390-ccw-virtio-yakkety</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.9</machine>
      <machine maxCpus='248'>s390-ccw-virtio-eoan</machine>
      <machine maxCpus='248'>s390-ccw-virtio-3.0</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.2</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.5</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.11</machine>
      <machine maxCpus='248'>s390-ccw-virtio-xenial</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.8</machine>
      <machine maxCpus='248'>s390-ccw-virtio-bionic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-zesty</machine>
      <machine maxCpus='248'>s390-ccw-virtio-4.1</machine>
      <machine maxCpus='248'>s390-ccw-virtio-cosmic</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.4</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.10</machine>
      <machine maxCpus='248'>s390-ccw-virtio-2.7</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sh4</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sh4eb'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sh4eb</emulator>
      <machine maxCpus='1'>shix</machine>
      <machine maxCpus='1'>r2d</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-sparc</emulator>
      <machine maxCpus='1'>SS-5</machine>
      <machine maxCpus='4'>SS-20</machine>
      <machine maxCpus='1'>LX</machine>
      <machine maxCpus='1'>SPARCClassic</machine>
      <machine maxCpus='1'>leon3_generic</machine>
      <machine maxCpus='1'>SPARCbook</machine>
      <machine maxCpus='1'>SS-4</machine>
      <machine maxCpus='4'>SS-600MP</machine>
      <machine maxCpus='4'>SS-10</machine>
      <machine maxCpus='1'>Voyager</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='sparc64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-sparc64</emulator>
      <machine maxCpus='1'>sun4u</machine>
      <machine maxCpus='1'>niagara</machine>
      <machine maxCpus='1'>sun4v</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='unicore32'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-unicore32</emulator>
      <machine maxCpus='1'>puv3</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='x86_64'>
      <wordsize>64</wordsize>
      <emulator>/usr/bin/qemu-system-x86_64</emulator>
      <machine maxCpus='255'>pc-i440fx-focal</machine>
      <machine canonical='pc-i440fx-focal' maxCpus='255'>ubuntu</machine>
      <machine maxCpus='255'>pc-0.15</machine>
      <machine maxCpus='255'>pc-i440fx-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-2.0</machine>
      <machine maxCpus='255'>pc-i440fx-xenial</machine>
      <machine maxCpus='288'>pc-q35-4.2</machine>
      <machine canonical='pc-q35-4.2' maxCpus='288'>q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-4.2</machine>
      <machine canonical='pc-i440fx-4.2' maxCpus='255'>pc</machine>
      <machine maxCpus='255'>pc-q35-xenial</machine>
      <machine maxCpus='255'>pc-i440fx-1.5</machine>
      <machine maxCpus='255'>pc-q35-2.7</machine>
      <machine maxCpus='255'>pc-0.12</machine>
      <machine maxCpus='288'>pc-q35-eoan-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-zesty</machine>
      <machine maxCpus='255'>pc-i440fx-disco-hpb</machine>
      <machine maxCpus='288'>pc-q35-artful</machine>
      <machine maxCpus='255'>pc-i440fx-trusty</machine>
      <machine maxCpus='255'>pc-i440fx-2.2</machine>
      <machine maxCpus='255'>pc-i440fx-eoan-hpb</machine>
      <machine maxCpus='288'>pc-q35-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.1</machine>
      <machine maxCpus='288'>pc-q35-bionic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-artful</machine>
      <machine maxCpus='255'>pc-i440fx-2.7</machine>
      <machine maxCpus='255'>pc-i440fx-yakkety</machine>
      <machine maxCpus='255'>pc-q35-2.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic-hpb</machine>
      <machine maxCpus='288'>pc-q35-2.10</machine>
      <machine maxCpus='255'>pc-i440fx-1.7</machine>
      <machine maxCpus='255'>pc-0.14</machine>
      <machine maxCpus='288'>pc-q35-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-2.11</machine>
      <machine maxCpus='288'>pc-q35-3.1</machine>
      <machine maxCpus='288'>pc-q35-4.1</machine>
      <machine maxCpus='255'>pc-i440fx-2.4</machine>
      <machine maxCpus='255'>pc-1.3</machine>
      <machine maxCpus='255'>pc-i440fx-4.1</machine>
      <machine maxCpus='288'>pc-q35-eoan</machine>
      <machine maxCpus='255'>pc-i440fx-2.9</machine>
      <machine maxCpus='255'>pc-i440fx-bionic-hpb</machine>
      <machine maxCpus='1'>isapc</machine>
      <machine maxCpus='255'>pc-i440fx-1.4</machine>
      <machine maxCpus='288'>pc-q35-cosmic</machine>
      <machine maxCpus='255'>pc-q35-2.6</machine>
      <machine maxCpus='288'>pc-q35-bionic</machine>
      <machine maxCpus='255'>pc-i440fx-3.1</machine>
      <machine maxCpus='288'>pc-q35-disco-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic</machine>
      <machine maxCpus='288'>pc-q35-2.12</machine>
      <machine maxCpus='255'>pc-i440fx-bionic</machine>
      <machine maxCpus='288'>pc-q35-disco</machine>
      <machine maxCpus='255'>pc-i440fx-cosmic-hpb</machine>
      <machine maxCpus='255'>pc-i440fx-2.1</machine>
      <machine maxCpus='255'>pc-1.0</machine>
      <machine maxCpus='255'>pc-i440fx-wily</machine>
      <machine maxCpus='255'>pc-i440fx-2.6</machine>
      <machine maxCpus='288'>pc-q35-4.0.1</machine>
      <machine maxCpus='255'>pc-i440fx-1.6</machine>
      <machine maxCpus='255'>pc-0.13</machine>
      <machine maxCpus='288'>pc-q35-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-2.10</machine>
      <machine maxCpus='288'>pc-q35-3.0</machine>
      <machine maxCpus='288'>pc-q35-zesty</machine>
      <machine maxCpus='288'>pc-q35-4.0</machine>
      <machine maxCpus='288'>microvm</machine>
      <machine maxCpus='288'>pc-q35-focal</machine>
      <machine canonical='pc-q35-focal' maxCpus='288'>ubuntu-q35</machine>
      <machine maxCpus='255'>pc-i440fx-2.3</machine>
      <machine maxCpus='255'>pc-i440fx-focal-hpb</machine>
      <machine maxCpus='255'>pc-1.2</machine>
      <machine maxCpus='255'>pc-i440fx-4.0</machine>
      <machine maxCpus='255'>pc-i440fx-disco</machine>
      <machine maxCpus='255'>pc-i440fx-2.8</machine>
      <machine maxCpus='255'>pc-i440fx-eoan</machine>
      <machine maxCpus='255'>pc-q35-2.5</machine>
      <machine maxCpus='255'>pc-i440fx-3.0</machine>
      <machine maxCpus='255'>pc-q35-yakkety</machine>
      <machine maxCpus='288'>pc-q35-2.11</machine>
      <domain type='qemu'/>
      <domain type='kvm'/>
    </arch>
    <features>
      <acpi default='on' toggle='yes'/>
      <apic default='on' toggle='no'/>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensa'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensa</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

  <guest>
    <os_type>hvm</os_type>
    <arch name='xtensaeb'>
      <wordsize>32</wordsize>
      <emulator>/usr/bin/qemu-system-xtensaeb</emulator>
      <machine maxCpus='4'>sim</machine>
      <machine maxCpus='32'>kc705</machine>
      <machine maxCpus='32'>ml605</machine>
      <machine maxCpus='32'>ml605-nommu</machine>
      <machine maxCpus='32'>virt</machine>
      <machine maxCpus='32'>lx60-nommu</machine>
      <machine maxCpus='32'>lx200</machine>
      <machine maxCpus='32'>lx200-nommu</machine>
      <machine maxCpus='32'>lx60</machine>
      <machine maxCpus='32'>kc705-nommu</machine>
      <domain type='qemu'/>
    </arch>
    <features>
      <cpuselection/>
      <deviceboot/>
      <disksnapshot default='on' toggle='no'/>
    </features>
  </guest>

</capabilities>

2022-02-22 02:35:15.449 7 INFO nova.virt.libvirt.host [-] Secure Boot support detected
2022-02-22 02:35:15.464 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a libvirt version less than 7.0.0 is deprecated. The required minimum version of libvirt will be raised to 7.0.0 in the next release.
2022-02-22 02:35:15.466 7 WARNING nova.virt.libvirt.driver [-] Running Nova with a QEMU version less than 5.2.0 is deprecated. The required minimum version of QEMU will be raised to 5.2.0 in the next release.
2022-02-22 02:35:15.868 7 INFO nova.compute.manager [req-b364fc33-19d5-4b9a-afaa-ccc13ac6398f - - - - -] Looking for unclaimed instances stuck in BUILDING status for nodes managed by this host
2022-02-22 02:35:17.700 7 INFO nova.virt.libvirt.host [req-b364fc33-19d5-4b9a-afaa-ccc13ac6398f - - - - -] kernel doesn't support AMD SEV
2022-02-22 02:36:11.431 7 INFO nova.compute.claims [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Claim successful on node rack08-server63
2022-02-22 02:36:11.852 7 INFO nova.virt.libvirt.driver [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Creating image
2022-02-22 02:36:11.856 7 INFO oslo.privsep.daemon [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Running privsep helper: ['sudo', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'nova.privsep.sys_admin_pctxt', '--privsep_sock_path', '/tmp/tmp2xj4yeb7/privsep.sock']
2022-02-22 02:36:13.513 7 INFO oslo.privsep.daemon [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Spawned new privsep daemon via rootwrap
2022-02-22 02:36:13.362 81 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 02:36:13.368 81 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 02:36:13.373 81 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/CAP_CHOWN|CAP_DAC_OVERRIDE|CAP_DAC_READ_SEARCH|CAP_FOWNER|CAP_NET_ADMIN|CAP_SYS_ADMIN/none
2022-02-22 02:36:13.373 81 INFO oslo.privsep.daemon [-] privsep daemon running as pid 81
2022-02-22 02:36:14.794 7 INFO nova.compute.manager [-] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] VM Resumed (Lifecycle Event)
2022-02-22 02:36:14.801 7 INFO nova.virt.libvirt.driver [-] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Instance spawned successfully.
2022-02-22 02:36:14.801 7 INFO nova.compute.manager [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Took 2.95 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:14.849 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:14.849 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] VM Started (Lifecycle Event)
2022-02-22 02:36:14.887 7 INFO nova.compute.manager [req-8c48a70f-088b-47dd-864f-a39cf56dec2c c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Took 3.50 seconds to build instance.
2022-02-22 02:36:17.175 7 INFO nova.compute.manager [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Attaching volume 8685040f-1218-4e82-be75-acd9b181dd57 to /dev/vdb
2022-02-22 02:36:17.250 7 INFO oslo.privsep.daemon [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Running privsep helper: ['sudo', '-E', 'nova-rootwrap', '/etc/nova/rootwrap.conf', 'privsep-helper', '--config-file', '/etc/nova/nova.conf', '--privsep_context', 'os_brick.privileged.default', '--privsep_sock_path', '/tmp/tmpxjmsmujd/privsep.sock']
2022-02-22 02:36:17.911 7 INFO oslo.privsep.daemon [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Spawned new privsep daemon via rootwrap
2022-02-22 02:36:17.829 120 INFO oslo.privsep.daemon [-] privsep daemon starting
2022-02-22 02:36:17.836 120 INFO oslo.privsep.daemon [-] privsep process running with uid/gid: 0/0
2022-02-22 02:36:17.841 120 INFO oslo.privsep.daemon [-] privsep process running with capabilities (eff/prm/inh): CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/CAP_DAC_READ_SEARCH|CAP_SYS_ADMIN/none
2022-02-22 02:36:17.841 120 INFO oslo.privsep.daemon [-] privsep daemon running as pid 120
2022-02-22 02:36:18.235 7 WARNING os_brick.initiator.connectors.nvmeof [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:19.628 7 INFO os_brick.initiator.connectors.lightos [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: connect_volume called for volume 6057fc0b-befa-4916-9bb9-0300291ce8ef, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '6057fc0b-befa-4916-9bb9-0300291ce8ef', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:36:19.664 7 INFO os_brick.initiator.connectors.lightos [req-48835cf9-a142-4db4-8106-6590f02d59f6 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6057fc0b-befa-4916-9bb9-0300291ce8ef
2022-02-22 02:36:21.829 7 INFO nova.compute.claims [req-b3c98cf9-116c-4120-90e5-96db85fa4961 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Claim successful on node rack08-server63
2022-02-22 02:36:22.231 7 INFO nova.virt.libvirt.driver [req-b3c98cf9-116c-4120-90e5-96db85fa4961 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Creating image
2022-02-22 02:36:23.403 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8aef0838-56ff-428c-a385-191538b6624b] VM Resumed (Lifecycle Event)
2022-02-22 02:36:23.411 7 INFO nova.virt.libvirt.driver [-] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Instance spawned successfully.
2022-02-22 02:36:23.412 7 INFO nova.compute.manager [req-b3c98cf9-116c-4120-90e5-96db85fa4961 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Took 1.18 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:23.462 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8aef0838-56ff-428c-a385-191538b6624b] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:23.463 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8aef0838-56ff-428c-a385-191538b6624b] VM Started (Lifecycle Event)
2022-02-22 02:36:23.498 7 INFO nova.compute.manager [req-b3c98cf9-116c-4120-90e5-96db85fa4961 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Took 1.71 seconds to build instance.
2022-02-22 02:36:24.965 7 INFO nova.compute.manager [req-da99b62f-6f39-4ca5-a989-ba78e1614ce5 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Detaching volume 8685040f-1218-4e82-be75-acd9b181dd57
2022-02-22 02:36:25.024 7 INFO nova.virt.block_device [req-da99b62f-6f39-4ca5-a989-ba78e1614ce5 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Attempting to driver detach volume 8685040f-1218-4e82-be75-acd9b181dd57 from mountpoint /dev/vdb
2022-02-22 02:36:25.042 7 INFO nova.virt.libvirt.driver [req-da99b62f-6f39-4ca5-a989-ba78e1614ce5 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance e3400ece-8bae-4875-a9ea-f1107c8eb926 from the persistent domain config.
2022-02-22 02:36:25.183 7 INFO nova.virt.libvirt.driver [req-da99b62f-6f39-4ca5-a989-ba78e1614ce5 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance e3400ece-8bae-4875-a9ea-f1107c8eb926 from the live domain config.
2022-02-22 02:36:25.186 7 INFO os_brick.initiator.connectors.lightos [req-da99b62f-6f39-4ca5-a989-ba78e1614ce5 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 6057fc0b-befa-4916-9bb9-0300291ce8ef
2022-02-22 02:36:27.639 7 INFO nova.compute.claims [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Claim successful on node rack08-server63
2022-02-22 02:36:27.905 7 INFO nova.virt.libvirt.driver [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 02:36:27.991 7 INFO nova.virt.block_device [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Booting with volume 9d14022c-d5cd-477a-8b32-583d54ccbc5a at /dev/vda
2022-02-22 02:36:28.075 7 WARNING os_brick.initiator.connectors.nvmeof [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:28.397 7 INFO nova.compute.claims [req-557325b7-77cc-415a-9757-a97d0ce3d28d c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Claim successful on node rack08-server63
2022-02-22 02:36:28.791 7 INFO nova.virt.libvirt.driver [req-557325b7-77cc-415a-9757-a97d0ce3d28d c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Creating image
2022-02-22 02:36:29.598 7 INFO nova.virt.libvirt.driver [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Creating image
2022-02-22 02:36:29.607 7 INFO os_brick.initiator.connectors.lightos [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: connect_volume called for volume 74ba102a-f6ab-4989-bf35-e35a69a69125, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '74ba102a-f6ab-4989-bf35-e35a69a69125', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:36:29.610 7 INFO os_brick.initiator.connectors.lightos [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 74ba102a-f6ab-4989-bf35-e35a69a69125
2022-02-22 02:36:30.047 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] VM Resumed (Lifecycle Event)
2022-02-22 02:36:30.055 7 INFO nova.virt.libvirt.driver [-] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Instance spawned successfully.
2022-02-22 02:36:30.055 7 INFO nova.compute.manager [req-557325b7-77cc-415a-9757-a97d0ce3d28d c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Took 1.27 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:30.098 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:30.099 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] VM Started (Lifecycle Event)
2022-02-22 02:36:30.141 7 INFO nova.compute.manager [req-557325b7-77cc-415a-9757-a97d0ce3d28d c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Took 1.78 seconds to build instance.
2022-02-22 02:36:30.458 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] VM Resumed (Lifecycle Event)
2022-02-22 02:36:30.465 7 INFO nova.virt.libvirt.driver [-] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Instance spawned successfully.
2022-02-22 02:36:30.465 7 INFO nova.compute.manager [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Took 0.87 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:30.511 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:30.512 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] VM Started (Lifecycle Event)
2022-02-22 02:36:30.550 7 INFO nova.compute.manager [req-80ccccca-498e-46e2-9432-15082cf5d247 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Took 2.95 seconds to build instance.
2022-02-22 02:36:32.801 7 INFO nova.compute.claims [req-a28c913e-1e91-4ab9-824c-cec2807eb286 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Claim successful on node rack08-server63
2022-02-22 02:36:33.204 7 INFO nova.virt.libvirt.driver [req-a28c913e-1e91-4ab9-824c-cec2807eb286 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Creating image
2022-02-22 02:36:33.331 7 INFO nova.compute.claims [req-578ec688-1275-4bb0-86f2-bec5d42ea4f5 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Claim successful on node rack08-server63
2022-02-22 02:36:33.707 7 INFO nova.virt.libvirt.driver [req-578ec688-1275-4bb0-86f2-bec5d42ea4f5 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Creating image
2022-02-22 02:36:34.042 7 INFO nova.compute.manager [req-a171654b-37c9-4e73-a920-5a04da9c6401 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Attaching volume 4a08657f-076e-4fd4-842b-093782d90567 to /dev/vdb
2022-02-22 02:36:34.133 7 WARNING os_brick.initiator.connectors.nvmeof [req-a171654b-37c9-4e73-a920-5a04da9c6401 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:34.380 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] VM Resumed (Lifecycle Event)
2022-02-22 02:36:34.390 7 INFO nova.virt.libvirt.driver [-] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Instance spawned successfully.
2022-02-22 02:36:34.390 7 INFO nova.compute.manager [req-a28c913e-1e91-4ab9-824c-cec2807eb286 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:34.438 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:34.438 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] VM Started (Lifecycle Event)
2022-02-22 02:36:34.476 7 INFO nova.compute.manager [req-a28c913e-1e91-4ab9-824c-cec2807eb286 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Took 1.72 seconds to build instance.
2022-02-22 02:36:34.922 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] VM Resumed (Lifecycle Event)
2022-02-22 02:36:34.929 7 INFO nova.virt.libvirt.driver [-] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Instance spawned successfully.
2022-02-22 02:36:34.930 7 INFO nova.compute.manager [req-578ec688-1275-4bb0-86f2-bec5d42ea4f5 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Took 1.22 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:34.980 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:34.980 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] VM Started (Lifecycle Event)
2022-02-22 02:36:35.015 7 INFO nova.compute.manager [req-578ec688-1275-4bb0-86f2-bec5d42ea4f5 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Took 1.72 seconds to build instance.
2022-02-22 02:36:35.489 7 INFO os_brick.initiator.connectors.lightos [req-a171654b-37c9-4e73-a920-5a04da9c6401 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: connect_volume called for volume 28876f27-06e3-480b-b15c-ba9428fb70df, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '28876f27-06e3-480b-b15c-ba9428fb70df', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:36:35.493 7 INFO os_brick.initiator.connectors.lightos [req-a171654b-37c9-4e73-a920-5a04da9c6401 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 28876f27-06e3-480b-b15c-ba9428fb70df
2022-02-22 02:36:36.638 7 INFO nova.compute.manager [req-d9a45438-ee99-4348-81e4-50c19da30baa c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Detaching volume 4a08657f-076e-4fd4-842b-093782d90567
2022-02-22 02:36:36.704 7 INFO nova.virt.block_device [req-d9a45438-ee99-4348-81e4-50c19da30baa c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Attempting to driver detach volume 4a08657f-076e-4fd4-842b-093782d90567 from mountpoint /dev/vdb
2022-02-22 02:36:36.725 7 INFO nova.virt.libvirt.driver [req-d9a45438-ee99-4348-81e4-50c19da30baa c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance 0fd88239-06fc-46da-89b6-ca10020de9e9 from the persistent domain config.
2022-02-22 02:36:36.870 7 INFO nova.virt.libvirt.driver [req-d9a45438-ee99-4348-81e4-50c19da30baa c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance 0fd88239-06fc-46da-89b6-ca10020de9e9 from the live domain config.
2022-02-22 02:36:36.873 7 INFO os_brick.initiator.connectors.lightos [req-d9a45438-ee99-4348-81e4-50c19da30baa c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 28876f27-06e3-480b-b15c-ba9428fb70df
2022-02-22 02:36:37.069 7 INFO nova.compute.manager [req-ff975bbe-83da-436c-99c3-d00a3d773c6f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Attaching volume b283de4e-f0ce-4373-9352-02fb42c0b9d5 to /dev/vdb
2022-02-22 02:36:37.162 7 WARNING os_brick.initiator.connectors.nvmeof [req-ff975bbe-83da-436c-99c3-d00a3d773c6f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:38.513 7 INFO os_brick.initiator.connectors.lightos [req-ff975bbe-83da-436c-99c3-d00a3d773c6f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: connect_volume called for volume 3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:36:38.517 7 INFO os_brick.initiator.connectors.lightos [req-ff975bbe-83da-436c-99c3-d00a3d773c6f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff
2022-02-22 02:36:39.540 7 INFO nova.compute.manager [req-32c74526-2cc1-45ad-925b-99315ed7f79e e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Attaching volume b283de4e-f0ce-4373-9352-02fb42c0b9d5 to /dev/vdb
2022-02-22 02:36:39.627 7 WARNING os_brick.initiator.connectors.nvmeof [req-32c74526-2cc1-45ad-925b-99315ed7f79e e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:39.974 7 INFO nova.compute.claims [req-267945f9-9645-4224-9482-aad2a7411695 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Claim successful on node rack08-server63
2022-02-22 02:36:40.372 7 INFO nova.virt.libvirt.driver [req-267945f9-9645-4224-9482-aad2a7411695 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Creating image
2022-02-22 02:36:41.017 7 INFO os_brick.initiator.connectors.lightos [req-32c74526-2cc1-45ad-925b-99315ed7f79e e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: connect_volume called for volume 3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:36:41.019 7 INFO os_brick.initiator.connectors.lightos [req-32c74526-2cc1-45ad-925b-99315ed7f79e e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid 3b8fb0d5-3e04-41c5-8e4c-57dfe287c2ff
2022-02-22 02:36:41.572 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] VM Resumed (Lifecycle Event)
2022-02-22 02:36:41.580 7 INFO nova.virt.libvirt.driver [-] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Instance spawned successfully.
2022-02-22 02:36:41.581 7 INFO nova.compute.manager [req-267945f9-9645-4224-9482-aad2a7411695 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Took 1.21 seconds to spawn the instance on the hypervisor.
2022-02-22 02:36:41.631 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:36:41.632 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] VM Started (Lifecycle Event)
2022-02-22 02:36:41.669 7 INFO nova.compute.manager [req-267945f9-9645-4224-9482-aad2a7411695 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Took 1.74 seconds to build instance.
2022-02-22 02:36:42.116 7 INFO nova.compute.manager [req-53581946-192c-483f-a764-93611f11c22f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Detaching volume b283de4e-f0ce-4373-9352-02fb42c0b9d5
2022-02-22 02:36:42.182 7 INFO nova.virt.block_device [req-53581946-192c-483f-a764-93611f11c22f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Attempting to driver detach volume b283de4e-f0ce-4373-9352-02fb42c0b9d5 from mountpoint /dev/vdb
2022-02-22 02:36:42.199 7 INFO nova.virt.libvirt.driver [req-53581946-192c-483f-a764-93611f11c22f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Successfully detached device vdb from instance 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa from the persistent domain config.
2022-02-22 02:36:42.351 7 INFO nova.virt.libvirt.driver [req-53581946-192c-483f-a764-93611f11c22f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Successfully detached device vdb from instance 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa from the live domain config.
2022-02-22 02:36:42.423 7 INFO nova.virt.libvirt.driver [req-53581946-192c-483f-a764-93611f11c22f e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Detected multiple connections on this host for volume: b283de4e-f0ce-4373-9352-02fb42c0b9d5, skipping target disconnect.
2022-02-22 02:36:44.535 7 INFO nova.compute.manager [req-5e5424ac-0f93-4559-892d-1f394085ea44 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Attaching volume f310483b-0098-4be0-a323-e3c01507d55d to /dev/vdb
2022-02-22 02:36:44.612 7 INFO nova.compute.manager [req-90bf37bf-5090-41a0-b0cf-9b62f7cebb40 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Detaching volume b283de4e-f0ce-4373-9352-02fb42c0b9d5
2022-02-22 02:36:44.626 7 WARNING os_brick.initiator.connectors.nvmeof [req-5e5424ac-0f93-4559-892d-1f394085ea44 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:36:44.671 7 INFO nova.virt.block_device [req-90bf37bf-5090-41a0-b0cf-9b62f7cebb40 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Attempting to driver detach volume b283de4e-f0ce-4373-9352-02fb42c0b9d5 from mountpoint /dev/vdb
2022-02-22 02:36:44.689 7 INFO nova.virt.libvirt.driver [req-90bf37bf-5090-41a0-b0cf-9b62f7cebb40 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Successfully detached device vdb from instance 4b09628c-16b1-4b91-8a90-f53582504e65 from the persistent domain config.
2022-02-22 02:36:44.863 7 INFO nova.virt.libvirt.driver [req-90bf37bf-5090-41a0-b0cf-9b62f7cebb40 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Successfully detached device vdb from instance 4b09628c-16b1-4b91-8a90-f53582504e65 from the live domain config.
2022-02-22 02:37:45.241 7 INFO os_brick.initiator.connectors.lightos [req-5e5424ac-0f93-4559-892d-1f394085ea44 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: connect_volume called for volume ddda4bbc-18fd-4919-880d-76290f1d9339, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'ddda4bbc-18fd-4919-880d-76290f1d9339', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:37:45.245 7 INFO os_brick.initiator.connectors.lightos [req-5e5424ac-0f93-4559-892d-1f394085ea44 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ddda4bbc-18fd-4919-880d-76290f1d9339
2022-02-22 02:37:46.389 7 INFO nova.compute.manager [req-498b1fd2-cdd1-40d4-b046-003d5cd49c99 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Detaching volume f310483b-0098-4be0-a323-e3c01507d55d
2022-02-22 02:37:46.452 7 INFO nova.virt.block_device [req-498b1fd2-cdd1-40d4-b046-003d5cd49c99 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Attempting to driver detach volume f310483b-0098-4be0-a323-e3c01507d55d from mountpoint /dev/vdb
2022-02-22 02:37:46.470 7 INFO nova.virt.libvirt.driver [req-498b1fd2-cdd1-40d4-b046-003d5cd49c99 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac from the persistent domain config.
2022-02-22 02:37:46.620 7 INFO nova.virt.libvirt.driver [req-498b1fd2-cdd1-40d4-b046-003d5cd49c99 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Successfully detached device vdb from instance 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac from the live domain config.
2022-02-22 02:37:46.624 7 INFO os_brick.initiator.connectors.lightos [req-498b1fd2-cdd1-40d4-b046-003d5cd49c99 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid ddda4bbc-18fd-4919-880d-76290f1d9339
2022-02-22 02:37:49.838 7 INFO nova.compute.manager [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Terminating instance
2022-02-22 02:37:50.181 7 INFO nova.virt.libvirt.driver [-] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Instance destroyed successfully.
2022-02-22 02:37:50.196 7 INFO nova.virt.libvirt.driver [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Deleting instance files /var/lib/nova/instances/2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac_del
2022-02-22 02:37:50.198 7 INFO nova.virt.libvirt.driver [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Deletion of /var/lib/nova/instances/2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac_del complete
2022-02-22 02:37:50.262 7 INFO nova.virt.libvirt.host [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] UEFI support detected
2022-02-22 02:37:50.265 7 INFO nova.compute.manager [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:37:50.335 7 INFO nova.compute.manager [-] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:37:50.515 7 INFO nova.scheduler.client.report [req-c8e0b839-a8c5-4e7b-9701-cef21015b9f1 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Deleted allocations for instance 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac
2022-02-22 02:37:52.223 7 INFO nova.compute.manager [req-9cdc4300-b700-47e4-ab33-1aed55350455 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Terminating instance
2022-02-22 02:37:52.569 7 INFO nova.virt.libvirt.driver [-] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Instance destroyed successfully.
2022-02-22 02:37:52.583 7 INFO nova.virt.libvirt.driver [req-9cdc4300-b700-47e4-ab33-1aed55350455 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Deleting instance files /var/lib/nova/instances/0fd88239-06fc-46da-89b6-ca10020de9e9_del
2022-02-22 02:37:52.585 7 INFO nova.virt.libvirt.driver [req-9cdc4300-b700-47e4-ab33-1aed55350455 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Deletion of /var/lib/nova/instances/0fd88239-06fc-46da-89b6-ca10020de9e9_del complete
2022-02-22 02:37:52.657 7 INFO nova.compute.manager [req-9cdc4300-b700-47e4-ab33-1aed55350455 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:37:52.721 7 INFO nova.compute.manager [-] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:37:52.915 7 INFO nova.scheduler.client.report [req-9cdc4300-b700-47e4-ab33-1aed55350455 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Deleted allocations for instance 0fd88239-06fc-46da-89b6-ca10020de9e9
2022-02-22 02:37:53.476 7 INFO nova.compute.manager [req-87fe6115-2a8d-4813-b665-98f1a379e9c7 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Terminating instance
2022-02-22 02:37:53.825 7 INFO nova.virt.libvirt.driver [-] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Instance destroyed successfully.
2022-02-22 02:37:53.845 7 INFO nova.virt.libvirt.driver [req-87fe6115-2a8d-4813-b665-98f1a379e9c7 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Deleting instance files /var/lib/nova/instances/8aef0838-56ff-428c-a385-191538b6624b_del
2022-02-22 02:37:53.846 7 INFO nova.virt.libvirt.driver [req-87fe6115-2a8d-4813-b665-98f1a379e9c7 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Deletion of /var/lib/nova/instances/8aef0838-56ff-428c-a385-191538b6624b_del complete
2022-02-22 02:37:53.908 7 INFO nova.compute.manager [req-87fe6115-2a8d-4813-b665-98f1a379e9c7 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:37:53.973 7 INFO nova.compute.manager [-] [instance: 8aef0838-56ff-428c-a385-191538b6624b] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:37:54.166 7 INFO nova.scheduler.client.report [req-87fe6115-2a8d-4813-b665-98f1a379e9c7 c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Deleted allocations for instance 8aef0838-56ff-428c-a385-191538b6624b
2022-02-22 02:37:55.854 7 INFO nova.compute.manager [req-f30735f9-715b-4db0-81d1-96a7b77463ad c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Terminating instance
2022-02-22 02:37:56.193 7 INFO nova.virt.libvirt.driver [-] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Instance destroyed successfully.
2022-02-22 02:37:56.212 7 INFO nova.virt.libvirt.driver [req-f30735f9-715b-4db0-81d1-96a7b77463ad c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Deleting instance files /var/lib/nova/instances/e3400ece-8bae-4875-a9ea-f1107c8eb926_del
2022-02-22 02:37:56.214 7 INFO nova.virt.libvirt.driver [req-f30735f9-715b-4db0-81d1-96a7b77463ad c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Deletion of /var/lib/nova/instances/e3400ece-8bae-4875-a9ea-f1107c8eb926_del complete
2022-02-22 02:37:56.287 7 INFO nova.compute.manager [req-f30735f9-715b-4db0-81d1-96a7b77463ad c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:37:56.356 7 INFO nova.compute.manager [-] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:37:56.568 7 INFO nova.scheduler.client.report [req-f30735f9-715b-4db0-81d1-96a7b77463ad c1e8c3938e3f4825b22fbc6ef333717e 78757e409e5b47308f4f2d4d4e6559bf - default default] Deleted allocations for instance e3400ece-8bae-4875-a9ea-f1107c8eb926
2022-02-22 02:38:03.761 7 INFO nova.compute.claims [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Claim successful on node rack08-server63
2022-02-22 02:38:04.032 7 INFO nova.virt.libvirt.driver [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Ignoring supplied device name: /dev/vda. Libvirt can't honour user-supplied dev names
2022-02-22 02:38:04.122 7 INFO nova.virt.block_device [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Booting with volume a291a8b4-f881-498f-95bf-01675a1b3948 at /dev/vda
2022-02-22 02:38:04.226 7 WARNING os_brick.initiator.connectors.nvmeof [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:38:05.179 7 INFO nova.compute.manager [-] [instance: 2e186ab9-9ef8-4aa9-90bc-fb9de2d45cac] VM Stopped (Lifecycle Event)
2022-02-22 02:38:05.730 7 INFO nova.virt.libvirt.driver [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Creating image
2022-02-22 02:38:05.742 7 INFO os_brick.initiator.connectors.lightos [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: connect_volume called for volume a1d8f91e-441e-4a7c-9400-5f876891f64f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'a1d8f91e-441e-4a7c-9400-5f876891f64f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:38:05.746 7 INFO os_brick.initiator.connectors.lightos [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a1d8f91e-441e-4a7c-9400-5f876891f64f
2022-02-22 02:38:06.571 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] VM Resumed (Lifecycle Event)
2022-02-22 02:38:06.578 7 INFO nova.virt.libvirt.driver [-] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Instance spawned successfully.
2022-02-22 02:38:06.579 7 INFO nova.compute.manager [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Took 0.85 seconds to spawn the instance on the hypervisor.
2022-02-22 02:38:06.627 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:38:06.627 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] VM Started (Lifecycle Event)
2022-02-22 02:38:06.669 7 INFO nova.compute.manager [req-81d98416-5940-4288-9afa-981493539b34 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Took 2.95 seconds to build instance.
2022-02-22 02:38:07.568 7 INFO nova.compute.manager [-] [instance: 0fd88239-06fc-46da-89b6-ca10020de9e9] VM Stopped (Lifecycle Event)
2022-02-22 02:38:08.823 7 INFO nova.compute.manager [-] [instance: 8aef0838-56ff-428c-a385-191538b6624b] VM Stopped (Lifecycle Event)
2022-02-22 02:38:08.950 7 INFO nova.compute.manager [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Terminating instance
2022-02-22 02:38:09.345 7 INFO nova.virt.libvirt.driver [-] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Instance destroyed successfully.
2022-02-22 02:38:09.413 7 INFO os_brick.initiator.connectors.lightos [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n3 detected for uuid a1d8f91e-441e-4a7c-9400-5f876891f64f
2022-02-22 02:38:09.425 7 INFO nova.virt.libvirt.driver [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Deleting instance files /var/lib/nova/instances/8f5734d8-b982-4bbd-8177-46aee7d00a8d_del
2022-02-22 02:38:09.426 7 INFO nova.virt.libvirt.driver [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Deletion of /var/lib/nova/instances/8f5734d8-b982-4bbd-8177-46aee7d00a8d_del complete
2022-02-22 02:38:09.493 7 INFO nova.compute.manager [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Took 0.36 seconds to destroy the instance on the hypervisor.
2022-02-22 02:38:09.559 7 INFO nova.compute.manager [-] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:38:10.799 7 INFO nova.compute.manager [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 02:38:10.997 7 INFO nova.scheduler.client.report [req-25e9d32f-bc35-4031-900f-c189be0c22dd e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Deleted allocations for instance 8f5734d8-b982-4bbd-8177-46aee7d00a8d
2022-02-22 02:38:11.191 7 INFO nova.compute.manager [-] [instance: e3400ece-8bae-4875-a9ea-f1107c8eb926] VM Stopped (Lifecycle Event)
2022-02-22 02:38:13.922 7 INFO nova.compute.manager [req-bce3cbe2-1911-45c6-8284-dfad86b69866 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Terminating instance
2022-02-22 02:38:14.256 7 INFO nova.virt.libvirt.driver [-] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Instance destroyed successfully.
2022-02-22 02:38:14.271 7 INFO nova.virt.libvirt.driver [req-bce3cbe2-1911-45c6-8284-dfad86b69866 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Deleting instance files /var/lib/nova/instances/4b09628c-16b1-4b91-8a90-f53582504e65_del
2022-02-22 02:38:14.273 7 INFO nova.virt.libvirt.driver [req-bce3cbe2-1911-45c6-8284-dfad86b69866 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Deletion of /var/lib/nova/instances/4b09628c-16b1-4b91-8a90-f53582504e65_del complete
2022-02-22 02:38:14.345 7 INFO nova.compute.manager [req-bce3cbe2-1911-45c6-8284-dfad86b69866 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:38:14.410 7 INFO nova.compute.manager [-] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:38:14.609 7 INFO nova.scheduler.client.report [req-bce3cbe2-1911-45c6-8284-dfad86b69866 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Deleted allocations for instance 4b09628c-16b1-4b91-8a90-f53582504e65
2022-02-22 02:38:15.162 7 INFO nova.compute.manager [req-03416be7-e0ea-4007-aa19-37eb49ce2c28 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Terminating instance
2022-02-22 02:38:15.502 7 INFO nova.virt.libvirt.driver [-] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Instance destroyed successfully.
2022-02-22 02:38:15.521 7 INFO nova.virt.libvirt.driver [req-03416be7-e0ea-4007-aa19-37eb49ce2c28 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Deleting instance files /var/lib/nova/instances/92d00a9e-326b-4210-9fb2-bf3e01e0bdaa_del
2022-02-22 02:38:15.523 7 INFO nova.virt.libvirt.driver [req-03416be7-e0ea-4007-aa19-37eb49ce2c28 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Deletion of /var/lib/nova/instances/92d00a9e-326b-4210-9fb2-bf3e01e0bdaa_del complete
2022-02-22 02:38:15.590 7 INFO nova.compute.manager [req-03416be7-e0ea-4007-aa19-37eb49ce2c28 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:38:15.655 7 INFO nova.compute.manager [-] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:38:15.854 7 INFO nova.scheduler.client.report [req-03416be7-e0ea-4007-aa19-37eb49ce2c28 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Deleted allocations for instance 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa
2022-02-22 02:38:16.406 7 INFO nova.compute.manager [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Terminating instance
2022-02-22 02:38:16.749 7 INFO nova.virt.libvirt.driver [-] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Instance destroyed successfully.
2022-02-22 02:38:16.822 7 INFO os_brick.initiator.connectors.lightos [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 74ba102a-f6ab-4989-bf35-e35a69a69125
2022-02-22 02:38:16.834 7 INFO nova.virt.libvirt.driver [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Deleting instance files /var/lib/nova/instances/db39e252-c02f-4476-b2cb-bef45ee5a1eb_del
2022-02-22 02:38:16.836 7 INFO nova.virt.libvirt.driver [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Deletion of /var/lib/nova/instances/db39e252-c02f-4476-b2cb-bef45ee5a1eb_del complete
2022-02-22 02:38:16.911 7 INFO nova.compute.manager [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Took 0.38 seconds to destroy the instance on the hypervisor.
2022-02-22 02:38:16.980 7 INFO nova.compute.manager [-] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:38:18.219 7 INFO nova.compute.manager [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] Took 1.24 seconds to detach 1 volumes for instance.
2022-02-22 02:38:18.415 7 INFO nova.scheduler.client.report [req-61db00a8-b0ea-43af-99ea-3fae70422ab4 e3deda6a257647e98496fdc2719e189e 5f293b7da24f470480cf5883454079fc - default default] Deleted allocations for instance db39e252-c02f-4476-b2cb-bef45ee5a1eb
2022-02-22 02:38:24.343 7 INFO nova.compute.manager [-] [instance: 8f5734d8-b982-4bbd-8177-46aee7d00a8d] VM Stopped (Lifecycle Event)
2022-02-22 02:38:29.253 7 INFO nova.compute.manager [-] [instance: 4b09628c-16b1-4b91-8a90-f53582504e65] VM Stopped (Lifecycle Event)
2022-02-22 02:38:30.500 7 INFO nova.compute.manager [-] [instance: 92d00a9e-326b-4210-9fb2-bf3e01e0bdaa] VM Stopped (Lifecycle Event)
2022-02-22 02:38:31.746 7 INFO nova.compute.manager [-] [instance: db39e252-c02f-4476-b2cb-bef45ee5a1eb] VM Stopped (Lifecycle Event)
2022-02-22 02:38:54.828 7 INFO nova.compute.claims [req-b80e9a40-d28d-4db1-a0d7-fbb96c4e4fd8 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Claim successful on node rack08-server63
2022-02-22 02:38:55.214 7 INFO nova.virt.libvirt.driver [req-b80e9a40-d28d-4db1-a0d7-fbb96c4e4fd8 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Creating image
2022-02-22 02:38:56.340 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] VM Resumed (Lifecycle Event)
2022-02-22 02:38:56.348 7 INFO nova.virt.libvirt.driver [-] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Instance spawned successfully.
2022-02-22 02:38:56.348 7 INFO nova.compute.manager [req-b80e9a40-d28d-4db1-a0d7-fbb96c4e4fd8 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Took 1.13 seconds to spawn the instance on the hypervisor.
2022-02-22 02:38:56.403 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:38:56.403 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] VM Started (Lifecycle Event)
2022-02-22 02:38:56.439 7 INFO nova.compute.manager [req-b80e9a40-d28d-4db1-a0d7-fbb96c4e4fd8 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Took 1.65 seconds to build instance.
2022-02-22 02:38:57.095 7 INFO nova.compute.manager [req-db3fd6db-2aa6-4a07-b84e-5fa37b56a8a1 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Terminating instance
2022-02-22 02:38:57.437 7 INFO nova.virt.libvirt.driver [-] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Instance destroyed successfully.
2022-02-22 02:38:57.453 7 INFO nova.virt.libvirt.driver [req-db3fd6db-2aa6-4a07-b84e-5fa37b56a8a1 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Deleting instance files /var/lib/nova/instances/90a1b181-0f5b-437d-abbe-ec095e03ff44_del
2022-02-22 02:38:57.454 7 INFO nova.virt.libvirt.driver [req-db3fd6db-2aa6-4a07-b84e-5fa37b56a8a1 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Deletion of /var/lib/nova/instances/90a1b181-0f5b-437d-abbe-ec095e03ff44_del complete
2022-02-22 02:38:57.521 7 INFO nova.compute.manager [req-db3fd6db-2aa6-4a07-b84e-5fa37b56a8a1 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:38:57.591 7 INFO nova.compute.manager [-] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:38:57.786 7 INFO nova.scheduler.client.report [req-db3fd6db-2aa6-4a07-b84e-5fa37b56a8a1 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] Deleted allocations for instance 90a1b181-0f5b-437d-abbe-ec095e03ff44
2022-02-22 02:38:59.413 7 INFO nova.compute.claims [req-f8672a7d-1d32-49b3-83d9-6845ccc35b00 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Claim successful on node rack08-server63
2022-02-22 02:38:59.781 7 INFO nova.virt.libvirt.driver [req-f8672a7d-1d32-49b3-83d9-6845ccc35b00 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Creating image
2022-02-22 02:39:00.915 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: d23f5303-a011-414d-bb56-38549981bed6] VM Resumed (Lifecycle Event)
2022-02-22 02:39:00.923 7 INFO nova.virt.libvirt.driver [-] [instance: d23f5303-a011-414d-bb56-38549981bed6] Instance spawned successfully.
2022-02-22 02:39:00.924 7 INFO nova.compute.manager [req-f8672a7d-1d32-49b3-83d9-6845ccc35b00 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Took 1.14 seconds to spawn the instance on the hypervisor.
2022-02-22 02:39:00.969 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: d23f5303-a011-414d-bb56-38549981bed6] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:39:00.969 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: d23f5303-a011-414d-bb56-38549981bed6] VM Started (Lifecycle Event)
2022-02-22 02:39:01.007 7 INFO nova.compute.manager [req-f8672a7d-1d32-49b3-83d9-6845ccc35b00 bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Took 1.63 seconds to build instance.
2022-02-22 02:39:01.781 7 INFO nova.compute.manager [req-b9f8b92d-0caa-4721-8b60-05b5266904bd bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Terminating instance
2022-02-22 02:39:02.119 7 INFO nova.virt.libvirt.driver [-] [instance: d23f5303-a011-414d-bb56-38549981bed6] Instance destroyed successfully.
2022-02-22 02:39:02.135 7 INFO nova.virt.libvirt.driver [req-b9f8b92d-0caa-4721-8b60-05b5266904bd bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Deleting instance files /var/lib/nova/instances/d23f5303-a011-414d-bb56-38549981bed6_del
2022-02-22 02:39:02.136 7 INFO nova.virt.libvirt.driver [req-b9f8b92d-0caa-4721-8b60-05b5266904bd bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Deletion of /var/lib/nova/instances/d23f5303-a011-414d-bb56-38549981bed6_del complete
2022-02-22 02:39:02.201 7 INFO nova.compute.manager [req-b9f8b92d-0caa-4721-8b60-05b5266904bd bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] [instance: d23f5303-a011-414d-bb56-38549981bed6] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:39:02.262 7 INFO nova.compute.manager [-] [instance: d23f5303-a011-414d-bb56-38549981bed6] Took 0.06 seconds to deallocate network for instance.
2022-02-22 02:39:02.444 7 INFO nova.scheduler.client.report [req-b9f8b92d-0caa-4721-8b60-05b5266904bd bd064af4fa144b2c89c846a2d83494c0 97fb45cd51c941f1966b5863f55dc537 - default default] Deleted allocations for instance d23f5303-a011-414d-bb56-38549981bed6
2022-02-22 02:39:12.436 7 INFO nova.compute.manager [-] [instance: 90a1b181-0f5b-437d-abbe-ec095e03ff44] VM Stopped (Lifecycle Event)
2022-02-22 02:39:17.118 7 INFO nova.compute.manager [-] [instance: d23f5303-a011-414d-bb56-38549981bed6] VM Stopped (Lifecycle Event)
2022-02-22 02:39:49.369 7 INFO nova.compute.claims [req-f4359f08-36f9-4346-8633-54be7d8a62c7 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Claim successful on node rack08-server63
2022-02-22 02:39:49.773 7 INFO nova.virt.libvirt.driver [req-f4359f08-36f9-4346-8633-54be7d8a62c7 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Creating image
2022-02-22 02:39:50.890 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] VM Resumed (Lifecycle Event)
2022-02-22 02:39:50.896 7 INFO nova.virt.libvirt.driver [-] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Instance spawned successfully.
2022-02-22 02:39:50.897 7 INFO nova.compute.manager [req-f4359f08-36f9-4346-8633-54be7d8a62c7 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Took 1.12 seconds to spawn the instance on the hypervisor.
2022-02-22 02:39:50.947 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:39:50.948 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] VM Started (Lifecycle Event)
2022-02-22 02:39:50.988 7 INFO nova.compute.manager [req-f4359f08-36f9-4346-8633-54be7d8a62c7 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Took 1.66 seconds to build instance.
2022-02-22 02:39:54.175 7 INFO nova.compute.claims [req-9270c1db-b6cb-4f4a-bde7-7c25799c5d65 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Claim successful on node rack08-server63
2022-02-22 02:39:54.563 7 INFO nova.virt.libvirt.driver [req-9270c1db-b6cb-4f4a-bde7-7c25799c5d65 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Creating image
2022-02-22 02:39:54.843 7 INFO nova.compute.manager [req-dd407cc2-d474-470d-99df-68c559db144c 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Terminating instance
2022-02-22 02:39:55.191 7 INFO nova.virt.libvirt.driver [-] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Instance destroyed successfully.
2022-02-22 02:39:55.206 7 INFO nova.virt.libvirt.driver [req-dd407cc2-d474-470d-99df-68c559db144c 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Deleting instance files /var/lib/nova/instances/a891884f-1e31-4cae-b921-553a5d8ecb33_del
2022-02-22 02:39:55.207 7 INFO nova.virt.libvirt.driver [req-dd407cc2-d474-470d-99df-68c559db144c 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Deletion of /var/lib/nova/instances/a891884f-1e31-4cae-b921-553a5d8ecb33_del complete
2022-02-22 02:39:55.274 7 INFO nova.compute.manager [req-dd407cc2-d474-470d-99df-68c559db144c 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:39:55.343 7 INFO nova.compute.manager [-] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:39:55.534 7 INFO nova.scheduler.client.report [req-dd407cc2-d474-470d-99df-68c559db144c 7b83565d25ef4ddcae4752e5cb0d4e0e fcd3dec94d2648a0bdbdc1fe32deb5e3 - default default] Deleted allocations for instance a891884f-1e31-4cae-b921-553a5d8ecb33
2022-02-22 02:39:55.975 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] VM Resumed (Lifecycle Event)
2022-02-22 02:39:55.981 7 INFO nova.virt.libvirt.driver [-] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Instance spawned successfully.
2022-02-22 02:39:55.982 7 INFO nova.compute.manager [req-9270c1db-b6cb-4f4a-bde7-7c25799c5d65 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Took 1.42 seconds to spawn the instance on the hypervisor.
2022-02-22 02:39:56.029 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:39:56.030 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] VM Started (Lifecycle Event)
2022-02-22 02:39:56.070 7 INFO nova.compute.manager [req-9270c1db-b6cb-4f4a-bde7-7c25799c5d65 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Took 1.94 seconds to build instance.
2022-02-22 02:39:57.199 7 INFO nova.compute.manager [req-c02305d5-7ac4-46df-b0dd-cd9abbe1c414 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Terminating instance
2022-02-22 02:39:57.541 7 INFO nova.virt.libvirt.driver [-] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Instance destroyed successfully.
2022-02-22 02:39:57.557 7 INFO nova.virt.libvirt.driver [req-c02305d5-7ac4-46df-b0dd-cd9abbe1c414 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Deleting instance files /var/lib/nova/instances/964426e2-5934-4df4-b33f-333c4c70d7f5_del
2022-02-22 02:39:57.558 7 INFO nova.virt.libvirt.driver [req-c02305d5-7ac4-46df-b0dd-cd9abbe1c414 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Deletion of /var/lib/nova/instances/964426e2-5934-4df4-b33f-333c4c70d7f5_del complete
2022-02-22 02:39:57.625 7 INFO nova.compute.manager [req-c02305d5-7ac4-46df-b0dd-cd9abbe1c414 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:39:57.693 7 INFO nova.compute.manager [-] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:39:57.894 7 INFO nova.scheduler.client.report [req-c02305d5-7ac4-46df-b0dd-cd9abbe1c414 10fee5762b8b42e3a96366106c728ab8 3e59b989d82d4c99996539edb2cc80c2 - default default] Deleted allocations for instance 964426e2-5934-4df4-b33f-333c4c70d7f5
2022-02-22 02:40:08.689 7 INFO nova.compute.claims [req-7f5e9e65-3a41-4807-be4d-8e7f027a975b 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Claim successful on node rack08-server63
2022-02-22 02:40:09.092 7 INFO nova.virt.libvirt.driver [req-7f5e9e65-3a41-4807-be4d-8e7f027a975b 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Creating image
2022-02-22 02:40:10.187 7 INFO nova.compute.manager [-] [instance: a891884f-1e31-4cae-b921-553a5d8ecb33] VM Stopped (Lifecycle Event)
2022-02-22 02:40:10.247 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] VM Resumed (Lifecycle Event)
2022-02-22 02:40:10.254 7 INFO nova.virt.libvirt.driver [-] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Instance spawned successfully.
2022-02-22 02:40:10.255 7 INFO nova.compute.manager [req-7f5e9e65-3a41-4807-be4d-8e7f027a975b 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 02:40:10.302 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:40:10.302 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] VM Started (Lifecycle Event)
2022-02-22 02:40:10.342 7 INFO nova.compute.manager [req-7f5e9e65-3a41-4807-be4d-8e7f027a975b 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Took 1.69 seconds to build instance.
2022-02-22 02:40:12.539 7 INFO nova.compute.manager [-] [instance: 964426e2-5934-4df4-b33f-333c4c70d7f5] VM Stopped (Lifecycle Event)
2022-02-22 02:40:25.875 7 INFO nova.virt.libvirt.driver [req-b5a91130-56be-416b-9424-384cab152a10 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Ignoring supplied device name: /dev/vdb
2022-02-22 02:40:26.045 7 INFO nova.compute.manager [req-b5a91130-56be-416b-9424-384cab152a10 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Attaching volume 890c4f4e-5dbf-43bd-8fb4-f7fdf4f10f4e to /dev/vdb
2022-02-22 02:40:26.133 7 WARNING os_brick.initiator.connectors.nvmeof [req-b5a91130-56be-416b-9424-384cab152a10 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:40:27.500 7 INFO os_brick.initiator.connectors.lightos [req-b5a91130-56be-416b-9424-384cab152a10 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: connect_volume called for volume 54d98cd1-d6da-4eb4-aa36-dbaa0eca6504, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '54d98cd1-d6da-4eb4-aa36-dbaa0eca6504', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:40:27.504 7 INFO os_brick.initiator.connectors.lightos [req-b5a91130-56be-416b-9424-384cab152a10 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 54d98cd1-d6da-4eb4-aa36-dbaa0eca6504
2022-02-22 02:40:38.674 7 INFO nova.compute.manager [req-c7144546-06fe-4a5a-8dc2-7ed976b097ab 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Detaching volume 890c4f4e-5dbf-43bd-8fb4-f7fdf4f10f4e
2022-02-22 02:40:38.732 7 INFO nova.virt.block_device [req-c7144546-06fe-4a5a-8dc2-7ed976b097ab 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Attempting to driver detach volume 890c4f4e-5dbf-43bd-8fb4-f7fdf4f10f4e from mountpoint /dev/vdb
2022-02-22 02:40:38.751 7 INFO nova.virt.libvirt.driver [req-c7144546-06fe-4a5a-8dc2-7ed976b097ab 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Successfully detached device vdb from instance 358b5c18-a15b-4dc3-a8d6-7a34a0e05120 from the persistent domain config.
2022-02-22 02:40:38.894 7 INFO nova.virt.libvirt.driver [req-c7144546-06fe-4a5a-8dc2-7ed976b097ab 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Successfully detached device vdb from instance 358b5c18-a15b-4dc3-a8d6-7a34a0e05120 from the live domain config.
2022-02-22 02:40:38.897 7 INFO os_brick.initiator.connectors.lightos [req-c7144546-06fe-4a5a-8dc2-7ed976b097ab 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 54d98cd1-d6da-4eb4-aa36-dbaa0eca6504
2022-02-22 02:40:40.923 7 INFO nova.compute.manager [req-27af9469-db8e-4bb9-a251-addaaeb1b53f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Terminating instance
2022-02-22 02:40:41.271 7 INFO nova.virt.libvirt.driver [-] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Instance destroyed successfully.
2022-02-22 02:40:41.286 7 INFO nova.virt.libvirt.driver [req-27af9469-db8e-4bb9-a251-addaaeb1b53f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Deleting instance files /var/lib/nova/instances/358b5c18-a15b-4dc3-a8d6-7a34a0e05120_del
2022-02-22 02:40:41.287 7 INFO nova.virt.libvirt.driver [req-27af9469-db8e-4bb9-a251-addaaeb1b53f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Deletion of /var/lib/nova/instances/358b5c18-a15b-4dc3-a8d6-7a34a0e05120_del complete
2022-02-22 02:40:41.357 7 INFO nova.compute.manager [req-27af9469-db8e-4bb9-a251-addaaeb1b53f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Took 0.31 seconds to destroy the instance on the hypervisor.
2022-02-22 02:40:41.426 7 INFO nova.compute.manager [-] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:40:41.629 7 INFO nova.scheduler.client.report [req-27af9469-db8e-4bb9-a251-addaaeb1b53f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Deleted allocations for instance 358b5c18-a15b-4dc3-a8d6-7a34a0e05120
2022-02-22 02:40:49.075 7 INFO nova.compute.claims [req-f47111c8-e677-42f0-9336-b323706c33df 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Claim successful on node rack08-server63
2022-02-22 02:40:49.475 7 INFO nova.virt.libvirt.driver [req-f47111c8-e677-42f0-9336-b323706c33df 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Creating image
2022-02-22 02:40:50.627 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 83dc7632-a062-4589-b603-ddc235531bed] VM Resumed (Lifecycle Event)
2022-02-22 02:40:50.635 7 INFO nova.virt.libvirt.driver [-] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Instance spawned successfully.
2022-02-22 02:40:50.636 7 INFO nova.compute.manager [req-f47111c8-e677-42f0-9336-b323706c33df 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Took 1.16 seconds to spawn the instance on the hypervisor.
2022-02-22 02:40:50.683 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 83dc7632-a062-4589-b603-ddc235531bed] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:40:50.684 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 83dc7632-a062-4589-b603-ddc235531bed] VM Started (Lifecycle Event)
2022-02-22 02:40:50.717 7 INFO nova.compute.manager [req-f47111c8-e677-42f0-9336-b323706c33df 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Took 1.69 seconds to build instance.
2022-02-22 02:40:51.022 7 INFO nova.virt.libvirt.driver [req-4f593c03-4567-4e6b-a63e-3e1c257360ff 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Ignoring supplied device name: /dev/vdb
2022-02-22 02:40:51.170 7 INFO nova.compute.manager [req-4f593c03-4567-4e6b-a63e-3e1c257360ff 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Attaching volume bad1c8b8-6aad-4ede-a56a-0ca363f4e283 to /dev/vdb
2022-02-22 02:40:51.261 7 WARNING os_brick.initiator.connectors.nvmeof [req-4f593c03-4567-4e6b-a63e-3e1c257360ff 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:40:52.602 7 INFO os_brick.initiator.connectors.lightos [req-4f593c03-4567-4e6b-a63e-3e1c257360ff 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: connect_volume called for volume add84abb-0f58-42f4-bff9-a062c23412e0, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': 'add84abb-0f58-42f4-bff9-a062c23412e0', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:40:52.606 7 INFO os_brick.initiator.connectors.lightos [req-4f593c03-4567-4e6b-a63e-3e1c257360ff 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid add84abb-0f58-42f4-bff9-a062c23412e0
2022-02-22 02:40:56.269 7 INFO nova.compute.manager [-] [instance: 358b5c18-a15b-4dc3-a8d6-7a34a0e05120] VM Stopped (Lifecycle Event)
2022-02-22 02:41:01.376 7 INFO nova.compute.manager [req-6552980e-1647-4c28-bb2a-2b5a9f15935f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Detaching volume bad1c8b8-6aad-4ede-a56a-0ca363f4e283
2022-02-22 02:41:01.436 7 INFO nova.virt.block_device [req-6552980e-1647-4c28-bb2a-2b5a9f15935f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Attempting to driver detach volume bad1c8b8-6aad-4ede-a56a-0ca363f4e283 from mountpoint /dev/vdb
2022-02-22 02:41:01.455 7 INFO nova.virt.libvirt.driver [req-6552980e-1647-4c28-bb2a-2b5a9f15935f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Successfully detached device vdb from instance 83dc7632-a062-4589-b603-ddc235531bed from the persistent domain config.
2022-02-22 02:41:01.598 7 INFO nova.virt.libvirt.driver [req-6552980e-1647-4c28-bb2a-2b5a9f15935f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Successfully detached device vdb from instance 83dc7632-a062-4589-b603-ddc235531bed from the live domain config.
2022-02-22 02:41:01.601 7 INFO os_brick.initiator.connectors.lightos [req-6552980e-1647-4c28-bb2a-2b5a9f15935f 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid add84abb-0f58-42f4-bff9-a062c23412e0
2022-02-22 02:41:03.635 7 INFO nova.compute.manager [req-58fc79ad-4000-4ad4-95e7-610a70b96696 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Terminating instance
2022-02-22 02:41:03.976 7 INFO nova.virt.libvirt.driver [-] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Instance destroyed successfully.
2022-02-22 02:41:03.991 7 INFO nova.virt.libvirt.driver [req-58fc79ad-4000-4ad4-95e7-610a70b96696 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Deleting instance files /var/lib/nova/instances/83dc7632-a062-4589-b603-ddc235531bed_del
2022-02-22 02:41:03.992 7 INFO nova.virt.libvirt.driver [req-58fc79ad-4000-4ad4-95e7-610a70b96696 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Deletion of /var/lib/nova/instances/83dc7632-a062-4589-b603-ddc235531bed_del complete
2022-02-22 02:41:04.053 7 INFO nova.compute.manager [req-58fc79ad-4000-4ad4-95e7-610a70b96696 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:41:04.120 7 INFO nova.compute.manager [-] [instance: 83dc7632-a062-4589-b603-ddc235531bed] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:41:04.318 7 INFO nova.scheduler.client.report [req-58fc79ad-4000-4ad4-95e7-610a70b96696 3f1a5edb13c34fdb85824bdd9cf66297 ceca54a4f39842e384d72d45b7f5b842 - default default] Deleted allocations for instance 83dc7632-a062-4589-b603-ddc235531bed
2022-02-22 02:41:16.375 7 INFO nova.compute.claims [req-eee2586a-ea46-4a9b-83cd-0db650dc660c 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Claim successful on node rack08-server63
2022-02-22 02:41:16.772 7 INFO nova.virt.libvirt.driver [req-eee2586a-ea46-4a9b-83cd-0db650dc660c 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Creating image
2022-02-22 02:41:17.955 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] VM Resumed (Lifecycle Event)
2022-02-22 02:41:17.962 7 INFO nova.virt.libvirt.driver [-] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Instance spawned successfully.
2022-02-22 02:41:17.963 7 INFO nova.compute.manager [req-eee2586a-ea46-4a9b-83cd-0db650dc660c 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Took 1.19 seconds to spawn the instance on the hypervisor.
2022-02-22 02:41:18.009 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] During sync_power_state the instance has a pending task (spawning). Skip.
2022-02-22 02:41:18.010 7 INFO nova.compute.manager [req-b1dee7bc-1e51-43a4-bf50-5efacf74db40 - - - - -] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] VM Started (Lifecycle Event)
2022-02-22 02:41:18.053 7 INFO nova.compute.manager [req-eee2586a-ea46-4a9b-83cd-0db650dc660c 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Took 1.72 seconds to build instance.
2022-02-22 02:41:18.700 7 INFO nova.virt.libvirt.driver [req-8810bb4e-2d52-41df-a3f6-60526500ca0f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Ignoring supplied device name: /dev/vdb
2022-02-22 02:41:18.885 7 INFO nova.compute.manager [req-8810bb4e-2d52-41df-a3f6-60526500ca0f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Attaching volume 5068a48c-e45f-4a0b-99de-db57bb931432 to /dev/vdb
2022-02-22 02:41:18.974 7 INFO nova.compute.manager [-] [instance: 83dc7632-a062-4589-b603-ddc235531bed] VM Stopped (Lifecycle Event)
2022-02-22 02:41:18.985 7 WARNING os_brick.initiator.connectors.nvmeof [req-8810bb4e-2d52-41df-a3f6-60526500ca0f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] Process execution error in _get_host_uuid: Unexpected error while running command.
Command: blkid overlay -s UUID -o value
Exit code: 2
Stdout: ''
Stderr: '': oslo_concurrency.processutils.ProcessExecutionError: Unexpected error while running command.
2022-02-22 02:41:20.333 7 INFO os_brick.initiator.connectors.lightos [req-8810bb4e-2d52-41df-a3f6-60526500ca0f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] LIGHTOS: connect_volume called for volume 01ede10b-61cc-4997-9aa9-1c8f08f9cd7f, connection properties: {'lightos_nodes': {'[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}, '[LB_IP_ADDRESS]': {'target_portal': '[LB_IP_ADDRESS]', 'target_port': 8009, 'transport_type': 'tcp'}}, 'uuid': '01ede10b-61cc-4997-9aa9-1c8f08f9cd7f', 'subsysnqn': 'nqn.2016-01.com.lightbitslabs:uuid:2df610f7-a728-4fa9-8ec0-3ecb55dad510', 'qos_specs': None, 'access_mode': 'rw', 'encrypted': False, 'cacheable': False}
2022-02-22 02:41:20.337 7 INFO os_brick.initiator.connectors.lightos [req-8810bb4e-2d52-41df-a3f6-60526500ca0f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 01ede10b-61cc-4997-9aa9-1c8f08f9cd7f
2022-02-22 02:41:22.064 7 INFO nova.compute.manager [req-aafd11d5-9439-40f5-a620-9089150449f3 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Cinder extended volume 5068a48c-e45f-4a0b-99de-db57bb931432; extending it to detect new size
2022-02-22 02:41:22.138 7 INFO os_brick.initiator.connectors.lightos [req-aafd11d5-9439-40f5-a620-9089150449f3 e12fe8b009bc475e8267d14a0328dbf9 a0863d78b77f4cdd844f9510e7ad8692 - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 01ede10b-61cc-4997-9aa9-1c8f08f9cd7f
2022-02-22 02:41:22.836 7 INFO nova.compute.manager [req-bac3752a-3f19-444c-b0f1-9837f2c9466f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Detaching volume 5068a48c-e45f-4a0b-99de-db57bb931432
2022-02-22 02:41:22.893 7 INFO nova.virt.block_device [req-bac3752a-3f19-444c-b0f1-9837f2c9466f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Attempting to driver detach volume 5068a48c-e45f-4a0b-99de-db57bb931432 from mountpoint /dev/vdb
2022-02-22 02:41:22.912 7 INFO nova.virt.libvirt.driver [req-bac3752a-3f19-444c-b0f1-9837f2c9466f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] Successfully detached device vdb from instance 468338f3-7d11-4a97-8838-5a53061fddee from the persistent domain config.
2022-02-22 02:41:23.052 7 INFO nova.virt.libvirt.driver [req-bac3752a-3f19-444c-b0f1-9837f2c9466f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] Successfully detached device vdb from instance 468338f3-7d11-4a97-8838-5a53061fddee from the live domain config.
2022-02-22 02:41:23.055 7 INFO os_brick.initiator.connectors.lightos [req-bac3752a-3f19-444c-b0f1-9837f2c9466f 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] LIGHTOS: devpath /dev/nvme0n1 detected for uuid 01ede10b-61cc-4997-9aa9-1c8f08f9cd7f
2022-02-22 02:41:25.074 7 INFO nova.compute.manager [req-8db1c896-e4ce-4304-a74e-88fb1039fbf6 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Terminating instance
2022-02-22 02:41:25.412 7 INFO nova.virt.libvirt.driver [-] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Instance destroyed successfully.
2022-02-22 02:41:25.428 7 INFO nova.virt.libvirt.driver [req-8db1c896-e4ce-4304-a74e-88fb1039fbf6 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Deleting instance files /var/lib/nova/instances/468338f3-7d11-4a97-8838-5a53061fddee_del
2022-02-22 02:41:25.429 7 INFO nova.virt.libvirt.driver [req-8db1c896-e4ce-4304-a74e-88fb1039fbf6 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Deletion of /var/lib/nova/instances/468338f3-7d11-4a97-8838-5a53061fddee_del complete
2022-02-22 02:41:25.495 7 INFO nova.compute.manager [req-8db1c896-e4ce-4304-a74e-88fb1039fbf6 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Took 0.30 seconds to destroy the instance on the hypervisor.
2022-02-22 02:41:25.561 7 INFO nova.compute.manager [-] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] Took 0.07 seconds to deallocate network for instance.
2022-02-22 02:41:25.748 7 INFO nova.scheduler.client.report [req-8db1c896-e4ce-4304-a74e-88fb1039fbf6 5546b3fff25b4a8b8bb14bc7c02f18e2 7a3f473a3c4b4680a68b7782f0a1469c - default default] Deleted allocations for instance 468338f3-7d11-4a97-8838-5a53061fddee
2022-02-22 02:41:40.411 7 INFO nova.compute.manager [-] [instance: 468338f3-7d11-4a97-8838-5a53061fddee] VM Stopped (Lifecycle Event)
